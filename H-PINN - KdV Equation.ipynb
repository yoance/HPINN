{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Rb1T-jMoZEkh"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPgGckjbVXJe4KY17GUId5g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoance/HPINN/blob/main/H-PINN%20-%20KdV%20Equation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwFWxL93ZEkX"
      },
      "source": [
        "# KdV Equation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb1T-jMoZEkh"
      },
      "source": [
        "# 1. Import the required Library and Package.\n",
        "\n",
        "The code can be run with TensorFlow version `2.5.x`.\n",
        "The model implementation is done with the library NumPy and the library for machine learning TensorFlow.\n",
        "\n",
        "A class implementation has been developed for creating the PINN as an object of Keras in a package stored in the file `PINNPDESolver.py`.\n",
        "\n",
        "Computation is performed on Google Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBwXewmX9UsN"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Current Working Directory\n",
        "dir = '/content/drive/My Drive/Tugas Akhir/Colab'\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, dir)\n",
        "\n",
        "# Import TensorFlow and NumPy\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Import Physics-Informed Neural Network\n",
        "import PINNPDESolver as pinn\n",
        "\n",
        "# Import Combined Learning Rate Decay\n",
        "from CombinedDecay import CombinedDecay\n",
        "\n",
        "# Import time\n",
        "from time import time\n",
        "\n",
        "# Import matplotlib for plots\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Creating tables\n",
        "import pandas as pd\n",
        "from tabulate import tabulate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqsZAzW4CLUh"
      },
      "outputs": [],
      "source": [
        "!sudo apt install cm-super dvipng texlive-latex-extra texlive-latex-recommended\n",
        "\n",
        "pgf_with_latex = {                      # setup matplotlib to use latex for output\n",
        "    \"pgf.texsystem\": \"pdflatex\",        # change this if using xetex or lautex\n",
        "    \"text.usetex\": True,                # use LaTeX to write all text\n",
        "    \"font.family\": \"serif\",\n",
        "    \"font.serif\": [],                   # blank entries should cause plots to inherit fonts from the document\n",
        "    \"font.sans-serif\": [],\n",
        "    \"font.monospace\": [],\n",
        "    \"axes.labelsize\": 24,               # LaTeX default is 10pt font.\n",
        "    \"font.size\": 24,\n",
        "    \"legend.fontsize\": 24,               # Make the legend/label fonts a little smaller\n",
        "    \"xtick.labelsize\": 22,\n",
        "    \"ytick.labelsize\": 22,\n",
        "    \"pgf.preamble\": [\n",
        "        r\"\\usepackage[utf8x]{inputenc}\",    # use utf8 fonts becasue your computer can handle it :)\n",
        "        r\"\\usepackage[T1]{fontenc}\",        # plots will be generated using this preamble\n",
        "        ]\n",
        "    }\n",
        "plt.rcParams.update(pgf_with_latex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXkjWO_yZEkj"
      },
      "outputs": [],
      "source": [
        "# Set data type\n",
        "DTYPE='float32'\n",
        "tf.keras.backend.set_floatx(DTYPE)\n",
        "\n",
        "# Set constants\n",
        "pi = tf.constant(np.pi, dtype=DTYPE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUMULE5leIkM"
      },
      "source": [
        "# 2. Korteweg-de Vries (KdV) 1-Soliton Equation and Transformation into Loss Function\n",
        "\n",
        "The KdV equation to be used is\n",
        "\n",
        "$$\n",
        "\\begin{equation}\n",
        "    u_t - 6uu_{x} + u_{xxx} = 0, \\quad -\\infty<x<\\infty, \\quad t>0\n",
        "\\end{equation}.\n",
        "$$\n",
        "Given the initial condition (IC)\n",
        "$$\n",
        "\\begin{equation}\n",
        "    u(x,\\,0) = -2sech^2(x).\n",
        "\\end{equation}\n",
        "$$\n",
        "The unique solution to this problem is\n",
        "$$\n",
        "\\begin{equation}\n",
        "\t        u(x,\\;t) = -2sech^2(x-4t).\n",
        "\\end{equation}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzxtEKAYhQ_o"
      },
      "outputs": [],
      "source": [
        "lambda_star = [-6, 1]\n",
        "\n",
        "# Define initial condition\n",
        "def fun_u_0(x):\n",
        "    return -2 * 1/(tf.math.cosh(x))**2\n",
        "\n",
        "# Define residual of the PDE\n",
        "def fun_r(t, x, u, u_t, u_x, u_xx, u_xxx, lambd = lambda_star):\n",
        "    return u_t + lambd[0] * u * u_x + lambd[1] * u_xxx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXYaeRWWhQ_o"
      },
      "outputs": [],
      "source": [
        "# Explicit Solution\n",
        "def u_expl(t, x):\n",
        "    \"\"\"Explicit Solution to the KdV Equation.\"\"\"\n",
        "    return -2 * 1/(np.cosh(x-4*t))**2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2ZApRluhQ_p"
      },
      "outputs": [],
      "source": [
        "# Set boundary\n",
        "tmin = -1.\n",
        "tmax = 1.\n",
        "xmin = -10.\n",
        "xmax = 10.\n",
        "\n",
        "# Lower bounds\n",
        "lb = tf.constant([tmin, xmin], dtype=DTYPE)\n",
        "# Upper bounds\n",
        "ub = tf.constant([tmax, xmax], dtype=DTYPE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-dA6c91uqKH"
      },
      "source": [
        "# 3. Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZ4qQpjjnyXY"
      },
      "source": [
        "## 1. Preparation for Modeling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi4Qy-SBd93E"
      },
      "source": [
        "### Generating Training Data and Collocation Points for Inverse Problems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psuO6wY2vN7l"
      },
      "outputs": [],
      "source": [
        "N_d = 500\n",
        "noise = 0.0\n",
        "\n",
        "plot = True\n",
        "\n",
        "# Set random seed for reproducible results\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "if plot == True:\n",
        "  # Draw points with measurements randomly\n",
        "  t_d = tf.random.uniform((N_d,1), lb[0], ub[0], dtype=DTYPE)\n",
        "  x_d = tf.random.uniform((N_d,1), lb[1], ub[1], dtype=DTYPE)\n",
        "  X_d = tf.concat([t_d, x_d], axis=1)\n",
        "\n",
        "  # Explicit analytical solution\n",
        "  u_d = u_expl(t_d, x_d)\n",
        "  u_d += noise * tf.random.normal(u_d.shape, dtype=DTYPE)\n",
        "\n",
        "elif plot == False:\n",
        "  X_d, u_d = pinn.generate_collocation_points(N_d, lb, ub, u_expl, noise=0)\n",
        "\n",
        "X_param = [X_d]\n",
        "u_param = [u_d]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "YJOSfgfEv8D8",
        "outputId": "354d9021-80dd-445d-d65f-4a9b1bafcb3d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig = plt.figure(figsize=(9,6))\n",
        "plt.scatter(t_d, x_d, c='r', marker='.', alpha=0.5)\n",
        "plt.xlabel('$t$')\n",
        "plt.ylabel('$x$')\n",
        "\n",
        "# plt.title('(b) Visualisasi koordinat data $\\it{training}$ dan $\\it{collocation\\;points}$ untuk masalah invers persamaan KdV.');\n",
        "# plt.savefig('kdv_eqn_inv_train.pdf', bbox_inches='tight', dpi=600, facecolor='none')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2ztHkR_2J-o"
      },
      "source": [
        "### Preparation of the PINN Architecture\n",
        "\n",
        "In the first hidden layer, there are $2 \\times 20 = 40$ weight parameters and $20$ bias parameters. In the subsequent hidden layers, there are $20 \\times 20 = 400$ weight parameters and $20$ bias parameters in each layer. In the output layer connected to the last hidden layer, there are $1 \\times 20 = 20$ weight parameters and $20$ bias parameters.\n",
        "\n",
        "Thus, there is a total of:\n",
        "\\begin{align*}\n",
        "    1 \\times (40+20) + 1 \\times (400+20) + 1 \\times (20+20) = 520\n",
        "\\end{align*}\n",
        "parameters that can be determined and updated in each epoch within the PINN model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Kv0SvE3dake"
      },
      "outputs": [],
      "source": [
        "arch = {'output_dim':1, 'num_hidden_layers':2, 'num_neurons_per_layer':20}\n",
        "n_models = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4Fg4SuuRJfy"
      },
      "outputs": [],
      "source": [
        "models = [None] * n_models\n",
        "\n",
        "for i in range(n_models):\n",
        "  tf.random.set_seed(i)\n",
        "  models[i] = pinn.PINN_IdentificationNet(initial_lambda=[0.0, 0.0], lb=lb, ub=ub, **arch)\n",
        "  models[i].build((None, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O34m5tUxfl_3"
      },
      "source": [
        "### Preparation for Calculating the Loss Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k06VMHYtfmAB"
      },
      "outputs": [],
      "source": [
        "def get_r(t, x, model, fun_r):\n",
        "\n",
        "    # A tf.GradientTape is used to compute derivatives in TensorFlow\n",
        "    with tf.GradientTape(persistent=True) as tape1:\n",
        "\n",
        "        tape1.watch(x)\n",
        "        with tf.GradientTape(persistent=True) as tape2:\n",
        "\n",
        "          tape2.watch(x)\n",
        "          with tf.GradientTape(persistent=True) as tape3:\n",
        "\n",
        "            # Variables t and x are watched during tape\n",
        "            # to compute derivatives u_t and u_x\n",
        "            tape3.watch(t)\n",
        "            tape3.watch(x)\n",
        "\n",
        "            # Determine residual\n",
        "            u = model(tf.stack([t[:,0], x[:,0]], axis=1))\n",
        "\n",
        "          # Compute gradient u_x and u_t\n",
        "          u_t = tape3.gradient(u, t)\n",
        "          u_x = tape3.gradient(u, x)\n",
        "\n",
        "        u_xx = tape2.gradient(u_x, x)\n",
        "\n",
        "    u_xxx = tape1.gradient(u_xx, x)\n",
        "\n",
        "    del tape1\n",
        "    del tape2\n",
        "    del tape3\n",
        "\n",
        "    return fun_r(t, x, u, u_t, u_x, u_xx, u_xxx, model)\n",
        "\n",
        "def fun_r(t, x, u, u_t, u_x, u_xx, u_xxx, model):\n",
        "    return u_t + model.lambd[0] * u * u_x + model.lambd[1] * u_xxx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OYKNO-jOEQr"
      },
      "outputs": [],
      "source": [
        "def get_r_param(t, x, model):\n",
        "\n",
        "    # A tf.GradientTape is used to compute derivatives in TensorFlow\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        # Split t and x to compute partial derivatives\n",
        "        # t, x = X_r[:, 0:1], X_r[:,1:2]\n",
        "\n",
        "        tape.watch(x)\n",
        "        with tf.GradientTape(persistent=True) as tape2:\n",
        "\n",
        "          tape2.watch(x)\n",
        "          with tf.GradientTape(persistent=True) as tape3:\n",
        "            tape3.watch(t)\n",
        "            tape3.watch(x)\n",
        "\n",
        "            # Determine residual\n",
        "            u = model(tf.stack([t[:,0], x[:,0]], axis=1))\n",
        "\n",
        "          u_t = tape3.gradient(u, t)\n",
        "          u_x = tape3.gradient(u, x)\n",
        "\n",
        "        # Compute gradient u_x within the GradientTape\n",
        "        # since we need second derivatives\n",
        "        u_xx = tape2.gradient(u_x, x)\n",
        "\n",
        "\n",
        "    u_xxx = tape.gradient(u_xx, x)\n",
        "\n",
        "    del tape\n",
        "    del tape2\n",
        "    del tape3\n",
        "\n",
        "    with tf.GradientTape(persistent=True) as tape_lambd:\n",
        "      tape_lambd.watch(model.lambd)\n",
        "      r = u_t + model.lambd[0] * u * u_x + model.lambd[1] * u_xxx\n",
        "      loss = tf.reduce_mean(tf.square(r))\n",
        "\n",
        "    g = tape_lambd.gradient(loss, model.lambd)\n",
        "\n",
        "    del tape_lambd\n",
        "\n",
        "    return loss, g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cuekBMlfmAB"
      },
      "source": [
        "## 2. Preparation of the Optimizer\n",
        "\n",
        "Since less data is used for the inverse problem case, the number of iterations in the gradient descent-based optimizer will increase. Therefore, the boundary for the learning rate to be used in the Piecewise Constant Decay must be larger."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rl3Ci17-fmAC",
        "outputId": "4fa4a971-5171-47f6-850d-3830e9d3072f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'initial_learning_rate': 0.1,\n",
              " 'decay_steps': 150,\n",
              " 'decay_rate': 0.9,\n",
              " 'staircase': False,\n",
              " 'boundaries': [3000, 7000, 14000],\n",
              " 'values': [0.012157665459056936,\n",
              "  0.006078832729528468,\n",
              "  0.003039416364764234,\n",
              "  0.001519708182382117],\n",
              " 'values_steps': [2, 2, 2],\n",
              " 'name': None}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# lr_pw = tf.keras.optimizers.schedules.PiecewiseConstantDecay([3000,7000],[1e-1,1e-2,1e-3])\n",
        "\n",
        "# # Choose the optimizer\n",
        "# optim_SGD = tf.keras.optimizers.SGD(learning_rate=lr_pw)\n",
        "# optim_Adam = tf.keras.optimizers.Adam(learning_rate=lr_pw)\n",
        "\n",
        "# boundaries = [3000,7000]\n",
        "# values = [1e-1,1e-2,1e-3]\n",
        "lr_comb_param = {'boundaries': [3000,7000,14000],\n",
        "                 'initial_learning_rate': 1e-1,\n",
        "                 'decay_steps': 150,\n",
        "                 'decay_rate': 0.9,\n",
        "                 'values_steps': 2}\n",
        "lr_comb = CombinedDecay(**lr_comb_param)\n",
        "lr_comb.get_config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ3Yv61V1iqc"
      },
      "source": [
        "## 3. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to6Y4RiPPobe",
        "outputId": "36816388-6427-43a0-ede5-a35b0e8aa738"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "Iteration: 1 Initial lambda: [0.0, 0.0]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "L-BFGS\n",
            "\n",
            "It 00000: loss = 2.58083671e-01 lambda = [-3.4764460e-06 -1.1897985e-06]\n",
            "It 00050: loss = 1.52042001e-01 lambda = [-0.6725802 -0.4526452]\n",
            "It 00100: loss = 8.94438773e-02 lambda = [-4.1198273  0.1602027]\n",
            "It 00150: loss = 1.17732007e-02 lambda = [-5.2874403   0.59955394]\n",
            "It 00200: loss = 3.74858826e-03 lambda = [-5.220403   0.7202463]\n",
            "It 00250: loss = 1.46021089e-03 lambda = [-5.4984336   0.78801507]\n",
            "It 00300: loss = 4.27827676e-04 lambda = [-5.7718287   0.92154473]\n",
            "It 00350: loss = 2.19210182e-04 lambda = [-5.8913536  0.9681635]\n",
            "It 00400: loss = 1.39220443e-04 lambda = [-5.966344    0.98368007]\n",
            "It 00450: loss = 8.74988255e-05 lambda = [-6.0250363  1.003382 ]\n",
            "It 00500: loss = 5.47622403e-05 lambda = [-6.02119    1.0044199]\n",
            "It 00550: loss = 3.86812644e-05 lambda = [-6.0201488  1.0116858]\n",
            "It 00600: loss = 2.14638276e-05 lambda = [-6.034956   1.0143982]\n",
            "It 00650: loss = 1.50677461e-05 lambda = [-6.037133   1.0103874]\n",
            "It 00700: loss = 1.02615577e-05 lambda = [-6.0215816  1.0110551]\n",
            "It 00750: loss = 7.58138503e-06 lambda = [-6.012374   1.0050985]\n",
            "\n",
            "\n",
            "SGD\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: loss = 3.53887588e-01 lambda = [-3.8234907e-06 -1.3085730e-06]\n",
            "It 00050: loss = 2.28291735e-01 lambda = [-2.3276532e-04 -6.4082007e-05]\n",
            "It 00100: loss = 2.20735073e-01 lambda = [-0.00089994 -0.00018309]\n",
            "It 00150: loss = 2.11206824e-01 lambda = [-0.00223737 -0.00043192]\n",
            "It 00200: loss = 2.00727731e-01 lambda = [-0.00438304 -0.00090008]\n",
            "It 00250: loss = 1.92476794e-01 lambda = [-0.00718247 -0.00164232]\n",
            "It 00300: loss = 1.87942624e-01 lambda = [-0.01044108 -0.00266366]\n",
            "It 00350: loss = 1.85805395e-01 lambda = [-0.01406783 -0.0039264 ]\n",
            "It 00400: loss = 1.84553877e-01 lambda = [-0.01801937 -0.00537014]\n",
            "It 00450: loss = 1.83513373e-01 lambda = [-0.02227273 -0.00694562]\n",
            "It 00500: loss = 1.82499737e-01 lambda = [-0.02681429 -0.00862583]\n",
            "It 00550: loss = 1.81491107e-01 lambda = [-0.03163274 -0.01040103]\n",
            "It 00600: loss = 1.80499867e-01 lambda = [-0.03671663 -0.01227119]\n",
            "It 00650: loss = 1.79537043e-01 lambda = [-0.04205376 -0.01424006]\n",
            "It 00700: loss = 1.78607821e-01 lambda = [-0.04763073 -0.01631153]\n",
            "It 00750: loss = 1.77713662e-01 lambda = [-0.0534326  -0.01848795]\n",
            "It 00800: loss = 1.76854119e-01 lambda = [-0.05944305 -0.02076971]\n",
            "It 00850: loss = 1.76028073e-01 lambda = [-0.06564473 -0.02315547]\n",
            "It 00900: loss = 1.75233960e-01 lambda = [-0.07201975 -0.02564247]\n",
            "It 00950: loss = 1.74470320e-01 lambda = [-0.07855002 -0.02822693]\n",
            "It 01000: loss = 1.73735783e-01 lambda = [-0.08521755 -0.03090424]\n",
            "It 01050: loss = 1.73029080e-01 lambda = [-0.09200455 -0.03366926]\n",
            "It 01100: loss = 1.72349170e-01 lambda = [-0.09889369 -0.0365164 ]\n",
            "It 01150: loss = 1.71695098e-01 lambda = [-0.10586818 -0.03943985]\n",
            "It 01200: loss = 1.71066120e-01 lambda = [-0.11291179 -0.04243354]\n",
            "It 01250: loss = 1.70461491e-01 lambda = [-0.12000899 -0.04549135]\n",
            "It 01300: loss = 1.69880643e-01 lambda = [-0.1271448  -0.04860703]\n",
            "It 01350: loss = 1.69322878e-01 lambda = [-0.13430496 -0.05177436]\n",
            "It 01400: loss = 1.68787673e-01 lambda = [-0.14147586 -0.05498709]\n",
            "It 01450: loss = 1.68274418e-01 lambda = [-0.14864479 -0.05823905]\n",
            "It 01500: loss = 1.67782560e-01 lambda = [-0.1557995  -0.06152411]\n",
            "It 01550: loss = 1.67311475e-01 lambda = [-0.16292861 -0.06483626]\n",
            "It 01600: loss = 1.66860506e-01 lambda = [-0.17002138 -0.06816964]\n",
            "It 01650: loss = 1.66429013e-01 lambda = [-0.17706783 -0.07151846]\n",
            "It 01700: loss = 1.66016400e-01 lambda = [-0.18405871 -0.07487712]\n",
            "It 01750: loss = 1.65621892e-01 lambda = [-0.19098543 -0.07824022]\n",
            "It 01800: loss = 1.65244877e-01 lambda = [-0.1978402  -0.08160257]\n",
            "It 01850: loss = 1.64884612e-01 lambda = [-0.20461573 -0.08495911]\n",
            "It 01900: loss = 1.64540455e-01 lambda = [-0.21130548 -0.0883051 ]\n",
            "It 01950: loss = 1.64211676e-01 lambda = [-0.21790363 -0.09163602]\n",
            "It 02000: loss = 1.63897589e-01 lambda = [-0.22440486 -0.09494752]\n",
            "It 02050: loss = 1.63597569e-01 lambda = [-0.2308045  -0.09823557]\n",
            "It 02100: loss = 1.63310915e-01 lambda = [-0.23709841 -0.10149639]\n",
            "It 02150: loss = 1.63037017e-01 lambda = [-0.24328318 -0.10472647]\n",
            "It 02200: loss = 1.62775248e-01 lambda = [-0.24935548 -0.10792255]\n",
            "It 02250: loss = 1.62524998e-01 lambda = [-0.25531292 -0.11108161]\n",
            "It 02300: loss = 1.62285745e-01 lambda = [-0.26115322 -0.1142009 ]\n",
            "It 02350: loss = 1.62056923e-01 lambda = [-0.26687485 -0.11727791]\n",
            "It 02400: loss = 1.61838040e-01 lambda = [-0.27247638 -0.1203104 ]\n",
            "It 02450: loss = 1.61628529e-01 lambda = [-0.27795693 -0.12329637]\n",
            "It 02500: loss = 1.61427960e-01 lambda = [-0.28331587 -0.12623401]\n",
            "It 02550: loss = 1.61235884e-01 lambda = [-0.28855294 -0.12912181]\n",
            "It 02600: loss = 1.61051899e-01 lambda = [-0.29366815 -0.13195837]\n",
            "It 02650: loss = 1.60875589e-01 lambda = [-0.2986617  -0.13474254]\n",
            "It 02700: loss = 1.60706520e-01 lambda = [-0.3035342  -0.13747337]\n",
            "It 02750: loss = 1.60544455e-01 lambda = [-0.30828637 -0.14015009]\n",
            "It 02800: loss = 1.60388947e-01 lambda = [-0.31291917 -0.14277202]\n",
            "It 02850: loss = 1.60239726e-01 lambda = [-0.31743357 -0.14533876]\n",
            "It 02900: loss = 1.60096496e-01 lambda = [-0.32183093 -0.14784998]\n",
            "It 02950: loss = 1.59958959e-01 lambda = [-0.32611266 -0.15030557]\n",
            "It 03000: loss = 1.59826845e-01 lambda = [-0.33028027 -0.1527054 ]\n",
            "It 03050: loss = 1.59760937e-01 lambda = [-0.3323406  -0.15389533]\n",
            "It 03100: loss = 1.59696445e-01 lambda = [-0.33440894 -0.1550922 ]\n",
            "It 03150: loss = 1.59632117e-01 lambda = [-0.33648527 -0.15629598]\n",
            "It 03200: loss = 1.59567937e-01 lambda = [-0.33856955 -0.15750673]\n",
            "It 03250: loss = 1.59503907e-01 lambda = [-0.34066185 -0.15872444]\n",
            "It 03300: loss = 1.59440041e-01 lambda = [-0.34276208 -0.15994912]\n",
            "It 03350: loss = 1.59376293e-01 lambda = [-0.34487024 -0.16118081]\n",
            "It 03400: loss = 1.59312680e-01 lambda = [-0.34698644 -0.16241948]\n",
            "It 03450: loss = 1.59249231e-01 lambda = [-0.3491106  -0.16366518]\n",
            "It 03500: loss = 1.59185916e-01 lambda = [-0.3512427 -0.1649179]\n",
            "It 03550: loss = 1.59122720e-01 lambda = [-0.3533828  -0.16617766]\n",
            "It 03600: loss = 1.59059644e-01 lambda = [-0.35553083 -0.16744448]\n",
            "It 03650: loss = 1.58996701e-01 lambda = [-0.3576868  -0.16871834]\n",
            "It 03700: loss = 1.58933908e-01 lambda = [-0.35985076 -0.16999929]\n",
            "It 03750: loss = 1.58871189e-01 lambda = [-0.36202267 -0.1712873 ]\n",
            "It 03800: loss = 1.58808634e-01 lambda = [-0.36420247 -0.17258243]\n",
            "It 03850: loss = 1.58746153e-01 lambda = [-0.3663903  -0.17388465]\n",
            "It 03900: loss = 1.58683792e-01 lambda = [-0.368586   -0.17519397]\n",
            "It 03950: loss = 1.58621579e-01 lambda = [-0.37078965 -0.17651041]\n",
            "It 04000: loss = 1.58559427e-01 lambda = [-0.37300128 -0.17783399]\n",
            "It 04050: loss = 1.58497408e-01 lambda = [-0.3752208  -0.17916471]\n",
            "It 04100: loss = 1.58435479e-01 lambda = [-0.37744823 -0.18050256]\n",
            "It 04150: loss = 1.58373639e-01 lambda = [-0.3796836  -0.18184757]\n",
            "It 04200: loss = 1.58311918e-01 lambda = [-0.3819269  -0.18319973]\n",
            "It 04250: loss = 1.58250257e-01 lambda = [-0.38417804 -0.18455906]\n",
            "It 04300: loss = 1.58188701e-01 lambda = [-0.38643715 -0.18592559]\n",
            "It 04350: loss = 1.58127218e-01 lambda = [-0.38870415 -0.18729928]\n",
            "It 04400: loss = 1.58065841e-01 lambda = [-0.39097902 -0.18868017]\n",
            "It 04450: loss = 1.58004537e-01 lambda = [-0.3932618  -0.19006826]\n",
            "It 04500: loss = 1.57943293e-01 lambda = [-0.39555246 -0.19146353]\n",
            "It 04550: loss = 1.57882124e-01 lambda = [-0.397851   -0.19286603]\n",
            "It 04600: loss = 1.57821029e-01 lambda = [-0.40015736 -0.19427574]\n",
            "It 04650: loss = 1.57760009e-01 lambda = [-0.4024717  -0.19569267]\n",
            "It 04700: loss = 1.57699019e-01 lambda = [-0.40479386 -0.19711682]\n",
            "It 04750: loss = 1.57638118e-01 lambda = [-0.40712383 -0.19854821]\n",
            "It 04800: loss = 1.57577276e-01 lambda = [-0.40946165 -0.19998683]\n",
            "It 04850: loss = 1.57516450e-01 lambda = [-0.41180736 -0.20143268]\n",
            "It 04900: loss = 1.57455698e-01 lambda = [-0.41416088 -0.20288578]\n",
            "It 04950: loss = 1.57395035e-01 lambda = [-0.41652223 -0.2043461 ]\n",
            "It 05000: loss = 1.57334328e-01 lambda = [-0.41889143 -0.2058137 ]\n",
            "It 05050: loss = 1.57273740e-01 lambda = [-0.4212685  -0.20728855]\n",
            "It 05100: loss = 1.57213151e-01 lambda = [-0.4236533  -0.20877065]\n",
            "It 05150: loss = 1.57152608e-01 lambda = [-0.42604595 -0.21026002]\n",
            "It 05200: loss = 1.57092065e-01 lambda = [-0.42844638 -0.21175666]\n",
            "It 05250: loss = 1.57031581e-01 lambda = [-0.43085468 -0.21326055]\n",
            "It 05300: loss = 1.56971082e-01 lambda = [-0.43327075 -0.2147717 ]\n",
            "It 05350: loss = 1.56910628e-01 lambda = [-0.4356946  -0.21629015]\n",
            "It 05400: loss = 1.56850204e-01 lambda = [-0.4381262  -0.21781586]\n",
            "It 05450: loss = 1.56789765e-01 lambda = [-0.44056562 -0.21934885]\n",
            "It 05500: loss = 1.56729326e-01 lambda = [-0.4430128  -0.22088912]\n",
            "It 05550: loss = 1.56668931e-01 lambda = [-0.44546774 -0.22243665]\n",
            "It 05600: loss = 1.56608522e-01 lambda = [-0.44793043 -0.22399147]\n",
            "It 05650: loss = 1.56548098e-01 lambda = [-0.45040083 -0.22555356]\n",
            "It 05700: loss = 1.56487659e-01 lambda = [-0.45287904 -0.22712295]\n",
            "It 05750: loss = 1.56427264e-01 lambda = [-0.455365   -0.22869962]\n",
            "It 05800: loss = 1.56366810e-01 lambda = [-0.45785865 -0.23028357]\n",
            "It 05850: loss = 1.56306341e-01 lambda = [-0.46036005 -0.23187481]\n",
            "It 05900: loss = 1.56245872e-01 lambda = [-0.46286917 -0.23347333]\n",
            "It 05950: loss = 1.56185359e-01 lambda = [-0.465386   -0.23507914]\n",
            "It 06000: loss = 1.56124845e-01 lambda = [-0.46791056 -0.23669222]\n",
            "It 06050: loss = 1.56064302e-01 lambda = [-0.4704428  -0.23831259]\n",
            "It 06100: loss = 1.56003729e-01 lambda = [-0.47298276 -0.23994024]\n",
            "It 06150: loss = 1.55943096e-01 lambda = [-0.4755304  -0.24157518]\n",
            "It 06200: loss = 1.55882463e-01 lambda = [-0.4780857  -0.24321741]\n",
            "It 06250: loss = 1.55821741e-01 lambda = [-0.4806487  -0.24486691]\n",
            "It 06300: loss = 1.55761003e-01 lambda = [-0.4832194  -0.24652366]\n",
            "It 06350: loss = 1.55700207e-01 lambda = [-0.48579773 -0.24818772]\n",
            "It 06400: loss = 1.55639350e-01 lambda = [-0.48838374 -0.24985905]\n",
            "It 06450: loss = 1.55578449e-01 lambda = [-0.4909774  -0.25153768]\n",
            "It 06500: loss = 1.55517489e-01 lambda = [-0.49357873 -0.25322354]\n",
            "It 06550: loss = 1.55456468e-01 lambda = [-0.4961877 -0.2549167]\n",
            "It 06600: loss = 1.55395374e-01 lambda = [-0.49880427 -0.25661713]\n",
            "It 06650: loss = 1.55334190e-01 lambda = [-0.5014286  -0.25832483]\n",
            "It 06700: loss = 1.55272961e-01 lambda = [-0.5040604  -0.26003984]\n",
            "It 06750: loss = 1.55211687e-01 lambda = [-0.5067     -0.26176205]\n",
            "It 06800: loss = 1.55150279e-01 lambda = [-0.50934696 -0.26349154]\n",
            "It 06850: loss = 1.55088782e-01 lambda = [-0.5120019 -0.2652283]\n",
            "It 06900: loss = 1.55027255e-01 lambda = [-0.5146641 -0.2669723]\n",
            "It 06950: loss = 1.54965609e-01 lambda = [-0.51733416 -0.26872355]\n",
            "It 07000: loss = 1.54903829e-01 lambda = [-0.52001166 -0.27048206]\n",
            "It 07050: loss = 1.54872328e-01 lambda = [-0.52135277 -0.27136394]\n",
            "It 07100: loss = 1.54841408e-01 lambda = [-0.52269685 -0.27224785]\n",
            "It 07150: loss = 1.54810473e-01 lambda = [-0.5240422  -0.27313352]\n",
            "It 07200: loss = 1.54779509e-01 lambda = [-0.52538925 -0.27402094]\n",
            "It 07250: loss = 1.54748499e-01 lambda = [-0.5267389 -0.2749101]\n",
            "It 07300: loss = 1.54717460e-01 lambda = [-0.52808976 -0.2758011 ]\n",
            "It 07350: loss = 1.54686421e-01 lambda = [-0.5294428  -0.27669403]\n",
            "It 07400: loss = 1.54655293e-01 lambda = [-0.5307979  -0.27758873]\n",
            "It 07450: loss = 1.54624194e-01 lambda = [-0.5321543  -0.27848515]\n",
            "It 07500: loss = 1.54593036e-01 lambda = [-0.5335133  -0.27938333]\n",
            "It 07550: loss = 1.54561833e-01 lambda = [-0.53487396 -0.28028345]\n",
            "It 07600: loss = 1.54530644e-01 lambda = [-0.5362359  -0.28118542]\n",
            "It 07650: loss = 1.54499456e-01 lambda = [-0.5376008  -0.28208914]\n",
            "It 07700: loss = 1.54468223e-01 lambda = [-0.53896695 -0.2829946 ]\n",
            "It 07750: loss = 1.54436976e-01 lambda = [-0.5403349 -0.2839018]\n",
            "It 07800: loss = 1.54405668e-01 lambda = [-0.5417053  -0.28481105]\n",
            "It 07850: loss = 1.54374316e-01 lambda = [-0.543077   -0.28572202]\n",
            "It 07900: loss = 1.54342949e-01 lambda = [-0.5444509  -0.28663474]\n",
            "It 07950: loss = 1.54311523e-01 lambda = [-0.5458268  -0.28754923]\n",
            "It 08000: loss = 1.54280096e-01 lambda = [-0.547204   -0.28846553]\n",
            "It 08050: loss = 1.54248625e-01 lambda = [-0.54858387 -0.28938377]\n",
            "It 08100: loss = 1.54217124e-01 lambda = [-0.5499653  -0.29030377]\n",
            "It 08150: loss = 1.54185578e-01 lambda = [-0.55134815 -0.2912255 ]\n",
            "It 08200: loss = 1.54154003e-01 lambda = [-0.5527338  -0.29214898]\n",
            "It 08250: loss = 1.54122382e-01 lambda = [-0.55412066 -0.29307434]\n",
            "It 08300: loss = 1.54090747e-01 lambda = [-0.55550945 -0.29400158]\n",
            "It 08350: loss = 1.54059082e-01 lambda = [-0.55690056 -0.29493058]\n",
            "It 08400: loss = 1.54027358e-01 lambda = [-0.558293  -0.2958613]\n",
            "It 08450: loss = 1.53995633e-01 lambda = [-0.55968773 -0.2967938 ]\n",
            "It 08500: loss = 1.53963849e-01 lambda = [-0.5610844 -0.2977282]\n",
            "It 08550: loss = 1.53932080e-01 lambda = [-0.56248224 -0.29866445]\n",
            "It 08600: loss = 1.53900221e-01 lambda = [-0.56388295 -0.29960242]\n",
            "It 08650: loss = 1.53868347e-01 lambda = [-0.565285   -0.30054215]\n",
            "It 08700: loss = 1.53836444e-01 lambda = [-0.5666887 -0.3014836]\n",
            "It 08750: loss = 1.53804466e-01 lambda = [-0.568095   -0.30242702]\n",
            "It 08800: loss = 1.53772458e-01 lambda = [-0.5695026  -0.30337223]\n",
            "It 08850: loss = 1.53740436e-01 lambda = [-0.57091224 -0.30431917]\n",
            "It 08900: loss = 1.53708339e-01 lambda = [-0.57232404 -0.30526787]\n",
            "It 08950: loss = 1.53676227e-01 lambda = [-0.5737371 -0.3062183]\n",
            "It 09000: loss = 1.53644040e-01 lambda = [-0.5751527  -0.30717075]\n",
            "It 09050: loss = 1.53611869e-01 lambda = [-0.57657    -0.30812493]\n",
            "It 09100: loss = 1.53579637e-01 lambda = [-0.57798856 -0.30908084]\n",
            "It 09150: loss = 1.53547361e-01 lambda = [-0.57941   -0.3100385]\n",
            "It 09200: loss = 1.53515041e-01 lambda = [-0.58083266 -0.31099793]\n",
            "It 09250: loss = 1.53482676e-01 lambda = [-0.5822572  -0.31195933]\n",
            "It 09300: loss = 1.53450266e-01 lambda = [-0.5836841  -0.31292245]\n",
            "It 09350: loss = 1.53417841e-01 lambda = [-0.5851122  -0.31388733]\n",
            "It 09400: loss = 1.53385356e-01 lambda = [-0.5865427  -0.31485394]\n",
            "It 09450: loss = 1.53352857e-01 lambda = [-0.5879751 -0.3158223]\n",
            "It 09500: loss = 1.53320298e-01 lambda = [-0.5894087  -0.31679264]\n",
            "It 09550: loss = 1.53287679e-01 lambda = [-0.59084517 -0.31776473]\n",
            "It 09600: loss = 1.53255031e-01 lambda = [-0.59228295 -0.31873855]\n",
            "It 09650: loss = 1.53222337e-01 lambda = [-0.5937224 -0.3197141]\n",
            "It 09700: loss = 1.53189614e-01 lambda = [-0.5951644 -0.3206914]\n",
            "It 09750: loss = 1.53156832e-01 lambda = [-0.5966076  -0.32167068]\n",
            "It 09800: loss = 1.53124005e-01 lambda = [-0.59805304 -0.32265168]\n",
            "It 09850: loss = 1.53091118e-01 lambda = [-0.5995005  -0.32363442]\n",
            "It 09900: loss = 1.53058201e-01 lambda = [-0.6009491  -0.32461888]\n",
            "It 09950: loss = 1.53025225e-01 lambda = [-0.6024005 -0.3256051]\n",
            "It 10000: loss = 1.52992234e-01 lambda = [-0.60385334 -0.32659328]\n",
            "It 10050: loss = 1.52959138e-01 lambda = [-0.6053077 -0.3275832]\n",
            "It 10100: loss = 1.52926028e-01 lambda = [-0.60676473 -0.32857487]\n",
            "It 10150: loss = 1.52892858e-01 lambda = [-0.608223   -0.32956827]\n",
            "It 10200: loss = 1.52859658e-01 lambda = [-0.60968333 -0.3305634 ]\n",
            "It 10250: loss = 1.52826399e-01 lambda = [-0.6111458  -0.33156046]\n",
            "It 10300: loss = 1.52793065e-01 lambda = [-0.6126095 -0.3325593]\n",
            "It 10350: loss = 1.52759701e-01 lambda = [-0.6140758  -0.33355984]\n",
            "It 10400: loss = 1.52726263e-01 lambda = [-0.61554366 -0.33456212]\n",
            "It 10450: loss = 1.52692825e-01 lambda = [-0.6170129  -0.33556613]\n",
            "It 10500: loss = 1.52659327e-01 lambda = [-0.618485   -0.33657208]\n",
            "It 10550: loss = 1.52625754e-01 lambda = [-0.6199583  -0.33757982]\n",
            "It 10600: loss = 1.52592182e-01 lambda = [-0.6214335  -0.33858925]\n",
            "It 10650: loss = 1.52558535e-01 lambda = [-0.622911  -0.3396004]\n",
            "It 10700: loss = 1.52524829e-01 lambda = [-0.6243897 -0.3406133]\n",
            "It 10750: loss = 1.52491078e-01 lambda = [-0.6258709  -0.34162802]\n",
            "It 10800: loss = 1.52457252e-01 lambda = [-0.6273538 -0.3426446]\n",
            "It 10850: loss = 1.52423397e-01 lambda = [-0.62883794 -0.34366292]\n",
            "It 10900: loss = 1.52389497e-01 lambda = [-0.6303251  -0.34468296]\n",
            "It 10950: loss = 1.52355522e-01 lambda = [-0.6318134  -0.34570473]\n",
            "It 11000: loss = 1.52321488e-01 lambda = [-0.6333035 -0.3467282]\n",
            "It 11050: loss = 1.52287409e-01 lambda = [-0.634796   -0.34775364]\n",
            "It 11100: loss = 1.52253285e-01 lambda = [-0.6362897 -0.3487808]\n",
            "It 11150: loss = 1.52219072e-01 lambda = [-0.6377858 -0.3498097]\n",
            "It 11200: loss = 1.52184829e-01 lambda = [-0.6392837 -0.3508403]\n",
            "It 11250: loss = 1.52150542e-01 lambda = [-0.64078283 -0.35187262]\n",
            "It 11300: loss = 1.52116179e-01 lambda = [-0.64228487 -0.35290682]\n",
            "It 11350: loss = 1.52081758e-01 lambda = [-0.64378816 -0.3539428 ]\n",
            "It 11400: loss = 1.52047276e-01 lambda = [-0.6452932  -0.35498053]\n",
            "It 11450: loss = 1.52012736e-01 lambda = [-0.6468007  -0.35601997]\n",
            "It 11500: loss = 1.51978150e-01 lambda = [-0.6483094  -0.35706112]\n",
            "It 11550: loss = 1.51943490e-01 lambda = [-0.6498204  -0.35810402]\n",
            "It 11600: loss = 1.51908785e-01 lambda = [-0.6513333  -0.35914883]\n",
            "It 11650: loss = 1.51874006e-01 lambda = [-0.6528474  -0.36019537]\n",
            "It 11700: loss = 1.51839167e-01 lambda = [-0.65436435 -0.36124364]\n",
            "It 11750: loss = 1.51804283e-01 lambda = [-0.65588266 -0.3622936 ]\n",
            "It 11800: loss = 1.51769340e-01 lambda = [-0.6574026 -0.3633453]\n",
            "It 11850: loss = 1.51734337e-01 lambda = [-0.6589251  -0.36439884]\n",
            "It 11900: loss = 1.51699275e-01 lambda = [-0.66044885 -0.36545417]\n",
            "It 11950: loss = 1.51664153e-01 lambda = [-0.6619747  -0.36651123]\n",
            "It 12000: loss = 1.51628956e-01 lambda = [-0.66350263 -0.36756998]\n",
            "It 12050: loss = 1.51593745e-01 lambda = [-0.66503173 -0.36863047]\n",
            "It 12100: loss = 1.51558459e-01 lambda = [-0.6665636  -0.36969265]\n",
            "It 12150: loss = 1.51523113e-01 lambda = [-0.66809684 -0.37075672]\n",
            "It 12200: loss = 1.51487708e-01 lambda = [-0.66963166 -0.37182254]\n",
            "It 12250: loss = 1.51452228e-01 lambda = [-0.67116916 -0.37289006]\n",
            "It 12300: loss = 1.51416659e-01 lambda = [-0.67270786 -0.3739593 ]\n",
            "It 12350: loss = 1.51381060e-01 lambda = [-0.67424864 -0.37503025]\n",
            "It 12400: loss = 1.51345387e-01 lambda = [-0.6757915 -0.3761029]\n",
            "It 12450: loss = 1.51309669e-01 lambda = [-0.6773356  -0.37717745]\n",
            "It 12500: loss = 1.51273847e-01 lambda = [-0.67888236 -0.37825373]\n",
            "It 12550: loss = 1.51237994e-01 lambda = [-0.68043065 -0.3793317 ]\n",
            "It 12600: loss = 1.51202068e-01 lambda = [-0.6819804 -0.3804114]\n",
            "It 12650: loss = 1.51166052e-01 lambda = [-0.6835329 -0.3814928]\n",
            "It 12700: loss = 1.51129976e-01 lambda = [-0.6850866 -0.3825759]\n",
            "It 12750: loss = 1.51093856e-01 lambda = [-0.6866423 -0.3836609]\n",
            "It 12800: loss = 1.51057675e-01 lambda = [-0.6882002  -0.38474762]\n",
            "It 12850: loss = 1.51021421e-01 lambda = [-0.68975925 -0.38583604]\n",
            "It 12900: loss = 1.50985092e-01 lambda = [-0.6913209 -0.3869261]\n",
            "It 12950: loss = 1.50948703e-01 lambda = [-0.69288415 -0.3880179 ]\n",
            "It 13000: loss = 1.50912240e-01 lambda = [-0.69444877 -0.38911137]\n",
            "It 13050: loss = 1.50875703e-01 lambda = [-0.6960162 -0.3902067]\n",
            "It 13100: loss = 1.50839090e-01 lambda = [-0.69758487 -0.39130378]\n",
            "It 13150: loss = 1.50802448e-01 lambda = [-0.69915545 -0.39240256]\n",
            "It 13200: loss = 1.50765687e-01 lambda = [-0.7007283  -0.39350304]\n",
            "It 13250: loss = 1.50728911e-01 lambda = [-0.70230234 -0.3946052 ]\n",
            "It 13300: loss = 1.50692016e-01 lambda = [-0.7038789  -0.39570904]\n",
            "It 13350: loss = 1.50655076e-01 lambda = [-0.7054571  -0.39681464]\n",
            "It 13400: loss = 1.50618047e-01 lambda = [-0.7070366  -0.39792207]\n",
            "It 13450: loss = 1.50580958e-01 lambda = [-0.708619  -0.3990312]\n",
            "It 13500: loss = 1.50543809e-01 lambda = [-0.71020263 -0.400142  ]\n",
            "It 13550: loss = 1.50506556e-01 lambda = [-0.7117881 -0.4012545]\n",
            "It 13600: loss = 1.50469244e-01 lambda = [-0.7133759 -0.4023687]\n",
            "It 13650: loss = 1.50431871e-01 lambda = [-0.714965   -0.40348458]\n",
            "It 13700: loss = 1.50394425e-01 lambda = [-0.71655643 -0.40460232]\n",
            "It 13750: loss = 1.50356904e-01 lambda = [-0.71814966 -0.40572175]\n",
            "It 13800: loss = 1.50319323e-01 lambda = [-0.71974415 -0.4068429 ]\n",
            "It 13850: loss = 1.50281623e-01 lambda = [-0.72134155 -0.4079657 ]\n",
            "It 13900: loss = 1.50243893e-01 lambda = [-0.7229402 -0.4090902]\n",
            "It 13950: loss = 1.50206074e-01 lambda = [-0.7245406  -0.41021636]\n",
            "It 14000: loss = 1.50168180e-01 lambda = [-0.7261435  -0.41134426]\n",
            "It 14050: loss = 1.50148839e-01 lambda = [-0.72694516 -0.411909  ]\n",
            "It 14100: loss = 1.50129884e-01 lambda = [-0.72774684 -0.41247377]\n",
            "It 14150: loss = 1.50110915e-01 lambda = [-0.7285485  -0.41303915]\n",
            "It 14200: loss = 1.50091872e-01 lambda = [-0.7293528 -0.4136054]\n",
            "It 14250: loss = 1.50072828e-01 lambda = [-0.73015743 -0.41417164]\n",
            "It 14300: loss = 1.50053784e-01 lambda = [-0.7309621  -0.41473788]\n",
            "It 14350: loss = 1.50034711e-01 lambda = [-0.73176676 -0.41530547]\n",
            "It 14400: loss = 1.50015637e-01 lambda = [-0.7325714 -0.4158732]\n",
            "It 14450: loss = 1.49996534e-01 lambda = [-0.7333761  -0.41644093]\n",
            "It 14500: loss = 1.49977416e-01 lambda = [-0.7341822  -0.41700923]\n",
            "It 14550: loss = 1.49958283e-01 lambda = [-0.7349898  -0.41757846]\n",
            "It 14600: loss = 1.49939090e-01 lambda = [-0.73579746 -0.41814768]\n",
            "It 14650: loss = 1.49919927e-01 lambda = [-0.7366051 -0.4187169]\n",
            "It 14700: loss = 1.49900749e-01 lambda = [-0.73741275 -0.41928738]\n",
            "It 14750: loss = 1.49881527e-01 lambda = [-0.7382204 -0.4198581]\n",
            "It 14800: loss = 1.49862304e-01 lambda = [-0.7390283 -0.4204288]\n",
            "It 14850: loss = 1.49843052e-01 lambda = [-0.7398389  -0.42099997]\n",
            "It 14900: loss = 1.49823755e-01 lambda = [-0.7406495  -0.42157218]\n",
            "It 14950: loss = 1.49804473e-01 lambda = [-0.74146014 -0.42214438]\n",
            "It 15000: loss = 1.49785161e-01 lambda = [-0.74227077 -0.4227166 ]\n",
            "It 15050: loss = 1.49765849e-01 lambda = [-0.7430814  -0.42328992]\n",
            "It 15100: loss = 1.49746507e-01 lambda = [-0.743892   -0.42386362]\n",
            "It 15150: loss = 1.49727136e-01 lambda = [-0.74470466 -0.4244373 ]\n",
            "It 15200: loss = 1.49707749e-01 lambda = [-0.74551827 -0.42501134]\n",
            "It 15250: loss = 1.49688333e-01 lambda = [-0.7463319  -0.42558652]\n",
            "It 15300: loss = 1.49668902e-01 lambda = [-0.7471455 -0.4261617]\n",
            "It 15350: loss = 1.49649441e-01 lambda = [-0.7479591 -0.4267369]\n",
            "It 15400: loss = 1.49629995e-01 lambda = [-0.7487727 -0.4273131]\n",
            "It 15450: loss = 1.49610505e-01 lambda = [-0.7495872  -0.42788976]\n",
            "It 15500: loss = 1.49590999e-01 lambda = [-0.75040376 -0.42846644]\n",
            "It 15550: loss = 1.49571463e-01 lambda = [-0.75122035 -0.4290433 ]\n",
            "It 15600: loss = 1.49551913e-01 lambda = [-0.7520369  -0.42962146]\n",
            "It 15650: loss = 1.49532318e-01 lambda = [-0.7528535  -0.43019962]\n",
            "It 15700: loss = 1.49512768e-01 lambda = [-0.7536701 -0.4307778]\n",
            "It 15750: loss = 1.49493158e-01 lambda = [-0.7544867 -0.4313568]\n",
            "It 15800: loss = 1.49473503e-01 lambda = [-0.755306   -0.43193644]\n",
            "It 15850: loss = 1.49453864e-01 lambda = [-0.75612557 -0.4325161 ]\n",
            "It 15900: loss = 1.49434179e-01 lambda = [-0.75694513 -0.43309575]\n",
            "It 15950: loss = 1.49414495e-01 lambda = [-0.7577647 -0.4336769]\n",
            "It 16000: loss = 1.49394765e-01 lambda = [-0.75858426 -0.43425804]\n",
            "It 16050: loss = 1.49375081e-01 lambda = [-0.7594038 -0.4348392]\n",
            "It 16100: loss = 1.49355322e-01 lambda = [-0.76022494 -0.43542096]\n",
            "It 16150: loss = 1.49335563e-01 lambda = [-0.7610475 -0.4360036]\n",
            "It 16200: loss = 1.49315760e-01 lambda = [-0.76187    -0.43658623]\n",
            "It 16250: loss = 1.49295956e-01 lambda = [-0.7626926  -0.43716887]\n",
            "It 16300: loss = 1.49276137e-01 lambda = [-0.7635151  -0.43775275]\n",
            "It 16350: loss = 1.49256289e-01 lambda = [-0.76433766 -0.43833688]\n",
            "It 16400: loss = 1.49236426e-01 lambda = [-0.76516056 -0.438921  ]\n",
            "It 16450: loss = 1.49216533e-01 lambda = [-0.7659861 -0.4395055]\n",
            "It 16500: loss = 1.49196625e-01 lambda = [-0.7668116 -0.4400911]\n",
            "It 16550: loss = 1.49176672e-01 lambda = [-0.76763713 -0.44067672]\n",
            "It 16600: loss = 1.49156719e-01 lambda = [-0.76846266 -0.44126233]\n",
            "It 16650: loss = 1.49136752e-01 lambda = [-0.7692882  -0.44184893]\n",
            "It 16700: loss = 1.49116769e-01 lambda = [-0.7701137  -0.44243604]\n",
            "It 16750: loss = 1.49096757e-01 lambda = [-0.7709414  -0.44302315]\n",
            "It 16800: loss = 1.49076700e-01 lambda = [-0.7717699  -0.44361034]\n",
            "It 16850: loss = 1.49056643e-01 lambda = [-0.7725984  -0.44419894]\n",
            "It 16900: loss = 1.49036571e-01 lambda = [-0.7734269  -0.44478753]\n",
            "It 16950: loss = 1.49016485e-01 lambda = [-0.7742554  -0.44537613]\n",
            "It 17000: loss = 1.48996368e-01 lambda = [-0.7750839 -0.4459654]\n",
            "It 17050: loss = 1.48976222e-01 lambda = [-0.7759134 -0.4465555]\n",
            "It 17100: loss = 1.48956046e-01 lambda = [-0.7767449  -0.44714558]\n",
            "It 17150: loss = 1.48935869e-01 lambda = [-0.7775764  -0.44773567]\n",
            "It 17200: loss = 1.48915663e-01 lambda = [-0.7784079 -0.448327 ]\n",
            "It 17250: loss = 1.48895442e-01 lambda = [-0.77923936 -0.44891858]\n",
            "It 17300: loss = 1.48875222e-01 lambda = [-0.78007084 -0.44951016]\n",
            "It 17350: loss = 1.48854971e-01 lambda = [-0.7809023  -0.45010203]\n",
            "It 17400: loss = 1.48834690e-01 lambda = [-0.7817366 -0.4506951]\n",
            "It 17450: loss = 1.48814365e-01 lambda = [-0.7825711  -0.45128816]\n",
            "It 17500: loss = 1.48794055e-01 lambda = [-0.78340554 -0.45188123]\n",
            "It 17550: loss = 1.48773715e-01 lambda = [-0.78424    -0.45247513]\n",
            "It 17600: loss = 1.48753345e-01 lambda = [-0.7850745 -0.4530697]\n",
            "It 17650: loss = 1.48732990e-01 lambda = [-0.78590894 -0.45366424]\n",
            "It 17700: loss = 1.48712590e-01 lambda = [-0.78674495 -0.4542588 ]\n",
            "It 17750: loss = 1.48692146e-01 lambda = [-0.7875824 -0.4548547]\n",
            "It 17800: loss = 1.48671702e-01 lambda = [-0.78841984 -0.45545074]\n",
            "It 17850: loss = 1.48651242e-01 lambda = [-0.7892573 -0.4560468]\n",
            "It 17900: loss = 1.48630768e-01 lambda = [-0.79009473 -0.4566432 ]\n",
            "It 17950: loss = 1.48610264e-01 lambda = [-0.7909322  -0.45724073]\n",
            "It 18000: loss = 1.48589745e-01 lambda = [-0.79177    -0.45783827]\n",
            "It 18050: loss = 1.48569182e-01 lambda = [-0.7926104 -0.4584358]\n",
            "It 18100: loss = 1.48548573e-01 lambda = [-0.79345083 -0.4590342 ]\n",
            "It 18150: loss = 1.48527995e-01 lambda = [-0.79429126 -0.45963323]\n",
            "It 18200: loss = 1.48507372e-01 lambda = [-0.7951317  -0.46023226]\n",
            "It 18250: loss = 1.48486733e-01 lambda = [-0.7959721  -0.46083128]\n",
            "It 18300: loss = 1.48466095e-01 lambda = [-0.79681253 -0.46143168]\n",
            "It 18350: loss = 1.48445413e-01 lambda = [-0.7976551 -0.4620322]\n",
            "It 18400: loss = 1.48424685e-01 lambda = [-0.7984985  -0.46263272]\n",
            "It 18450: loss = 1.48403943e-01 lambda = [-0.7993419 -0.4632336]\n",
            "It 18500: loss = 1.48383230e-01 lambda = [-0.8001853 -0.4638356]\n",
            "It 18550: loss = 1.48362458e-01 lambda = [-0.8010287 -0.4644376]\n",
            "It 18600: loss = 1.48341686e-01 lambda = [-0.80187213 -0.4650396 ]\n",
            "It 18650: loss = 1.48320884e-01 lambda = [-0.80271643 -0.46564242]\n",
            "It 18700: loss = 1.48300022e-01 lambda = [-0.8035628  -0.46624592]\n",
            "It 18750: loss = 1.48279160e-01 lambda = [-0.8044092  -0.46684942]\n",
            "It 18800: loss = 1.48258314e-01 lambda = [-0.8052556 -0.4674529]\n",
            "It 18850: loss = 1.48237407e-01 lambda = [-0.806102   -0.46805766]\n",
            "It 18900: loss = 1.48216486e-01 lambda = [-0.80694836 -0.46866265]\n",
            "It 18950: loss = 1.48195550e-01 lambda = [-0.80779475 -0.46926764]\n",
            "It 19000: loss = 1.48174584e-01 lambda = [-0.80864376 -0.46987277]\n",
            "It 19050: loss = 1.48153573e-01 lambda = [-0.8094931  -0.47047925]\n",
            "It 19100: loss = 1.48132592e-01 lambda = [-0.8103425  -0.47108573]\n",
            "It 19150: loss = 1.48111552e-01 lambda = [-0.81119186 -0.4716922 ]\n",
            "It 19200: loss = 1.48090497e-01 lambda = [-0.8120412  -0.47229922]\n",
            "It 19250: loss = 1.48069441e-01 lambda = [-0.8128906 -0.4729072]\n",
            "It 19300: loss = 1.48048341e-01 lambda = [-0.8137413  -0.47351515]\n",
            "It 19350: loss = 1.48027226e-01 lambda = [-0.8145937  -0.47412312]\n",
            "It 19400: loss = 1.48006067e-01 lambda = [-0.815446 -0.474732]\n",
            "It 19450: loss = 1.47984922e-01 lambda = [-0.81629837 -0.47534147]\n",
            "It 19500: loss = 1.47963703e-01 lambda = [-0.8171507  -0.47595093]\n",
            "It 19550: loss = 1.47942513e-01 lambda = [-0.81800306 -0.47656038]\n",
            "It 19600: loss = 1.47921294e-01 lambda = [-0.81885546 -0.47717112]\n",
            "It 19650: loss = 1.47900030e-01 lambda = [-0.8197108  -0.47778207]\n",
            "It 19700: loss = 1.47878736e-01 lambda = [-0.8205661  -0.47839302]\n",
            "It 19750: loss = 1.47857457e-01 lambda = [-0.82142144 -0.4790041 ]\n",
            "It 19800: loss = 1.47836119e-01 lambda = [-0.8222768  -0.47961655]\n",
            "It 19850: loss = 1.47814780e-01 lambda = [-0.8231321 -0.480229 ]\n",
            "It 19900: loss = 1.47793442e-01 lambda = [-0.8239874  -0.48084143]\n",
            "It 19950: loss = 1.47772044e-01 lambda = [-0.82484454 -0.48145434]\n",
            "It 20000: loss = 1.47750616e-01 lambda = [-0.82570285 -0.48206827]\n",
            "It 20050: loss = 1.47729188e-01 lambda = [-0.82656115 -0.4826822 ]\n",
            "It 20100: loss = 1.47707731e-01 lambda = [-0.82741946 -0.48329613]\n",
            "It 20150: loss = 1.47686273e-01 lambda = [-0.82827777 -0.48391083]\n",
            "It 20200: loss = 1.47664770e-01 lambda = [-0.8291361  -0.48452625]\n",
            "It 20250: loss = 1.47643268e-01 lambda = [-0.82999486 -0.48514166]\n",
            "It 20300: loss = 1.47621751e-01 lambda = [-0.83085614 -0.48575708]\n",
            "It 20350: loss = 1.47600144e-01 lambda = [-0.83171743 -0.48637354]\n",
            "It 20400: loss = 1.47578567e-01 lambda = [-0.8325787  -0.48699045]\n",
            "It 20450: loss = 1.47556946e-01 lambda = [-0.83344    -0.48760736]\n",
            "It 20500: loss = 1.47535324e-01 lambda = [-0.8343013  -0.48822427]\n",
            "It 20550: loss = 1.47513688e-01 lambda = [-0.8351626  -0.48884246]\n",
            "It 20600: loss = 1.47491992e-01 lambda = [-0.83602595 -0.48946086]\n",
            "It 20650: loss = 1.47470266e-01 lambda = [-0.8368902  -0.49007925]\n",
            "It 20700: loss = 1.47448540e-01 lambda = [-0.8377545  -0.49069768]\n",
            "It 20750: loss = 1.47426799e-01 lambda = [-0.83861876 -0.49131757]\n",
            "It 20800: loss = 1.47405028e-01 lambda = [-0.839483   -0.49193746]\n",
            "It 20850: loss = 1.47383258e-01 lambda = [-0.8403473  -0.49255735]\n",
            "It 20900: loss = 1.47361428e-01 lambda = [-0.84121233 -0.49317747]\n",
            "It 20950: loss = 1.47339568e-01 lambda = [-0.8420796  -0.49379885]\n",
            "It 21000: loss = 1.47317678e-01 lambda = [-0.8429468  -0.49442023]\n",
            "It 21050: loss = 1.47295803e-01 lambda = [-0.8438141 -0.4950416]\n",
            "It 21100: loss = 1.47273883e-01 lambda = [-0.8446813  -0.49566346]\n",
            "It 21150: loss = 1.47251934e-01 lambda = [-0.84554857 -0.49628633]\n",
            "It 21200: loss = 1.47229984e-01 lambda = [-0.8464158 -0.4969092]\n",
            "It 21250: loss = 1.47208020e-01 lambda = [-0.84728557 -0.49753207]\n",
            "It 21300: loss = 1.47186011e-01 lambda = [-0.8481558 -0.4981556]\n",
            "It 21350: loss = 1.47163957e-01 lambda = [-0.849026   -0.49877995]\n",
            "It 21400: loss = 1.47141904e-01 lambda = [-0.84989625 -0.4994043 ]\n",
            "It 21450: loss = 1.47119850e-01 lambda = [-0.8507665 -0.5000287]\n",
            "It 21500: loss = 1.47097751e-01 lambda = [-0.8516367 -0.5006546]\n",
            "It 21550: loss = 1.47075668e-01 lambda = [-0.8525081 -0.5012804]\n",
            "It 21600: loss = 1.47053510e-01 lambda = [-0.85338134 -0.5019063 ]\n",
            "It 21650: loss = 1.47031352e-01 lambda = [-0.85425454 -0.5025321 ]\n",
            "It 21700: loss = 1.47009164e-01 lambda = [-0.85512775 -0.503158  ]\n",
            "It 21750: loss = 1.46986991e-01 lambda = [-0.85600096 -0.5037838 ]\n",
            "It 21800: loss = 1.46964774e-01 lambda = [-0.85687417 -0.5044116 ]\n",
            "It 21850: loss = 1.46942541e-01 lambda = [-0.8577474 -0.5050404]\n",
            "It 21900: loss = 1.46920249e-01 lambda = [-0.8586233  -0.50566924]\n",
            "It 21950: loss = 1.46897942e-01 lambda = [-0.8594995  -0.50629807]\n",
            "It 22000: loss = 1.46875620e-01 lambda = [-0.8603757 -0.5069269]\n",
            "It 22050: loss = 1.46853298e-01 lambda = [-0.8612519 -0.5075557]\n",
            "It 22100: loss = 1.46830946e-01 lambda = [-0.8621281  -0.50818455]\n",
            "It 22150: loss = 1.46808580e-01 lambda = [-0.86300427 -0.5088134 ]\n",
            "It 22200: loss = 1.46786153e-01 lambda = [-0.86388165 -0.5094442 ]\n",
            "It 22250: loss = 1.46763712e-01 lambda = [-0.8647608 -0.510076 ]\n",
            "It 22300: loss = 1.46741241e-01 lambda = [-0.86564   -0.5107078]\n",
            "It 22350: loss = 1.46718755e-01 lambda = [-0.86651915 -0.5113396 ]\n",
            "It 22400: loss = 1.46696255e-01 lambda = [-0.8673983 -0.5119714]\n",
            "It 22450: loss = 1.46673769e-01 lambda = [-0.8682775 -0.5126032]\n",
            "It 22500: loss = 1.46651238e-01 lambda = [-0.86915666 -0.51323503]\n",
            "It 22550: loss = 1.46628663e-01 lambda = [-0.8700384  -0.51386684]\n",
            "It 22600: loss = 1.46606088e-01 lambda = [-0.87092054 -0.5145003 ]\n",
            "It 22650: loss = 1.46583453e-01 lambda = [-0.8718027 -0.5151351]\n",
            "It 22700: loss = 1.46560818e-01 lambda = [-0.87268484 -0.5157699 ]\n",
            "It 22750: loss = 1.46538138e-01 lambda = [-0.873567  -0.5164047]\n",
            "It 22800: loss = 1.46515459e-01 lambda = [-0.87444913 -0.5170395 ]\n",
            "It 22850: loss = 1.46492735e-01 lambda = [-0.87533206 -0.51767427]\n",
            "It 22900: loss = 1.46469980e-01 lambda = [-0.8762172  -0.51830906]\n",
            "It 22950: loss = 1.46447182e-01 lambda = [-0.8771023  -0.51894385]\n",
            "It 23000: loss = 1.46424398e-01 lambda = [-0.87798744 -0.51957977]\n",
            "It 23050: loss = 1.46401554e-01 lambda = [-0.8788726  -0.52021754]\n",
            "It 23100: loss = 1.46378696e-01 lambda = [-0.8797577 -0.5208553]\n",
            "It 23150: loss = 1.46355852e-01 lambda = [-0.88064283 -0.5214931 ]\n",
            "It 23200: loss = 1.46332949e-01 lambda = [-0.88153017 -0.52213085]\n",
            "It 23250: loss = 1.46310031e-01 lambda = [-0.8824183 -0.5227686]\n",
            "It 23300: loss = 1.46287099e-01 lambda = [-0.8833064 -0.5234064]\n",
            "It 23350: loss = 1.46264136e-01 lambda = [-0.8841945  -0.52404416]\n",
            "It 23400: loss = 1.46241173e-01 lambda = [-0.8850826 -0.5246823]\n",
            "It 23450: loss = 1.46218181e-01 lambda = [-0.8859707  -0.52532303]\n",
            "It 23500: loss = 1.46195143e-01 lambda = [-0.88685936 -0.5259638 ]\n",
            "It 23550: loss = 1.46172091e-01 lambda = [-0.88775045 -0.52660453]\n",
            "It 23600: loss = 1.46149009e-01 lambda = [-0.88864154 -0.5272453 ]\n",
            "It 23650: loss = 1.46125913e-01 lambda = [-0.8895326  -0.52788603]\n",
            "It 23700: loss = 1.46102786e-01 lambda = [-0.8904237 -0.5285268]\n",
            "It 23750: loss = 1.46079659e-01 lambda = [-0.8913148  -0.52916753]\n",
            "It 23800: loss = 1.46056518e-01 lambda = [-0.8922059 -0.5298083]\n",
            "It 23850: loss = 1.46033302e-01 lambda = [-0.8930988  -0.53045124]\n",
            "It 23900: loss = 1.46010086e-01 lambda = [-0.89399284 -0.53109497]\n",
            "It 23950: loss = 1.45986855e-01 lambda = [-0.8948869 -0.5317387]\n",
            "It 24000: loss = 1.45963579e-01 lambda = [-0.895781  -0.5323824]\n",
            "It 24050: loss = 1.45940304e-01 lambda = [-0.89667505 -0.53302616]\n",
            "Timeout is reached. Time elapsed: 100.00292253494263 seconds\n",
            "\n",
            "\n",
            "Adam\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: loss = 3.53887588e-01 lambda = [-0.09236384 -0.08053975]\n",
            "It 00050: loss = 1.37833506e-01 lambda = [-0.9945003 -2.1860347]\n",
            "It 00100: loss = 8.59780163e-02 lambda = [-4.273322    0.41225356]\n",
            "It 00150: loss = 8.31666365e-02 lambda = [-4.663208    0.15164727]\n",
            "It 00200: loss = 4.00878154e-02 lambda = [-5.0758862   0.60440433]\n",
            "It 00250: loss = 8.70599449e-02 lambda = [-5.193726    0.15210709]\n",
            "It 00300: loss = 8.49865973e-02 lambda = [-5.232492    0.49358177]\n",
            "It 00350: loss = 1.32965177e-01 lambda = [-5.2153063   0.36525938]\n",
            "It 00400: loss = 2.82041654e-02 lambda = [-5.0897055   0.52655184]\n",
            "It 00450: loss = 8.75201151e-02 lambda = [-5.0695996  0.1107297]\n",
            "It 00500: loss = 8.54146332e-02 lambda = [-5.0461473   0.45682165]\n",
            "It 00550: loss = 3.96376401e-02 lambda = [-5.103935   0.5375768]\n",
            "It 00600: loss = 4.74733785e-02 lambda = [-5.211997   0.6531678]\n",
            "It 00650: loss = 2.92682485e-03 lambda = [-5.3289204  0.778098 ]\n",
            "It 00700: loss = 4.13477421e-03 lambda = [-5.4218      0.79409933]\n",
            "It 00750: loss = 7.96255074e-04 lambda = [-5.542492   0.8266562]\n",
            "It 00800: loss = 5.15857013e-04 lambda = [-5.6078935   0.84868646]\n",
            "It 00850: loss = 3.65544285e-04 lambda = [-5.661176   0.8688545]\n",
            "It 00900: loss = 2.68402859e-04 lambda = [-5.7062364   0.88597476]\n",
            "It 00950: loss = 2.02267562e-04 lambda = [-5.7443805  0.9005105]\n",
            "It 01000: loss = 1.55624992e-04 lambda = [-5.776739    0.91287947]\n",
            "It 01050: loss = 1.21813995e-04 lambda = [-5.804288   0.9234472]\n",
            "It 01100: loss = 9.68007953e-05 lambda = [-5.8278384  0.9325207]\n",
            "It 01150: loss = 7.79883703e-05 lambda = [-5.8480616  0.9403451]\n",
            "It 01200: loss = 6.36462355e-05 lambda = [-5.8654966   0.94711787]\n",
            "It 01250: loss = 5.25736978e-05 lambda = [-5.880586   0.9529985]\n",
            "It 01300: loss = 4.39312716e-05 lambda = [-5.8936887  0.9581196]\n",
            "It 01350: loss = 3.71166243e-05 lambda = [-5.9050956  0.9625896]\n",
            "It 01400: loss = 3.16885053e-05 lambda = [-5.915053   0.9665006]\n",
            "It 01450: loss = 2.73287551e-05 lambda = [-5.923767   0.9699289]\n",
            "It 01500: loss = 2.37939785e-05 lambda = [-5.9314094   0.97294044]\n",
            "It 01550: loss = 2.09033624e-05 lambda = [-5.9381256  0.975591 ]\n",
            "It 01600: loss = 1.85198842e-05 lambda = [-5.944042   0.9779281]\n",
            "It 01650: loss = 1.65387937e-05 lambda = [-5.949261   0.9799925]\n",
            "It 01700: loss = 1.48804374e-05 lambda = [-5.9538765  0.9818191]\n",
            "It 01750: loss = 1.34800002e-05 lambda = [-5.9579635  0.983438 ]\n",
            "It 01800: loss = 1.22905494e-05 lambda = [-5.961589   0.9848756]\n",
            "It 01850: loss = 1.12710286e-05 lambda = [-5.9648137  0.9861539]\n",
            "It 01900: loss = 1.03926395e-05 lambda = [-5.967685   0.9872927]\n",
            "It 01950: loss = 9.63102502e-06 lambda = [-5.970247   0.9883093]\n",
            "It 02000: loss = 8.96570054e-06 lambda = [-5.972536   0.9892177]\n",
            "It 02050: loss = 8.38132291e-06 lambda = [-5.9745855  0.9900313]\n",
            "It 02100: loss = 7.86578312e-06 lambda = [-5.976423    0.99076074]\n",
            "It 02150: loss = 7.40762061e-06 lambda = [-5.9780746   0.99141604]\n",
            "It 02200: loss = 6.99958218e-06 lambda = [-5.979561    0.99200565]\n",
            "It 02250: loss = 6.63356423e-06 lambda = [-5.980901  0.992537]\n",
            "It 02300: loss = 6.30416571e-06 lambda = [-5.98211    0.9930168]\n",
            "It 02350: loss = 6.00655312e-06 lambda = [-5.9832044   0.99345046]\n",
            "It 02400: loss = 5.73633315e-06 lambda = [-5.984195   0.9938432]\n",
            "It 02450: loss = 5.49092601e-06 lambda = [-5.985095   0.9941994]\n",
            "It 02500: loss = 5.26626263e-06 lambda = [-5.9859138   0.99452347]\n",
            "It 02550: loss = 5.06075230e-06 lambda = [-5.986658   0.9948181]\n",
            "It 02600: loss = 4.87194620e-06 lambda = [-5.9873376  0.9950867]\n",
            "It 02650: loss = 4.69803626e-06 lambda = [-5.9879584  0.995332 ]\n",
            "It 02700: loss = 4.53755183e-06 lambda = [-5.988528   0.9955566]\n",
            "It 02750: loss = 4.38883035e-06 lambda = [-5.989048    0.99576217]\n",
            "It 02800: loss = 4.25119060e-06 lambda = [-5.9895267  0.9959508]\n",
            "It 02850: loss = 4.12333202e-06 lambda = [-5.989967  0.996124]\n",
            "It 02900: loss = 4.00388399e-06 lambda = [-5.990372   0.9962837]\n",
            "It 02950: loss = 3.89260003e-06 lambda = [-5.990746   0.9964306]\n",
            "It 03000: loss = 3.78859932e-06 lambda = [-5.991091   0.9965663]\n",
            "It 03050: loss = 3.73752664e-06 lambda = [-5.9912577  0.996631 ]\n",
            "It 03100: loss = 3.68745123e-06 lambda = [-5.9914246   0.99669534]\n",
            "It 03150: loss = 3.63778145e-06 lambda = [-5.9915915  0.9967594]\n",
            "It 03200: loss = 3.58798434e-06 lambda = [-5.9917583  0.9968231]\n",
            "It 03250: loss = 3.53870428e-06 lambda = [-5.9919157   0.99688625]\n",
            "It 03300: loss = 3.48951812e-06 lambda = [-5.992068    0.99694836]\n",
            "It 03350: loss = 3.44070077e-06 lambda = [-5.9922166  0.9970082]\n",
            "It 03400: loss = 3.39212738e-06 lambda = [-5.9923625   0.99706733]\n",
            "It 03450: loss = 3.34394190e-06 lambda = [-5.992506   0.9971245]\n",
            "It 03500: loss = 3.29606542e-06 lambda = [-5.992649   0.9971811]\n",
            "It 03550: loss = 3.24852545e-06 lambda = [-5.992792   0.9972369]\n",
            "It 03600: loss = 3.20149752e-06 lambda = [-5.992935   0.9972916]\n",
            "It 03650: loss = 3.15426450e-06 lambda = [-5.993078    0.99734575]\n",
            "It 03700: loss = 3.10817131e-06 lambda = [-5.9932213  0.9973999]\n",
            "It 03750: loss = 3.06173979e-06 lambda = [-5.9933643   0.99745375]\n",
            "It 03800: loss = 3.01643718e-06 lambda = [-5.9935074   0.99750745]\n",
            "It 03850: loss = 2.97175120e-06 lambda = [-5.9936395   0.99756056]\n",
            "It 03900: loss = 2.92656046e-06 lambda = [-5.993767   0.9976116]\n",
            "It 03950: loss = 2.88280398e-06 lambda = [-5.99389   0.997661]\n",
            "It 04000: loss = 2.83922463e-06 lambda = [-5.9940095  0.9977087]\n",
            "It 04050: loss = 2.79604706e-06 lambda = [-5.9941287  0.9977548]\n",
            "It 04100: loss = 2.75377556e-06 lambda = [-5.994248    0.99780035]\n",
            "It 04150: loss = 2.71165209e-06 lambda = [-5.994367   0.9978455]\n",
            "It 04200: loss = 2.67034693e-06 lambda = [-5.9944863   0.99788994]\n",
            "It 04250: loss = 2.62955450e-06 lambda = [-5.9946055  0.9979345]\n",
            "It 04300: loss = 2.58894170e-06 lambda = [-5.99472    0.9979785]\n",
            "It 04350: loss = 2.54971815e-06 lambda = [-5.9948277  0.998021 ]\n",
            "It 04400: loss = 2.51031793e-06 lambda = [-5.9949307  0.9980619]\n",
            "It 04450: loss = 2.47210414e-06 lambda = [-5.99503    0.9981011]\n",
            "It 04500: loss = 2.43387808e-06 lambda = [-5.995129    0.99813914]\n",
            "It 04550: loss = 2.39666633e-06 lambda = [-5.995225    0.99817634]\n",
            "It 04600: loss = 2.36023243e-06 lambda = [-5.9953203  0.9982124]\n",
            "It 04650: loss = 2.32387356e-06 lambda = [-5.9954157   0.99824816]\n",
            "It 04700: loss = 2.28832232e-06 lambda = [-5.995511    0.99828374]\n",
            "It 04750: loss = 2.25333201e-06 lambda = [-5.995602    0.99831855]\n",
            "It 04800: loss = 2.21901610e-06 lambda = [-5.9956903   0.99835247]\n",
            "It 04850: loss = 2.20996617e-06 lambda = [-5.9957695  0.9983894]\n",
            "It 04900: loss = 1.35920372e-05 lambda = [-5.9956756  0.9982441]\n",
            "It 04950: loss = 2.31554850e-06 lambda = [-5.9957857  0.9983148]\n",
            "It 05000: loss = 2.11107226e-06 lambda = [-5.995803    0.99838823]\n",
            "It 05050: loss = 2.07618723e-06 lambda = [-5.9958787   0.99842024]\n",
            "It 05100: loss = 1.19961413e-04 lambda = [-5.995592   0.9981171]\n",
            "It 05150: loss = 2.07513085e-06 lambda = [-5.995816    0.99828684]\n",
            "It 05200: loss = 2.02151250e-06 lambda = [-5.9958024  0.9983805]\n",
            "It 05250: loss = 1.98323255e-06 lambda = [-5.9958763   0.99842024]\n",
            "It 05300: loss = 2.28363433e-06 lambda = [-5.995987   0.9984425]\n",
            "It 05350: loss = 3.76690077e-05 lambda = [-5.9958506  0.9983333]\n",
            "It 05400: loss = 2.10088547e-06 lambda = [-5.995865    0.99837697]\n",
            "It 05450: loss = 2.82350695e-04 lambda = [-5.9958086  0.9982822]\n",
            "It 05500: loss = 4.78321863e-06 lambda = [-5.995889   0.9985503]\n",
            "It 05550: loss = 1.85368845e-06 lambda = [-5.996064   0.9985135]\n",
            "It 05600: loss = 7.72979110e-04 lambda = [-5.9970164   0.99764526]\n",
            "It 05650: loss = 5.14861586e-06 lambda = [-5.996217   0.9983377]\n",
            "It 05700: loss = 1.89391199e-06 lambda = [-5.996049   0.9984554]\n",
            "It 05750: loss = 5.96822210e-05 lambda = [-5.995752    0.99857724]\n",
            "It 05800: loss = 2.01178318e-06 lambda = [-5.9961033   0.99857044]\n",
            "It 05850: loss = 1.72909415e-06 lambda = [-5.9962573  0.9985783]\n",
            "It 05900: loss = 4.46482554e-05 lambda = [-5.995913   0.9984288]\n",
            "It 05950: loss = 4.86069439e-06 lambda = [-5.996398   0.9983319]\n",
            "It 06000: loss = 2.81246699e-04 lambda = [-5.996259    0.99842733]\n",
            "It 06050: loss = 5.63015010e-06 lambda = [-5.9961357  0.9986684]\n",
            "It 06100: loss = 1.67137728e-06 lambda = [-5.996317    0.99862087]\n",
            "It 06150: loss = 1.73132707e-06 lambda = [-5.996437    0.99865234]\n",
            "It 06200: loss = 9.94420589e-06 lambda = [-5.9961905   0.99884725]\n",
            "It 06250: loss = 4.37754497e-05 lambda = [-5.996392    0.99864215]\n",
            "It 06300: loss = 1.63841423e-06 lambda = [-5.9965825   0.99866074]\n",
            "It 06350: loss = 4.58164577e-04 lambda = [-5.997264    0.99799937]\n",
            "It 06400: loss = 4.16606508e-06 lambda = [-5.996754   0.9985664]\n",
            "It 06450: loss = 9.65224899e-06 lambda = [-5.996365   0.9986481]\n",
            "It 06500: loss = 2.41626481e-06 lambda = [-5.99663    0.9987838]\n",
            "It 06550: loss = 2.04619628e-05 lambda = [-5.9964213  0.998617 ]\n",
            "It 06600: loss = 1.79270432e-06 lambda = [-5.9967985  0.9986264]\n",
            "It 06650: loss = 1.46121265e-05 lambda = [-5.996711   0.9987619]\n",
            "It 06700: loss = 9.32991679e-06 lambda = [-5.9966645   0.99890757]\n",
            "It 06750: loss = 1.52889822e-06 lambda = [-5.9968476   0.99883807]\n",
            "It 06800: loss = 1.03889324e-03 lambda = [-5.9976625   0.99785465]\n",
            "It 06850: loss = 1.62893377e-06 lambda = [-5.996999   0.9986863]\n",
            "It 06900: loss = 3.43052845e-04 lambda = [-5.9966955  0.9988011]\n",
            "It 06950: loss = 1.95834923e-06 lambda = [-5.99686    0.9989149]\n",
            "It 07000: loss = 1.38198823e-06 lambda = [-5.997021   0.9988973]\n",
            "It 07050: loss = 1.36622111e-06 lambda = [-5.997074   0.9989123]\n",
            "It 07100: loss = 1.35203345e-06 lambda = [-5.997122   0.9989287]\n",
            "It 07150: loss = 1.33828905e-06 lambda = [-5.9971695   0.99894524]\n",
            "It 07200: loss = 1.32492005e-06 lambda = [-5.997217    0.99896145]\n",
            "It 07250: loss = 1.31182833e-06 lambda = [-5.997265   0.9989776]\n",
            "It 07300: loss = 1.29881630e-06 lambda = [-5.9973125  0.9989939]\n",
            "It 07350: loss = 1.28611714e-06 lambda = [-5.99736  0.99901]\n",
            "It 07400: loss = 1.27365945e-06 lambda = [-5.997406    0.99902624]\n",
            "It 07450: loss = 1.26111831e-06 lambda = [-5.997448   0.9990422]\n",
            "It 07500: loss = 1.24858127e-06 lambda = [-5.9974875  0.9990568]\n",
            "It 07550: loss = 1.23615337e-06 lambda = [-5.997524  0.999071]\n",
            "It 07600: loss = 1.22344431e-06 lambda = [-5.997559   0.9990848]\n",
            "It 07650: loss = 1.21130529e-06 lambda = [-5.997595  0.999098]\n",
            "It 07700: loss = 1.19892525e-06 lambda = [-5.99763    0.9991111]\n",
            "It 07750: loss = 1.18643629e-06 lambda = [-5.9976664   0.99912447]\n",
            "It 07800: loss = 1.17436412e-06 lambda = [-5.997699    0.99913746]\n",
            "It 07850: loss = 1.16190290e-06 lambda = [-5.997732   0.9991502]\n",
            "It 07900: loss = 1.14949989e-06 lambda = [-5.9977655  0.999163 ]\n",
            "It 07950: loss = 1.13720716e-06 lambda = [-5.9977994  0.9991758]\n",
            "It 08000: loss = 1.12491011e-06 lambda = [-5.9978323  0.9991886]\n",
            "It 08050: loss = 1.11289785e-06 lambda = [-5.997866   0.9992013]\n",
            "It 08100: loss = 1.10047972e-06 lambda = [-5.9978986   0.99921435]\n",
            "It 08150: loss = 1.08828885e-06 lambda = [-5.997932    0.99922734]\n",
            "It 08200: loss = 1.07585436e-06 lambda = [-5.997966    0.99923986]\n",
            "It 08250: loss = 1.06374603e-06 lambda = [-5.997998    0.99925274]\n",
            "It 08300: loss = 1.05142306e-06 lambda = [-5.998032   0.9992655]\n",
            "It 08350: loss = 1.03926641e-06 lambda = [-5.998065   0.9992785]\n",
            "It 08400: loss = 1.02704348e-06 lambda = [-5.9980974   0.99929106]\n",
            "It 08450: loss = 8.05986201e-05 lambda = [-5.9979506   0.99926454]\n",
            "It 08500: loss = 1.33539197e-06 lambda = [-5.998077   0.9992809]\n",
            "It 08550: loss = 5.09069578e-05 lambda = [-5.9978642  0.9995328]\n",
            "It 08600: loss = 1.17066804e-06 lambda = [-5.998209    0.99927515]\n",
            "It 08650: loss = 9.95248570e-07 lambda = [-5.998177    0.99931955]\n",
            "It 08700: loss = 9.68688369e-07 lambda = [-5.998201    0.99933547]\n",
            "It 08750: loss = 3.12269299e-06 lambda = [-5.99828   0.999303]\n",
            "It 08800: loss = 1.14576346e-06 lambda = [-5.9982963   0.99938345]\n",
            "It 08850: loss = 1.16707179e-05 lambda = [-5.99815    0.9994188]\n",
            "It 08900: loss = 1.36206836e-06 lambda = [-5.9982786   0.99934447]\n",
            "It 08950: loss = 9.30079068e-07 lambda = [-5.998292   0.9993695]\n",
            "It 09000: loss = 4.34630874e-06 lambda = [-5.998264    0.99929947]\n",
            "It 09050: loss = 9.66778657e-07 lambda = [-5.99828     0.99936914]\n",
            "It 09100: loss = 8.98321844e-07 lambda = [-5.998315    0.99938804]\n",
            "It 09150: loss = 1.62691867e-05 lambda = [-5.9984126  0.9993043]\n",
            "It 09200: loss = 1.00075783e-06 lambda = [-5.9984045  0.9993957]\n",
            "It 09250: loss = 1.39205586e-04 lambda = [-5.9985857  0.9992277]\n",
            "It 09300: loss = 2.24222072e-06 lambda = [-5.9983535   0.99941385]\n",
            "It 09350: loss = 8.53711640e-07 lambda = [-5.998388   0.9994162]\n",
            "It 09400: loss = 8.36411516e-07 lambda = [-5.9984217  0.9994294]\n",
            "It 09450: loss = 3.16138990e-04 lambda = [-5.9978642   0.99997467]\n",
            "It 09500: loss = 1.45714080e-06 lambda = [-5.9985366  0.9993941]\n",
            "It 09550: loss = 8.12597762e-07 lambda = [-5.9984837  0.9994424]\n",
            "It 09600: loss = 2.87271064e-06 lambda = [-5.998505   0.9994513]\n",
            "It 09650: loss = 2.64444157e-06 lambda = [-5.9984446   0.99950176]\n",
            "It 09700: loss = 7.92678634e-07 lambda = [-5.998499   0.9994709]\n",
            "It 09750: loss = 7.75896751e-07 lambda = [-5.9985337  0.9994741]\n",
            "It 09800: loss = 7.65634297e-07 lambda = [-5.9985604   0.99948347]\n",
            "It 09850: loss = 3.15018151e-05 lambda = [-5.998702   0.9992569]\n",
            "It 09900: loss = 8.70467943e-07 lambda = [-5.998576    0.99947095]\n",
            "It 09950: loss = 7.42867940e-07 lambda = [-5.9985847  0.9994916]\n",
            "It 10000: loss = 1.05641802e-05 lambda = [-5.9984713  0.9995435]\n",
            "It 10050: loss = 8.82617258e-07 lambda = [-5.9986057   0.99951774]\n",
            "It 10100: loss = 7.32788749e-07 lambda = [-5.998649    0.99951273]\n",
            "It 10150: loss = 1.37558445e-05 lambda = [-5.9986444  0.999493 ]\n",
            "It 10200: loss = 7.64874017e-07 lambda = [-5.9986725  0.9995025]\n",
            "It 10250: loss = 9.44666681e-06 lambda = [-5.9986744  0.9995283]\n",
            "It 10300: loss = 1.48582660e-06 lambda = [-5.998642   0.9995885]\n",
            "It 10350: loss = 6.98252791e-07 lambda = [-5.998703    0.99955136]\n",
            "It 10400: loss = 1.07883343e-05 lambda = [-5.9988823   0.99933404]\n",
            "It 10450: loss = 7.70046825e-07 lambda = [-5.99873    0.9995432]\n",
            "It 10500: loss = 6.52363497e-07 lambda = [-5.9987435  0.999556 ]\n",
            "It 10550: loss = 9.88512547e-05 lambda = [-5.9986978  0.999505 ]\n",
            "It 10600: loss = 8.67067399e-07 lambda = [-5.9987283  0.9995916]\n",
            "It 10650: loss = 2.87002194e-06 lambda = [-5.99882     0.99951285]\n",
            "It 10700: loss = 7.16504246e-07 lambda = [-5.9987955  0.9995773]\n",
            "It 10750: loss = 6.39877442e-07 lambda = [-5.9988055   0.99958974]\n",
            "It 10800: loss = 1.17462150e-05 lambda = [-5.9989786   0.99939907]\n",
            "It 10850: loss = 7.57325906e-05 lambda = [-5.9988403  0.999561 ]\n",
            "It 10900: loss = 1.30711851e-06 lambda = [-5.998823   0.9996093]\n",
            "It 10950: loss = 5.97050018e-07 lambda = [-5.998861   0.9996028]\n",
            "It 11000: loss = 4.45491823e-05 lambda = [-5.9990664  0.9993504]\n",
            "It 11050: loss = 8.29210057e-06 lambda = [-5.99887    0.9996332]\n",
            "It 11100: loss = 1.39922338e-06 lambda = [-5.9988775   0.99963105]\n",
            "It 11150: loss = 1.05706195e-05 lambda = [-5.998845   0.9996234]\n",
            "It 11200: loss = 6.93137849e-07 lambda = [-5.998901    0.99962336]\n",
            "It 11250: loss = 1.06148163e-05 lambda = [-5.9988427  0.9996857]\n",
            "It 11300: loss = 3.86612228e-05 lambda = [-5.998991   0.9995901]\n",
            "It 11350: loss = 1.36523181e-06 lambda = [-5.9989195  0.9996662]\n",
            "It 11400: loss = 5.45187561e-07 lambda = [-5.998966    0.99964964]\n",
            "It 11450: loss = 6.41266379e-05 lambda = [-5.9988885  0.9996311]\n",
            "It 11500: loss = 3.40472138e-06 lambda = [-5.9990063  0.9995933]\n",
            "It 11550: loss = 2.20319657e-06 lambda = [-5.999014  0.999674]\n",
            "It 11600: loss = 6.62525053e-07 lambda = [-5.999038   0.9996572]\n",
            "It 11650: loss = 5.02943863e-07 lambda = [-5.9990582   0.99968076]\n",
            "It 11700: loss = 2.35578831e-04 lambda = [-5.9991455  0.9995317]\n",
            "It 11750: loss = 6.77364085e-07 lambda = [-5.9990263  0.9996928]\n",
            "It 11800: loss = 4.83463396e-07 lambda = [-5.999074    0.99969935]\n",
            "It 11850: loss = 2.24998497e-04 lambda = [-5.9985814  1.0001874]\n",
            "It 11900: loss = 5.22050129e-07 lambda = [-5.999216   0.9996325]\n",
            "It 11950: loss = 4.68428141e-07 lambda = [-5.999147   0.9997122]\n",
            "It 12000: loss = 3.16085425e-06 lambda = [-5.999158    0.99971795]\n",
            "It 12050: loss = 2.71625345e-06 lambda = [-5.9991064  0.9997711]\n",
            "It 12100: loss = 4.66907636e-07 lambda = [-5.9991713  0.9997436]\n",
            "It 12150: loss = 4.43934709e-07 lambda = [-5.9992013  0.9997398]\n",
            "It 12200: loss = 9.24603046e-06 lambda = [-5.999331   0.9996337]\n",
            "It 12250: loss = 5.50826826e-07 lambda = [-5.999232    0.99974793]\n",
            "It 12300: loss = 3.99659621e-06 lambda = [-5.99924    0.9997575]\n",
            "It 12350: loss = 3.82113103e-06 lambda = [-5.9992003   0.99981564]\n",
            "It 12400: loss = 4.39267723e-07 lambda = [-5.999274   0.9997835]\n",
            "It 12450: loss = 4.10817648e-07 lambda = [-5.9993     0.9997819]\n",
            "It 12500: loss = 2.78020634e-05 lambda = [-5.9992228   0.99982494]\n",
            "It 12550: loss = 6.39083510e-07 lambda = [-5.9993215   0.99978566]\n",
            "It 12600: loss = 2.15156228e-06 lambda = [-5.999299   0.9998203]\n",
            "It 12650: loss = 4.63398720e-07 lambda = [-5.999356    0.99981743]\n",
            "It 12700: loss = 3.95865726e-07 lambda = [-5.999381    0.99981475]\n",
            "It 12750: loss = 4.89180411e-06 lambda = [-5.999259    0.99983376]\n",
            "It 12800: loss = 1.06877796e-05 lambda = [-5.999449    0.99971163]\n",
            "It 12850: loss = 1.98070165e-06 lambda = [-5.999439   0.9998772]\n",
            "It 12900: loss = 3.78332658e-07 lambda = [-5.999479    0.99985874]\n",
            "It 12950: loss = 3.82741177e-07 lambda = [-5.9994926   0.99985534]\n",
            "It 13000: loss = 2.01246803e-06 lambda = [-5.999662  0.999757]\n",
            "It 13050: loss = 4.01275372e-07 lambda = [-5.999529   0.9998754]\n",
            "It 13100: loss = 7.16197292e-07 lambda = [-5.9995303  0.9998906]\n",
            "It 13150: loss = 5.46477668e-06 lambda = [-5.9995484   0.99984914]\n",
            "It 13200: loss = 3.95794757e-07 lambda = [-5.9995456  0.9998961]\n",
            "It 13250: loss = 9.17793659e-05 lambda = [-5.9997106   0.99968785]\n",
            "It 13300: loss = 1.51370969e-05 lambda = [-5.999644    0.99985474]\n",
            "It 13350: loss = 4.67136488e-07 lambda = [-5.999597   0.9999317]\n",
            "It 13400: loss = 3.55447128e-07 lambda = [-5.9996395   0.99993277]\n",
            "It 13450: loss = 1.04921937e-05 lambda = [-5.9995766  0.9999496]\n",
            "It 13500: loss = 8.23304508e-05 lambda = [-5.999903    0.99968094]\n",
            "It 13550: loss = 4.96407324e-07 lambda = [-5.9997096  0.9999527]\n",
            "It 13600: loss = 6.33510945e-06 lambda = [-5.9997935   0.99988663]\n",
            "It 13650: loss = 5.90455954e-07 lambda = [-5.9997354  0.9999123]\n",
            "It 13700: loss = 2.03894742e-05 lambda = [-5.999768   0.9999673]\n",
            "It 13750: loss = 3.26374476e-07 lambda = [-5.999802   1.0000113]\n",
            "It 13800: loss = 3.19317678e-07 lambda = [-5.9998274  1.0000008]\n",
            "It 13850: loss = 1.98053549e-05 lambda = [-5.999996   0.9997459]\n",
            "It 13900: loss = 3.40917069e-07 lambda = [-5.999802    0.99999326]\n",
            "It 13950: loss = 4.39035261e-07 lambda = [-5.9998336  1.0000086]\n",
            "It 14000: loss = 1.00176317e-06 lambda = [-5.9998555  1.0000778]\n",
            "It 14050: loss = 3.17004293e-07 lambda = [-5.9998856  1.0000614]\n",
            "It 14100: loss = 3.07195876e-07 lambda = [-5.9999094  1.0000509]\n",
            "It 14150: loss = 3.02996625e-07 lambda = [-5.9999156  1.0000458]\n",
            "It 14200: loss = 2.99280771e-07 lambda = [-5.9999156  1.0000412]\n",
            "It 14250: loss = 2.95969130e-07 lambda = [-5.9999156  1.0000373]\n",
            "It 14300: loss = 2.92776946e-07 lambda = [-5.9999156  1.0000339]\n",
            "It 14350: loss = 2.89736562e-07 lambda = [-5.9999156  1.0000308]\n",
            "It 14400: loss = 2.86742846e-07 lambda = [-5.9999156  1.0000279]\n",
            "It 14450: loss = 2.83796368e-07 lambda = [-5.9999104  1.0000247]\n",
            "It 14500: loss = 2.80938309e-07 lambda = [-5.9999027  1.000021 ]\n",
            "It 14550: loss = 2.78134593e-07 lambda = [-5.999893   1.0000162]\n",
            "It 14600: loss = 2.75312431e-07 lambda = [-5.9998817  1.000011 ]\n",
            "It 14650: loss = 2.72619275e-07 lambda = [-5.9998703  1.0000054]\n",
            "It 14700: loss = 2.69872885e-07 lambda = [-5.999858  1.      ]\n",
            "It 14750: loss = 2.67267922e-07 lambda = [-5.999847    0.99999434]\n",
            "It 14800: loss = 2.64593524e-07 lambda = [-5.999834   0.9999886]\n",
            "It 14850: loss = 2.61930836e-07 lambda = [-5.9998217  0.9999829]\n",
            "It 14900: loss = 2.59335422e-07 lambda = [-5.9998097   0.99997735]\n",
            "It 14950: loss = 2.56814275e-07 lambda = [-5.9997983   0.99997187]\n",
            "It 15000: loss = 2.54197573e-07 lambda = [-5.999787    0.99996656]\n",
            "It 15050: loss = 2.51780648e-07 lambda = [-5.999776    0.99996126]\n",
            "It 15100: loss = 2.49201690e-07 lambda = [-5.9997654  0.9999562]\n",
            "It 15150: loss = 2.46693105e-07 lambda = [-5.999754   0.9999513]\n",
            "It 15200: loss = 2.44223315e-07 lambda = [-5.999744    0.99994636]\n",
            "It 15250: loss = 2.41736586e-07 lambda = [-5.999734   0.9999419]\n",
            "It 15300: loss = 2.39285328e-07 lambda = [-5.9997253  0.9999373]\n",
            "It 15350: loss = 2.36995973e-07 lambda = [-5.999715    0.99993306]\n",
            "It 15400: loss = 2.34543521e-07 lambda = [-5.999705   0.9999285]\n",
            "It 15450: loss = 2.32197380e-07 lambda = [-5.999696    0.99992406]\n",
            "It 15500: loss = 2.65869903e-06 lambda = [-5.999631   0.9999753]\n",
            "It 15550: loss = 4.02943897e-07 lambda = [-5.999715   0.9998735]\n",
            "It 15600: loss = 4.05099968e-07 lambda = [-5.999669   0.9999197]\n",
            "It 15650: loss = 1.14644217e-06 lambda = [-5.9996667  0.9999316]\n",
            "It 15700: loss = 2.24488844e-07 lambda = [-5.9996834  0.9999256]\n",
            "It 15750: loss = 2.23345097e-07 lambda = [-5.999687   0.9999241]\n",
            "It 15800: loss = 3.32298191e-06 lambda = [-5.999745    0.99988735]\n",
            "It 15850: loss = 8.27635176e-07 lambda = [-5.9997354  0.9998861]\n",
            "It 15900: loss = 3.36640966e-07 lambda = [-5.999694    0.99993205]\n",
            "It 15950: loss = 2.16067320e-07 lambda = [-5.999704   0.9999303]\n",
            "It 16000: loss = 1.54923066e-06 lambda = [-5.9996734   0.99996233]\n",
            "It 16050: loss = 4.18954215e-07 lambda = [-5.9997015   0.99988693]\n",
            "It 16100: loss = 2.15505167e-07 lambda = [-5.9996924   0.99992985]\n",
            "It 16150: loss = 2.13255717e-07 lambda = [-5.9997106  0.9999375]\n",
            "It 16200: loss = 4.28565772e-06 lambda = [-5.9996796  1.0000035]\n",
            "It 16250: loss = 2.31450983e-07 lambda = [-5.9997535  0.9999507]\n",
            "It 16300: loss = 2.07333102e-07 lambda = [-5.999753    0.99994934]\n",
            "It 16350: loss = 2.05307515e-07 lambda = [-5.99975    0.9999474]\n",
            "It 16400: loss = 2.73416958e-07 lambda = [-5.999784   0.9999023]\n",
            "It 16450: loss = 3.03897110e-07 lambda = [-5.999779    0.99995244]\n",
            "It 16500: loss = 8.99537372e-06 lambda = [-5.9997115   0.99997765]\n",
            "It 16550: loss = 2.51475768e-07 lambda = [-5.999758   0.9999442]\n",
            "It 16600: loss = 1.99724866e-07 lambda = [-5.9997597  0.999954 ]\n",
            "It 16650: loss = 1.98069984e-07 lambda = [-5.999763   0.9999543]\n",
            "It 16700: loss = 5.90332775e-06 lambda = [-5.99978    0.9998959]\n",
            "It 16750: loss = 1.97295634e-07 lambda = [-5.9997478   0.99994934]\n",
            "It 16800: loss = 1.65411475e-05 lambda = [-5.9996552  1.0000479]\n",
            "It 16850: loss = 2.71047071e-07 lambda = [-5.9997926  0.9999656]\n",
            "It 16900: loss = 1.93658579e-07 lambda = [-5.999795    0.99996567]\n",
            "It 16950: loss = 1.93464942e-07 lambda = [-5.999793   0.9999664]\n",
            "It 17000: loss = 5.04673608e-06 lambda = [-5.999825   0.9999015]\n",
            "It 17050: loss = 2.33120275e-07 lambda = [-5.9997783  0.9999573]\n",
            "It 17100: loss = 1.96806354e-06 lambda = [-5.999772    0.99999624]\n",
            "It 17150: loss = 1.89417023e-07 lambda = [-5.9998064   0.99997425]\n",
            "It 17200: loss = 1.86005011e-07 lambda = [-5.999811   0.9999719]\n",
            "It 17250: loss = 8.32008300e-05 lambda = [-6.000053   0.9997142]\n",
            "It 17300: loss = 5.81277789e-07 lambda = [-5.99979     0.99996084]\n",
            "It 17350: loss = 9.49440800e-06 lambda = [-5.9998326  0.9999289]\n",
            "It 17400: loss = 5.58645638e-07 lambda = [-5.999802    0.99999267]\n",
            "It 17450: loss = 1.83728403e-07 lambda = [-5.999826    0.99998033]\n",
            "It 17500: loss = 1.80517020e-07 lambda = [-5.999831    0.99997985]\n",
            "It 17550: loss = 2.55317104e-07 lambda = [-5.9998393  0.9999701]\n",
            "It 17600: loss = 1.15715113e-06 lambda = [-5.9998355  1.0000082]\n",
            "It 17650: loss = 1.76988237e-06 lambda = [-5.9998326  0.9999857]\n",
            "It 17700: loss = 2.40782271e-07 lambda = [-5.9998355   0.99998635]\n",
            "It 17750: loss = 1.02596086e-05 lambda = [-5.9998913  0.9999092]\n",
            "It 17800: loss = 2.54956319e-07 lambda = [-5.999831  0.999981]\n",
            "It 17850: loss = 2.45201522e-06 lambda = [-5.999785   1.0000362]\n",
            "It 17900: loss = 8.49799733e-07 lambda = [-5.9998503  1.0000052]\n",
            "It 17950: loss = 1.34301672e-05 lambda = [-5.999797   1.0000212]\n",
            "It 18000: loss = 2.12380115e-07 lambda = [-5.99985     0.99998266]\n",
            "It 18050: loss = 1.71797367e-07 lambda = [-5.999854   0.9999894]\n",
            "It 18100: loss = 2.64880123e-06 lambda = [-5.9998055  1.0000455]\n",
            "It 18150: loss = 6.31826140e-07 lambda = [-5.9998493   0.99999344]\n",
            "It 18200: loss = 1.42166300e-05 lambda = [-5.999828   1.0000036]\n",
            "It 18250: loss = 2.55346748e-07 lambda = [-5.999864    0.99999726]\n",
            "It 18300: loss = 1.67776335e-07 lambda = [-5.999872   0.9999965]\n",
            "It 18350: loss = 1.98036241e-06 lambda = [-5.9999256   0.99994546]\n",
            "It 18400: loss = 1.11322572e-06 lambda = [-5.999874   0.9999849]\n",
            "It 18450: loss = 8.94653226e-07 lambda = [-5.9998655  0.999996 ]\n",
            "It 18500: loss = 1.80298343e-07 lambda = [-5.9998646  1.0000082]\n",
            "It 18550: loss = 1.69334029e-07 lambda = [-5.999882   1.0000021]\n",
            "It 18600: loss = 1.62958102e-07 lambda = [-5.9998875  1.0000013]\n",
            "It 18650: loss = 2.38703842e-06 lambda = [-5.999886   1.0000026]\n",
            "It 18700: loss = 8.24457175e-07 lambda = [-5.9998612  1.0000255]\n",
            "It 18750: loss = 9.14143357e-07 lambda = [-5.99988    1.0000196]\n",
            "It 18800: loss = 1.98704925e-07 lambda = [-5.9999056   0.99999744]\n",
            "It 18850: loss = 1.66958978e-06 lambda = [-5.9999447   0.99996114]\n",
            "It 18900: loss = 1.65803840e-07 lambda = [-5.9998984  1.0000063]\n",
            "It 18950: loss = 7.84669112e-07 lambda = [-5.9999013  1.0000021]\n",
            "It 19000: loss = 5.37110282e-07 lambda = [-5.999882   1.0000119]\n",
            "It 19050: loss = 1.76448646e-06 lambda = [-5.999946    0.99996024]\n",
            "It 19100: loss = 6.51642893e-07 lambda = [-5.999902   1.0000168]\n",
            "It 19150: loss = 1.61055581e-07 lambda = [-5.99991    1.0000058]\n",
            "It 19200: loss = 9.91162051e-06 lambda = [-5.9998784  1.000037 ]\n",
            "It 19250: loss = 1.99236794e-07 lambda = [-5.999895   1.0000045]\n",
            "It 19300: loss = 1.50720075e-06 lambda = [-5.9999223  0.9999773]\n",
            "It 19350: loss = 1.84783417e-07 lambda = [-5.999915   1.0000142]\n",
            "It 19400: loss = 1.52966322e-07 lambda = [-5.9999185  1.0000114]\n",
            "It 19450: loss = 3.17952872e-05 lambda = [-5.999868   1.0000559]\n",
            "It 19500: loss = 3.27391689e-07 lambda = [-5.999904   1.0000072]\n",
            "It 19550: loss = 8.68852749e-06 lambda = [-5.9998407  1.0000734]\n",
            "It 19600: loss = 1.53908772e-07 lambda = [-5.9999228  1.0000098]\n",
            "It 19650: loss = 1.56986587e-07 lambda = [-5.99992   1.000016]\n",
            "It 19700: loss = 2.24110227e-06 lambda = [-5.999992   0.9999422]\n",
            "It 19750: loss = 9.06332025e-06 lambda = [-5.999917    0.99999875]\n",
            "It 19800: loss = 2.18880047e-07 lambda = [-5.999913   1.0000165]\n",
            "It 19850: loss = 1.47515280e-07 lambda = [-5.999922   1.0000137]\n",
            "It 19900: loss = 1.44820578e-05 lambda = [-6.000045   0.9998709]\n",
            "It 19950: loss = 6.13294219e-07 lambda = [-5.9999437   0.99999815]\n",
            "It 20000: loss = 9.26423184e-07 lambda = [-5.999914   1.0000176]\n",
            "It 20050: loss = 1.69918098e-06 lambda = [-5.999914   1.0000222]\n",
            "It 20100: loss = 2.38431454e-07 lambda = [-5.9999266  1.0000026]\n",
            "It 20150: loss = 6.32423598e-06 lambda = [-5.999835   1.0000993]\n",
            "It 20200: loss = 2.97913812e-06 lambda = [-5.9999504   0.99998546]\n",
            "It 20250: loss = 1.99590588e-07 lambda = [-5.9999194  1.000016 ]\n",
            "It 20300: loss = 1.55176323e-07 lambda = [-5.9999294  1.0000137]\n",
            "It 20350: loss = 3.40922452e-06 lambda = [-5.999972    0.99997795]\n",
            "It 20400: loss = 2.38711655e-05 lambda = [-6.000059    0.99989015]\n",
            "It 20450: loss = 3.01530918e-07 lambda = [-5.999927   1.0000182]\n",
            "It 20500: loss = 2.74603991e-07 lambda = [-5.999921   1.0000261]\n",
            "It 20550: loss = 4.37211526e-07 lambda = [-5.9999146  1.0000141]\n",
            "It 20600: loss = 1.01732849e-06 lambda = [-5.9999127  1.0000215]\n",
            "It 20650: loss = 3.65712822e-07 lambda = [-5.999924  1.000041]\n",
            "It 20700: loss = 1.41174937e-07 lambda = [-5.999942   1.0000213]\n",
            "It 20750: loss = 1.83905183e-06 lambda = [-5.9998527  1.0000787]\n",
            "It 20800: loss = 2.38761658e-07 lambda = [-5.9999375  1.0000002]\n",
            "It 20850: loss = 1.39479710e-07 lambda = [-5.9999294  1.0000161]\n",
            "It 20900: loss = 3.95053212e-06 lambda = [-5.9999223  1.0000101]\n",
            "It 20950: loss = 2.19266781e-07 lambda = [-5.9999304  1.000027 ]\n",
            "It 21000: loss = 1.36362573e-07 lambda = [-5.999941   1.0000198]\n",
            "It 21050: loss = 5.68983205e-06 lambda = [-6.000052   0.9998836]\n",
            "It 21100: loss = 2.50378434e-07 lambda = [-5.99994    1.0000128]\n",
            "It 21150: loss = 8.93120045e-07 lambda = [-5.9999185  1.0000203]\n",
            "It 21200: loss = 1.62663483e-07 lambda = [-5.9999304  1.0000257]\n",
            "It 21250: loss = 1.33814240e-07 lambda = [-5.9999423  1.0000191]\n",
            "It 21300: loss = 1.03590628e-05 lambda = [-5.999849   1.0000885]\n",
            "It 21350: loss = 2.45090337e-06 lambda = [-5.9999423  1.0000131]\n",
            "It 21400: loss = 4.53883956e-07 lambda = [-5.999936  1.000023]\n",
            "It 21450: loss = 1.40666543e-07 lambda = [-5.999942   1.0000196]\n",
            "It 21500: loss = 9.40901032e-07 lambda = [-5.9999323  1.0000124]\n",
            "It 21550: loss = 2.51339361e-06 lambda = [-5.9998837  1.0000765]\n",
            "It 21600: loss = 2.94225146e-07 lambda = [-5.99997     0.99999523]\n",
            "It 21650: loss = 1.33810801e-07 lambda = [-5.999947   1.0000163]\n",
            "It 21700: loss = 3.55474913e-06 lambda = [-5.9999037  1.0000176]\n",
            "It 21750: loss = 5.39019311e-07 lambda = [-5.999906   1.0000405]\n",
            "It 21800: loss = 4.73112692e-07 lambda = [-5.999966    0.99999994]\n",
            "It 21850: loss = 1.30483315e-07 lambda = [-5.9999466  1.0000196]\n",
            "It 21900: loss = 1.64739595e-05 lambda = [-5.9997907  1.000175 ]\n",
            "It 21950: loss = 6.77928881e-07 lambda = [-5.9999514  1.0000256]\n",
            "It 22000: loss = 9.27117071e-06 lambda = [-5.9999394  1.0000316]\n",
            "It 22050: loss = 1.99916840e-07 lambda = [-5.9999375  1.0000265]\n",
            "It 22100: loss = 1.28181256e-07 lambda = [-5.9999475  1.0000203]\n",
            "It 22150: loss = 1.57921079e-07 lambda = [-5.99995   1.000021]\n",
            "It 22200: loss = 2.37292852e-06 lambda = [-5.9999304  1.000025 ]\n",
            "It 22250: loss = 2.29699526e-05 lambda = [-5.9998074  1.0001439]\n",
            "It 22300: loss = 2.49489318e-07 lambda = [-5.9999633  1.0000066]\n",
            "It 22350: loss = 1.27431406e-07 lambda = [-5.9999523  1.0000175]\n",
            "It 22400: loss = 9.41820190e-07 lambda = [-5.9999356  1.0000196]\n",
            "It 22450: loss = 1.57682976e-07 lambda = [-5.999949   1.0000075]\n",
            "It 22500: loss = 1.38157702e-07 lambda = [-5.999949   1.0000212]\n",
            "It 22550: loss = 1.02020613e-06 lambda = [-5.9999495  1.0000122]\n",
            "It 22600: loss = 1.75551534e-07 lambda = [-5.9999566  1.0000174]\n",
            "It 22650: loss = 3.47926948e-06 lambda = [-5.999924  1.000049]\n",
            "It 22700: loss = 2.68661934e-05 lambda = [-5.999951   1.0000163]\n",
            "It 22750: loss = 2.46519107e-07 lambda = [-5.999945   1.0000277]\n",
            "It 22800: loss = 1.45303062e-07 lambda = [-5.9999514  1.000027 ]\n",
            "It 22850: loss = 4.37119388e-06 lambda = [-6.000015   0.9999527]\n",
            "It 22900: loss = 1.56112037e-05 lambda = [-5.999962   1.0000046]\n",
            "It 22950: loss = 1.84644122e-07 lambda = [-5.999952   1.0000241]\n",
            "It 23000: loss = 2.18922123e-05 lambda = [-5.99996    1.0000154]\n",
            "It 23050: loss = 1.59026604e-05 lambda = [-5.999823   1.0001516]\n",
            "Timeout is reached. Time elapsed: 100.0008397102356 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:65: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:66: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "It 22200: loss = 6.75186016e-07 lambda = [-5.999983   0.9999838]\n",
            "It 22250: loss = 8.15905821e-07 lambda = [-6.0000186   0.99990886]\n",
            "It 22300: loss = 9.27802830e-07 lambda = [-5.9999676  1.0000068]\n",
            "It 22350: loss = 6.71537009e-07 lambda = [-5.999989   0.9999885]\n",
            "It 22400: loss = 2.02010915e-06 lambda = [-5.9999948  0.9999782]\n",
            "It 22450: loss = 1.00423904e-06 lambda = [-5.999977   0.9999901]\n",
            "It 22500: loss = 5.22123128e-06 lambda = [-6.000014   0.9999526]\n",
            "It 22550: loss = 6.83922224e-07 lambda = [-5.99999    0.9999893]\n",
            "It 22600: loss = 6.59331477e-07 lambda = [-5.9999914  0.9999875]\n",
            "It 22650: loss = 2.69173070e-05 lambda = [-6.0000257  0.9998983]\n",
            "It 22700: loss = 7.78529056e-07 lambda = [-5.9999785  0.99999  ]\n",
            "It 22750: loss = 6.59545947e-07 lambda = [-5.9999833  0.999987 ]\n",
            "It 22800: loss = 7.43285909e-07 lambda = [-5.9999747  0.9999832]\n",
            "It 22850: loss = 6.71662690e-07 lambda = [-5.999983    0.99998546]\n",
            "It 22900: loss = 5.36189364e-05 lambda = [-6.000177   0.9997831]\n",
            "It 22950: loss = 1.31862657e-06 lambda = [-5.9999895  0.9999832]\n",
            "It 23000: loss = 6.48968069e-07 lambda = [-5.999984   0.9999891]\n",
            "It 23050: loss = 6.45038199e-07 lambda = [-5.9999876  0.9999848]\n",
            "It 23100: loss = 5.32289187e-06 lambda = [-5.9999766   0.99996287]\n",
            "It 23150: loss = 6.86136048e-07 lambda = [-5.999975   0.9999852]\n",
            "Timeout is reached. Time elapsed: 100.00226354598999 seconds\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration: 4 Initial lambda: [1.0, -6.0]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "L-BFGS\n",
            "\n",
            "It 00000: loss = 2.62451828e-01 lambda = [ 0.999974  -5.9999976]\n",
            "It 00050: loss = 1.33587971e-01 lambda = [ 0.6158843 -5.9637675]\n",
            "It 00100: loss = 1.10190108e-01 lambda = [-0.5371712 -5.6394973]\n",
            "It 00150: loss = 1.01149857e-01 lambda = [-1.6642598 -5.0729065]\n",
            "It 00200: loss = 9.51577500e-02 lambda = [-2.0327592 -4.6812973]\n",
            "It 00250: loss = 9.13107395e-02 lambda = [-1.8610007 -4.294241 ]\n",
            "It 00300: loss = 8.67771655e-02 lambda = [-1.7267295 -3.6155057]\n",
            "It 00350: loss = 8.28959122e-02 lambda = [-1.8213422 -2.8406353]\n",
            "It 00400: loss = 7.98747763e-02 lambda = [-2.3691065 -2.4254942]\n",
            "It 00450: loss = 7.68351927e-02 lambda = [-3.0560544 -2.0679157]\n",
            "It 00500: loss = 7.53534511e-02 lambda = [-3.2215085 -1.9413904]\n",
            "It 00550: loss = 7.44738504e-02 lambda = [-3.2284548 -1.7965181]\n",
            "It 00600: loss = 7.34272450e-02 lambda = [-3.1857681 -1.5927554]\n",
            "It 00650: loss = 7.21452907e-02 lambda = [-3.2276711 -1.3971035]\n",
            "It 00700: loss = 7.08595440e-02 lambda = [-3.3847108 -1.2099725]\n",
            "It 00750: loss = 6.99284971e-02 lambda = [-3.5458865 -1.2034681]\n",
            "It 00800: loss = 6.91778064e-02 lambda = [-3.6712267 -1.0960909]\n",
            "It 00850: loss = 6.87229782e-02 lambda = [-3.7202148 -1.0481215]\n",
            "It 00900: loss = 6.83185160e-02 lambda = [-3.7246475 -1.0389098]\n",
            "It 00950: loss = 6.78982139e-02 lambda = [-3.687332  -1.0149573]\n",
            "It 01000: loss = 6.73953146e-02 lambda = [-3.6571207 -0.9981986]\n",
            "It 01050: loss = 6.71494007e-02 lambda = [-3.6841712 -1.000615 ]\n",
            "It 01100: loss = 6.69060573e-02 lambda = [-3.712936  -1.0116141]\n",
            "It 01150: loss = 6.66865781e-02 lambda = [-3.7240353 -1.0030042]\n",
            "It 01200: loss = 6.63844422e-02 lambda = [-3.7168334 -1.001668 ]\n",
            "It 01250: loss = 6.59373552e-02 lambda = [-3.68515   -0.9756738]\n",
            "It 01300: loss = 6.55577332e-02 lambda = [-3.6850808 -0.9682194]\n",
            "It 01350: loss = 6.51791692e-02 lambda = [-3.6924286 -0.9679439]\n",
            "It 01400: loss = 6.48086071e-02 lambda = [-3.71766   -0.9473782]\n",
            "It 01450: loss = 6.44962117e-02 lambda = [-3.7443068  -0.93020564]\n",
            "It 01500: loss = 6.41861632e-02 lambda = [-3.7741437 -0.9423158]\n",
            "It 01550: loss = 6.39460310e-02 lambda = [-3.772619   -0.95784205]\n",
            "It 01600: loss = 6.37280121e-02 lambda = [-3.759859  -0.9586349]\n",
            "It 01650: loss = 6.35039359e-02 lambda = [-3.7511904 -0.9460429]\n",
            "It 01700: loss = 6.32928759e-02 lambda = [-3.757462   -0.94372356]\n",
            "It 01750: loss = 6.31330013e-02 lambda = [-3.758084  -0.9442396]\n",
            "It 01800: loss = 6.30189031e-02 lambda = [-3.759286  -0.9411876]\n",
            "It 01850: loss = 6.29214719e-02 lambda = [-3.7620995  -0.92213607]\n",
            "It 01900: loss = 6.28313199e-02 lambda = [-3.7722468 -0.9290392]\n",
            "It 01950: loss = 6.27051294e-02 lambda = [-3.7947083 -0.9396757]\n",
            "It 02000: loss = 6.25998229e-02 lambda = [-3.7948513 -0.9286626]\n",
            "Timeout is reached. Time elapsed: 100.0397458076477\n",
            "\n",
            "\n",
            "SGD\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: loss = 3.70772004e-01 lambda = [ 0.9999745 -5.9999976]\n",
            "It 00050: loss = 2.32966065e-01 lambda = [ 0.9999261 -5.999978 ]\n",
            "It 00100: loss = 2.30515108e-01 lambda = [ 0.9999548 -5.9999776]\n",
            "It 00150: loss = 2.26620018e-01 lambda = [ 0.9999173 -5.9999776]\n",
            "It 00200: loss = 2.19832286e-01 lambda = [ 0.9996864 -5.9999948]\n",
            "It 00250: loss = 2.08873644e-01 lambda = [ 0.9989379 -6.000101 ]\n",
            "It 00300: loss = 1.95946977e-01 lambda = [ 0.9972156 -6.00045  ]\n",
            "It 00350: loss = 1.85896397e-01 lambda = [ 0.99432296 -6.0011897 ]\n",
            "It 00400: loss = 1.79701373e-01 lambda = [ 0.9902998 -6.0023546]\n",
            "It 00450: loss = 1.75520658e-01 lambda = [ 0.98524636 -6.003911  ]\n",
            "It 00500: loss = 1.72006920e-01 lambda = [ 0.97929 -6.00579]\n",
            "It 00550: loss = 1.68583319e-01 lambda = [ 0.9725403 -6.0079045]\n",
            "It 00600: loss = 1.65152386e-01 lambda = [ 0.96509004 -6.01016   ]\n",
            "It 00650: loss = 1.61829054e-01 lambda = [ 0.9570379 -6.0124626]\n",
            "It 00700: loss = 1.58750102e-01 lambda = [ 0.94850045 -6.0147    ]\n",
            "It 00750: loss = 1.56000629e-01 lambda = [ 0.93960905 -6.0167584 ]\n",
            "It 00800: loss = 1.53606579e-01 lambda = [ 0.93049735 -6.0185447 ]\n",
            "It 00850: loss = 1.51549771e-01 lambda = [ 0.921289 -6.020005]\n",
            "It 00900: loss = 1.49788693e-01 lambda = [ 0.91209024 -6.0211344 ]\n",
            "It 00950: loss = 1.48275822e-01 lambda = [ 0.9029873 -6.02196  ]\n",
            "It 01000: loss = 1.46967590e-01 lambda = [ 0.89404774 -6.0225263 ]\n",
            "It 01050: loss = 1.45827115e-01 lambda = [ 0.8853217 -6.022884 ]\n",
            "It 01100: loss = 1.44824147e-01 lambda = [ 0.8768439 -6.023081 ]\n",
            "It 01150: loss = 1.43933788e-01 lambda = [ 0.86863536 -6.02316   ]\n",
            "It 01200: loss = 1.43135354e-01 lambda = [ 0.86070657 -6.0231586 ]\n",
            "It 01250: loss = 1.42411724e-01 lambda = [ 0.85306007 -6.023108  ]\n",
            "It 01300: loss = 1.41748875e-01 lambda = [ 0.8456932 -6.0230365]\n",
            "It 01350: loss = 1.41135424e-01 lambda = [ 0.83860004 -6.022965  ]\n",
            "It 01400: loss = 1.40562519e-01 lambda = [ 0.8317729 -6.0228934]\n",
            "It 01450: loss = 1.40023291e-01 lambda = [ 0.8252031 -6.0228386]\n",
            "It 01500: loss = 1.39512628e-01 lambda = [ 0.81888145 -6.0228057 ]\n",
            "It 01550: loss = 1.39026925e-01 lambda = [ 0.81279874 -6.022798  ]\n",
            "It 01600: loss = 1.38563573e-01 lambda = [ 0.8069454 -6.0228167]\n",
            "It 01650: loss = 1.38120785e-01 lambda = [ 0.8013132 -6.0228615]\n",
            "It 01700: loss = 1.37697279e-01 lambda = [ 0.79589325 -6.0229316 ]\n",
            "It 01750: loss = 1.37292221e-01 lambda = [ 0.79067695 -6.023025  ]\n",
            "It 01800: loss = 1.36904866e-01 lambda = [ 0.78565645 -6.0231385 ]\n",
            "It 01850: loss = 1.36534691e-01 lambda = [ 0.7808238 -6.0232673]\n",
            "It 01900: loss = 1.36181220e-01 lambda = [ 0.7761717 -6.0234103]\n",
            "It 01950: loss = 1.35843962e-01 lambda = [ 0.7716927 -6.0235662]\n",
            "It 02000: loss = 1.35522425e-01 lambda = [ 0.76738024 -6.023733  ]\n",
            "It 02050: loss = 1.35216147e-01 lambda = [ 0.76322764 -6.0239    ]\n",
            "It 02100: loss = 1.34924605e-01 lambda = [ 0.759229 -6.024067]\n",
            "It 02150: loss = 1.34647250e-01 lambda = [ 0.75537753 -6.024234  ]\n",
            "It 02200: loss = 1.34383574e-01 lambda = [ 0.75166774 -6.0244007 ]\n",
            "It 02250: loss = 1.34132981e-01 lambda = [ 0.7480942 -6.0245676]\n",
            "It 02300: loss = 1.33894920e-01 lambda = [ 0.74465173 -6.0247345 ]\n",
            "It 02350: loss = 1.33668825e-01 lambda = [ 0.74133503 -6.0249014 ]\n",
            "It 02400: loss = 1.33454144e-01 lambda = [ 0.73813945 -6.0250683 ]\n",
            "It 02450: loss = 1.33250296e-01 lambda = [ 0.7350602 -6.025235 ]\n",
            "It 02500: loss = 1.33056745e-01 lambda = [ 0.7320929 -6.025399 ]\n",
            "It 02550: loss = 1.32872939e-01 lambda = [ 0.72923326 -6.0255423 ]\n",
            "It 02600: loss = 1.32698417e-01 lambda = [ 0.72647715 -6.0256853 ]\n",
            "It 02650: loss = 1.32532641e-01 lambda = [ 0.72382057 -6.0258284 ]\n",
            "It 02700: loss = 1.32375151e-01 lambda = [ 0.72126  -6.025963]\n",
            "It 02750: loss = 1.32225499e-01 lambda = [ 0.7187918 -6.026082 ]\n",
            "It 02800: loss = 1.32083222e-01 lambda = [ 0.7164122 -6.0262012]\n",
            "It 02850: loss = 1.31947964e-01 lambda = [ 0.7141181 -6.0263205]\n",
            "It 02900: loss = 1.31819263e-01 lambda = [ 0.71190625 -6.026424  ]\n",
            "It 02950: loss = 1.31696820e-01 lambda = [ 0.7097736 -6.0265193]\n",
            "It 03000: loss = 1.31580248e-01 lambda = [ 0.70771724 -6.0266147 ]\n",
            "It 03050: loss = 1.31522462e-01 lambda = [ 0.70670694 -6.0266623 ]\n",
            "It 03100: loss = 1.31466195e-01 lambda = [ 0.7056969 -6.02671  ]\n",
            "It 03150: loss = 1.31410331e-01 lambda = [ 0.70468956 -6.0267577 ]\n",
            "It 03200: loss = 1.31354854e-01 lambda = [ 0.70368224 -6.0268054 ]\n",
            "It 03250: loss = 1.31299749e-01 lambda = [ 0.7026749 -6.026853 ]\n",
            "It 03300: loss = 1.31245017e-01 lambda = [ 0.7016676 -6.026901 ]\n",
            "It 03350: loss = 1.31190658e-01 lambda = [ 0.7006608 -6.0269485]\n",
            "It 03400: loss = 1.31136686e-01 lambda = [ 0.6996565 -6.026996 ]\n",
            "It 03450: loss = 1.31083086e-01 lambda = [ 0.69865215 -6.027044  ]\n",
            "It 03500: loss = 1.31029874e-01 lambda = [ 0.6976478 -6.0270915]\n",
            "It 03550: loss = 1.30977005e-01 lambda = [ 0.6966435 -6.027139 ]\n",
            "It 03600: loss = 1.30924493e-01 lambda = [ 0.6956397 -6.027187 ]\n",
            "It 03650: loss = 1.30872369e-01 lambda = [ 0.6946384 -6.0272346]\n",
            "It 03700: loss = 1.30820572e-01 lambda = [ 0.693637  -6.0272655]\n",
            "It 03750: loss = 1.30769148e-01 lambda = [ 0.69263566 -6.0272894 ]\n",
            "It 03800: loss = 1.30718082e-01 lambda = [ 0.6916343 -6.027313 ]\n",
            "It 03850: loss = 1.30667359e-01 lambda = [ 0.69063294 -6.027337  ]\n",
            "It 03900: loss = 1.30616993e-01 lambda = [ 0.6896344 -6.027361 ]\n",
            "It 03950: loss = 1.30566970e-01 lambda = [ 0.688636  -6.0273848]\n",
            "It 04000: loss = 1.30517259e-01 lambda = [ 0.6876376 -6.0274086]\n",
            "It 04050: loss = 1.30467892e-01 lambda = [ 0.68663925 -6.0274324 ]\n",
            "It 04100: loss = 1.30418867e-01 lambda = [ 0.6856409 -6.0274563]\n",
            "It 04150: loss = 1.30370170e-01 lambda = [ 0.6846441 -6.02748  ]\n",
            "It 04200: loss = 1.30321801e-01 lambda = [ 0.6836487 -6.027504 ]\n",
            "It 04250: loss = 1.30273744e-01 lambda = [ 0.6826533 -6.027528 ]\n",
            "It 04300: loss = 1.30226016e-01 lambda = [ 0.6816579 -6.0275517]\n",
            "It 04350: loss = 1.30178586e-01 lambda = [ 0.6806625 -6.0275755]\n",
            "It 04400: loss = 1.30131483e-01 lambda = [ 0.6796672 -6.0275993]\n",
            "It 04450: loss = 1.30084664e-01 lambda = [ 0.67867476 -6.027623  ]\n",
            "It 04500: loss = 1.30038172e-01 lambda = [ 0.67768234 -6.027647  ]\n",
            "It 04550: loss = 1.29991964e-01 lambda = [ 0.6766899 -6.027671 ]\n",
            "It 04600: loss = 1.29946038e-01 lambda = [ 0.6756975 -6.0276947]\n",
            "It 04650: loss = 1.29900426e-01 lambda = [ 0.6747051 -6.0277185]\n",
            "It 04700: loss = 1.29855067e-01 lambda = [ 0.6737135 -6.0277424]\n",
            "It 04750: loss = 1.29810020e-01 lambda = [ 0.67272407 -6.027766  ]\n",
            "It 04800: loss = 1.29765242e-01 lambda = [ 0.67173463 -6.02779   ]\n",
            "It 04850: loss = 1.29720733e-01 lambda = [ 0.6707452 -6.027814 ]\n",
            "It 04900: loss = 1.29676521e-01 lambda = [ 0.66975576 -6.0278378 ]\n",
            "It 04950: loss = 1.29632518e-01 lambda = [ 0.6687663 -6.0278482]\n",
            "It 05000: loss = 1.29588813e-01 lambda = [ 0.6677778 -6.0278482]\n",
            "It 05050: loss = 1.29545376e-01 lambda = [ 0.6667913 -6.0278482]\n",
            "It 05100: loss = 1.29502177e-01 lambda = [ 0.66580486 -6.0278482 ]\n",
            "It 05150: loss = 1.29459232e-01 lambda = [ 0.6648184 -6.0278482]\n",
            "It 05200: loss = 1.29416510e-01 lambda = [ 0.66383195 -6.0278482 ]\n",
            "It 05250: loss = 1.29374042e-01 lambda = [ 0.6628455 -6.0278482]\n",
            "It 05300: loss = 1.29331827e-01 lambda = [ 0.66185904 -6.0278482 ]\n",
            "It 05350: loss = 1.29289851e-01 lambda = [ 0.6608754 -6.0278482]\n",
            "It 05400: loss = 1.29248083e-01 lambda = [ 0.6598919 -6.0278482]\n",
            "It 05450: loss = 1.29206523e-01 lambda = [ 0.6589084 -6.0278482]\n",
            "It 05500: loss = 1.29165217e-01 lambda = [ 0.65792495 -6.0278482 ]\n",
            "It 05550: loss = 1.29124105e-01 lambda = [ 0.6569415 -6.0278482]\n",
            "It 05600: loss = 1.29083201e-01 lambda = [ 0.655958  -6.0278482]\n",
            "It 05650: loss = 1.29042521e-01 lambda = [ 0.65497565 -6.0278482 ]\n",
            "It 05700: loss = 1.29002050e-01 lambda = [ 0.65399516 -6.0278482 ]\n",
            "It 05750: loss = 1.28961772e-01 lambda = [ 0.65301466 -6.0278482 ]\n",
            "It 05800: loss = 1.28921658e-01 lambda = [ 0.65203416 -6.0278482 ]\n",
            "It 05850: loss = 1.28881797e-01 lambda = [ 0.65105367 -6.0278482 ]\n",
            "It 05900: loss = 1.28842086e-01 lambda = [ 0.6500732 -6.0278482]\n",
            "It 05950: loss = 1.28802553e-01 lambda = [ 0.6490927 -6.0278482]\n",
            "It 06000: loss = 1.28763229e-01 lambda = [ 0.6481138 -6.0278482]\n",
            "It 06050: loss = 1.28724083e-01 lambda = [ 0.6471363 -6.0278482]\n",
            "It 06100: loss = 1.28685102e-01 lambda = [ 0.64615875 -6.0278482 ]\n",
            "It 06150: loss = 1.28646299e-01 lambda = [ 0.64518124 -6.0278373 ]\n",
            "It 06200: loss = 1.28607646e-01 lambda = [ 0.6442037 -6.0278134]\n",
            "It 06250: loss = 1.28569156e-01 lambda = [ 0.6432262 -6.0277896]\n",
            "It 06300: loss = 1.28530830e-01 lambda = [ 0.6422487 -6.0277658]\n",
            "It 06350: loss = 1.28492668e-01 lambda = [ 0.6412717 -6.027742 ]\n",
            "It 06400: loss = 1.28454641e-01 lambda = [ 0.6402972 -6.027718 ]\n",
            "It 06450: loss = 1.28416792e-01 lambda = [ 0.63932264 -6.027694  ]\n",
            "It 06500: loss = 1.28379062e-01 lambda = [ 0.6383481 -6.0276704]\n",
            "It 06550: loss = 1.28341481e-01 lambda = [ 0.63737357 -6.0276465 ]\n",
            "It 06600: loss = 1.28304049e-01 lambda = [ 0.63639903 -6.0276227 ]\n",
            "It 06650: loss = 1.28266722e-01 lambda = [ 0.6354245 -6.027599 ]\n",
            "It 06700: loss = 1.28229558e-01 lambda = [ 0.63444996 -6.027575  ]\n",
            "It 06750: loss = 1.28192514e-01 lambda = [ 0.633477 -6.027551]\n",
            "It 06800: loss = 1.28155604e-01 lambda = [ 0.6325054 -6.0275273]\n",
            "It 06850: loss = 1.28118798e-01 lambda = [ 0.63153386 -6.0275035 ]\n",
            "It 06900: loss = 1.28082126e-01 lambda = [ 0.6305623 -6.0274796]\n",
            "It 06950: loss = 1.28045574e-01 lambda = [ 0.62959075 -6.027456  ]\n",
            "It 07000: loss = 1.28009140e-01 lambda = [ 0.6286192 -6.027432 ]\n",
            "It 07050: loss = 1.27990559e-01 lambda = [ 0.6281334 -6.027408 ]\n",
            "It 07100: loss = 1.27972409e-01 lambda = [ 0.62764764 -6.0273843 ]\n",
            "It 07150: loss = 1.27954274e-01 lambda = [ 0.62716186 -6.0273604 ]\n",
            "It 07200: loss = 1.27936184e-01 lambda = [ 0.6266761 -6.0273366]\n",
            "It 07250: loss = 1.27918109e-01 lambda = [ 0.6261903 -6.0273128]\n",
            "It 07300: loss = 1.27900064e-01 lambda = [ 0.6257045 -6.027289 ]\n",
            "It 07350: loss = 1.27882048e-01 lambda = [ 0.62521875 -6.027265  ]\n",
            "It 07400: loss = 1.27864033e-01 lambda = [ 0.624733 -6.027241]\n",
            "It 07450: loss = 1.27846062e-01 lambda = [ 0.6242472 -6.0272174]\n",
            "It 07500: loss = 1.27828121e-01 lambda = [ 0.6237614 -6.0271935]\n",
            "It 07550: loss = 1.27810195e-01 lambda = [ 0.62327564 -6.0271697 ]\n",
            "It 07600: loss = 1.27792299e-01 lambda = [ 0.62278986 -6.027146  ]\n",
            "It 07650: loss = 1.27774417e-01 lambda = [ 0.6223041 -6.027122 ]\n",
            "It 07700: loss = 1.27756536e-01 lambda = [ 0.62181956 -6.027098  ]\n",
            "It 07750: loss = 1.27738729e-01 lambda = [ 0.62133676 -6.0270743 ]\n",
            "It 07800: loss = 1.27720892e-01 lambda = [ 0.62085396 -6.0270505 ]\n",
            "It 07850: loss = 1.27703115e-01 lambda = [ 0.62037116 -6.0270267 ]\n",
            "It 07900: loss = 1.27685368e-01 lambda = [ 0.61988837 -6.027003  ]\n",
            "It 07950: loss = 1.27667621e-01 lambda = [ 0.61940557 -6.026979  ]\n",
            "It 08000: loss = 1.27649903e-01 lambda = [ 0.61892277 -6.026955  ]\n",
            "It 08050: loss = 1.27632216e-01 lambda = [ 0.61844   -6.0269313]\n",
            "It 08100: loss = 1.27614528e-01 lambda = [ 0.6179572 -6.0269074]\n",
            "It 08150: loss = 1.27596870e-01 lambda = [ 0.6174744 -6.0268836]\n",
            "It 08200: loss = 1.27579212e-01 lambda = [ 0.6169916 -6.0268598]\n",
            "It 08250: loss = 1.27561599e-01 lambda = [ 0.6165088 -6.026836 ]\n",
            "It 08300: loss = 1.27544001e-01 lambda = [ 0.616026 -6.026812]\n",
            "It 08350: loss = 1.27526447e-01 lambda = [ 0.6155432 -6.026788 ]\n",
            "It 08400: loss = 1.27508864e-01 lambda = [ 0.6150604 -6.0267644]\n",
            "It 08450: loss = 1.27491325e-01 lambda = [ 0.6145776 -6.0267406]\n",
            "It 08500: loss = 1.27473801e-01 lambda = [ 0.6140948 -6.0267167]\n",
            "It 08550: loss = 1.27456307e-01 lambda = [ 0.613612 -6.026693]\n",
            "It 08600: loss = 1.27438813e-01 lambda = [ 0.6131292 -6.026669 ]\n",
            "It 08650: loss = 1.27421349e-01 lambda = [ 0.6126464 -6.026645 ]\n",
            "It 08700: loss = 1.27403900e-01 lambda = [ 0.6121636 -6.0266213]\n",
            "It 08750: loss = 1.27386466e-01 lambda = [ 0.6116808 -6.0265975]\n",
            "It 08800: loss = 1.27369031e-01 lambda = [ 0.611198  -6.0265737]\n",
            "It 08850: loss = 1.27351627e-01 lambda = [ 0.6107152 -6.02655  ]\n",
            "It 08900: loss = 1.27334237e-01 lambda = [ 0.6102324 -6.026526 ]\n",
            "It 08950: loss = 1.27316877e-01 lambda = [ 0.6097496 -6.026502 ]\n",
            "It 09000: loss = 1.27299488e-01 lambda = [ 0.6092668 -6.0264783]\n",
            "It 09050: loss = 1.27282143e-01 lambda = [ 0.608784  -6.0264544]\n",
            "It 09100: loss = 1.27264798e-01 lambda = [ 0.6083012 -6.0264306]\n",
            "It 09150: loss = 1.27247497e-01 lambda = [ 0.6078184 -6.026407 ]\n",
            "It 09200: loss = 1.27230182e-01 lambda = [ 0.6073356 -6.026383 ]\n",
            "It 09250: loss = 1.27212897e-01 lambda = [ 0.6068528 -6.026359 ]\n",
            "It 09300: loss = 1.27195612e-01 lambda = [ 0.60637003 -6.0263352 ]\n",
            "It 09350: loss = 1.27178356e-01 lambda = [ 0.60588723 -6.0263114 ]\n",
            "It 09400: loss = 1.27161086e-01 lambda = [ 0.6054045 -6.0262876]\n",
            "It 09450: loss = 1.27143860e-01 lambda = [ 0.6049247 -6.0262637]\n",
            "It 09500: loss = 1.27126649e-01 lambda = [ 0.60444486 -6.02624   ]\n",
            "It 09550: loss = 1.27109453e-01 lambda = [ 0.60396504 -6.026216  ]\n",
            "It 09600: loss = 1.27092257e-01 lambda = [ 0.6034852 -6.026192 ]\n",
            "It 09650: loss = 1.27075076e-01 lambda = [ 0.6030054 -6.0261683]\n",
            "It 09700: loss = 1.27057925e-01 lambda = [ 0.6025256 -6.0261445]\n",
            "It 09750: loss = 1.27040774e-01 lambda = [ 0.6020458 -6.0261207]\n",
            "It 09800: loss = 1.27023637e-01 lambda = [ 0.60156596 -6.026097  ]\n",
            "It 09850: loss = 1.27006486e-01 lambda = [ 0.60108614 -6.026073  ]\n",
            "It 09900: loss = 1.26989365e-01 lambda = [ 0.6006063 -6.026049 ]\n",
            "It 09950: loss = 1.26972243e-01 lambda = [ 0.6001265 -6.0260253]\n",
            "It 10000: loss = 1.26955166e-01 lambda = [ 0.5996467 -6.0260015]\n",
            "It 10050: loss = 1.26938060e-01 lambda = [ 0.59916687 -6.0259776 ]\n",
            "It 10100: loss = 1.26921013e-01 lambda = [ 0.59868705 -6.025954  ]\n",
            "It 10150: loss = 1.26903936e-01 lambda = [ 0.59820724 -6.02593   ]\n",
            "It 10200: loss = 1.26886889e-01 lambda = [ 0.5977274 -6.025906 ]\n",
            "It 10250: loss = 1.26869828e-01 lambda = [ 0.5972476 -6.0258822]\n",
            "It 10300: loss = 1.26852781e-01 lambda = [ 0.5967678 -6.0258584]\n",
            "It 10350: loss = 1.26835778e-01 lambda = [ 0.59628797 -6.0258346 ]\n",
            "It 10400: loss = 1.26818746e-01 lambda = [ 0.59580815 -6.0258107 ]\n",
            "It 10450: loss = 1.26801729e-01 lambda = [ 0.59532833 -6.025787  ]\n",
            "It 10500: loss = 1.26784727e-01 lambda = [ 0.5948485 -6.025763 ]\n",
            "It 10550: loss = 1.26767740e-01 lambda = [ 0.5943687 -6.025739 ]\n",
            "It 10600: loss = 1.26750752e-01 lambda = [ 0.5938889 -6.0257154]\n",
            "It 10650: loss = 1.26733780e-01 lambda = [ 0.59340906 -6.0256915 ]\n",
            "It 10700: loss = 1.26716822e-01 lambda = [ 0.59292924 -6.0256677 ]\n",
            "It 10750: loss = 1.26699865e-01 lambda = [ 0.5924494 -6.025644 ]\n",
            "It 10800: loss = 1.26682907e-01 lambda = [ 0.5919696 -6.02562  ]\n",
            "It 10850: loss = 1.26665980e-01 lambda = [ 0.5914898 -6.025596 ]\n",
            "It 10900: loss = 1.26649022e-01 lambda = [ 0.59101   -6.0255723]\n",
            "It 10950: loss = 1.26632079e-01 lambda = [ 0.59053016 -6.0255485 ]\n",
            "It 11000: loss = 1.26615152e-01 lambda = [ 0.59005034 -6.0255246 ]\n",
            "It 11050: loss = 1.26598239e-01 lambda = [ 0.5895705 -6.025501 ]\n",
            "It 11100: loss = 1.26581341e-01 lambda = [ 0.5890907 -6.025477 ]\n",
            "It 11150: loss = 1.26564428e-01 lambda = [ 0.58861196 -6.025453  ]\n",
            "It 11200: loss = 1.26547545e-01 lambda = [ 0.5881351 -6.0254292]\n",
            "It 11250: loss = 1.26530662e-01 lambda = [ 0.5876583 -6.0254054]\n",
            "It 11300: loss = 1.26513779e-01 lambda = [ 0.58718145 -6.0253816 ]\n",
            "It 11350: loss = 1.26496896e-01 lambda = [ 0.5867046 -6.0253577]\n",
            "It 11400: loss = 1.26480028e-01 lambda = [ 0.5862278 -6.025334 ]\n",
            "It 11450: loss = 1.26463175e-01 lambda = [ 0.58575094 -6.02531   ]\n",
            "It 11500: loss = 1.26446307e-01 lambda = [ 0.5852741 -6.025286 ]\n",
            "It 11550: loss = 1.26429439e-01 lambda = [ 0.58479726 -6.0252624 ]\n",
            "It 11600: loss = 1.26412600e-01 lambda = [ 0.5843204 -6.0252385]\n",
            "It 11650: loss = 1.26395747e-01 lambda = [ 0.5838436 -6.0252147]\n",
            "It 11700: loss = 1.26378924e-01 lambda = [ 0.58336675 -6.025191  ]\n",
            "It 11750: loss = 1.26362070e-01 lambda = [ 0.5828899 -6.025167 ]\n",
            "It 11800: loss = 1.26345247e-01 lambda = [ 0.5824131 -6.025143 ]\n",
            "It 11850: loss = 1.26328394e-01 lambda = [ 0.58193624 -6.0251193 ]\n",
            "It 11900: loss = 1.26311570e-01 lambda = [ 0.5814594 -6.0250955]\n",
            "It 11950: loss = 1.26294747e-01 lambda = [ 0.58098257 -6.0250716 ]\n",
            "It 12000: loss = 1.26277924e-01 lambda = [ 0.5805057 -6.025048 ]\n",
            "It 12050: loss = 1.26261100e-01 lambda = [ 0.5800289 -6.025024 ]\n",
            "It 12100: loss = 1.26244292e-01 lambda = [ 0.57955205 -6.025     ]\n",
            "It 12150: loss = 1.26227468e-01 lambda = [ 0.5790752 -6.0249763]\n",
            "It 12200: loss = 1.26210645e-01 lambda = [ 0.5785984 -6.0249524]\n",
            "It 12250: loss = 1.26193821e-01 lambda = [ 0.57812154 -6.0249286 ]\n",
            "It 12300: loss = 1.26177013e-01 lambda = [ 0.5776447 -6.0249047]\n",
            "It 12350: loss = 1.26160204e-01 lambda = [ 0.57716787 -6.024881  ]\n",
            "It 12400: loss = 1.26143411e-01 lambda = [ 0.57669103 -6.024857  ]\n",
            "It 12450: loss = 1.26126602e-01 lambda = [ 0.5762142 -6.024833 ]\n",
            "It 12500: loss = 1.26109824e-01 lambda = [ 0.57573736 -6.0248094 ]\n",
            "It 12550: loss = 1.26093045e-01 lambda = [ 0.5752605 -6.0247855]\n",
            "It 12600: loss = 1.26076236e-01 lambda = [ 0.5747837 -6.0247617]\n",
            "It 12650: loss = 1.26059473e-01 lambda = [ 0.57430685 -6.024738  ]\n",
            "It 12700: loss = 1.26042664e-01 lambda = [ 0.57383  -6.024714]\n",
            "It 12750: loss = 1.26025870e-01 lambda = [ 0.5733532 -6.02469  ]\n",
            "It 12800: loss = 1.26009092e-01 lambda = [ 0.57287633 -6.0246663 ]\n",
            "It 12850: loss = 1.25992313e-01 lambda = [ 0.5723997 -6.0246425]\n",
            "It 12900: loss = 1.25975519e-01 lambda = [ 0.5719258 -6.0246186]\n",
            "It 12950: loss = 1.25958741e-01 lambda = [ 0.57145196 -6.024595  ]\n",
            "It 13000: loss = 1.25941962e-01 lambda = [ 0.5709781 -6.024571 ]\n",
            "It 13050: loss = 1.25925198e-01 lambda = [ 0.57050425 -6.024547  ]\n",
            "It 13100: loss = 1.25908434e-01 lambda = [ 0.5700304 -6.0245233]\n",
            "It 13150: loss = 1.25891671e-01 lambda = [ 0.56955653 -6.0244994 ]\n",
            "It 13200: loss = 1.25874907e-01 lambda = [ 0.5690827 -6.0244756]\n",
            "It 13250: loss = 1.25858143e-01 lambda = [ 0.5686088 -6.0244517]\n",
            "It 13300: loss = 1.25841379e-01 lambda = [ 0.56813496 -6.024428  ]\n",
            "It 13350: loss = 1.25824615e-01 lambda = [ 0.5676611 -6.024404 ]\n",
            "It 13400: loss = 1.25807852e-01 lambda = [ 0.56718725 -6.02438   ]\n",
            "It 13450: loss = 1.25791088e-01 lambda = [ 0.5667134 -6.0243564]\n",
            "It 13500: loss = 1.25774339e-01 lambda = [ 0.56623954 -6.0243325 ]\n",
            "It 13550: loss = 1.25757575e-01 lambda = [ 0.5657657 -6.0243087]\n",
            "It 13600: loss = 1.25740811e-01 lambda = [ 0.5652918 -6.024285 ]\n",
            "It 13650: loss = 1.25724062e-01 lambda = [ 0.56481797 -6.024261  ]\n",
            "It 13700: loss = 1.25707299e-01 lambda = [ 0.5643441 -6.024237 ]\n",
            "It 13750: loss = 1.25690535e-01 lambda = [ 0.56387025 -6.0242133 ]\n",
            "It 13800: loss = 1.25673786e-01 lambda = [ 0.5633964 -6.0241895]\n",
            "It 13850: loss = 1.25657022e-01 lambda = [ 0.56292254 -6.0241656 ]\n",
            "It 13900: loss = 1.25640243e-01 lambda = [ 0.5624487 -6.024142 ]\n",
            "It 13950: loss = 1.25623465e-01 lambda = [ 0.5619748 -6.024118 ]\n",
            "It 14000: loss = 1.25606701e-01 lambda = [ 0.56150097 -6.024094  ]\n",
            "It 14050: loss = 1.25598133e-01 lambda = [ 0.5612655 -6.0240703]\n",
            "It 14100: loss = 1.25589728e-01 lambda = [ 0.5610301 -6.0240464]\n",
            "It 14150: loss = 1.25581324e-01 lambda = [ 0.56079465 -6.0240226 ]\n",
            "It 14200: loss = 1.25572935e-01 lambda = [ 0.5605592 -6.0239987]\n",
            "It 14250: loss = 1.25564530e-01 lambda = [ 0.5603238 -6.023975 ]\n",
            "It 14300: loss = 1.25556126e-01 lambda = [ 0.56008834 -6.023951  ]\n",
            "It 14350: loss = 1.25547737e-01 lambda = [ 0.5598529 -6.023927 ]\n",
            "It 14400: loss = 1.25539348e-01 lambda = [ 0.55961746 -6.0239034 ]\n",
            "It 14450: loss = 1.25530943e-01 lambda = [ 0.559382  -6.0238795]\n",
            "It 14500: loss = 1.25522584e-01 lambda = [ 0.5591466 -6.0238557]\n",
            "It 14550: loss = 1.25514194e-01 lambda = [ 0.55891114 -6.023832  ]\n",
            "It 14600: loss = 1.25505835e-01 lambda = [ 0.5586757 -6.023808 ]\n",
            "It 14650: loss = 1.25497445e-01 lambda = [ 0.55844027 -6.023784  ]\n",
            "It 14700: loss = 1.25489056e-01 lambda = [ 0.5582048 -6.0237603]\n",
            "It 14750: loss = 1.25480652e-01 lambda = [ 0.5579694 -6.0237365]\n",
            "It 14800: loss = 1.25472263e-01 lambda = [ 0.55773395 -6.0237126 ]\n",
            "It 14850: loss = 1.25463888e-01 lambda = [ 0.5574985 -6.023689 ]\n",
            "It 14900: loss = 1.25455484e-01 lambda = [ 0.5572631 -6.023665 ]\n",
            "It 14950: loss = 1.25447124e-01 lambda = [ 0.55702764 -6.023641  ]\n",
            "It 15000: loss = 1.25438735e-01 lambda = [ 0.5567922 -6.0236173]\n",
            "It 15050: loss = 1.25430360e-01 lambda = [ 0.55655676 -6.0235934 ]\n",
            "It 15100: loss = 1.25421971e-01 lambda = [ 0.5563213 -6.0235696]\n",
            "It 15150: loss = 1.25413582e-01 lambda = [ 0.5560859 -6.0235457]\n",
            "It 15200: loss = 1.25405192e-01 lambda = [ 0.55585045 -6.023522  ]\n",
            "It 15250: loss = 1.25396833e-01 lambda = [ 0.555615 -6.023498]\n",
            "It 15300: loss = 1.25388429e-01 lambda = [ 0.55537957 -6.023474  ]\n",
            "It 15350: loss = 1.25380054e-01 lambda = [ 0.55514413 -6.0234504 ]\n",
            "It 15400: loss = 1.25371665e-01 lambda = [ 0.5549087 -6.0234265]\n",
            "It 15450: loss = 1.25363290e-01 lambda = [ 0.55467325 -6.0234027 ]\n",
            "It 15500: loss = 1.25354901e-01 lambda = [ 0.5544378 -6.023379 ]\n",
            "It 15550: loss = 1.25346512e-01 lambda = [ 0.5542024 -6.023355 ]\n",
            "It 15600: loss = 1.25338122e-01 lambda = [ 0.55396694 -6.023331  ]\n",
            "It 15650: loss = 1.25329733e-01 lambda = [ 0.5537315 -6.0233073]\n",
            "It 15700: loss = 1.25321329e-01 lambda = [ 0.55349606 -6.0232835 ]\n",
            "It 15750: loss = 1.25312924e-01 lambda = [ 0.5532606 -6.0232596]\n",
            "It 15800: loss = 1.25304520e-01 lambda = [ 0.5530252 -6.023236 ]\n",
            "It 15850: loss = 1.25296131e-01 lambda = [ 0.55278975 -6.023212  ]\n",
            "It 15900: loss = 1.25287741e-01 lambda = [ 0.5525543 -6.023188 ]\n",
            "It 15950: loss = 1.25279307e-01 lambda = [ 0.5523189 -6.0231643]\n",
            "It 16000: loss = 1.25270933e-01 lambda = [ 0.55208343 -6.0231404 ]\n",
            "It 16050: loss = 1.25262529e-01 lambda = [ 0.551848  -6.0231166]\n",
            "It 16100: loss = 1.25254139e-01 lambda = [ 0.55161256 -6.0230927 ]\n",
            "It 16150: loss = 1.25245720e-01 lambda = [ 0.5513771 -6.023069 ]\n",
            "It 16200: loss = 1.25237331e-01 lambda = [ 0.5511417 -6.023045 ]\n",
            "It 16250: loss = 1.25228941e-01 lambda = [ 0.55090624 -6.023021  ]\n",
            "It 16300: loss = 1.25220552e-01 lambda = [ 0.5506708 -6.0229974]\n",
            "It 16350: loss = 1.25212163e-01 lambda = [ 0.55043536 -6.0229735 ]\n",
            "It 16400: loss = 1.25203758e-01 lambda = [ 0.5501999 -6.0229497]\n",
            "It 16450: loss = 1.25195384e-01 lambda = [ 0.5499645 -6.022926 ]\n",
            "It 16500: loss = 1.25186995e-01 lambda = [ 0.54972905 -6.022902  ]\n",
            "It 16550: loss = 1.25178576e-01 lambda = [ 0.5494936 -6.022878 ]\n",
            "It 16600: loss = 1.25170186e-01 lambda = [ 0.5492582 -6.0228543]\n",
            "It 16650: loss = 1.25161782e-01 lambda = [ 0.54902273 -6.0228305 ]\n",
            "It 16700: loss = 1.25153363e-01 lambda = [ 0.5487873 -6.0228066]\n",
            "It 16750: loss = 1.25144958e-01 lambda = [ 0.54855186 -6.022783  ]\n",
            "It 16800: loss = 1.25136554e-01 lambda = [ 0.5483164 -6.022759 ]\n",
            "It 16850: loss = 1.25128135e-01 lambda = [ 0.548081 -6.022735]\n",
            "It 16900: loss = 1.25119716e-01 lambda = [ 0.54784554 -6.0227113 ]\n",
            "It 16950: loss = 1.25111312e-01 lambda = [ 0.5476101 -6.0226874]\n",
            "It 17000: loss = 1.25102893e-01 lambda = [ 0.54737467 -6.0226636 ]\n",
            "It 17050: loss = 1.25094488e-01 lambda = [ 0.5471392 -6.0226398]\n",
            "It 17100: loss = 1.25086069e-01 lambda = [ 0.5469038 -6.022616 ]\n",
            "It 17150: loss = 1.25077635e-01 lambda = [ 0.54666835 -6.022592  ]\n",
            "It 17200: loss = 1.25069231e-01 lambda = [ 0.5464329 -6.022568 ]\n",
            "It 17250: loss = 1.25060827e-01 lambda = [ 0.5461975 -6.0225444]\n",
            "It 17300: loss = 1.25052407e-01 lambda = [ 0.54596204 -6.0225205 ]\n",
            "It 17350: loss = 1.25043973e-01 lambda = [ 0.5457266 -6.0224967]\n",
            "It 17400: loss = 1.25035584e-01 lambda = [ 0.54549116 -6.022473  ]\n",
            "It 17450: loss = 1.25027150e-01 lambda = [ 0.5452557 -6.022449 ]\n",
            "It 17500: loss = 1.25018731e-01 lambda = [ 0.5450203 -6.022425 ]\n",
            "It 17550: loss = 1.25010312e-01 lambda = [ 0.54478484 -6.0224013 ]\n",
            "It 17600: loss = 1.25001878e-01 lambda = [ 0.5445494 -6.0223775]\n",
            "It 17650: loss = 1.24993473e-01 lambda = [ 0.54431397 -6.0223536 ]\n",
            "It 17700: loss = 1.24985024e-01 lambda = [ 0.5440785 -6.02233  ]\n",
            "It 17750: loss = 1.24976583e-01 lambda = [ 0.5438431 -6.022306 ]\n",
            "It 17800: loss = 1.24968149e-01 lambda = [ 0.54360765 -6.022282  ]\n",
            "It 17850: loss = 1.24959722e-01 lambda = [ 0.5433722 -6.0222583]\n",
            "It 17900: loss = 1.24951273e-01 lambda = [ 0.5431368 -6.0222344]\n",
            "It 17950: loss = 1.24942839e-01 lambda = [ 0.54290134 -6.0222106 ]\n",
            "It 18000: loss = 1.24934413e-01 lambda = [ 0.5426659 -6.0221868]\n",
            "It 18050: loss = 1.24925978e-01 lambda = [ 0.54243046 -6.022163  ]\n",
            "It 18100: loss = 1.24917552e-01 lambda = [ 0.542195 -6.022139]\n",
            "It 18150: loss = 1.24909103e-01 lambda = [ 0.5419596 -6.022115 ]\n",
            "It 18200: loss = 1.24900676e-01 lambda = [ 0.54172415 -6.0220914 ]\n",
            "It 18250: loss = 1.24892250e-01 lambda = [ 0.5414887 -6.0220675]\n",
            "It 18300: loss = 1.24883808e-01 lambda = [ 0.54125327 -6.0220437 ]\n",
            "It 18350: loss = 1.24875374e-01 lambda = [ 0.54101783 -6.02202   ]\n",
            "It 18400: loss = 1.24866933e-01 lambda = [ 0.5407824 -6.021996 ]\n",
            "It 18450: loss = 1.24858499e-01 lambda = [ 0.54054695 -6.021972  ]\n",
            "It 18500: loss = 1.24850072e-01 lambda = [ 0.5403115 -6.0219483]\n",
            "It 18550: loss = 1.24841645e-01 lambda = [ 0.5400761 -6.0219245]\n",
            "It 18600: loss = 1.24833204e-01 lambda = [ 0.53984064 -6.0219007 ]\n",
            "It 18650: loss = 1.24824777e-01 lambda = [ 0.5396052 -6.021877 ]\n",
            "It 18700: loss = 1.24816321e-01 lambda = [ 0.53936976 -6.021853  ]\n",
            "It 18750: loss = 1.24807872e-01 lambda = [ 0.5391343 -6.021829 ]\n",
            "It 18800: loss = 1.24799430e-01 lambda = [ 0.5388989 -6.0218053]\n",
            "It 18850: loss = 1.24790981e-01 lambda = [ 0.53866345 -6.0217814 ]\n",
            "It 18900: loss = 1.24782540e-01 lambda = [ 0.538428  -6.0217576]\n",
            "It 18950: loss = 1.24774076e-01 lambda = [ 0.5381926 -6.0217338]\n",
            "It 19000: loss = 1.24765635e-01 lambda = [ 0.53795713 -6.02171   ]\n",
            "It 19050: loss = 1.24757171e-01 lambda = [ 0.5377217 -6.021686 ]\n",
            "It 19100: loss = 1.24748722e-01 lambda = [ 0.53748626 -6.021662  ]\n",
            "It 19150: loss = 1.24740250e-01 lambda = [ 0.5372508 -6.0216384]\n",
            "It 19200: loss = 1.24731794e-01 lambda = [ 0.5370154 -6.0216146]\n",
            "It 19250: loss = 1.24723330e-01 lambda = [ 0.53677994 -6.0215907 ]\n",
            "It 19300: loss = 1.24714881e-01 lambda = [ 0.5365445 -6.021567 ]\n",
            "It 19350: loss = 1.24706417e-01 lambda = [ 0.53630906 -6.021543  ]\n",
            "It 19400: loss = 1.24697961e-01 lambda = [ 0.5360736 -6.021519 ]\n",
            "It 19450: loss = 1.24689512e-01 lambda = [ 0.5358382 -6.0214953]\n",
            "It 19500: loss = 1.24681041e-01 lambda = [ 0.53560275 -6.0214715 ]\n",
            "It 19550: loss = 1.24672584e-01 lambda = [ 0.5353673 -6.0214477]\n",
            "It 19600: loss = 1.24664143e-01 lambda = [ 0.5351319 -6.021424 ]\n",
            "It 19650: loss = 1.24655671e-01 lambda = [ 0.53489643 -6.0214    ]\n",
            "It 19700: loss = 1.24647200e-01 lambda = [ 0.534661 -6.021376]\n",
            "It 19750: loss = 1.24638744e-01 lambda = [ 0.53442556 -6.0213523 ]\n",
            "It 19800: loss = 1.24630272e-01 lambda = [ 0.5341901 -6.0213284]\n",
            "It 19850: loss = 1.24621838e-01 lambda = [ 0.5339547 -6.0213046]\n",
            "It 19900: loss = 1.24613374e-01 lambda = [ 0.53371924 -6.021281  ]\n",
            "It 19950: loss = 1.24604911e-01 lambda = [ 0.5334838 -6.021257 ]\n",
            "It 20000: loss = 1.24596432e-01 lambda = [ 0.53324836 -6.021233  ]\n",
            "It 20050: loss = 1.24587961e-01 lambda = [ 0.5330129 -6.0212092]\n",
            "It 20100: loss = 1.24579467e-01 lambda = [ 0.5327775 -6.0211854]\n",
            "It 20150: loss = 1.24571010e-01 lambda = [ 0.5325444 -6.0211616]\n",
            "It 20200: loss = 1.24562539e-01 lambda = [ 0.5323119 -6.0211377]\n",
            "It 20250: loss = 1.24554068e-01 lambda = [ 0.53207946 -6.021114  ]\n",
            "It 20300: loss = 1.24545589e-01 lambda = [ 0.531847 -6.02109 ]\n",
            "It 20350: loss = 1.24537140e-01 lambda = [ 0.53161454 -6.021066  ]\n",
            "It 20400: loss = 1.24528661e-01 lambda = [ 0.5313821 -6.0210423]\n",
            "It 20450: loss = 1.24520175e-01 lambda = [ 0.5311496 -6.0210185]\n",
            "It 20500: loss = 1.24511719e-01 lambda = [ 0.53091717 -6.0209947 ]\n",
            "It 20550: loss = 1.24503255e-01 lambda = [ 0.5306847 -6.020971 ]\n",
            "It 20600: loss = 1.24494791e-01 lambda = [ 0.53045225 -6.020947  ]\n",
            "It 20650: loss = 1.24486327e-01 lambda = [ 0.5302198 -6.020923 ]\n",
            "It 20700: loss = 1.24477871e-01 lambda = [ 0.52998734 -6.0208993 ]\n",
            "It 20750: loss = 1.24469399e-01 lambda = [ 0.5297549 -6.0208755]\n",
            "It 20800: loss = 1.24460936e-01 lambda = [ 0.5295224 -6.0208516]\n",
            "It 20850: loss = 1.24452479e-01 lambda = [ 0.52928996 -6.020828  ]\n",
            "It 20900: loss = 1.24444000e-01 lambda = [ 0.5290575 -6.020804 ]\n",
            "It 20950: loss = 1.24435529e-01 lambda = [ 0.52882504 -6.02078   ]\n",
            "It 21000: loss = 1.24427065e-01 lambda = [ 0.5285926 -6.0207562]\n",
            "It 21050: loss = 1.24418594e-01 lambda = [ 0.5283601 -6.0207324]\n",
            "It 21100: loss = 1.24410108e-01 lambda = [ 0.5281277 -6.0207086]\n",
            "It 21150: loss = 1.24401636e-01 lambda = [ 0.5278952 -6.0206847]\n",
            "It 21200: loss = 1.24393150e-01 lambda = [ 0.52766275 -6.020661  ]\n",
            "It 21250: loss = 1.24384671e-01 lambda = [ 0.5274303 -6.020637 ]\n",
            "It 21300: loss = 1.24376185e-01 lambda = [ 0.52719784 -6.020613  ]\n",
            "It 21350: loss = 1.24367706e-01 lambda = [ 0.5269654 -6.0205894]\n",
            "It 21400: loss = 1.24359235e-01 lambda = [ 0.5267329 -6.0205655]\n",
            "It 21450: loss = 1.24350742e-01 lambda = [ 0.52650046 -6.0205417 ]\n",
            "It 21500: loss = 1.24342248e-01 lambda = [ 0.526268 -6.020518]\n",
            "It 21550: loss = 1.24333769e-01 lambda = [ 0.52603555 -6.020494  ]\n",
            "It 21600: loss = 1.24325290e-01 lambda = [ 0.5258031 -6.02047  ]\n",
            "It 21650: loss = 1.24316804e-01 lambda = [ 0.52557063 -6.0204463 ]\n",
            "It 21700: loss = 1.24308318e-01 lambda = [ 0.5253382 -6.0204225]\n",
            "It 21750: loss = 1.24299824e-01 lambda = [ 0.5251057 -6.0203986]\n",
            "It 21800: loss = 1.24291338e-01 lambda = [ 0.52487326 -6.020375  ]\n",
            "It 21850: loss = 1.24282859e-01 lambda = [ 0.5246408 -6.020351 ]\n",
            "It 21900: loss = 1.24274351e-01 lambda = [ 0.52440834 -6.020327  ]\n",
            "It 21950: loss = 1.24265872e-01 lambda = [ 0.5241759 -6.0203032]\n",
            "It 22000: loss = 1.24257378e-01 lambda = [ 0.5239434 -6.0202794]\n",
            "It 22050: loss = 1.24248877e-01 lambda = [ 0.52371097 -6.0202556 ]\n",
            "It 22100: loss = 1.24240398e-01 lambda = [ 0.5234785 -6.0202317]\n",
            "It 22150: loss = 1.24231882e-01 lambda = [ 0.52324605 -6.020208  ]\n",
            "It 22200: loss = 1.24223374e-01 lambda = [ 0.5230136 -6.020184 ]\n",
            "It 22250: loss = 1.24214880e-01 lambda = [ 0.52278113 -6.02016   ]\n",
            "It 22300: loss = 1.24206379e-01 lambda = [ 0.5225487 -6.0201364]\n",
            "It 22350: loss = 1.24197863e-01 lambda = [ 0.5223162 -6.0201125]\n",
            "It 22400: loss = 1.24189332e-01 lambda = [ 0.52208376 -6.0200887 ]\n",
            "It 22450: loss = 1.24180824e-01 lambda = [ 0.5218513 -6.020065 ]\n",
            "It 22500: loss = 1.24172308e-01 lambda = [ 0.52161884 -6.020041  ]\n",
            "It 22550: loss = 1.24163792e-01 lambda = [ 0.5213864 -6.020017 ]\n",
            "It 22600: loss = 1.24155253e-01 lambda = [ 0.5211539 -6.0199933]\n",
            "It 22650: loss = 1.24146760e-01 lambda = [ 0.52092147 -6.0199695 ]\n",
            "It 22700: loss = 1.24138221e-01 lambda = [ 0.520689  -6.0199456]\n",
            "It 22750: loss = 1.24129713e-01 lambda = [ 0.52045655 -6.019922  ]\n",
            "It 22800: loss = 1.24121189e-01 lambda = [ 0.5202241 -6.019898 ]\n",
            "It 22850: loss = 1.24112666e-01 lambda = [ 0.51999164 -6.019874  ]\n",
            "It 22900: loss = 1.24104142e-01 lambda = [ 0.5197592 -6.0198503]\n",
            "It 22950: loss = 1.24095634e-01 lambda = [ 0.5195267 -6.0198264]\n",
            "It 23000: loss = 1.24087110e-01 lambda = [ 0.51929426 -6.0198026 ]\n",
            "It 23050: loss = 1.24078587e-01 lambda = [ 0.5190618 -6.0197787]\n",
            "It 23100: loss = 1.24070071e-01 lambda = [ 0.51882935 -6.019755  ]\n",
            "It 23150: loss = 1.24061547e-01 lambda = [ 0.5185969 -6.019731 ]\n",
            "It 23200: loss = 1.24053031e-01 lambda = [ 0.5183644 -6.019707 ]\n",
            "It 23250: loss = 1.24044523e-01 lambda = [ 0.518132  -6.0196834]\n",
            "It 23300: loss = 1.24035969e-01 lambda = [ 0.5178995 -6.0196595]\n",
            "It 23350: loss = 1.24027446e-01 lambda = [ 0.51766706 -6.0196357 ]\n",
            "It 23400: loss = 1.24018922e-01 lambda = [ 0.5174346 -6.019612 ]\n",
            "It 23450: loss = 1.24010399e-01 lambda = [ 0.51720214 -6.019588  ]\n",
            "It 23500: loss = 1.24001861e-01 lambda = [ 0.5169697 -6.019564 ]\n",
            "It 23550: loss = 1.23993315e-01 lambda = [ 0.5167372 -6.0195403]\n",
            "It 23600: loss = 1.23984776e-01 lambda = [ 0.51650476 -6.0195165 ]\n",
            "It 23650: loss = 1.23976231e-01 lambda = [ 0.5162723 -6.0194926]\n",
            "It 23700: loss = 1.23967700e-01 lambda = [ 0.51603985 -6.019469  ]\n",
            "It 23750: loss = 1.23959161e-01 lambda = [ 0.5158074 -6.019445 ]\n",
            "It 23800: loss = 1.23950616e-01 lambda = [ 0.51557493 -6.019421  ]\n",
            "It 23850: loss = 1.23942077e-01 lambda = [ 0.5153425 -6.0193973]\n",
            "It 23900: loss = 1.23933531e-01 lambda = [ 0.51511   -6.0193734]\n",
            "It 23950: loss = 1.23924986e-01 lambda = [ 0.51487756 -6.0193496 ]\n",
            "It 24000: loss = 1.23916410e-01 lambda = [ 0.5146451 -6.0193257]\n",
            "It 24050: loss = 1.23907849e-01 lambda = [ 0.51441264 -6.019302  ]\n",
            "It 24100: loss = 1.23899296e-01 lambda = [ 0.5141802 -6.019278 ]\n",
            "It 24150: loss = 1.23890750e-01 lambda = [ 0.5139477 -6.019254 ]\n",
            "It 24200: loss = 1.23882212e-01 lambda = [ 0.51371527 -6.0192304 ]\n",
            "Timeout is reached. Time elapsed: 100.00123357772827 seconds\n",
            "\n",
            "\n",
            "Adam\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: loss = 3.70772004e-01 lambda = [ 0.9012209 -5.91167  ]\n",
            "It 00050: loss = 1.46974832e-01 lambda = [ 1.2715111 -5.5694184]\n",
            "It 00100: loss = 1.28325060e-01 lambda = [ 0.2168828 -5.1074367]\n",
            "It 00150: loss = 1.15710318e-01 lambda = [-1.0571557 -3.550653 ]\n",
            "It 00200: loss = 9.73142609e-02 lambda = [-2.6509876 -1.3648795]\n",
            "It 00250: loss = 8.74890834e-02 lambda = [-3.9342017  -0.11003526]\n",
            "It 00300: loss = 6.87953755e-02 lambda = [-4.2175856   0.41252315]\n",
            "It 00350: loss = 7.29353651e-02 lambda = [-4.332412    0.26928812]\n",
            "It 00400: loss = 7.73403868e-02 lambda = [-4.4293365   0.13769755]\n",
            "It 00450: loss = 1.32094458e-01 lambda = [-4.3368864  -0.13541733]\n",
            "It 00500: loss = 7.00480118e-02 lambda = [-4.28269     0.16552565]\n",
            "It 00550: loss = 9.55225676e-02 lambda = [-4.4322443  -0.03085842]\n",
            "It 00600: loss = 3.24024633e-02 lambda = [-4.608074    0.44892302]\n",
            "It 00650: loss = 3.87507267e-02 lambda = [-4.882478  0.421803]\n",
            "It 00700: loss = 1.00508951e-01 lambda = [-5.026843    0.15025787]\n",
            "It 00750: loss = 1.56397671e-02 lambda = [-5.0229664  0.5781377]\n",
            "It 00800: loss = 9.49492753e-02 lambda = [-4.9653115  -0.01745125]\n",
            "It 00850: loss = 5.25994636e-02 lambda = [-4.9123163   0.35996798]\n",
            "It 00900: loss = 8.51676464e-02 lambda = [-4.886798   0.3231131]\n",
            "It 00950: loss = 2.07800977e-02 lambda = [-5.000152   0.5783569]\n",
            "It 01000: loss = 1.40240621e-02 lambda = [-5.1533146   0.61436874]\n",
            "It 01050: loss = 2.08850261e-02 lambda = [-5.2130365  0.63662  ]\n",
            "It 01100: loss = 2.16831360e-03 lambda = [-5.3561616  0.7558729]\n",
            "It 01150: loss = 1.44885667e-03 lambda = [-5.451132    0.78620595]\n",
            "It 01200: loss = 7.67288264e-04 lambda = [-5.5316033  0.8230972]\n",
            "It 01250: loss = 5.33681479e-04 lambda = [-5.5944414   0.84548205]\n",
            "It 01300: loss = 3.97599128e-04 lambda = [-5.646298    0.86420584]\n",
            "It 01350: loss = 3.02771252e-04 lambda = [-5.689871   0.8802194]\n",
            "It 01400: loss = 2.33728060e-04 lambda = [-5.7269588  0.8940613]\n",
            "It 01450: loss = 1.82393022e-04 lambda = [-5.7588286  0.906091 ]\n",
            "It 01500: loss = 1.43726298e-04 lambda = [-5.786399    0.91658217]\n",
            "It 01550: loss = 1.14317387e-04 lambda = [-5.8103685  0.9257576]\n",
            "It 01600: loss = 9.17704529e-05 lambda = [-5.831286  0.933803]\n",
            "It 01650: loss = 7.43611818e-05 lambda = [-5.849597   0.9408728]\n",
            "It 01700: loss = 6.08342743e-05 lambda = [-5.8656693   0.94709766]\n",
            "It 01750: loss = 5.02618423e-05 lambda = [-5.8798094   0.95258915]\n",
            "It 01800: loss = 4.19505304e-05 lambda = [-5.8922715  0.9574421]\n",
            "It 01850: loss = 3.53830619e-05 lambda = [-5.90328    0.9617372]\n",
            "It 01900: loss = 3.01646905e-05 lambda = [-5.913019    0.96554506]\n",
            "It 01950: loss = 2.59972330e-05 lambda = [-5.921651    0.96892565]\n",
            "It 02000: loss = 2.26512457e-05 lambda = [-5.9293127   0.97193134]\n",
            "It 02050: loss = 1.99509723e-05 lambda = [-5.936124   0.9746073]\n",
            "It 02100: loss = 1.77595794e-05 lambda = [-5.9421883  0.9769929]\n",
            "It 02150: loss = 1.59718875e-05 lambda = [-5.9475946  0.9791224]\n",
            "It 02200: loss = 1.45058693e-05 lambda = [-5.952421  0.981026]\n",
            "It 02250: loss = 1.32957866e-05 lambda = [-5.9567347  0.9827295]\n",
            "It 02300: loss = 1.22921774e-05 lambda = [-5.960596    0.98425597]\n",
            "It 02350: loss = 1.14541081e-05 lambda = [-5.9640565   0.98562545]\n",
            "It 02400: loss = 1.07502292e-05 lambda = [-5.967162    0.98685575]\n",
            "It 02450: loss = 1.01554197e-05 lambda = [-5.9699535   0.98796207]\n",
            "It 02500: loss = 9.64869105e-06 lambda = [-5.9724646   0.98895836]\n",
            "It 02550: loss = 9.21496940e-06 lambda = [-5.9747257  0.9898568]\n",
            "It 02600: loss = 8.84118799e-06 lambda = [-5.9767647   0.99066734]\n",
            "It 02650: loss = 8.51615914e-06 lambda = [-5.978606   0.9913998]\n",
            "It 02700: loss = 8.23171104e-06 lambda = [-5.9802704   0.99206257]\n",
            "It 02750: loss = 7.98269411e-06 lambda = [-5.9817767  0.9926627]\n",
            "It 02800: loss = 7.76109300e-06 lambda = [-5.983142    0.99320704]\n",
            "It 02850: loss = 7.56431609e-06 lambda = [-5.9843807  0.9937013]\n",
            "It 02900: loss = 7.38620429e-06 lambda = [-5.9855046  0.9941505]\n",
            "It 02950: loss = 7.22644290e-06 lambda = [-5.9865265   0.99455917]\n",
            "It 03000: loss = 7.08146399e-06 lambda = [-5.9874573  0.9949312]\n",
            "It 03050: loss = 7.01187673e-06 lambda = [-5.9878902   0.99510616]\n",
            "It 03100: loss = 6.94466598e-06 lambda = [-5.9883194   0.99527776]\n",
            "It 03150: loss = 6.87776446e-06 lambda = [-5.9887486   0.99544716]\n",
            "It 03200: loss = 6.81193978e-06 lambda = [-5.989158   0.9956134]\n",
            "It 03250: loss = 6.74736157e-06 lambda = [-5.9895635   0.99577624]\n",
            "It 03300: loss = 6.68310031e-06 lambda = [-5.989969   0.9959361]\n",
            "It 03350: loss = 6.62010189e-06 lambda = [-5.9903536   0.99609274]\n",
            "It 03400: loss = 6.55778740e-06 lambda = [-5.990735   0.9962457]\n",
            "It 03450: loss = 6.49582307e-06 lambda = [-5.9911137   0.99639535]\n",
            "It 03500: loss = 6.43494377e-06 lambda = [-5.9914713   0.99654126]\n",
            "It 03550: loss = 6.37432959e-06 lambda = [-5.991829    0.99668324]\n",
            "It 03600: loss = 6.31502962e-06 lambda = [-5.9921713   0.99682194]\n",
            "It 03650: loss = 6.25622670e-06 lambda = [-5.992505   0.9969564]\n",
            "It 03700: loss = 6.19784441e-06 lambda = [-5.9928346  0.9970871]\n",
            "It 03750: loss = 6.13961038e-06 lambda = [-5.9931445   0.99721396]\n",
            "It 03800: loss = 6.08224400e-06 lambda = [-5.9934545  0.9973368]\n",
            "It 03850: loss = 6.02523369e-06 lambda = [-5.9937444   0.99745584]\n",
            "It 03900: loss = 5.96843165e-06 lambda = [-5.9940305  0.9975704]\n",
            "It 03950: loss = 5.91229536e-06 lambda = [-5.994306    0.99768144]\n",
            "It 04000: loss = 5.85668749e-06 lambda = [-5.9945683  0.9977883]\n",
            "It 04050: loss = 5.80077722e-06 lambda = [-5.9948287  0.9978913]\n",
            "It 04100: loss = 5.74520891e-06 lambda = [-5.9950686  0.9979902]\n",
            "It 04150: loss = 5.68998576e-06 lambda = [-5.995307    0.99808514]\n",
            "It 04200: loss = 5.63539425e-06 lambda = [-5.9955297   0.99817646]\n",
            "It 04250: loss = 5.58078546e-06 lambda = [-5.995744    0.99826354]\n",
            "It 04300: loss = 5.52646497e-06 lambda = [-5.995955   0.9983473]\n",
            "It 04350: loss = 5.47206173e-06 lambda = [-5.9961457  0.9984273]\n",
            "It 04400: loss = 5.41708960e-06 lambda = [-5.9963365  0.9985032]\n",
            "It 04450: loss = 5.36295647e-06 lambda = [-5.996515   0.9985762]\n",
            "It 04500: loss = 5.30899797e-06 lambda = [-5.9966817   0.99864507]\n",
            "It 04550: loss = 5.25466385e-06 lambda = [-5.9968486  0.9987108]\n",
            "It 04600: loss = 5.20056528e-06 lambda = [-5.9969993  0.9987737]\n",
            "It 04650: loss = 5.14627436e-06 lambda = [-5.9971433   0.99883294]\n",
            "It 04700: loss = 5.09234178e-06 lambda = [-5.997284  0.998889]\n",
            "It 04750: loss = 5.03811452e-06 lambda = [-5.997416   0.9989429]\n",
            "It 04800: loss = 4.98338477e-06 lambda = [-5.997541   0.9989943]\n",
            "It 04850: loss = 2.05139804e-05 lambda = [-5.997559   0.9991234]\n",
            "It 04900: loss = 1.55750058e-05 lambda = [-5.9975367  0.9988189]\n",
            "It 04950: loss = 5.03600450e-06 lambda = [-5.9976144   0.99901026]\n",
            "It 05000: loss = 4.77670119e-06 lambda = [-5.997741    0.99907625]\n",
            "It 05050: loss = 4.72046941e-06 lambda = [-5.9978447  0.9991173]\n",
            "It 05100: loss = 4.66763322e-06 lambda = [-5.99794    0.9991567]\n",
            "It 05150: loss = 4.61507489e-06 lambda = [-5.9980307  0.9991953]\n",
            "It 05200: loss = 3.33299191e-04 lambda = [-5.998218   0.9983134]\n",
            "It 05250: loss = 4.61016998e-06 lambda = [-5.9979696  0.9992326]\n",
            "It 05300: loss = 4.49735671e-06 lambda = [-5.9981093  0.9992354]\n",
            "It 05350: loss = 4.40894610e-06 lambda = [-5.998202    0.99927044]\n",
            "It 05400: loss = 4.35670927e-06 lambda = [-5.9982824  0.9993024]\n",
            "It 05450: loss = 6.44038315e-04 lambda = [-5.9981027  0.9983897]\n",
            "It 05500: loss = 5.81803579e-06 lambda = [-5.9982014   0.99930036]\n",
            "It 05550: loss = 4.23738265e-06 lambda = [-5.9983215  0.9993377]\n",
            "It 05600: loss = 4.15561044e-06 lambda = [-5.9984126   0.99936306]\n",
            "It 05650: loss = 4.10491793e-06 lambda = [-5.998485    0.99939066]\n",
            "It 05700: loss = 1.16242561e-03 lambda = [-5.997649   1.0000871]\n",
            "It 05750: loss = 4.58222030e-06 lambda = [-5.998443   0.9993674]\n",
            "It 05800: loss = 3.97068561e-06 lambda = [-5.9985137   0.99941444]\n",
            "It 05850: loss = 3.90994774e-06 lambda = [-5.9986014  0.9994452]\n",
            "It 05900: loss = 3.87738282e-06 lambda = [-5.998675    0.99946964]\n",
            "It 05950: loss = 7.84380336e-06 lambda = [-5.9986362   0.99920094]\n",
            "It 06000: loss = 4.22073441e-04 lambda = [-5.9984803  0.9985904]\n",
            "It 06050: loss = 6.88019190e-06 lambda = [-5.998592    0.99939686]\n",
            "It 06100: loss = 3.69250961e-06 lambda = [-5.99868   0.999483]\n",
            "It 06150: loss = 3.61929801e-06 lambda = [-5.998766    0.99952054]\n",
            "It 06200: loss = 1.70889928e-03 lambda = [-5.9978685  1.0000445]\n",
            "It 06250: loss = 6.66157212e-06 lambda = [-5.9987288  0.9995513]\n",
            "It 06300: loss = 3.52622669e-06 lambda = [-5.9988413  0.9995618]\n",
            "It 06350: loss = 4.80717717e-05 lambda = [-5.998655   0.9994331]\n",
            "It 06400: loss = 3.47568243e-06 lambda = [-5.998829    0.99951196]\n",
            "It 06450: loss = 1.20193945e-05 lambda = [-5.9989734  0.9995087]\n",
            "It 06500: loss = 9.20187449e-06 lambda = [-5.998808    0.99951786]\n",
            "It 06550: loss = 3.30527837e-06 lambda = [-5.9988985   0.99956596]\n",
            "It 06600: loss = 3.29035424e-06 lambda = [-5.9989924   0.99960506]\n",
            "It 06650: loss = 1.66747304e-05 lambda = [-5.998859   0.9994538]\n",
            "It 06700: loss = 1.28111369e-05 lambda = [-5.998827    0.99941707]\n",
            "It 06750: loss = 9.72107773e-06 lambda = [-5.9989634  0.9996587]\n",
            "It 06800: loss = 4.07175939e-05 lambda = [-5.998851    0.99966115]\n",
            "It 06850: loss = 9.61773276e-06 lambda = [-5.9990287   0.99971175]\n",
            "It 06900: loss = 9.20269940e-06 lambda = [-5.9990425  0.9996454]\n",
            "It 06950: loss = 5.70623961e-05 lambda = [-5.998892   0.9995358]\n",
            "It 07000: loss = 3.20614936e-06 lambda = [-5.999119   0.9996241]\n",
            "It 07050: loss = 2.89185277e-06 lambda = [-5.999147   0.9996596]\n",
            "It 07100: loss = 2.86676482e-06 lambda = [-5.9991784   0.99967825]\n",
            "It 07150: loss = 2.84409020e-06 lambda = [-5.9992023  0.999693 ]\n",
            "It 07200: loss = 2.82142696e-06 lambda = [-5.999226   0.9997047]\n",
            "It 07250: loss = 2.79922142e-06 lambda = [-5.99925     0.99971426]\n",
            "It 07300: loss = 2.77703521e-06 lambda = [-5.999274    0.99972254]\n",
            "It 07350: loss = 2.75455955e-06 lambda = [-5.9992976  0.9997303]\n",
            "It 07400: loss = 2.73174760e-06 lambda = [-5.9993215   0.99973786]\n",
            "It 07450: loss = 2.70962232e-06 lambda = [-5.9993453  0.999745 ]\n",
            "It 07500: loss = 2.68732560e-06 lambda = [-5.999369   0.9997521]\n",
            "It 07550: loss = 2.66463599e-06 lambda = [-5.999393   0.9997594]\n",
            "It 07600: loss = 2.64182609e-06 lambda = [-5.999411    0.99976623]\n",
            "It 07650: loss = 2.61910282e-06 lambda = [-5.9994264  0.9997721]\n",
            "It 07700: loss = 2.59599369e-06 lambda = [-5.999437    0.99977696]\n",
            "It 07750: loss = 2.57336751e-06 lambda = [-5.999446   0.9997806]\n",
            "It 07800: loss = 2.54999850e-06 lambda = [-5.999453    0.99978346]\n",
            "It 07850: loss = 2.52665632e-06 lambda = [-5.999461   0.9997859]\n",
            "It 07900: loss = 2.50320204e-06 lambda = [-5.999468    0.99978817]\n",
            "It 07950: loss = 2.47977141e-06 lambda = [-5.9994707  0.9997896]\n",
            "It 08000: loss = 2.45619685e-06 lambda = [-5.9994736  0.9997907]\n",
            "It 08050: loss = 2.43211730e-06 lambda = [-5.9994755  0.9997915]\n",
            "It 08100: loss = 2.40842610e-06 lambda = [-5.999479    0.99979216]\n",
            "It 08150: loss = 2.38423422e-06 lambda = [-5.9994836   0.99979293]\n",
            "It 08200: loss = 2.35991706e-06 lambda = [-5.9994874  0.9997942]\n",
            "It 08250: loss = 2.33575770e-06 lambda = [-5.9994907   0.99979526]\n",
            "It 08300: loss = 2.31090257e-06 lambda = [-5.9994946   0.99979615]\n",
            "It 08350: loss = 2.28647673e-06 lambda = [-5.9995      0.99979734]\n",
            "It 08400: loss = 2.26363727e-06 lambda = [-5.999506  0.999798]\n",
            "It 08450: loss = 1.18590842e-05 lambda = [-5.999249    0.99979687]\n",
            "It 08500: loss = 2.25620352e-06 lambda = [-5.9994884   0.99977636]\n",
            "It 08550: loss = 1.11099380e-05 lambda = [-5.999466    0.99982893]\n",
            "It 08600: loss = 6.03855824e-06 lambda = [-5.9994974  0.9997385]\n",
            "It 08650: loss = 2.16361332e-06 lambda = [-5.999469    0.99978286]\n",
            "It 08700: loss = 2.13710541e-06 lambda = [-5.9994817   0.99979335]\n",
            "It 08750: loss = 2.42750666e-05 lambda = [-5.9994082   0.99967486]\n",
            "It 08800: loss = 2.23041093e-06 lambda = [-5.9994574  0.9997539]\n",
            "It 08850: loss = 1.28946394e-05 lambda = [-5.9994793  0.9996556]\n",
            "It 08900: loss = 2.14239344e-06 lambda = [-5.9994617   0.99977183]\n",
            "It 08950: loss = 3.09218922e-06 lambda = [-5.999504    0.99976176]\n",
            "It 09000: loss = 4.63176275e-06 lambda = [-5.999467   0.9997811]\n",
            "It 09050: loss = 2.04222215e-06 lambda = [-5.999491   0.9997842]\n",
            "It 09100: loss = 2.12500472e-05 lambda = [-5.9993753  0.9997819]\n",
            "It 09150: loss = 1.95284929e-06 lambda = [-5.9994574   0.99977267]\n",
            "It 09200: loss = 5.97738690e-05 lambda = [-5.999236    0.99980617]\n",
            "It 09250: loss = 2.18908326e-06 lambda = [-5.9994707   0.99976504]\n",
            "It 09300: loss = 1.86648424e-06 lambda = [-5.999483   0.9997899]\n",
            "It 09350: loss = 4.95182485e-06 lambda = [-5.9994683   0.99982285]\n",
            "It 09400: loss = 3.69444315e-05 lambda = [-5.9993653   0.99984175]\n",
            "It 09450: loss = 6.60406158e-06 lambda = [-5.999503    0.99972963]\n",
            "It 09500: loss = 2.44848070e-06 lambda = [-5.9994683   0.99977994]\n",
            "It 09550: loss = 2.02628617e-05 lambda = [-5.9995866   0.99968976]\n",
            "It 09600: loss = 2.39422320e-06 lambda = [-5.999491  0.999788]\n",
            "It 09650: loss = 1.78514790e-06 lambda = [-5.9995055  0.9997872]\n",
            "It 09700: loss = 7.46176229e-05 lambda = [-5.9991994  0.9999288]\n",
            "It 09750: loss = 2.42814076e-06 lambda = [-5.999481   0.9998047]\n",
            "It 09800: loss = 2.67358450e-06 lambda = [-5.9994674   0.99970263]\n",
            "It 09850: loss = 1.76417950e-06 lambda = [-5.999463   0.9997744]\n",
            "It 09900: loss = 2.46224197e-04 lambda = [-5.9998026  0.9994277]\n",
            "It 09950: loss = 1.68170993e-06 lambda = [-5.999467   0.9997966]\n",
            "It 10000: loss = 1.62039521e-06 lambda = [-5.9995     0.9997885]\n",
            "It 10050: loss = 3.47981154e-06 lambda = [-5.9994855  0.999819 ]\n",
            "It 10100: loss = 5.95783058e-06 lambda = [-5.999454   0.9998014]\n",
            "It 10150: loss = 1.50995193e-05 lambda = [-5.999475   0.9997086]\n",
            "It 10200: loss = 1.67140252e-06 lambda = [-5.999488   0.9997773]\n",
            "It 10250: loss = 1.52445102e-06 lambda = [-5.9995036  0.9997963]\n",
            "It 10300: loss = 1.95873963e-05 lambda = [-5.9993916  0.9996828]\n",
            "It 10350: loss = 1.86210718e-06 lambda = [-5.9995093  0.999765 ]\n",
            "It 10400: loss = 1.47562889e-06 lambda = [-5.999514    0.99979526]\n",
            "It 10450: loss = 1.04828487e-05 lambda = [-5.9993834  0.9997816]\n",
            "It 10500: loss = 1.53794804e-06 lambda = [-5.999487   0.9997671]\n",
            "It 10550: loss = 1.12151851e-04 lambda = [-5.999237   0.9998294]\n",
            "It 10600: loss = 1.53313749e-06 lambda = [-5.999491  0.999783]\n",
            "It 10650: loss = 1.40865109e-06 lambda = [-5.999519   0.9997969]\n",
            "It 10700: loss = 1.38808764e-06 lambda = [-5.9995337   0.99980086]\n",
            "It 10750: loss = 6.56414268e-05 lambda = [-5.9995193   0.99957925]\n",
            "It 10800: loss = 1.83290013e-06 lambda = [-5.999532    0.99977404]\n",
            "It 10850: loss = 8.66353585e-05 lambda = [-5.999597  0.999603]\n",
            "It 10900: loss = 1.66202699e-06 lambda = [-5.999514   0.9997665]\n",
            "It 10950: loss = 1.32449418e-06 lambda = [-5.9995184   0.99979734]\n",
            "It 11000: loss = 2.20330321e-06 lambda = [-5.99956     0.99977916]\n",
            "It 11050: loss = 5.33507909e-06 lambda = [-5.99955    0.9997402]\n",
            "It 11100: loss = 1.37335201e-06 lambda = [-5.999519   0.9997907]\n",
            "It 11150: loss = 1.27906526e-06 lambda = [-5.9995384   0.99980414]\n",
            "It 11200: loss = 4.30279033e-05 lambda = [-5.9993997  0.9998136]\n",
            "It 11250: loss = 1.44478793e-06 lambda = [-5.9995213   0.99978846]\n",
            "It 11300: loss = 1.23929692e-06 lambda = [-5.999537  0.999804]\n",
            "It 11350: loss = 1.22374354e-06 lambda = [-5.99955     0.99980795]\n",
            "It 11400: loss = 1.62081760e-05 lambda = [-5.9994473   0.99967813]\n",
            "It 11450: loss = 1.31462400e-06 lambda = [-5.9995584  0.9997858]\n",
            "It 11500: loss = 3.44408841e-06 lambda = [-5.9995646  0.9996606]\n",
            "It 11550: loss = 1.45983267e-06 lambda = [-5.999521   0.9997971]\n",
            "It 11600: loss = 1.17427635e-06 lambda = [-5.9995465  0.999809 ]\n",
            "It 11650: loss = 2.58791060e-05 lambda = [-5.9994516  0.999921 ]\n",
            "It 11700: loss = 4.00358203e-06 lambda = [-5.9995747   0.99977773]\n",
            "It 11750: loss = 1.19089191e-06 lambda = [-5.9995584  0.9998095]\n",
            "It 11800: loss = 4.70064424e-06 lambda = [-5.9995513   0.99976254]\n",
            "It 11850: loss = 1.21722576e-06 lambda = [-5.999556   0.9998074]\n",
            "It 11900: loss = 1.11832435e-06 lambda = [-5.9995737  0.999818 ]\n",
            "It 11950: loss = 5.69503300e-06 lambda = [-5.999474   0.9997853]\n",
            "It 12000: loss = 1.10478391e-06 lambda = [-5.9995728   0.99981636]\n",
            "It 12050: loss = 1.09815164e-06 lambda = [-5.9995966   0.99982226]\n",
            "It 12100: loss = 4.50366861e-06 lambda = [-5.999505   0.9998113]\n",
            "It 12150: loss = 1.07490996e-06 lambda = [-5.999559   0.9998041]\n",
            "It 12200: loss = 2.62299500e-06 lambda = [-5.99955    0.9998512]\n",
            "It 12250: loss = 1.01694432e-05 lambda = [-5.9995213   0.99988693]\n",
            "It 12300: loss = 1.09095845e-06 lambda = [-5.9995923  0.9998305]\n",
            "It 12350: loss = 1.03741206e-06 lambda = [-5.999613    0.99982953]\n",
            "It 12400: loss = 1.03438515e-06 lambda = [-5.999624  0.999826]\n",
            "It 12450: loss = 6.64793151e-06 lambda = [-5.9995117   0.99983525]\n",
            "It 12500: loss = 2.43806484e-04 lambda = [-5.999232   1.0001186]\n",
            "It 12550: loss = 2.58912542e-06 lambda = [-5.9996104  0.9997996]\n",
            "It 12600: loss = 1.00856846e-06 lambda = [-5.999613   0.9998308]\n",
            "It 12650: loss = 9.88977717e-07 lambda = [-5.9996305  0.9998345]\n",
            "It 12700: loss = 4.43558791e-04 lambda = [-5.9992385  1.0001105]\n",
            "It 12750: loss = 2.04105208e-06 lambda = [-5.99965     0.99980205]\n",
            "It 12800: loss = 9.74580075e-07 lambda = [-5.9996386   0.99983716]\n",
            "It 12850: loss = 2.96930171e-04 lambda = [-5.9994063   0.99999875]\n",
            "It 12900: loss = 1.39850579e-06 lambda = [-5.9996033  0.9998038]\n",
            "It 12950: loss = 9.58492819e-07 lambda = [-5.99961     0.99983096]\n",
            "It 13000: loss = 3.18868668e-04 lambda = [-5.9992194  1.0002004]\n",
            "It 13050: loss = 1.87173396e-06 lambda = [-5.999607    0.99986184]\n",
            "It 13100: loss = 9.43681584e-07 lambda = [-5.99965     0.99984056]\n",
            "It 13150: loss = 9.22661968e-07 lambda = [-5.999661    0.99984264]\n",
            "It 13200: loss = 2.74149614e-04 lambda = [-5.999892    0.99954754]\n",
            "It 13250: loss = 1.15714665e-05 lambda = [-5.999541   0.9998893]\n",
            "It 13300: loss = 3.25389351e-06 lambda = [-5.999588   0.9998738]\n",
            "It 13350: loss = 9.42034092e-07 lambda = [-5.999647    0.99983746]\n",
            "It 13400: loss = 3.79880148e-05 lambda = [-5.9996924   0.99969304]\n",
            "It 13450: loss = 1.15854186e-06 lambda = [-5.999666   0.9998322]\n",
            "It 13500: loss = 8.86166617e-07 lambda = [-5.999672  0.999848]\n",
            "It 13550: loss = 4.08427832e-06 lambda = [-5.9995117  0.9998284]\n",
            "It 13600: loss = 8.92285971e-06 lambda = [-5.999624    0.99987227]\n",
            "It 13650: loss = 3.37170377e-06 lambda = [-5.999635   0.9998513]\n",
            "It 13700: loss = 9.07583797e-07 lambda = [-5.99966    0.9998486]\n",
            "It 13750: loss = 3.45987719e-05 lambda = [-5.999588   0.9999369]\n",
            "It 13800: loss = 4.47970888e-06 lambda = [-5.999663   0.9998153]\n",
            "It 13850: loss = 8.61474916e-07 lambda = [-5.999656    0.99984676]\n",
            "It 13900: loss = 8.79183119e-07 lambda = [-5.999686    0.99984294]\n",
            "It 13950: loss = 1.56566894e-05 lambda = [-5.9996047   0.99989367]\n",
            "It 14000: loss = 8.99589963e-07 lambda = [-5.99968     0.99983823]\n",
            "It 14050: loss = 8.29370720e-07 lambda = [-5.999682   0.9998507]\n",
            "It 14100: loss = 8.24161134e-07 lambda = [-5.9996877  0.9998523]\n",
            "It 14150: loss = 8.19276522e-07 lambda = [-5.9996877   0.99985236]\n",
            "It 14200: loss = 8.14252246e-07 lambda = [-5.9996877   0.99985117]\n",
            "It 14250: loss = 8.10253198e-07 lambda = [-5.9996877   0.99984974]\n",
            "It 14300: loss = 8.06047183e-07 lambda = [-5.9996877   0.99984837]\n",
            "It 14350: loss = 8.01891815e-07 lambda = [-5.9996877  0.9998471]\n",
            "It 14400: loss = 7.97685232e-07 lambda = [-5.9996877  0.9998463]\n",
            "It 14450: loss = 7.93691981e-07 lambda = [-5.9996877  0.9998454]\n",
            "It 14500: loss = 7.89571629e-07 lambda = [-5.9996877  0.9998447]\n",
            "It 14550: loss = 7.85415523e-07 lambda = [-5.9996877   0.99984425]\n",
            "It 14600: loss = 7.81407039e-07 lambda = [-5.9996877   0.99984396]\n",
            "It 14650: loss = 7.77123262e-07 lambda = [-5.9996877   0.99984366]\n",
            "It 14700: loss = 7.73144393e-07 lambda = [-5.9996877  0.9998433]\n",
            "It 14750: loss = 7.68847769e-07 lambda = [-5.9996877  0.9998433]\n",
            "It 14800: loss = 7.64715537e-07 lambda = [-5.9996877  0.9998432]\n",
            "It 14850: loss = 7.60345529e-07 lambda = [-5.9996877  0.9998432]\n",
            "It 14900: loss = 7.56103191e-07 lambda = [-5.9996877  0.9998429]\n",
            "It 14950: loss = 7.51759671e-07 lambda = [-5.9996877   0.99984294]\n",
            "It 15000: loss = 7.47374827e-07 lambda = [-5.9996877  0.999843 ]\n",
            "It 15050: loss = 7.43062515e-07 lambda = [-5.9996877   0.99984264]\n",
            "It 15100: loss = 7.38540166e-07 lambda = [-5.9996877  0.9998424]\n",
            "It 15150: loss = 7.34111211e-07 lambda = [-5.9996877  0.9998424]\n",
            "It 15200: loss = 7.29528665e-07 lambda = [-5.9996877   0.99984217]\n",
            "It 15250: loss = 7.25238237e-07 lambda = [-5.9996877  0.9998421]\n",
            "It 15300: loss = 7.20593619e-07 lambda = [-5.9996877  0.9998422]\n",
            "It 15350: loss = 7.16120383e-07 lambda = [-5.9996877  0.9998421]\n",
            "It 15400: loss = 7.11535847e-07 lambda = [-5.999688   0.9998421]\n",
            "It 15450: loss = 9.37610021e-05 lambda = [-5.9995275  0.9999908]\n",
            "It 15500: loss = 9.38164021e-07 lambda = [-5.999686   0.9998426]\n",
            "It 15550: loss = 7.00384987e-07 lambda = [-5.999695    0.99984443]\n",
            "It 15600: loss = 6.95339281e-07 lambda = [-5.9996996   0.99984634]\n",
            "It 15650: loss = 1.07607884e-05 lambda = [-5.999691    0.99983054]\n",
            "It 15700: loss = 8.36920719e-07 lambda = [-5.9997134  0.9998312]\n",
            "It 15750: loss = 5.99051382e-05 lambda = [-5.999837   0.9997092]\n",
            "It 15800: loss = 8.89356158e-07 lambda = [-5.999697    0.99985504]\n",
            "It 15850: loss = 6.78183596e-07 lambda = [-5.9997144  0.9998512]\n",
            "It 15900: loss = 6.73268403e-07 lambda = [-5.9997225   0.99985313]\n",
            "It 15950: loss = 7.75991430e-06 lambda = [-5.999808   0.9997731]\n",
            "It 16000: loss = 8.99691599e-07 lambda = [-5.9997106   0.99987113]\n",
            "It 16050: loss = 2.07784942e-05 lambda = [-5.9996724   0.99991065]\n",
            "It 16100: loss = 7.03961234e-07 lambda = [-5.999718   0.9998633]\n",
            "It 16150: loss = 6.57399994e-07 lambda = [-5.9997334  0.9998584]\n",
            "It 16200: loss = 6.57369583e-07 lambda = [-5.999742    0.99985784]\n",
            "It 16250: loss = 5.85831867e-06 lambda = [-5.999745   0.9998315]\n",
            "It 16300: loss = 6.50300592e-07 lambda = [-5.999736    0.99986035]\n",
            "It 16350: loss = 3.00845568e-06 lambda = [-5.999735   0.9998388]\n",
            "It 16400: loss = 6.49927131e-07 lambda = [-5.9997416  0.9998593]\n",
            "It 16450: loss = 6.37340634e-07 lambda = [-5.9997487  0.9998621]\n",
            "It 16500: loss = 4.33718087e-05 lambda = [-5.9995704  1.0000404]\n",
            "It 16550: loss = 1.26102486e-06 lambda = [-5.999769    0.99985135]\n",
            "It 16600: loss = 3.28113811e-06 lambda = [-5.999765    0.99985915]\n",
            "It 16650: loss = 6.71114833e-07 lambda = [-5.999765   0.9998487]\n",
            "It 16700: loss = 6.22951632e-07 lambda = [-5.999757   0.9998654]\n",
            "It 16750: loss = 7.27790466e-05 lambda = [-5.999914   0.9997006]\n",
            "It 16800: loss = 7.00573423e-07 lambda = [-5.9997554   0.99987525]\n",
            "It 16850: loss = 1.36338531e-05 lambda = [-5.999842    0.99979377]\n",
            "It 16900: loss = 6.82970096e-07 lambda = [-5.9997673   0.99986243]\n",
            "It 16950: loss = 6.23469305e-07 lambda = [-5.999772   0.9998664]\n",
            "It 17000: loss = 3.23775134e-06 lambda = [-5.999806    0.99982494]\n",
            "It 17050: loss = 6.27913892e-07 lambda = [-5.99977    0.9998754]\n",
            "It 17100: loss = 6.31927890e-07 lambda = [-5.9997845  0.9998699]\n",
            "It 17150: loss = 1.75943876e-06 lambda = [-5.999782   0.9998554]\n",
            "It 17200: loss = 6.15699093e-07 lambda = [-5.9997725  0.9998745]\n",
            "It 17250: loss = 2.75395882e-06 lambda = [-5.9997673  0.9998741]\n",
            "It 17300: loss = 5.90597665e-07 lambda = [-5.9997854   0.99987316]\n",
            "It 17350: loss = 5.87284376e-07 lambda = [-5.9997907  0.9998765]\n",
            "It 17400: loss = 2.55892542e-06 lambda = [-5.9998164  0.9998542]\n",
            "It 17450: loss = 6.28066459e-07 lambda = [-5.9997835  0.9998708]\n",
            "It 17500: loss = 5.14035310e-06 lambda = [-5.999841    0.99981916]\n",
            "It 17550: loss = 1.51085101e-06 lambda = [-5.9998007  0.9998676]\n",
            "It 17600: loss = 5.80768813e-07 lambda = [-5.999792    0.99988085]\n",
            "It 17650: loss = 5.72099282e-07 lambda = [-5.999801   0.9998798]\n",
            "It 17700: loss = 6.58170256e-06 lambda = [-5.9998465   0.99983704]\n",
            "It 17750: loss = 1.60097500e-06 lambda = [-5.999775   0.9998743]\n",
            "It 17800: loss = 6.10116331e-07 lambda = [-5.9997964   0.99987364]\n",
            "It 17850: loss = 4.16178864e-06 lambda = [-5.999754   0.9999167]\n",
            "It 17900: loss = 5.86980093e-07 lambda = [-5.9998074   0.99987864]\n",
            "It 17950: loss = 5.72102635e-07 lambda = [-5.9998145  0.9998801]\n",
            "It 18000: loss = 5.56612349e-06 lambda = [-5.9997697  0.9999085]\n",
            "It 18050: loss = 6.20190690e-07 lambda = [-5.9998183  0.999876 ]\n",
            "It 18100: loss = 1.77625077e-06 lambda = [-5.9998145  0.9998654]\n",
            "It 18150: loss = 5.49961385e-07 lambda = [-5.9998064   0.99988204]\n",
            "It 18200: loss = 7.93008367e-05 lambda = [-5.9996057  1.0000782]\n",
            "It 18250: loss = 6.29295300e-07 lambda = [-5.9998    0.999896]\n",
            "It 18300: loss = 5.44525733e-07 lambda = [-5.9998164  0.9998849]\n",
            "It 18350: loss = 1.28688964e-06 lambda = [-5.999784    0.99987954]\n",
            "It 18400: loss = 5.90138995e-07 lambda = [-5.999811   0.9998779]\n",
            "It 18450: loss = 5.65070820e-07 lambda = [-5.9998116  0.9998884]\n",
            "It 18500: loss = 6.82652058e-07 lambda = [-5.99984     0.99985766]\n",
            "It 18550: loss = 5.52326185e-07 lambda = [-5.999818   0.9998879]\n",
            "It 18600: loss = 5.32423542e-07 lambda = [-5.999827   0.9998876]\n",
            "It 18650: loss = 7.30481725e-06 lambda = [-5.9998336  0.9998426]\n",
            "It 18700: loss = 5.57275314e-07 lambda = [-5.9998207  0.9998805]\n",
            "It 18750: loss = 7.63044136e-06 lambda = [-5.999711   0.9999485]\n",
            "It 18800: loss = 5.50848142e-07 lambda = [-5.999823    0.99988616]\n",
            "It 18850: loss = 5.22864411e-07 lambda = [-5.9998293  0.9998895]\n",
            "It 18900: loss = 5.66269648e-07 lambda = [-5.9998364  0.9998858]\n",
            "It 18950: loss = 1.82448537e-06 lambda = [-5.99981     0.99989104]\n",
            "It 19000: loss = 4.82343057e-06 lambda = [-5.999858    0.99982995]\n",
            "It 19050: loss = 5.16908472e-07 lambda = [-5.999825    0.99988997]\n",
            "It 19100: loss = 1.28812303e-06 lambda = [-5.9998546   0.99986804]\n",
            "It 19150: loss = 6.13295697e-07 lambda = [-5.9998193   0.99990726]\n",
            "It 19200: loss = 5.26899612e-07 lambda = [-5.999838   0.9998895]\n",
            "It 19250: loss = 5.26271492e-07 lambda = [-5.999838   0.9998629]\n",
            "It 19300: loss = 5.43385340e-07 lambda = [-5.999834    0.99988496]\n",
            "It 19350: loss = 2.67957421e-06 lambda = [-5.999716    0.99994224]\n",
            "It 19400: loss = 6.43366945e-07 lambda = [-5.9998393  0.9998831]\n",
            "It 19450: loss = 5.02921978e-07 lambda = [-5.9998393   0.99989283]\n",
            "It 19500: loss = 5.88988030e-07 lambda = [-5.9998384   0.99989665]\n",
            "It 19550: loss = 1.86953264e-06 lambda = [-5.9998446   0.99986917]\n",
            "It 19600: loss = 4.97227973e-07 lambda = [-5.9998317  0.999888 ]\n",
            "It 19650: loss = 2.06426284e-05 lambda = [-5.99995     0.99977493]\n",
            "It 19700: loss = 1.30122646e-06 lambda = [-5.9998193  0.9999095]\n",
            "It 19750: loss = 4.96014479e-07 lambda = [-5.999841    0.99989104]\n",
            "It 19800: loss = 9.45015131e-07 lambda = [-5.9998555  0.9998823]\n",
            "It 19850: loss = 1.35453945e-06 lambda = [-5.9998517  0.999868 ]\n",
            "It 19900: loss = 5.30478815e-07 lambda = [-5.9998307  0.9998955]\n",
            "It 19950: loss = 5.96036500e-07 lambda = [-5.9998603  0.9998665]\n",
            "It 20000: loss = 5.10423774e-07 lambda = [-5.9998393   0.99989635]\n",
            "It 20050: loss = 4.83061228e-07 lambda = [-5.99985    0.9998949]\n",
            "It 20100: loss = 4.19033904e-06 lambda = [-5.9998794  0.9998667]\n",
            "It 20150: loss = 1.05257743e-06 lambda = [-5.999856    0.99987406]\n",
            "It 20200: loss = 1.52452355e-06 lambda = [-5.9998307  0.9998986]\n",
            "It 20250: loss = 4.77846299e-07 lambda = [-5.999842   0.9998949]\n",
            "It 20300: loss = 4.78666266e-07 lambda = [-5.999851  0.999893]\n",
            "It 20350: loss = 9.38218091e-06 lambda = [-5.999783  0.999935]\n",
            "It 20400: loss = 4.82822941e-07 lambda = [-5.9998484  0.9998943]\n",
            "It 20450: loss = 7.74156069e-06 lambda = [-5.999797   0.9999154]\n",
            "It 20500: loss = 5.32269212e-07 lambda = [-5.999845   0.9998872]\n",
            "It 20550: loss = 4.72503672e-07 lambda = [-5.99985    0.9998921]\n",
            "It 20600: loss = 6.89392152e-07 lambda = [-5.999871   0.9998503]\n",
            "It 20650: loss = 4.76607568e-07 lambda = [-5.9998474  0.9998936]\n",
            "It 20700: loss = 4.16468538e-06 lambda = [-5.999882    0.99986595]\n",
            "It 20750: loss = 1.06545713e-06 lambda = [-5.999856   0.9998795]\n",
            "It 20800: loss = 4.64211752e-07 lambda = [-5.9998493   0.99989295]\n",
            "It 20850: loss = 3.42909625e-05 lambda = [-5.999677   1.0000168]\n",
            "It 20900: loss = 5.36227333e-07 lambda = [-5.9998493  0.9998932]\n",
            "It 20950: loss = 4.59469817e-07 lambda = [-5.9998536  0.9998978]\n",
            "It 21000: loss = 2.29176294e-05 lambda = [-5.9998903  0.9998251]\n",
            "It 21050: loss = 5.33442346e-07 lambda = [-5.999851   0.9998852]\n",
            "It 21100: loss = 4.57405292e-07 lambda = [-5.9998536  0.9998929]\n",
            "It 21150: loss = 4.35179709e-06 lambda = [-5.999825   0.9998954]\n",
            "It 21200: loss = 5.08792596e-07 lambda = [-5.999847  0.999899]\n",
            "It 21250: loss = 4.51616359e-07 lambda = [-5.999857  0.999897]\n",
            "It 21300: loss = 1.12937469e-05 lambda = [-5.999871    0.99983865]\n",
            "It 21350: loss = 4.81723760e-07 lambda = [-5.999846   0.9998899]\n",
            "It 21400: loss = 1.05726249e-04 lambda = [-6.0000377  0.9996852]\n",
            "It 21450: loss = 9.51550703e-07 lambda = [-5.999864    0.99988216]\n",
            "It 21500: loss = 4.47963657e-07 lambda = [-5.9998546   0.99989754]\n",
            "It 21550: loss = 4.43810308e-07 lambda = [-5.9998593   0.99989676]\n",
            "It 21600: loss = 2.19333451e-05 lambda = [-5.9999113  0.9998099]\n",
            "It 21650: loss = 1.91951108e-06 lambda = [-5.9998198   0.99992007]\n",
            "It 21700: loss = 4.44053654e-07 lambda = [-5.9998584   0.99988997]\n",
            "It 21750: loss = 4.44417708e-07 lambda = [-5.999857    0.99989533]\n",
            "It 21800: loss = 4.37923518e-07 lambda = [-5.99986     0.99989694]\n",
            "It 21850: loss = 5.74041314e-06 lambda = [-5.9998374   0.99987394]\n",
            "It 21900: loss = 4.38695281e-07 lambda = [-5.999859   0.9998933]\n",
            "It 21950: loss = 3.55741031e-06 lambda = [-5.999834    0.99992603]\n",
            "It 22000: loss = 6.43211479e-07 lambda = [-5.9998503   0.99988836]\n",
            "It 22050: loss = 4.33604214e-07 lambda = [-5.9998507  0.9998952]\n",
            "It 22100: loss = 4.31328971e-07 lambda = [-5.999859    0.99989605]\n",
            "It 22150: loss = 9.13933036e-05 lambda = [-6.0000353  0.9997023]\n",
            "It 22200: loss = 4.34370321e-07 lambda = [-5.999868  0.999888]\n",
            "It 22250: loss = 4.32352721e-07 lambda = [-5.999863    0.99989665]\n",
            "It 22300: loss = 1.11743611e-05 lambda = [-5.99989    0.9998319]\n",
            "It 22350: loss = 4.28296971e-07 lambda = [-5.9998546  0.9998917]\n",
            "It 22400: loss = 5.00659417e-06 lambda = [-5.9998016   0.99995375]\n",
            "It 22450: loss = 1.66955306e-06 lambda = [-5.999876   0.9998826]\n",
            "It 22500: loss = 4.31451895e-07 lambda = [-5.9998627  0.9998973]\n",
            "It 22550: loss = 4.22298996e-07 lambda = [-5.9998665  0.9998986]\n",
            "It 22600: loss = 4.43627823e-06 lambda = [-5.9997916  0.9999231]\n",
            "It 22650: loss = 4.28861370e-07 lambda = [-5.999853   0.9998908]\n",
            "It 22700: loss = 5.58942475e-06 lambda = [-5.999918   0.9998372]\n",
            "It 22750: loss = 1.35799201e-06 lambda = [-5.9998765  0.9998861]\n",
            "It 22800: loss = 4.19495109e-07 lambda = [-5.9998627   0.99990076]\n",
            "It 22850: loss = 4.16506879e-07 lambda = [-5.999868   0.9998997]\n",
            "It 22900: loss = 1.24019016e-05 lambda = [-5.999875   0.9998916]\n",
            "It 22950: loss = 8.24600363e-07 lambda = [-5.9998565   0.99988717]\n",
            "It 23000: loss = 8.48170828e-07 lambda = [-5.9998584  0.9998712]\n",
            "It 23050: loss = 5.21864308e-07 lambda = [-5.999871   0.9998879]\n",
            "It 23100: loss = 1.48308536e-05 lambda = [-5.9997597  1.0000027]\n",
            "It 23150: loss = 9.55053451e-07 lambda = [-5.999884    0.99988234]\n",
            "It 23200: loss = 4.35593336e-07 lambda = [-5.9998703   0.99989665]\n",
            "It 23250: loss = 2.13319413e-06 lambda = [-5.9998646   0.99987507]\n",
            "It 23300: loss = 2.06249915e-05 lambda = [-5.999767   0.9999671]\n",
            "It 23350: loss = 4.79308881e-07 lambda = [-5.9998574   0.99990034]\n",
            "It 23400: loss = 3.70887974e-05 lambda = [-6.0000043  0.9997503]\n",
            "It 23450: loss = 7.54739119e-07 lambda = [-5.999852    0.99991125]\n",
            "It 23500: loss = 6.43967780e-07 lambda = [-5.9998593  0.9998828]\n",
            "It 23550: loss = 1.76259891e-06 lambda = [-5.9998283  0.9999263]\n",
            "It 23600: loss = 9.57872885e-07 lambda = [-5.999854   0.9999068]\n",
            "It 23650: loss = 4.08092433e-07 lambda = [-5.9998665  0.9998956]\n",
            "Timeout is reached. Time elapsed: 100.00243330001831 seconds\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration: 4 Initial lambda: [10.0, 10.0]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "L-BFGS\n",
            "\n",
            "It 00000: loss = 2.77795851e-01 lambda = [ 9.999744 10.000003]\n",
            "It 00050: loss = 2.04108432e-01 lambda = [9.612195  9.9364395]\n",
            "It 00100: loss = 2.00948805e-01 lambda = [6.816157 9.491919]\n",
            "It 00150: loss = 8.22576061e-02 lambda = [-10.940093    6.3689737]\n",
            "It 00200: loss = 4.51497883e-02 lambda = [-13.066693    5.8202662]\n",
            "It 00250: loss = 3.89193036e-02 lambda = [-12.5034075   5.677424 ]\n",
            "It 00300: loss = 3.56319770e-02 lambda = [-12.065011    5.4790297]\n",
            "It 00350: loss = 3.21094356e-02 lambda = [-11.203114    4.8549685]\n",
            "It 00400: loss = 2.10212488e-02 lambda = [-9.396723   3.3008971]\n",
            "It 00450: loss = 1.41581930e-02 lambda = [-8.625559  2.521816]\n",
            "It 00500: loss = 7.70265330e-03 lambda = [-7.9295306  1.8195148]\n",
            "It 00550: loss = 5.92471007e-03 lambda = [-7.6827517  1.5661143]\n",
            "It 00600: loss = 4.60898550e-03 lambda = [-7.4362817  1.4053769]\n",
            "It 00650: loss = 3.41108069e-03 lambda = [-7.0711026  1.2604921]\n",
            "It 00700: loss = 1.68814289e-03 lambda = [-6.606876   1.2305589]\n",
            "It 00750: loss = 1.09130051e-03 lambda = [-6.4353113  1.1714568]\n",
            "It 00800: loss = 5.82532841e-04 lambda = [-6.193067   1.0674602]\n",
            "It 00850: loss = 4.12535504e-04 lambda = [-6.0538573  1.0153712]\n",
            "It 00900: loss = 3.48649570e-04 lambda = [-5.989988   1.0127367]\n",
            "It 00950: loss = 2.55509396e-04 lambda = [-5.963793   1.0045499]\n",
            "It 01000: loss = 1.89838305e-04 lambda = [-5.96121    0.9877062]\n",
            "It 01050: loss = 1.03450133e-04 lambda = [-5.99247    0.9969467]\n",
            "It 01100: loss = 7.89759797e-05 lambda = [-5.9985976   0.98956436]\n",
            "It 01150: loss = 5.86024471e-05 lambda = [-6.0037017   0.99469334]\n",
            "It 01200: loss = 5.12079132e-05 lambda = [-5.9996157  0.9979519]\n",
            "It 01250: loss = 4.52494132e-05 lambda = [-5.999419   1.0016255]\n",
            "\n",
            "\n",
            "SGD\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: loss = 3.81130040e-01 lambda = [ 9.999787 10.000002]\n",
            "It 00050: loss = 2.32947648e-01 lambda = [ 9.999659 10.000002]\n",
            "It 00100: loss = 2.30788469e-01 lambda = [ 9.999618 10.000002]\n",
            "It 00150: loss = 2.27739021e-01 lambda = [ 9.999443 10.000002]\n",
            "It 00200: loss = 2.23324567e-01 lambda = [9.998976 9.99995 ]\n",
            "It 00250: loss = 2.17600927e-01 lambda = [9.997915 9.999801]\n",
            "It 00300: loss = 2.11901605e-01 lambda = [9.995932 9.999431]\n",
            "It 00350: loss = 2.08138779e-01 lambda = [9.992896 9.998727]\n",
            "It 00400: loss = 2.06590727e-01 lambda = [9.988951 9.997696]\n",
            "It 00450: loss = 2.06117079e-01 lambda = [9.984454 9.996467]\n",
            "It 00500: loss = 2.05953449e-01 lambda = [9.979751 9.995179]\n",
            "It 00550: loss = 2.05864847e-01 lambda = [9.975044 9.993892]\n",
            "It 00600: loss = 2.05798268e-01 lambda = [9.970426 9.992632]\n",
            "It 00650: loss = 2.05741823e-01 lambda = [9.965938 9.991419]\n",
            "It 00700: loss = 2.05691963e-01 lambda = [9.961591 9.990254]\n",
            "It 00750: loss = 2.05647185e-01 lambda = [9.957387 9.989139]\n",
            "It 00800: loss = 2.05606431e-01 lambda = [9.953324 9.98807 ]\n",
            "It 00850: loss = 2.05569148e-01 lambda = [9.949401 9.987045]\n",
            "It 00900: loss = 2.05534726e-01 lambda = [9.94561  9.986063]\n",
            "It 00950: loss = 2.05502808e-01 lambda = [9.941948 9.985119]\n",
            "It 01000: loss = 2.05473125e-01 lambda = [9.938415 9.984213]\n",
            "It 01050: loss = 2.05445379e-01 lambda = [9.935002 9.983352]\n",
            "It 01100: loss = 2.05419436e-01 lambda = [9.931708 9.982522]\n",
            "It 01150: loss = 2.05395073e-01 lambda = [9.928525 9.981718]\n",
            "It 01200: loss = 2.05372140e-01 lambda = [9.925455 9.980955]\n",
            "It 01250: loss = 2.05350548e-01 lambda = [9.92249  9.980221]\n",
            "It 01300: loss = 2.05330148e-01 lambda = [9.919627 9.979506]\n",
            "It 01350: loss = 2.05310851e-01 lambda = [9.9168625 9.978834 ]\n",
            "It 01400: loss = 2.05292627e-01 lambda = [9.914193 9.978172]\n",
            "It 01450: loss = 2.05275327e-01 lambda = [9.911616 9.977552]\n",
            "It 01500: loss = 2.05258891e-01 lambda = [9.909127 9.976939]\n",
            "It 01550: loss = 2.05243304e-01 lambda = [9.906722 9.976367]\n",
            "It 01600: loss = 2.05228493e-01 lambda = [9.904406 9.975795]\n",
            "It 01650: loss = 2.05214381e-01 lambda = [9.902166 9.975269]\n",
            "It 01700: loss = 2.05200925e-01 lambda = [9.900002 9.974745]\n",
            "It 01750: loss = 2.05188140e-01 lambda = [9.897918 9.97425 ]\n",
            "It 01800: loss = 2.05175951e-01 lambda = [9.895899 9.973773]\n",
            "It 01850: loss = 2.05164284e-01 lambda = [9.893956 9.973296]\n",
            "It 01900: loss = 2.05153197e-01 lambda = [9.8920765 9.972866 ]\n",
            "It 01950: loss = 2.05142543e-01 lambda = [9.890262 9.972437]\n",
            "It 02000: loss = 2.05132380e-01 lambda = [9.888514 9.972009]\n",
            "It 02050: loss = 2.05122694e-01 lambda = [9.886823 9.971627]\n",
            "It 02100: loss = 2.05113381e-01 lambda = [9.885188 9.971246]\n",
            "It 02150: loss = 2.05104485e-01 lambda = [9.883611 9.970864]\n",
            "It 02200: loss = 2.05095962e-01 lambda = [9.8820915 9.970514 ]\n",
            "It 02250: loss = 2.05087811e-01 lambda = [9.880624  9.9701805]\n",
            "It 02300: loss = 2.05080017e-01 lambda = [9.879207 9.969847]\n",
            "It 02350: loss = 2.05072477e-01 lambda = [9.877838 9.969513]\n",
            "It 02400: loss = 2.05065325e-01 lambda = [9.876516 9.969217]\n",
            "It 02450: loss = 2.05058396e-01 lambda = [9.875239 9.968931]\n",
            "It 02500: loss = 2.05051780e-01 lambda = [9.874005 9.968645]\n",
            "It 02550: loss = 2.05045462e-01 lambda = [9.872813 9.968359]\n",
            "It 02600: loss = 2.05039337e-01 lambda = [9.871668 9.968084]\n",
            "It 02650: loss = 2.05033511e-01 lambda = [9.870562 9.967846]\n",
            "It 02700: loss = 2.05027878e-01 lambda = [9.869492  9.9676075]\n",
            "It 02750: loss = 2.05022469e-01 lambda = [9.868455 9.967369]\n",
            "It 02800: loss = 2.05017284e-01 lambda = [9.867454 9.967131]\n",
            "It 02850: loss = 2.05012292e-01 lambda = [9.866496 9.966892]\n",
            "It 02900: loss = 2.05007493e-01 lambda = [9.865565 9.966688]\n",
            "It 02950: loss = 2.05002889e-01 lambda = [9.864659 9.966497]\n",
            "It 03000: loss = 2.04998463e-01 lambda = [9.863801 9.966307]\n",
            "It 03050: loss = 2.04996273e-01 lambda = [9.863372 9.966211]\n",
            "It 03100: loss = 2.04994068e-01 lambda = [9.862943 9.966116]\n",
            "It 03150: loss = 2.04991922e-01 lambda = [9.862514 9.966021]\n",
            "It 03200: loss = 2.04989761e-01 lambda = [9.862084 9.965925]\n",
            "It 03250: loss = 2.04987586e-01 lambda = [9.861655 9.96583 ]\n",
            "It 03300: loss = 2.04985440e-01 lambda = [9.861226  9.9657345]\n",
            "It 03350: loss = 2.04983294e-01 lambda = [9.860797 9.965639]\n",
            "It 03400: loss = 2.04981148e-01 lambda = [9.860368 9.965544]\n",
            "It 03450: loss = 2.04979017e-01 lambda = [9.859939 9.965448]\n",
            "It 03500: loss = 2.04976872e-01 lambda = [9.859509 9.965353]\n",
            "It 03550: loss = 2.04974756e-01 lambda = [9.85908  9.965258]\n",
            "It 03600: loss = 2.04972610e-01 lambda = [9.858651 9.965162]\n",
            "It 03650: loss = 2.04970494e-01 lambda = [9.858222 9.965067]\n",
            "It 03700: loss = 2.04968363e-01 lambda = [9.857793 9.964972]\n",
            "It 03750: loss = 2.04966232e-01 lambda = [9.857364 9.964876]\n",
            "It 03800: loss = 2.04964146e-01 lambda = [9.856935 9.964781]\n",
            "It 03850: loss = 2.04962015e-01 lambda = [9.856505 9.964685]\n",
            "It 03900: loss = 2.04959929e-01 lambda = [9.856076 9.96459 ]\n",
            "It 03950: loss = 2.04957828e-01 lambda = [9.855647 9.964495]\n",
            "It 04000: loss = 2.04955712e-01 lambda = [9.855218 9.964399]\n",
            "It 04050: loss = 2.04953641e-01 lambda = [9.854789 9.964304]\n",
            "It 04100: loss = 2.04951525e-01 lambda = [9.85436  9.964209]\n",
            "It 04150: loss = 2.04949424e-01 lambda = [9.85393  9.964113]\n",
            "It 04200: loss = 2.04947352e-01 lambda = [9.853501 9.964018]\n",
            "It 04250: loss = 2.04945266e-01 lambda = [9.853072  9.9639225]\n",
            "It 04300: loss = 2.04943210e-01 lambda = [9.852643 9.963827]\n",
            "It 04350: loss = 2.04941139e-01 lambda = [9.852214 9.963732]\n",
            "It 04400: loss = 2.04939052e-01 lambda = [9.851785 9.963636]\n",
            "It 04450: loss = 2.04937011e-01 lambda = [9.851356 9.963541]\n",
            "It 04500: loss = 2.04934955e-01 lambda = [9.850926 9.963446]\n",
            "It 04550: loss = 2.04932883e-01 lambda = [9.850497 9.96335 ]\n",
            "It 04600: loss = 2.04930827e-01 lambda = [9.850068 9.963255]\n",
            "It 04650: loss = 2.04928786e-01 lambda = [9.849639 9.96316 ]\n",
            "It 04700: loss = 2.04926729e-01 lambda = [9.84921  9.963064]\n",
            "It 04750: loss = 2.04924673e-01 lambda = [9.848781 9.962969]\n",
            "It 04800: loss = 2.04922646e-01 lambda = [9.8483515 9.962873 ]\n",
            "It 04850: loss = 2.04920590e-01 lambda = [9.847922 9.962778]\n",
            "It 04900: loss = 2.04918593e-01 lambda = [9.847493 9.962683]\n",
            "It 04950: loss = 2.04916552e-01 lambda = [9.847064 9.962587]\n",
            "It 05000: loss = 2.04914510e-01 lambda = [9.846635 9.962492]\n",
            "It 05050: loss = 2.04912513e-01 lambda = [9.846206 9.962397]\n",
            "It 05100: loss = 2.04910472e-01 lambda = [9.845777 9.962301]\n",
            "It 05150: loss = 2.04908460e-01 lambda = [9.845347 9.962206]\n",
            "It 05200: loss = 2.04906449e-01 lambda = [9.844918  9.9621105]\n",
            "It 05250: loss = 2.04904437e-01 lambda = [9.844489 9.962015]\n",
            "It 05300: loss = 2.04902425e-01 lambda = [9.84406 9.96192]\n",
            "It 05350: loss = 2.04900429e-01 lambda = [9.843631 9.961824]\n",
            "It 05400: loss = 2.04898417e-01 lambda = [9.843202 9.961729]\n",
            "It 05450: loss = 2.04896435e-01 lambda = [9.8427725 9.961634 ]\n",
            "It 05500: loss = 2.04894423e-01 lambda = [9.842343 9.961538]\n",
            "It 05550: loss = 2.04892442e-01 lambda = [9.841914 9.961443]\n",
            "It 05600: loss = 2.04890445e-01 lambda = [9.841485 9.961348]\n",
            "It 05650: loss = 2.04888493e-01 lambda = [9.841056 9.961252]\n",
            "It 05700: loss = 2.04886496e-01 lambda = [9.840627 9.961157]\n",
            "It 05750: loss = 2.04884514e-01 lambda = [9.840198  9.9610615]\n",
            "It 05800: loss = 2.04882547e-01 lambda = [9.839768 9.960966]\n",
            "It 05850: loss = 2.04880565e-01 lambda = [9.839339 9.960871]\n",
            "It 05900: loss = 2.04878613e-01 lambda = [9.83891  9.960775]\n",
            "It 05950: loss = 2.04876646e-01 lambda = [9.838481 9.96068 ]\n",
            "It 06000: loss = 2.04874694e-01 lambda = [9.838052 9.960585]\n",
            "It 06050: loss = 2.04872727e-01 lambda = [9.837623 9.960489]\n",
            "It 06100: loss = 2.04870775e-01 lambda = [9.8371935 9.960394 ]\n",
            "It 06150: loss = 2.04868838e-01 lambda = [9.836764 9.960299]\n",
            "It 06200: loss = 2.04866871e-01 lambda = [9.836335 9.960203]\n",
            "It 06250: loss = 2.04864904e-01 lambda = [9.835906 9.960108]\n",
            "It 06300: loss = 2.04862997e-01 lambda = [9.835477 9.960012]\n",
            "It 06350: loss = 2.04861045e-01 lambda = [9.835048 9.959917]\n",
            "It 06400: loss = 2.04859123e-01 lambda = [9.834619 9.959822]\n",
            "It 06450: loss = 2.04857185e-01 lambda = [9.834189 9.959726]\n",
            "It 06500: loss = 2.04855263e-01 lambda = [9.83376  9.959631]\n",
            "It 06550: loss = 2.04853326e-01 lambda = [9.833331 9.959536]\n",
            "It 06600: loss = 2.04851389e-01 lambda = [9.832902 9.95944 ]\n",
            "It 06650: loss = 2.04849482e-01 lambda = [9.832473 9.959345]\n",
            "It 06700: loss = 2.04847559e-01 lambda = [9.832044  9.9592495]\n",
            "It 06750: loss = 2.04845652e-01 lambda = [9.8316145 9.959154 ]\n",
            "It 06800: loss = 2.04843730e-01 lambda = [9.831185 9.959059]\n",
            "It 06850: loss = 2.04841807e-01 lambda = [9.830756 9.958963]\n",
            "It 06900: loss = 2.04839915e-01 lambda = [9.830327 9.958868]\n",
            "It 06950: loss = 2.04838008e-01 lambda = [9.829898 9.958773]\n",
            "It 07000: loss = 2.04836130e-01 lambda = [9.829469 9.958677]\n",
            "It 07050: loss = 2.04835191e-01 lambda = [9.829278 9.95863 ]\n",
            "It 07100: loss = 2.04834267e-01 lambda = [9.829087 9.958582]\n",
            "It 07150: loss = 2.04833344e-01 lambda = [9.8288965 9.958534 ]\n",
            "It 07200: loss = 2.04832435e-01 lambda = [9.828706 9.958487]\n",
            "It 07250: loss = 2.04831541e-01 lambda = [9.828515 9.958439]\n",
            "It 07300: loss = 2.04830587e-01 lambda = [9.828324 9.958391]\n",
            "It 07350: loss = 2.04829693e-01 lambda = [9.828134  9.9583435]\n",
            "It 07400: loss = 2.04828769e-01 lambda = [9.827943 9.958296]\n",
            "It 07450: loss = 2.04827905e-01 lambda = [9.827752 9.958248]\n",
            "It 07500: loss = 2.04826966e-01 lambda = [9.827561 9.9582  ]\n",
            "It 07550: loss = 2.04826057e-01 lambda = [9.827371 9.958153]\n",
            "It 07600: loss = 2.04825133e-01 lambda = [9.82718  9.958105]\n",
            "It 07650: loss = 2.04824239e-01 lambda = [9.826989 9.958057]\n",
            "It 07700: loss = 2.04823345e-01 lambda = [9.826798 9.95801 ]\n",
            "It 07750: loss = 2.04822436e-01 lambda = [9.826608 9.957962]\n",
            "It 07800: loss = 2.04821527e-01 lambda = [9.826417 9.957914]\n",
            "It 07850: loss = 2.04820618e-01 lambda = [9.826226 9.957867]\n",
            "It 07900: loss = 2.04819709e-01 lambda = [9.8260355 9.957819 ]\n",
            "It 07950: loss = 2.04818830e-01 lambda = [9.825845 9.957771]\n",
            "It 08000: loss = 2.04817921e-01 lambda = [9.825654 9.957724]\n",
            "It 08050: loss = 2.04817027e-01 lambda = [9.825463 9.957676]\n",
            "It 08100: loss = 2.04816103e-01 lambda = [9.825273 9.957628]\n",
            "It 08150: loss = 2.04815194e-01 lambda = [9.825082 9.957581]\n",
            "It 08200: loss = 2.04814285e-01 lambda = [9.824891 9.957533]\n",
            "It 08250: loss = 2.04813406e-01 lambda = [9.8247   9.957485]\n",
            "It 08300: loss = 2.04812512e-01 lambda = [9.82451   9.9574375]\n",
            "It 08350: loss = 2.04811603e-01 lambda = [9.824319 9.95739 ]\n",
            "It 08400: loss = 2.04810709e-01 lambda = [9.824128 9.957342]\n",
            "It 08450: loss = 2.04809815e-01 lambda = [9.823937 9.957294]\n",
            "It 08500: loss = 2.04808921e-01 lambda = [9.823747 9.957247]\n",
            "It 08550: loss = 2.04808027e-01 lambda = [9.823556 9.957199]\n",
            "It 08600: loss = 2.04807162e-01 lambda = [9.823365 9.957151]\n",
            "It 08650: loss = 2.04806253e-01 lambda = [9.823174 9.957104]\n",
            "It 08700: loss = 2.04805344e-01 lambda = [9.822984 9.957056]\n",
            "It 08750: loss = 2.04804480e-01 lambda = [9.822793 9.957008]\n",
            "It 08800: loss = 2.04803586e-01 lambda = [9.822602 9.956961]\n",
            "It 08850: loss = 2.04802677e-01 lambda = [9.822412 9.956913]\n",
            "It 08900: loss = 2.04801783e-01 lambda = [9.822221 9.956865]\n",
            "It 08950: loss = 2.04800904e-01 lambda = [9.82203  9.956818]\n",
            "It 09000: loss = 2.04800040e-01 lambda = [9.821839 9.95677 ]\n",
            "It 09050: loss = 2.04799116e-01 lambda = [9.821649 9.956722]\n",
            "It 09100: loss = 2.04798251e-01 lambda = [9.821458 9.956675]\n",
            "It 09150: loss = 2.04797372e-01 lambda = [9.821267 9.956627]\n",
            "It 09200: loss = 2.04796478e-01 lambda = [9.821076 9.956579]\n",
            "It 09250: loss = 2.04795569e-01 lambda = [9.820886 9.956532]\n",
            "It 09300: loss = 2.04794690e-01 lambda = [9.820695 9.956484]\n",
            "It 09350: loss = 2.04793826e-01 lambda = [9.820504 9.956436]\n",
            "It 09400: loss = 2.04792947e-01 lambda = [9.820313 9.956388]\n",
            "It 09450: loss = 2.04792053e-01 lambda = [9.820123 9.956341]\n",
            "It 09500: loss = 2.04791144e-01 lambda = [9.819932 9.956293]\n",
            "It 09550: loss = 2.04790264e-01 lambda = [9.819741 9.956245]\n",
            "It 09600: loss = 2.04789415e-01 lambda = [9.8195505 9.956198 ]\n",
            "It 09650: loss = 2.04788521e-01 lambda = [9.81936 9.95615]\n",
            "It 09700: loss = 2.04787627e-01 lambda = [9.819169 9.956102]\n",
            "It 09750: loss = 2.04786763e-01 lambda = [9.818978 9.956055]\n",
            "It 09800: loss = 2.04785883e-01 lambda = [9.818788 9.956007]\n",
            "It 09850: loss = 2.04784989e-01 lambda = [9.818597 9.955959]\n",
            "It 09900: loss = 2.04784095e-01 lambda = [9.818406 9.955912]\n",
            "It 09950: loss = 2.04783231e-01 lambda = [9.818215 9.955864]\n",
            "It 10000: loss = 2.04782352e-01 lambda = [9.818025 9.955816]\n",
            "It 10050: loss = 2.04781488e-01 lambda = [9.817834 9.955769]\n",
            "It 10100: loss = 2.04780594e-01 lambda = [9.817643 9.955721]\n",
            "It 10150: loss = 2.04779729e-01 lambda = [9.817452 9.955673]\n",
            "It 10200: loss = 2.04778835e-01 lambda = [9.817262 9.955626]\n",
            "It 10250: loss = 2.04777971e-01 lambda = [9.817071 9.955578]\n",
            "It 10300: loss = 2.04777122e-01 lambda = [9.81688 9.95553]\n",
            "It 10350: loss = 2.04776242e-01 lambda = [9.8166895 9.9554825]\n",
            "It 10400: loss = 2.04775333e-01 lambda = [9.816499 9.955435]\n",
            "It 10450: loss = 2.04774469e-01 lambda = [9.816308 9.955387]\n",
            "It 10500: loss = 2.04773605e-01 lambda = [9.816117 9.955339]\n",
            "It 10550: loss = 2.04772726e-01 lambda = [9.815927 9.955292]\n",
            "It 10600: loss = 2.04771847e-01 lambda = [9.815736 9.955244]\n",
            "It 10650: loss = 2.04770982e-01 lambda = [9.815545 9.955196]\n",
            "It 10700: loss = 2.04770148e-01 lambda = [9.815354 9.955149]\n",
            "It 10750: loss = 2.04769254e-01 lambda = [9.815164 9.955101]\n",
            "It 10800: loss = 2.04768389e-01 lambda = [9.814973 9.955053]\n",
            "It 10850: loss = 2.04767540e-01 lambda = [9.814782 9.955006]\n",
            "It 10900: loss = 2.04766661e-01 lambda = [9.814591 9.954958]\n",
            "It 10950: loss = 2.04765797e-01 lambda = [9.814401 9.95491 ]\n",
            "It 11000: loss = 2.04764932e-01 lambda = [9.81421  9.954863]\n",
            "It 11050: loss = 2.04764083e-01 lambda = [9.814019 9.954815]\n",
            "It 11100: loss = 2.04763219e-01 lambda = [9.813828 9.954767]\n",
            "It 11150: loss = 2.04762340e-01 lambda = [9.813638 9.95472 ]\n",
            "It 11200: loss = 2.04761475e-01 lambda = [9.813447 9.954672]\n",
            "It 11250: loss = 2.04760626e-01 lambda = [9.813256 9.954624]\n",
            "It 11300: loss = 2.04759762e-01 lambda = [9.813066  9.9545765]\n",
            "It 11350: loss = 2.04758897e-01 lambda = [9.812875 9.954529]\n",
            "It 11400: loss = 2.04758033e-01 lambda = [9.812684 9.954481]\n",
            "It 11450: loss = 2.04757169e-01 lambda = [9.812493 9.954433]\n",
            "It 11500: loss = 2.04756305e-01 lambda = [9.812303 9.954386]\n",
            "It 11550: loss = 2.04755470e-01 lambda = [9.812112 9.954338]\n",
            "It 11600: loss = 2.04754606e-01 lambda = [9.811921 9.95429 ]\n",
            "It 11650: loss = 2.04753742e-01 lambda = [9.81173  9.954243]\n",
            "It 11700: loss = 2.04752892e-01 lambda = [9.81154  9.954195]\n",
            "It 11750: loss = 2.04752043e-01 lambda = [9.811349 9.954147]\n",
            "It 11800: loss = 2.04751164e-01 lambda = [9.811158 9.9541  ]\n",
            "It 11850: loss = 2.04750314e-01 lambda = [9.810967 9.954052]\n",
            "It 11900: loss = 2.04749465e-01 lambda = [9.810777 9.954004]\n",
            "It 11950: loss = 2.04748616e-01 lambda = [9.810586 9.953957]\n",
            "It 12000: loss = 2.04747766e-01 lambda = [9.810395 9.953909]\n",
            "It 12050: loss = 2.04746917e-01 lambda = [9.8102045 9.953861 ]\n",
            "It 12100: loss = 2.04746053e-01 lambda = [9.810014 9.953814]\n",
            "It 12150: loss = 2.04745203e-01 lambda = [9.809823 9.953766]\n",
            "It 12200: loss = 2.04744369e-01 lambda = [9.809632 9.953718]\n",
            "It 12250: loss = 2.04743490e-01 lambda = [9.809442  9.9536705]\n",
            "It 12300: loss = 2.04742640e-01 lambda = [9.809251 9.953623]\n",
            "It 12350: loss = 2.04741806e-01 lambda = [9.80906  9.953575]\n",
            "It 12400: loss = 2.04740942e-01 lambda = [9.808869 9.953527]\n",
            "It 12450: loss = 2.04740077e-01 lambda = [9.808679 9.95348 ]\n",
            "It 12500: loss = 2.04739273e-01 lambda = [9.808488 9.953432]\n",
            "It 12550: loss = 2.04738408e-01 lambda = [9.808297 9.953384]\n",
            "It 12600: loss = 2.04737574e-01 lambda = [9.808106 9.953337]\n",
            "It 12650: loss = 2.04736739e-01 lambda = [9.807916 9.953289]\n",
            "It 12700: loss = 2.04735875e-01 lambda = [9.807725 9.953241]\n",
            "It 12750: loss = 2.04735056e-01 lambda = [9.807534 9.953194]\n",
            "It 12800: loss = 2.04734206e-01 lambda = [9.8073435 9.953146 ]\n",
            "It 12850: loss = 2.04733342e-01 lambda = [9.807153 9.953098]\n",
            "It 12900: loss = 2.04732507e-01 lambda = [9.806962 9.953051]\n",
            "It 12950: loss = 2.04731673e-01 lambda = [9.806771 9.953003]\n",
            "It 13000: loss = 2.04730824e-01 lambda = [9.806581 9.952955]\n",
            "It 13050: loss = 2.04730004e-01 lambda = [9.80639  9.952908]\n",
            "It 13100: loss = 2.04729155e-01 lambda = [9.806199 9.95286 ]\n",
            "It 13150: loss = 2.04728335e-01 lambda = [9.806008 9.952812]\n",
            "It 13200: loss = 2.04727471e-01 lambda = [9.805818  9.9527645]\n",
            "It 13250: loss = 2.04726622e-01 lambda = [9.805627 9.952717]\n",
            "It 13300: loss = 2.04725802e-01 lambda = [9.805436 9.952669]\n",
            "It 13350: loss = 2.04724967e-01 lambda = [9.805245 9.952621]\n",
            "It 13400: loss = 2.04724163e-01 lambda = [9.805055 9.952574]\n",
            "It 13450: loss = 2.04723299e-01 lambda = [9.804864 9.952526]\n",
            "It 13500: loss = 2.04722479e-01 lambda = [9.804673 9.952478]\n",
            "It 13550: loss = 2.04721645e-01 lambda = [9.804482 9.952431]\n",
            "It 13600: loss = 2.04720795e-01 lambda = [9.804292 9.952383]\n",
            "It 13650: loss = 2.04719961e-01 lambda = [9.804101 9.952335]\n",
            "It 13700: loss = 2.04719141e-01 lambda = [9.80391  9.952288]\n",
            "It 13750: loss = 2.04718307e-01 lambda = [9.8037195 9.95224  ]\n",
            "It 13800: loss = 2.04717487e-01 lambda = [9.803529 9.952192]\n",
            "It 13850: loss = 2.04716653e-01 lambda = [9.803338 9.952145]\n",
            "It 13900: loss = 2.04715803e-01 lambda = [9.803147 9.952097]\n",
            "It 13950: loss = 2.04714984e-01 lambda = [9.802957 9.952049]\n",
            "It 14000: loss = 2.04714164e-01 lambda = [9.802766 9.952002]\n",
            "It 14050: loss = 2.04713732e-01 lambda = [9.8026705 9.952002 ]\n",
            "It 14100: loss = 2.04713330e-01 lambda = [9.802575 9.952002]\n",
            "It 14150: loss = 2.04712927e-01 lambda = [9.80248  9.952002]\n",
            "It 14200: loss = 2.04712525e-01 lambda = [9.802384 9.952002]\n",
            "It 14250: loss = 2.04712108e-01 lambda = [9.802289 9.952002]\n",
            "It 14300: loss = 2.04711691e-01 lambda = [9.802194 9.952002]\n",
            "It 14350: loss = 2.04711288e-01 lambda = [9.802098 9.952002]\n",
            "It 14400: loss = 2.04710886e-01 lambda = [9.802003 9.952002]\n",
            "It 14450: loss = 2.04710484e-01 lambda = [9.801908 9.952002]\n",
            "It 14500: loss = 2.04710081e-01 lambda = [9.801812 9.952002]\n",
            "It 14550: loss = 2.04709679e-01 lambda = [9.801717 9.952002]\n",
            "It 14600: loss = 2.04709277e-01 lambda = [9.801621 9.952002]\n",
            "It 14650: loss = 2.04708859e-01 lambda = [9.801526 9.952002]\n",
            "It 14700: loss = 2.04708472e-01 lambda = [9.801431 9.952002]\n",
            "It 14750: loss = 2.04708055e-01 lambda = [9.801335 9.952002]\n",
            "It 14800: loss = 2.04707637e-01 lambda = [9.80124  9.952002]\n",
            "It 14850: loss = 2.04707235e-01 lambda = [9.801145 9.952002]\n",
            "It 14900: loss = 2.04706848e-01 lambda = [9.801049 9.952002]\n",
            "It 14950: loss = 2.04706445e-01 lambda = [9.800954 9.952002]\n",
            "It 15000: loss = 2.04706028e-01 lambda = [9.8008585 9.952002 ]\n",
            "It 15050: loss = 2.04705626e-01 lambda = [9.800763 9.952002]\n",
            "It 15100: loss = 2.04705238e-01 lambda = [9.800668 9.952002]\n",
            "It 15150: loss = 2.04704821e-01 lambda = [9.800572 9.952002]\n",
            "It 15200: loss = 2.04704434e-01 lambda = [9.800477 9.952002]\n",
            "It 15250: loss = 2.04704016e-01 lambda = [9.800382 9.952002]\n",
            "It 15300: loss = 2.04703599e-01 lambda = [9.800286 9.952002]\n",
            "It 15350: loss = 2.04703197e-01 lambda = [9.800191 9.952002]\n",
            "It 15400: loss = 2.04702809e-01 lambda = [9.800096 9.952002]\n",
            "It 15450: loss = 2.04702407e-01 lambda = [9.8      9.952002]\n",
            "It 15500: loss = 2.04701990e-01 lambda = [9.799905 9.952002]\n",
            "It 15550: loss = 2.04701588e-01 lambda = [9.799809 9.952002]\n",
            "It 15600: loss = 2.04701200e-01 lambda = [9.799714 9.952002]\n",
            "It 15650: loss = 2.04700768e-01 lambda = [9.799619 9.952002]\n",
            "It 15700: loss = 2.04700381e-01 lambda = [9.799523 9.952002]\n",
            "It 15750: loss = 2.04699993e-01 lambda = [9.799428 9.952002]\n",
            "It 15800: loss = 2.04699576e-01 lambda = [9.799333 9.952002]\n",
            "It 15850: loss = 2.04699174e-01 lambda = [9.799237 9.952002]\n",
            "It 15900: loss = 2.04698786e-01 lambda = [9.799142 9.952002]\n",
            "It 15950: loss = 2.04698369e-01 lambda = [9.7990465 9.952002 ]\n",
            "It 16000: loss = 2.04697967e-01 lambda = [9.798951 9.952002]\n",
            "It 16050: loss = 2.04697579e-01 lambda = [9.798856 9.952002]\n",
            "It 16100: loss = 2.04697177e-01 lambda = [9.79876  9.952002]\n",
            "It 16150: loss = 2.04696774e-01 lambda = [9.798665 9.952002]\n",
            "It 16200: loss = 2.04696372e-01 lambda = [9.79857  9.952002]\n",
            "It 16250: loss = 2.04695970e-01 lambda = [9.798474 9.952002]\n",
            "It 16300: loss = 2.04695567e-01 lambda = [9.798379 9.952002]\n",
            "It 16350: loss = 2.04695180e-01 lambda = [9.798284 9.952002]\n",
            "It 16400: loss = 2.04694763e-01 lambda = [9.798188 9.952002]\n",
            "It 16450: loss = 2.04694375e-01 lambda = [9.798093 9.952002]\n",
            "It 16500: loss = 2.04693973e-01 lambda = [9.797997 9.952002]\n",
            "It 16550: loss = 2.04693556e-01 lambda = [9.797902 9.952002]\n",
            "It 16600: loss = 2.04693154e-01 lambda = [9.797807 9.952002]\n",
            "It 16650: loss = 2.04692736e-01 lambda = [9.797711 9.952002]\n",
            "It 16700: loss = 2.04692364e-01 lambda = [9.797616 9.952002]\n",
            "It 16750: loss = 2.04691947e-01 lambda = [9.797521 9.952002]\n",
            "It 16800: loss = 2.04691559e-01 lambda = [9.797425 9.952002]\n",
            "It 16850: loss = 2.04691172e-01 lambda = [9.79733  9.952002]\n",
            "It 16900: loss = 2.04690754e-01 lambda = [9.797235 9.952002]\n",
            "It 16950: loss = 2.04690367e-01 lambda = [9.797139 9.952002]\n",
            "It 17000: loss = 2.04689950e-01 lambda = [9.797044 9.952002]\n",
            "It 17050: loss = 2.04689562e-01 lambda = [9.796948 9.952002]\n",
            "It 17100: loss = 2.04689175e-01 lambda = [9.796853 9.952002]\n",
            "It 17150: loss = 2.04688773e-01 lambda = [9.796758 9.952002]\n",
            "It 17200: loss = 2.04688370e-01 lambda = [9.796662 9.952002]\n",
            "It 17250: loss = 2.04687953e-01 lambda = [9.796567 9.952002]\n",
            "It 17300: loss = 2.04687580e-01 lambda = [9.796472 9.952002]\n",
            "It 17350: loss = 2.04687163e-01 lambda = [9.796376 9.952002]\n",
            "It 17400: loss = 2.04686806e-01 lambda = [9.796281 9.952002]\n",
            "It 17450: loss = 2.04686373e-01 lambda = [9.7961855 9.952002 ]\n",
            "It 17500: loss = 2.04685986e-01 lambda = [9.79609  9.952002]\n",
            "It 17550: loss = 2.04685599e-01 lambda = [9.795995 9.952002]\n",
            "It 17600: loss = 2.04685181e-01 lambda = [9.795899 9.952002]\n",
            "It 17650: loss = 2.04684794e-01 lambda = [9.795804 9.952002]\n",
            "It 17700: loss = 2.04684362e-01 lambda = [9.795709 9.952002]\n",
            "It 17750: loss = 2.04684004e-01 lambda = [9.795613 9.952002]\n",
            "It 17800: loss = 2.04683572e-01 lambda = [9.795518 9.952002]\n",
            "It 17850: loss = 2.04683214e-01 lambda = [9.795423 9.952002]\n",
            "It 17900: loss = 2.04682797e-01 lambda = [9.795327 9.952002]\n",
            "It 17950: loss = 2.04682410e-01 lambda = [9.795232 9.952002]\n",
            "It 18000: loss = 2.04682007e-01 lambda = [9.795136 9.952002]\n",
            "It 18050: loss = 2.04681605e-01 lambda = [9.795041 9.952002]\n",
            "It 18100: loss = 2.04681218e-01 lambda = [9.794946 9.952002]\n",
            "It 18150: loss = 2.04680830e-01 lambda = [9.79485  9.952002]\n",
            "It 18200: loss = 2.04680443e-01 lambda = [9.794755 9.952002]\n",
            "It 18250: loss = 2.04680026e-01 lambda = [9.79466  9.952002]\n",
            "It 18300: loss = 2.04679623e-01 lambda = [9.794564 9.952002]\n",
            "It 18350: loss = 2.04679236e-01 lambda = [9.794469 9.952002]\n",
            "It 18400: loss = 2.04678833e-01 lambda = [9.7943735 9.952002 ]\n",
            "It 18450: loss = 2.04678446e-01 lambda = [9.794278 9.952002]\n",
            "It 18500: loss = 2.04678044e-01 lambda = [9.794183 9.952002]\n",
            "It 18550: loss = 2.04677656e-01 lambda = [9.794087 9.952002]\n",
            "It 18600: loss = 2.04677284e-01 lambda = [9.793992 9.952002]\n",
            "It 18650: loss = 2.04676881e-01 lambda = [9.793897 9.952002]\n",
            "It 18700: loss = 2.04676509e-01 lambda = [9.793801 9.952002]\n",
            "It 18750: loss = 2.04676092e-01 lambda = [9.793706 9.952002]\n",
            "It 18800: loss = 2.04675689e-01 lambda = [9.793611 9.952002]\n",
            "It 18850: loss = 2.04675302e-01 lambda = [9.793515 9.952002]\n",
            "It 18900: loss = 2.04674900e-01 lambda = [9.79342  9.952002]\n",
            "It 18950: loss = 2.04674512e-01 lambda = [9.793324 9.952002]\n",
            "It 19000: loss = 2.04674125e-01 lambda = [9.793229 9.952002]\n",
            "It 19050: loss = 2.04673722e-01 lambda = [9.793134 9.952002]\n",
            "It 19100: loss = 2.04673335e-01 lambda = [9.793038 9.952002]\n",
            "It 19150: loss = 2.04672962e-01 lambda = [9.792943 9.952002]\n",
            "It 19200: loss = 2.04672545e-01 lambda = [9.792848 9.952002]\n",
            "It 19250: loss = 2.04672143e-01 lambda = [9.792752 9.952002]\n",
            "It 19300: loss = 2.04671755e-01 lambda = [9.792657 9.952002]\n",
            "It 19350: loss = 2.04671353e-01 lambda = [9.792562 9.952002]\n",
            "It 19400: loss = 2.04670981e-01 lambda = [9.792466 9.952002]\n",
            "It 19450: loss = 2.04670578e-01 lambda = [9.792371 9.952002]\n",
            "It 19500: loss = 2.04670191e-01 lambda = [9.792275 9.952002]\n",
            "It 19550: loss = 2.04669788e-01 lambda = [9.79218  9.952002]\n",
            "It 19600: loss = 2.04669401e-01 lambda = [9.792085 9.952002]\n",
            "It 19650: loss = 2.04668999e-01 lambda = [9.791989 9.952002]\n",
            "It 19700: loss = 2.04668611e-01 lambda = [9.791894 9.952002]\n",
            "It 19750: loss = 2.04668209e-01 lambda = [9.791799 9.952002]\n",
            "It 19800: loss = 2.04667836e-01 lambda = [9.791703 9.952002]\n",
            "It 19850: loss = 2.04667434e-01 lambda = [9.791608 9.952002]\n",
            "It 19900: loss = 2.04667047e-01 lambda = [9.7915125 9.952002 ]\n",
            "It 19950: loss = 2.04666644e-01 lambda = [9.791417 9.952002]\n",
            "It 20000: loss = 2.04666257e-01 lambda = [9.791322 9.952002]\n",
            "It 20050: loss = 2.04665869e-01 lambda = [9.791226 9.952002]\n",
            "It 20100: loss = 2.04665467e-01 lambda = [9.791131 9.952002]\n",
            "It 20150: loss = 2.04665080e-01 lambda = [9.791036 9.952002]\n",
            "It 20200: loss = 2.04664662e-01 lambda = [9.79094  9.952002]\n",
            "It 20250: loss = 2.04664305e-01 lambda = [9.790845 9.952002]\n",
            "It 20300: loss = 2.04663888e-01 lambda = [9.79075  9.952002]\n",
            "It 20350: loss = 2.04663500e-01 lambda = [9.790654 9.952002]\n",
            "It 20400: loss = 2.04663113e-01 lambda = [9.790559 9.952002]\n",
            "It 20450: loss = 2.04662740e-01 lambda = [9.790463 9.952002]\n",
            "It 20500: loss = 2.04662323e-01 lambda = [9.790368 9.952002]\n",
            "It 20550: loss = 2.04661936e-01 lambda = [9.790273 9.952002]\n",
            "It 20600: loss = 2.04661533e-01 lambda = [9.790177 9.952002]\n",
            "It 20650: loss = 2.04661161e-01 lambda = [9.790082 9.952002]\n",
            "It 20700: loss = 2.04660758e-01 lambda = [9.789987 9.952002]\n",
            "It 20750: loss = 2.04660371e-01 lambda = [9.789891 9.952002]\n",
            "It 20800: loss = 2.04659969e-01 lambda = [9.789796 9.952002]\n",
            "It 20850: loss = 2.04659596e-01 lambda = [9.7897005 9.952002 ]\n",
            "It 20900: loss = 2.04659209e-01 lambda = [9.789605 9.952002]\n",
            "It 20950: loss = 2.04658821e-01 lambda = [9.78951  9.952002]\n",
            "It 21000: loss = 2.04658419e-01 lambda = [9.789414 9.952002]\n",
            "It 21050: loss = 2.04658031e-01 lambda = [9.789319 9.952002]\n",
            "It 21100: loss = 2.04657659e-01 lambda = [9.789224 9.952002]\n",
            "It 21150: loss = 2.04657242e-01 lambda = [9.789128 9.952002]\n",
            "It 21200: loss = 2.04656854e-01 lambda = [9.789033 9.952002]\n",
            "It 21250: loss = 2.04656467e-01 lambda = [9.788938 9.952002]\n",
            "It 21300: loss = 2.04656065e-01 lambda = [9.788842 9.952002]\n",
            "It 21350: loss = 2.04655677e-01 lambda = [9.788747 9.952002]\n",
            "It 21400: loss = 2.04655275e-01 lambda = [9.788651 9.952002]\n",
            "It 21450: loss = 2.04654917e-01 lambda = [9.788556 9.952002]\n",
            "It 21500: loss = 2.04654515e-01 lambda = [9.788461 9.952002]\n",
            "It 21550: loss = 2.04654142e-01 lambda = [9.788365 9.952002]\n",
            "It 21600: loss = 2.04653740e-01 lambda = [9.78827  9.952002]\n",
            "It 21650: loss = 2.04653323e-01 lambda = [9.788175 9.952002]\n",
            "It 21700: loss = 2.04652950e-01 lambda = [9.788079 9.952002]\n",
            "It 21750: loss = 2.04652578e-01 lambda = [9.787984 9.952002]\n",
            "It 21800: loss = 2.04652175e-01 lambda = [9.787889 9.952002]\n",
            "It 21850: loss = 2.04651803e-01 lambda = [9.787793 9.952002]\n",
            "It 21900: loss = 2.04651400e-01 lambda = [9.787698 9.952002]\n",
            "It 21950: loss = 2.04651013e-01 lambda = [9.787602 9.952002]\n",
            "It 22000: loss = 2.04650611e-01 lambda = [9.787507 9.952002]\n",
            "It 22050: loss = 2.04650223e-01 lambda = [9.787412 9.952002]\n",
            "It 22100: loss = 2.04649851e-01 lambda = [9.787316 9.952002]\n",
            "It 22150: loss = 2.04649463e-01 lambda = [9.787221 9.952002]\n",
            "It 22200: loss = 2.04649076e-01 lambda = [9.787126 9.952002]\n",
            "It 22250: loss = 2.04648659e-01 lambda = [9.78703  9.952002]\n",
            "It 22300: loss = 2.04648256e-01 lambda = [9.786935 9.952002]\n",
            "It 22350: loss = 2.04647884e-01 lambda = [9.7868395 9.952002 ]\n",
            "It 22400: loss = 2.04647496e-01 lambda = [9.786744 9.952002]\n",
            "It 22450: loss = 2.04647124e-01 lambda = [9.786649 9.952002]\n",
            "It 22500: loss = 2.04646707e-01 lambda = [9.786553 9.952002]\n",
            "It 22550: loss = 2.04646334e-01 lambda = [9.786458 9.952002]\n",
            "It 22600: loss = 2.04645962e-01 lambda = [9.786363 9.952002]\n",
            "It 22650: loss = 2.04645574e-01 lambda = [9.786267 9.952002]\n",
            "It 22700: loss = 2.04645187e-01 lambda = [9.786172 9.952002]\n",
            "It 22750: loss = 2.04644784e-01 lambda = [9.786077 9.952002]\n",
            "It 22800: loss = 2.04644382e-01 lambda = [9.785981 9.952002]\n",
            "It 22850: loss = 2.04644024e-01 lambda = [9.785886 9.952002]\n",
            "It 22900: loss = 2.04643622e-01 lambda = [9.78579  9.952002]\n",
            "It 22950: loss = 2.04643250e-01 lambda = [9.785695 9.952002]\n",
            "It 23000: loss = 2.04642847e-01 lambda = [9.7856   9.952002]\n",
            "It 23050: loss = 2.04642445e-01 lambda = [9.785504 9.952002]\n",
            "It 23100: loss = 2.04642072e-01 lambda = [9.785409 9.952002]\n",
            "It 23150: loss = 2.04641700e-01 lambda = [9.785314 9.952002]\n",
            "It 23200: loss = 2.04641327e-01 lambda = [9.785218 9.952002]\n",
            "It 23250: loss = 2.04640910e-01 lambda = [9.785123 9.952002]\n",
            "It 23300: loss = 2.04640552e-01 lambda = [9.7850275 9.952002 ]\n",
            "It 23350: loss = 2.04640135e-01 lambda = [9.784932 9.952002]\n",
            "It 23400: loss = 2.04639778e-01 lambda = [9.784837 9.952002]\n",
            "It 23450: loss = 2.04639360e-01 lambda = [9.784741 9.952002]\n",
            "It 23500: loss = 2.04638988e-01 lambda = [9.784646 9.952002]\n",
            "It 23550: loss = 2.04638615e-01 lambda = [9.784551 9.952002]\n",
            "It 23600: loss = 2.04638213e-01 lambda = [9.784455 9.952002]\n",
            "It 23650: loss = 2.04637840e-01 lambda = [9.78436  9.952002]\n",
            "It 23700: loss = 2.04637453e-01 lambda = [9.784265 9.952002]\n",
            "It 23750: loss = 2.04637080e-01 lambda = [9.784169 9.952002]\n",
            "It 23800: loss = 2.04636693e-01 lambda = [9.784074 9.952002]\n",
            "It 23850: loss = 2.04636306e-01 lambda = [9.783978 9.952002]\n",
            "It 23900: loss = 2.04635903e-01 lambda = [9.783883 9.952002]\n",
            "It 23950: loss = 2.04635531e-01 lambda = [9.783788 9.952002]\n",
            "It 24000: loss = 2.04635143e-01 lambda = [9.783692 9.952002]\n",
            "It 24050: loss = 2.04634756e-01 lambda = [9.783597 9.952002]\n",
            "It 24100: loss = 2.04634383e-01 lambda = [9.783502 9.952002]\n",
            "It 24150: loss = 2.04633966e-01 lambda = [9.783406 9.952002]\n",
            "It 24200: loss = 2.04633594e-01 lambda = [9.783311 9.952002]\n",
            "Timeout is reached. Time elapsed: 100.00076460838318 seconds\n",
            "\n",
            "\n",
            "Adam\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: loss = 3.81130040e-01 lambda = [ 9.900146 10.088248]\n",
            "It 00050: loss = 2.05530182e-01 lambda = [9.241428 8.495403]\n",
            "It 00100: loss = 1.99360609e-01 lambda = [8.968345 4.267089]\n",
            "It 00150: loss = 1.92757845e-01 lambda = [ 8.5682125 -1.6447382]\n",
            "It 00200: loss = 1.70974359e-01 lambda = [ 7.8874   -9.369638]\n",
            "It 00250: loss = 1.45404786e-01 lambda = [  7.063438 -14.167224]\n",
            "It 00300: loss = 1.76302761e-01 lambda = [  6.0271626 -15.193482 ]\n",
            "It 00350: loss = 1.25975728e-01 lambda = [  5.4245105 -15.469195 ]\n",
            "It 00400: loss = 1.21567592e-01 lambda = [  4.4598017 -15.77515  ]\n",
            "It 00450: loss = 1.10722400e-01 lambda = [  4.1135235 -15.568432 ]\n",
            "It 00500: loss = 1.08519278e-01 lambda = [  3.9446633 -15.224324 ]\n",
            "It 00550: loss = 1.06624797e-01 lambda = [  3.8289104 -14.887564 ]\n",
            "It 00600: loss = 1.10509925e-01 lambda = [  3.7397156 -14.668863 ]\n",
            "It 00650: loss = 1.03735074e-01 lambda = [  3.6756845 -14.520767 ]\n",
            "It 00700: loss = 1.06775835e-01 lambda = [  3.6446836 -14.375097 ]\n",
            "It 00750: loss = 1.02006584e-01 lambda = [  3.6146417 -14.273433 ]\n",
            "It 00800: loss = 1.00761950e-01 lambda = [  3.5152905 -14.14519  ]\n",
            "It 00850: loss = 1.01281360e-01 lambda = [  3.465222 -14.053089]\n",
            "It 00900: loss = 1.01043448e-01 lambda = [  3.446373  -13.9400425]\n",
            "It 00950: loss = 9.98026803e-02 lambda = [  3.4125004 -13.827967 ]\n",
            "It 01000: loss = 9.74438190e-02 lambda = [  3.3612204 -13.690539 ]\n",
            "It 01050: loss = 9.81663093e-02 lambda = [  3.1868193 -13.535611 ]\n",
            "It 01100: loss = 9.63121951e-02 lambda = [  3.198674 -13.332373]\n",
            "It 01150: loss = 9.58359092e-02 lambda = [  3.2350183 -13.209178 ]\n",
            "It 01200: loss = 1.01201124e-01 lambda = [  3.189084 -13.134087]\n",
            "It 01250: loss = 9.53155085e-02 lambda = [  3.1159327 -13.042155 ]\n",
            "It 01300: loss = 9.50445086e-02 lambda = [  3.1304731 -12.967482 ]\n",
            "It 01350: loss = 9.48295295e-02 lambda = [  3.1302063 -12.914325 ]\n",
            "It 01400: loss = 9.48705673e-02 lambda = [  3.0776982 -12.860409 ]\n",
            "It 01450: loss = 9.45366919e-02 lambda = [  3.0683904 -12.784308 ]\n",
            "It 01500: loss = 9.43543687e-02 lambda = [  3.0566435 -12.719085 ]\n",
            "It 01550: loss = 9.41793025e-02 lambda = [  3.0397549 -12.650876 ]\n",
            "It 01600: loss = 9.41152498e-02 lambda = [  3.0183282 -12.575807 ]\n",
            "It 01650: loss = 9.39959511e-02 lambda = [  2.9601915 -12.48784  ]\n",
            "It 01700: loss = 9.36892480e-02 lambda = [  2.9335115 -12.3805685]\n",
            "It 01750: loss = 9.34992507e-02 lambda = [  2.901702 -12.277789]\n",
            "It 01800: loss = 9.33053046e-02 lambda = [  2.8645344 -12.168099 ]\n",
            "It 01850: loss = 9.31006521e-02 lambda = [  2.822509 -12.048466]\n",
            "It 01900: loss = 9.28813815e-02 lambda = [  2.7756832 -11.918313 ]\n",
            "It 01950: loss = 9.26480964e-02 lambda = [  2.7240875 -11.778024 ]\n",
            "It 02000: loss = 9.24102366e-02 lambda = [  2.6676683 -11.629075 ]\n",
            "It 02050: loss = 9.24672186e-02 lambda = [  2.6059732 -11.47473  ]\n",
            "It 02100: loss = 9.19930413e-02 lambda = [  2.5336192 -11.315234 ]\n",
            "It 02150: loss = 9.18106660e-02 lambda = [  2.4616075 -11.160092 ]\n",
            "It 02200: loss = 9.16462317e-02 lambda = [  2.3841548 -11.012228 ]\n",
            "It 02250: loss = 9.14921314e-02 lambda = [  2.3027341 -10.868518 ]\n",
            "It 02300: loss = 9.13436264e-02 lambda = [  2.2185004 -10.727637 ]\n",
            "It 02350: loss = 9.11969319e-02 lambda = [  2.1322682 -10.587759 ]\n",
            "It 02400: loss = 9.10493210e-02 lambda = [  2.0444028 -10.446929 ]\n",
            "It 02450: loss = 9.08995122e-02 lambda = [  1.954869 -10.303507]\n",
            "It 02500: loss = 9.07479078e-02 lambda = [  1.8634642 -10.156694 ]\n",
            "It 02550: loss = 9.05961022e-02 lambda = [  1.7701247 -10.006711 ]\n",
            "It 02600: loss = 9.04455110e-02 lambda = [ 1.675058 -9.85441 ]\n",
            "It 02650: loss = 9.02967453e-02 lambda = [ 1.5786401 -9.700581 ]\n",
            "It 02700: loss = 9.01498049e-02 lambda = [ 1.4812548 -9.5455065]\n",
            "It 02750: loss = 9.00041461e-02 lambda = [ 1.3831873 -9.3888855]\n",
            "It 02800: loss = 8.98588821e-02 lambda = [ 1.284563 -9.229989]\n",
            "It 02850: loss = 8.97126570e-02 lambda = [ 1.1853333 -9.067903 ]\n",
            "It 02900: loss = 8.95640254e-02 lambda = [ 1.0852897 -8.901777 ]\n",
            "It 02950: loss = 8.94115418e-02 lambda = [ 0.98411804 -8.731098  ]\n",
            "It 03000: loss = 8.92541036e-02 lambda = [ 0.8814868 -8.555807 ]\n",
            "It 03050: loss = 8.91702548e-02 lambda = [ 0.8286175 -8.464878 ]\n",
            "It 03100: loss = 8.90837982e-02 lambda = [ 0.773608  -8.3700075]\n",
            "It 03150: loss = 8.89927968e-02 lambda = [ 0.7163765 -8.271139 ]\n",
            "It 03200: loss = 8.88969600e-02 lambda = [ 0.6568204 -8.168136 ]\n",
            "It 03250: loss = 8.87958556e-02 lambda = [ 0.5948398 -8.060838 ]\n",
            "It 03300: loss = 8.86890218e-02 lambda = [ 0.53033453 -7.9490423 ]\n",
            "It 03350: loss = 8.85758027e-02 lambda = [ 0.4632013 -7.832483 ]\n",
            "It 03400: loss = 8.84554833e-02 lambda = [ 0.39332765 -7.710797  ]\n",
            "It 03450: loss = 8.83269683e-02 lambda = [ 0.32058161 -7.583468  ]\n",
            "It 03500: loss = 8.81888047e-02 lambda = [ 0.24479392 -7.4497576 ]\n",
            "It 03550: loss = 8.80388767e-02 lambda = [ 0.16573231 -7.308607  ]\n",
            "It 03600: loss = 8.78741071e-02 lambda = [ 0.08305871 -7.1585007 ]\n",
            "It 03650: loss = 8.76900628e-02 lambda = [-3.7360154e-03 -6.9973030e+00]\n",
            "It 03700: loss = 8.74801874e-02 lambda = [-0.09543066 -6.822086  ]\n",
            "It 03750: loss = 8.72351751e-02 lambda = [-0.19322097 -6.629025  ]\n",
            "It 03800: loss = 8.69427025e-02 lambda = [-0.2989157 -6.413538 ]\n",
            "It 03850: loss = 8.65864307e-02 lambda = [-0.41509667 -6.170667  ]\n",
            "It 03900: loss = 8.61423165e-02 lambda = [-0.54501224 -5.8946443 ]\n",
            "It 03950: loss = 8.55665579e-02 lambda = [-0.6922435 -5.5766854]\n",
            "It 04000: loss = 8.48013833e-02 lambda = [-0.8612992 -5.2100606]\n",
            "It 04050: loss = 8.38378742e-02 lambda = [-1.0574982 -4.8127365]\n",
            "It 04100: loss = 8.26922879e-02 lambda = [-1.2786387 -4.409397 ]\n",
            "It 04150: loss = 8.13485011e-02 lambda = [-1.5160675 -3.9977906]\n",
            "It 04200: loss = 7.98912644e-02 lambda = [-1.766149  -3.5977466]\n",
            "It 04250: loss = 7.85490125e-02 lambda = [-2.0142305 -3.2596412]\n",
            "It 04300: loss = 7.73805007e-02 lambda = [-2.2340748 -2.9710443]\n",
            "It 04350: loss = 7.62351453e-02 lambda = [-2.4268808 -2.67231  ]\n",
            "It 04400: loss = 7.49580711e-02 lambda = [-2.6261945 -2.3853166]\n",
            "It 04450: loss = 7.41105676e-02 lambda = [-2.8081734 -2.221143 ]\n",
            "It 04500: loss = 7.35625699e-02 lambda = [-2.9210968 -2.1273158]\n",
            "It 04550: loss = 7.31431097e-02 lambda = [-2.992762  -2.0524635]\n",
            "It 04600: loss = 7.28687793e-02 lambda = [-3.033901  -2.0046444]\n",
            "It 04650: loss = 7.25250393e-02 lambda = [-3.0725288 -1.9481913]\n",
            "It 04700: loss = 7.28947148e-02 lambda = [-3.0974772 -1.9035231]\n",
            "It 04750: loss = 7.20178783e-02 lambda = [-3.1274555 -1.8578955]\n",
            "It 04800: loss = 7.17631280e-02 lambda = [-3.1589696 -1.8049954]\n",
            "It 04850: loss = 7.16232136e-02 lambda = [-3.1826262 -1.7618817]\n",
            "It 04900: loss = 7.13047385e-02 lambda = [-3.2118976 -1.7171317]\n",
            "It 04950: loss = 7.10669160e-02 lambda = [-3.2395062 -1.6722503]\n",
            "It 05000: loss = 7.08825961e-02 lambda = [-3.2494123 -1.6406823]\n",
            "It 05050: loss = 7.06350505e-02 lambda = [-3.2766552 -1.6037337]\n",
            "It 05100: loss = 7.04068616e-02 lambda = [-3.298974  -1.5669569]\n",
            "It 05150: loss = 7.05764517e-02 lambda = [-3.313422 -1.534981]\n",
            "It 05200: loss = 6.99925572e-02 lambda = [-3.336516 -1.507589]\n",
            "It 05250: loss = 7.27721006e-02 lambda = [-3.3522813 -1.4806323]\n",
            "It 05300: loss = 6.96336627e-02 lambda = [-3.3628144 -1.4646696]\n",
            "It 05350: loss = 6.94398358e-02 lambda = [-3.381174  -1.4462441]\n",
            "It 05400: loss = 6.92614317e-02 lambda = [-3.3935788 -1.4311128]\n",
            "It 05450: loss = 6.98001534e-02 lambda = [-3.400387  -1.4194909]\n",
            "It 05500: loss = 6.89163357e-02 lambda = [-3.4073083 -1.4108615]\n",
            "It 05550: loss = 6.87483922e-02 lambda = [-3.4122217 -1.402996 ]\n",
            "It 05600: loss = 6.85258806e-02 lambda = [-3.420964 -1.397024]\n",
            "It 05650: loss = 6.82792664e-02 lambda = [-3.423268  -1.3923391]\n",
            "It 05700: loss = 6.90179542e-02 lambda = [-3.430222  -1.3858411]\n",
            "It 05750: loss = 6.76591098e-02 lambda = [-3.4366233 -1.3844371]\n",
            "It 05800: loss = 6.73277974e-02 lambda = [-3.445499 -1.382406]\n",
            "It 05850: loss = 6.71261400e-02 lambda = [-3.442231  -1.3824606]\n",
            "It 05900: loss = 6.69086725e-02 lambda = [-3.4518142 -1.3789251]\n",
            "It 05950: loss = 6.64905459e-02 lambda = [-3.4558282 -1.3761249]\n",
            "It 06000: loss = 6.62262142e-02 lambda = [-3.460262  -1.3718984]\n",
            "It 06050: loss = 6.61091879e-02 lambda = [-3.4619775 -1.3673038]\n",
            "It 06100: loss = 6.58134818e-02 lambda = [-3.4627705 -1.3634485]\n",
            "It 06150: loss = 6.62917271e-02 lambda = [-3.4643612 -1.3566436]\n",
            "It 06200: loss = 6.54499084e-02 lambda = [-3.462553  -1.3541439]\n",
            "It 06250: loss = 6.53003976e-02 lambda = [-3.4621656 -1.3487065]\n",
            "It 06300: loss = 6.50883093e-02 lambda = [-3.4598603 -1.3437463]\n",
            "It 06350: loss = 6.50956035e-02 lambda = [-3.4574444 -1.3381819]\n",
            "It 06400: loss = 6.47409558e-02 lambda = [-3.456321  -1.3312031]\n",
            "It 06450: loss = 6.45984784e-02 lambda = [-3.4573598 -1.3255091]\n",
            "It 06500: loss = 6.44056499e-02 lambda = [-3.4579082 -1.3188248]\n",
            "It 06550: loss = 6.43108487e-02 lambda = [-3.457684  -1.3114121]\n",
            "It 06600: loss = 6.40856549e-02 lambda = [-3.4588788 -1.3068496]\n",
            "It 06650: loss = 6.55584335e-02 lambda = [-3.4603865 -1.298893 ]\n",
            "It 06700: loss = 6.38147742e-02 lambda = [-3.4610376 -1.2957609]\n",
            "It 06750: loss = 6.36626482e-02 lambda = [-3.4637976 -1.2901126]\n",
            "It 06800: loss = 6.35896921e-02 lambda = [-3.4598186 -1.2827165]\n",
            "It 06850: loss = 6.33921027e-02 lambda = [-3.4638214 -1.2799335]\n",
            "It 06900: loss = 6.41665235e-02 lambda = [-3.4675272 -1.2736613]\n",
            "It 06950: loss = 6.31183684e-02 lambda = [-3.468791 -1.268365]\n",
            "It 07000: loss = 6.31455854e-02 lambda = [-3.4697678 -1.260823 ]\n",
            "It 07050: loss = 6.28986284e-02 lambda = [-3.470986  -1.2589337]\n",
            "It 07100: loss = 6.28242865e-02 lambda = [-3.4722867 -1.2557684]\n",
            "It 07150: loss = 6.27486706e-02 lambda = [-3.4735017 -1.2523221]\n",
            "It 07200: loss = 6.26707301e-02 lambda = [-3.4746315 -1.2487164]\n",
            "It 07250: loss = 6.25904351e-02 lambda = [-3.4757159 -1.2449601]\n",
            "It 07300: loss = 6.25075698e-02 lambda = [-3.4767807 -1.2410411]\n",
            "It 07350: loss = 6.24220036e-02 lambda = [-3.47785   -1.2369448]\n",
            "It 07400: loss = 6.23335615e-02 lambda = [-3.478936  -1.2326561]\n",
            "It 07450: loss = 6.22420385e-02 lambda = [-3.480052  -1.2281579]\n",
            "It 07500: loss = 6.21471256e-02 lambda = [-3.481208  -1.2234316]\n",
            "It 07550: loss = 6.20485842e-02 lambda = [-3.4824145 -1.2184538]\n",
            "It 07600: loss = 6.19460009e-02 lambda = [-3.4836807 -1.2131952]\n",
            "It 07650: loss = 6.18389361e-02 lambda = [-3.4850187 -1.2076193]\n",
            "It 07700: loss = 6.17268458e-02 lambda = [-3.4864452 -1.2016789]\n",
            "It 07750: loss = 6.16089366e-02 lambda = [-3.4879835 -1.1953124]\n",
            "It 07800: loss = 6.14842772e-02 lambda = [-3.4896696 -1.1884412]\n",
            "It 07850: loss = 6.13515824e-02 lambda = [-3.4915583 -1.1809647]\n",
            "It 07900: loss = 6.12093583e-02 lambda = [-3.4937372 -1.1727581]\n",
            "It 07950: loss = 6.10554889e-02 lambda = [-3.4963355 -1.1636717]\n",
            "It 08000: loss = 6.08889237e-02 lambda = [-3.4995317 -1.153527 ]\n",
            "It 08050: loss = 6.07099533e-02 lambda = [-3.5040553 -1.1418748]\n",
            "It 08100: loss = 6.05103970e-02 lambda = [-3.5085495 -1.1299294]\n",
            "It 08150: loss = 6.02896214e-02 lambda = [-3.5150616 -1.1164024]\n",
            "It 08200: loss = 6.00647777e-02 lambda = [-3.5224752 -1.1020328]\n",
            "It 08250: loss = 5.97974733e-02 lambda = [-3.530832  -1.0881838]\n",
            "It 08300: loss = 6.00020140e-02 lambda = [-3.5392716 -1.0739393]\n",
            "It 08350: loss = 5.92669286e-02 lambda = [-3.5464263 -1.063208 ]\n",
            "It 08400: loss = 5.89920804e-02 lambda = [-3.5521672 -1.0534915]\n",
            "It 08450: loss = 5.89260161e-02 lambda = [-3.5547266 -1.0452176]\n",
            "It 08500: loss = 5.84714375e-02 lambda = [-3.5549908 -1.0408455]\n",
            "It 08550: loss = 5.82107864e-02 lambda = [-3.551539  -1.0375705]\n",
            "It 08600: loss = 5.79218045e-02 lambda = [-3.5462732 -1.0360556]\n",
            "It 08650: loss = 5.77169955e-02 lambda = [-3.5386567 -1.036831 ]\n",
            "It 08700: loss = 5.73075786e-02 lambda = [-3.531849 -1.037685]\n",
            "It 08750: loss = 5.69960438e-02 lambda = [-3.528555  -1.0380583]\n",
            "It 08800: loss = 5.67157194e-02 lambda = [-3.526672  -1.0377238]\n",
            "It 08850: loss = 5.64120784e-02 lambda = [-3.5282638 -1.0367655]\n",
            "It 08900: loss = 5.61327264e-02 lambda = [-3.5300207 -1.0353556]\n",
            "It 08950: loss = 5.58842085e-02 lambda = [-3.5319965 -1.0336841]\n",
            "It 09000: loss = 5.56246936e-02 lambda = [-3.5335207 -1.0320691]\n",
            "It 09050: loss = 5.54489195e-02 lambda = [-3.5342643 -1.0304227]\n",
            "It 09100: loss = 5.51702045e-02 lambda = [-3.53732   -1.0288603]\n",
            "It 09150: loss = 5.49746864e-02 lambda = [-3.5398111 -1.0271138]\n",
            "It 09200: loss = 5.47748841e-02 lambda = [-3.5418234 -1.0256677]\n",
            "It 09250: loss = 5.45841977e-02 lambda = [-3.543828  -1.0242684]\n",
            "It 09300: loss = 5.44409603e-02 lambda = [-3.5452394 -1.023196 ]\n",
            "It 09350: loss = 5.42519167e-02 lambda = [-3.5481377 -1.0219629]\n",
            "It 09400: loss = 5.41585460e-02 lambda = [-3.550485  -1.0204827]\n",
            "It 09450: loss = 5.39607294e-02 lambda = [-3.5525362 -1.020096 ]\n",
            "It 09500: loss = 5.38221709e-02 lambda = [-3.5550458 -1.0194855]\n",
            "It 09550: loss = 5.36985174e-02 lambda = [-3.5574236 -1.0184612]\n",
            "It 09600: loss = 5.35671860e-02 lambda = [-3.5600903 -1.0185022]\n",
            "It 09650: loss = 5.34382910e-02 lambda = [-3.5630038 -1.0182595]\n",
            "It 09700: loss = 5.33130094e-02 lambda = [-3.5657163 -1.0181679]\n",
            "It 09750: loss = 5.32058217e-02 lambda = [-3.5695107 -1.0179235]\n",
            "It 09800: loss = 5.30692376e-02 lambda = [-3.5722694 -1.0181533]\n",
            "It 09850: loss = 5.29407337e-02 lambda = [-3.576555  -1.0179949]\n",
            "It 09900: loss = 5.29274531e-02 lambda = [-3.578441  -1.0181943]\n",
            "It 09950: loss = 5.30797131e-02 lambda = [-3.5825994 -1.0175971]\n",
            "It 10000: loss = 5.25508150e-02 lambda = [-3.5874233 -1.0181445]\n",
            "It 10050: loss = 5.24228215e-02 lambda = [-3.5913818 -1.0171593]\n",
            "It 10100: loss = 5.23018576e-02 lambda = [-3.59488  -1.017825]\n",
            "It 10150: loss = 5.22122383e-02 lambda = [-3.5984206 -1.017262 ]\n",
            "It 10200: loss = 5.21781370e-02 lambda = [-3.6014774 -1.0170426]\n",
            "It 10250: loss = 5.19612320e-02 lambda = [-3.604814  -1.0170234]\n",
            "It 10300: loss = 5.18546291e-02 lambda = [-3.6084685 -1.0167247]\n",
            "It 10350: loss = 5.19177392e-02 lambda = [-3.6104035 -1.0155829]\n",
            "It 10400: loss = 5.16418889e-02 lambda = [-3.612709  -1.0159924]\n",
            "It 10450: loss = 5.16306274e-02 lambda = [-3.6146953 -1.0157452]\n",
            "It 10500: loss = 5.14207855e-02 lambda = [-3.6174884 -1.0154938]\n",
            "It 10550: loss = 5.14208861e-02 lambda = [-3.6179888 -1.0151653]\n",
            "It 10600: loss = 5.12278825e-02 lambda = [-3.6187987 -1.01534  ]\n",
            "It 10650: loss = 5.11049740e-02 lambda = [-3.6207786 -1.0149437]\n",
            "It 10700: loss = 5.10131046e-02 lambda = [-3.6205854 -1.0148237]\n",
            "It 10750: loss = 5.09072021e-02 lambda = [-3.6216486 -1.0145745]\n",
            "It 10800: loss = 5.07933795e-02 lambda = [-3.620596  -1.0146096]\n",
            "It 10850: loss = 5.06989434e-02 lambda = [-3.6202383 -1.0134363]\n",
            "It 10900: loss = 5.06647602e-02 lambda = [-3.6190479 -1.0142487]\n",
            "It 10950: loss = 5.04733771e-02 lambda = [-3.617299  -1.0146166]\n",
            "It 11000: loss = 5.03960364e-02 lambda = [-3.6159174 -1.0146453]\n",
            "It 11050: loss = 5.02531379e-02 lambda = [-3.614588  -1.0144936]\n",
            "It 11100: loss = 5.01261279e-02 lambda = [-3.6106758 -1.0147055]\n",
            "It 11150: loss = 5.03234044e-02 lambda = [-3.606369 -1.014857]\n",
            "It 11200: loss = 4.98837605e-02 lambda = [-3.6027074 -1.0151762]\n",
            "It 11250: loss = 4.97837365e-02 lambda = [-3.599014  -1.0145755]\n",
            "It 11300: loss = 4.96315248e-02 lambda = [-3.5937512 -1.0156089]\n",
            "It 11350: loss = 4.95001264e-02 lambda = [-3.5880308 -1.0160455]\n",
            "It 11400: loss = 4.93772812e-02 lambda = [-3.581585  -1.0152637]\n",
            "It 11450: loss = 4.92345728e-02 lambda = [-3.5751593 -1.017029 ]\n",
            "It 11500: loss = 4.90966402e-02 lambda = [-3.5676496 -1.0177292]\n",
            "It 11550: loss = 4.89843301e-02 lambda = [-3.5594268 -1.0184346]\n",
            "It 11600: loss = 4.89466973e-02 lambda = [-3.5521362 -1.0187234]\n",
            "It 11650: loss = 4.86950651e-02 lambda = [-3.5441892 -1.020035 ]\n",
            "It 11700: loss = 4.85773683e-02 lambda = [-3.535886  -1.0203792]\n",
            "It 11750: loss = 4.84323874e-02 lambda = [-3.5274315 -1.0218228]\n",
            "It 11800: loss = 4.85832766e-02 lambda = [-3.5183754 -1.0216143]\n",
            "It 11850: loss = 4.81831394e-02 lambda = [-3.510458  -1.0238063]\n",
            "It 11900: loss = 4.80633453e-02 lambda = [-3.5014296 -1.0249844]\n",
            "It 11950: loss = 4.79562692e-02 lambda = [-3.4934025 -1.0259242]\n",
            "It 12000: loss = 4.78508994e-02 lambda = [-3.4862196 -1.0269028]\n",
            "It 12050: loss = 4.77224365e-02 lambda = [-3.477542 -1.028069]\n",
            "It 12100: loss = 4.77889925e-02 lambda = [-3.46868  -1.028995]\n",
            "It 12150: loss = 4.77668792e-02 lambda = [-3.4613996 -1.0308241]\n",
            "It 12200: loss = 4.73890305e-02 lambda = [-3.4544399 -1.0315794]\n",
            "It 12250: loss = 4.72460017e-02 lambda = [-3.447511  -1.0323892]\n",
            "It 12300: loss = 4.71269265e-02 lambda = [-3.441353  -1.0329787]\n",
            "It 12350: loss = 4.70455103e-02 lambda = [-3.4365356 -1.0333142]\n",
            "It 12400: loss = 4.69201505e-02 lambda = [-3.4304183 -1.0338688]\n",
            "It 12450: loss = 4.68871519e-02 lambda = [-3.4241076 -1.0344101]\n",
            "It 12500: loss = 4.67386618e-02 lambda = [-3.4185696 -1.0353621]\n",
            "It 12550: loss = 4.66547012e-02 lambda = [-3.4131167 -1.0361698]\n",
            "It 12600: loss = 4.65501025e-02 lambda = [-3.406155  -1.0373479]\n",
            "It 12650: loss = 4.66981791e-02 lambda = [-3.399104 -1.038478]\n",
            "It 12700: loss = 4.63769063e-02 lambda = [-3.3931472 -1.0398054]\n",
            "It 12750: loss = 4.63023782e-02 lambda = [-3.3855212 -1.0409585]\n",
            "It 12800: loss = 4.62031662e-02 lambda = [-3.3796237 -1.0426353]\n",
            "It 12850: loss = 4.61922884e-02 lambda = [-3.3728871 -1.0434229]\n",
            "It 12900: loss = 4.60603088e-02 lambda = [-3.3666365 -1.0452193]\n",
            "It 12950: loss = 4.59092408e-02 lambda = [-3.3599563 -1.0467336]\n",
            "It 13000: loss = 4.58350442e-02 lambda = [-3.3525805 -1.0476379]\n",
            "It 13050: loss = 4.57133204e-02 lambda = [-3.3455987 -1.0483295]\n",
            "It 13100: loss = 4.56145555e-02 lambda = [-3.3394759 -1.0501093]\n",
            "It 13150: loss = 4.55179363e-02 lambda = [-3.3333447 -1.0511477]\n",
            "It 13200: loss = 4.55424599e-02 lambda = [-3.3273165 -1.0517176]\n",
            "It 13250: loss = 4.53324541e-02 lambda = [-3.321669 -1.053538]\n",
            "It 13300: loss = 4.54743952e-02 lambda = [-3.3160994 -1.0542516]\n",
            "It 13350: loss = 4.51634489e-02 lambda = [-3.31108   -1.0560008]\n",
            "It 13400: loss = 4.51744497e-02 lambda = [-3.3060203 -1.05652  ]\n",
            "It 13450: loss = 4.50048335e-02 lambda = [-3.3013139 -1.0586392]\n",
            "It 13500: loss = 4.49337699e-02 lambda = [-3.2964323 -1.0600629]\n",
            "It 13550: loss = 4.48652506e-02 lambda = [-3.2925062 -1.0612537]\n",
            "It 13600: loss = 4.53093722e-02 lambda = [-3.2872434 -1.0621046]\n",
            "It 13650: loss = 4.47106101e-02 lambda = [-3.2837994 -1.0641643]\n",
            "It 13700: loss = 4.48715761e-02 lambda = [-3.2795475 -1.0653858]\n",
            "It 13750: loss = 4.45697866e-02 lambda = [-3.2757251 -1.0668564]\n",
            "It 13800: loss = 4.45942208e-02 lambda = [-3.2711911 -1.0680814]\n",
            "It 13850: loss = 4.44549993e-02 lambda = [-3.2678328 -1.0694205]\n",
            "It 13900: loss = 4.46614362e-02 lambda = [-3.2637832 -1.0705197]\n",
            "It 13950: loss = 4.45530675e-02 lambda = [-3.260554  -1.0723311]\n",
            "It 14000: loss = 4.43829373e-02 lambda = [-3.2572935 -1.0738449]\n",
            "It 14050: loss = 4.42182608e-02 lambda = [-3.2556155 -1.0744239]\n",
            "It 14100: loss = 4.41870503e-02 lambda = [-3.25387   -1.0751219]\n",
            "It 14150: loss = 4.41560410e-02 lambda = [-3.2521958 -1.0758023]\n",
            "It 14200: loss = 4.41245362e-02 lambda = [-3.2505558 -1.0764834]\n",
            "It 14250: loss = 4.40926962e-02 lambda = [-3.2489355 -1.0771672]\n",
            "It 14300: loss = 4.40604202e-02 lambda = [-3.2473345 -1.0778532]\n",
            "It 14350: loss = 4.40276861e-02 lambda = [-3.245751  -1.0785413]\n",
            "It 14400: loss = 4.39945683e-02 lambda = [-3.2441857 -1.0792295]\n",
            "It 14450: loss = 4.39610407e-02 lambda = [-3.2426412 -1.079916 ]\n",
            "It 14500: loss = 4.39271033e-02 lambda = [-3.2411182 -1.0805999]\n",
            "It 14550: loss = 4.38927747e-02 lambda = [-3.23962   -1.0812788]\n",
            "It 14600: loss = 4.38580066e-02 lambda = [-3.2381487 -1.0819509]\n",
            "It 14650: loss = 4.38228659e-02 lambda = [-3.2367072 -1.0826137]\n",
            "It 14700: loss = 4.37871665e-02 lambda = [-3.2352984 -1.0832657]\n",
            "It 14750: loss = 4.37510908e-02 lambda = [-3.233923  -1.0839051]\n",
            "It 14800: loss = 4.37144972e-02 lambda = [-3.2325807 -1.0845318]\n",
            "It 14850: loss = 4.36774343e-02 lambda = [-3.2312708 -1.0851448]\n",
            "It 14900: loss = 4.36397381e-02 lambda = [-3.229989  -1.0857455]\n",
            "It 14950: loss = 4.36014794e-02 lambda = [-3.2287338 -1.0863336]\n",
            "It 15000: loss = 4.35639061e-02 lambda = [-3.227585  -1.0868721]\n",
            "It 15050: loss = 4.35238853e-02 lambda = [-3.2262712 -1.0874392]\n",
            "It 15100: loss = 4.34842594e-02 lambda = [-3.225028  -1.0879769]\n",
            "It 15150: loss = 4.34449837e-02 lambda = [-3.2239103 -1.0884544]\n",
            "It 15200: loss = 4.34035100e-02 lambda = [-3.2226467 -1.0889658]\n",
            "It 15250: loss = 4.33630049e-02 lambda = [-3.2216427 -1.089375 ]\n",
            "It 15300: loss = 4.33296114e-02 lambda = [-3.2204056 -1.0896896]\n",
            "It 15350: loss = 4.32815515e-02 lambda = [-3.2194316 -1.0902038]\n",
            "It 15400: loss = 4.33044210e-02 lambda = [-3.2181854 -1.0903252]\n",
            "It 15450: loss = 4.32019383e-02 lambda = [-3.217569  -1.0908784]\n",
            "It 15500: loss = 4.32338938e-02 lambda = [-3.216476  -1.0911587]\n",
            "It 15550: loss = 4.31261994e-02 lambda = [-3.2157264 -1.091503 ]\n",
            "It 15600: loss = 4.30856757e-02 lambda = [-3.2150111 -1.0918231]\n",
            "It 15650: loss = 4.30547409e-02 lambda = [-3.2143147 -1.0919832]\n",
            "It 15700: loss = 4.30214033e-02 lambda = [-3.2132409 -1.0921415]\n",
            "It 15750: loss = 4.29666638e-02 lambda = [-3.2126148 -1.0925498]\n",
            "It 15800: loss = 4.29381281e-02 lambda = [-3.2121816 -1.0926427]\n",
            "It 15850: loss = 4.28892523e-02 lambda = [-3.211273  -1.0929369]\n",
            "It 15900: loss = 4.28720564e-02 lambda = [-3.210611  -1.0929418]\n",
            "It 15950: loss = 4.28130627e-02 lambda = [-3.2098813 -1.0933021]\n",
            "It 16000: loss = 4.27774265e-02 lambda = [-3.20936   -1.0933998]\n",
            "It 16050: loss = 4.28347737e-02 lambda = [-3.2085705 -1.0936828]\n",
            "It 16100: loss = 4.26976196e-02 lambda = [-3.2079222 -1.0937347]\n",
            "It 16150: loss = 4.26815040e-02 lambda = [-3.2072544 -1.0937376]\n",
            "It 16200: loss = 4.26330082e-02 lambda = [-3.2063649 -1.0939246]\n",
            "It 16250: loss = 4.25856486e-02 lambda = [-3.2059534 -1.0940415]\n",
            "It 16300: loss = 4.25455160e-02 lambda = [-3.205041  -1.0941569]\n",
            "It 16350: loss = 4.27250490e-02 lambda = [-3.2042933 -1.0941724]\n",
            "It 16400: loss = 4.24692780e-02 lambda = [-3.2036948 -1.0943015]\n",
            "It 16450: loss = 4.24331464e-02 lambda = [-3.2028642 -1.0943459]\n",
            "It 16500: loss = 4.24408987e-02 lambda = [-3.2020147 -1.0944185]\n",
            "It 16550: loss = 4.23566028e-02 lambda = [-3.201322  -1.0944226]\n",
            "It 16600: loss = 4.23236415e-02 lambda = [-3.2002764 -1.0943309]\n",
            "It 16650: loss = 4.23405692e-02 lambda = [-3.1995106 -1.0945598]\n",
            "It 16700: loss = 4.22350019e-02 lambda = [-3.198675  -1.0945444]\n",
            "It 16750: loss = 4.22021709e-02 lambda = [-3.1978984 -1.0945237]\n",
            "It 16800: loss = 4.21577655e-02 lambda = [-3.1967127 -1.0946004]\n",
            "It 16850: loss = 4.21198681e-02 lambda = [-3.1957843 -1.0945915]\n",
            "It 16900: loss = 4.20826450e-02 lambda = [-3.1947982 -1.0945337]\n",
            "It 16950: loss = 4.20465171e-02 lambda = [-3.1937416 -1.0945288]\n",
            "It 17000: loss = 4.20237929e-02 lambda = [-3.19243   -1.0944983]\n",
            "It 17050: loss = 4.19604369e-02 lambda = [-3.1917324 -1.0944875]\n",
            "It 17100: loss = 4.19219211e-02 lambda = [-3.1902828 -1.0945175]\n",
            "It 17150: loss = 4.19534445e-02 lambda = [-3.1891954 -1.0942223]\n",
            "It 17200: loss = 4.18452956e-02 lambda = [-3.1880214 -1.0943962]\n",
            "It 17250: loss = 4.18211818e-02 lambda = [-3.186736  -1.0939696]\n",
            "It 17300: loss = 4.17686887e-02 lambda = [-3.1856804 -1.0942816]\n",
            "It 17350: loss = 4.17685658e-02 lambda = [-3.1844594 -1.0941155]\n",
            "It 17400: loss = 4.16912287e-02 lambda = [-3.1832795 -1.0941004]\n",
            "It 17450: loss = 4.16615270e-02 lambda = [-3.1821258 -1.0937529]\n",
            "It 17500: loss = 4.16133218e-02 lambda = [-3.180846  -1.0938995]\n",
            "It 17550: loss = 4.15778533e-02 lambda = [-3.1797888 -1.0936939]\n",
            "It 17600: loss = 4.16422933e-02 lambda = [-3.1784923 -1.0936991]\n",
            "It 17650: loss = 4.14961241e-02 lambda = [-3.177362  -1.0934912]\n",
            "It 17700: loss = 4.15857695e-02 lambda = [-3.1759675 -1.0932703]\n",
            "It 17750: loss = 4.14174497e-02 lambda = [-3.1750305 -1.0931526]\n",
            "It 17800: loss = 4.13774028e-02 lambda = [-3.1739821 -1.0929694]\n",
            "It 17850: loss = 4.13377769e-02 lambda = [-3.172624  -1.0928665]\n",
            "It 17900: loss = 4.13025618e-02 lambda = [-3.171561  -1.0926479]\n",
            "It 17950: loss = 4.12661880e-02 lambda = [-3.1704245 -1.0924087]\n",
            "It 18000: loss = 4.12339196e-02 lambda = [-3.1692753 -1.0921856]\n",
            "It 18050: loss = 4.12332043e-02 lambda = [-3.167944  -1.0918537]\n",
            "It 18100: loss = 4.11339998e-02 lambda = [-3.166948  -1.0918707]\n",
            "It 18150: loss = 4.11008187e-02 lambda = [-3.166033  -1.0914686]\n",
            "It 18200: loss = 4.10945788e-02 lambda = [-3.1648316 -1.0914576]\n",
            "It 18250: loss = 4.10080552e-02 lambda = [-3.1636968 -1.0911711]\n",
            "It 18300: loss = 4.09659073e-02 lambda = [-3.1625829 -1.0909401]\n",
            "It 18350: loss = 4.09236401e-02 lambda = [-3.162066  -1.0906237]\n",
            "It 18400: loss = 4.08734493e-02 lambda = [-3.1605256 -1.0904014]\n",
            "It 18450: loss = 4.08921055e-02 lambda = [-3.1593535 -1.0900456]\n",
            "It 18500: loss = 4.07824591e-02 lambda = [-3.1583524 -1.0898861]\n",
            "It 18550: loss = 4.07506861e-02 lambda = [-3.157637  -1.0895499]\n",
            "It 18600: loss = 4.06890959e-02 lambda = [-3.156332  -1.0893531]\n",
            "It 18650: loss = 4.06436622e-02 lambda = [-3.1555276 -1.0889127]\n",
            "It 18700: loss = 4.05946597e-02 lambda = [-3.1542535 -1.0887281]\n",
            "It 18750: loss = 4.05431092e-02 lambda = [-3.1534545 -1.0884117]\n",
            "It 18800: loss = 4.04919200e-02 lambda = [-3.1522045 -1.0881839]\n",
            "It 18850: loss = 4.04407158e-02 lambda = [-3.1514158 -1.0878097]\n",
            "It 18900: loss = 4.03992124e-02 lambda = [-3.1501994 -1.0873468]\n",
            "It 18950: loss = 4.03278992e-02 lambda = [-3.1490693 -1.0872577]\n",
            "It 19000: loss = 4.03286889e-02 lambda = [-3.1478236 -1.0867084]\n",
            "It 19050: loss = 4.02137525e-02 lambda = [-3.1468654 -1.0866555]\n",
            "It 19100: loss = 4.01685089e-02 lambda = [-3.1459846 -1.0862273]\n",
            "It 19150: loss = 4.00966890e-02 lambda = [-3.1444664 -1.0861197]\n",
            "It 19200: loss = 4.00359556e-02 lambda = [-3.143346  -1.0858214]\n",
            "It 19250: loss = 4.00185138e-02 lambda = [-3.1418402 -1.0855972]\n",
            "It 19300: loss = 3.99095677e-02 lambda = [-3.1405745 -1.0853187]\n",
            "It 19350: loss = 3.98854502e-02 lambda = [-3.139005  -1.0849758]\n",
            "It 19400: loss = 3.97749618e-02 lambda = [-3.1375866 -1.0849441]\n",
            "It 19450: loss = 3.97089198e-02 lambda = [-3.1358356 -1.0848349]\n",
            "It 19500: loss = 3.96445394e-02 lambda = [-3.1344929 -1.0845953]\n",
            "It 19550: loss = 3.95778716e-02 lambda = [-3.1329048 -1.0844337]\n",
            "It 19600: loss = 3.95051725e-02 lambda = [-3.1309934 -1.0844493]\n",
            "It 19650: loss = 3.97553295e-02 lambda = [-3.1292055 -1.0843633]\n",
            "It 19700: loss = 3.93676050e-02 lambda = [-3.1275194 -1.0843084]\n",
            "It 19750: loss = 3.93226519e-02 lambda = [-3.1256733 -1.0841578]\n",
            "It 19800: loss = 3.92353982e-02 lambda = [-3.123484  -1.0843112]\n",
            "It 19850: loss = 3.91605720e-02 lambda = [-3.1217637 -1.0843737]\n",
            "It 19900: loss = 3.90982702e-02 lambda = [-3.1196036 -1.084363 ]\n",
            "It 19950: loss = 3.91477831e-02 lambda = [-3.1175272 -1.0845127]\n",
            "It 20000: loss = 3.89487445e-02 lambda = [-3.115491  -1.0845693]\n",
            "It 20050: loss = 3.89532857e-02 lambda = [-3.113185  -1.0843112]\n",
            "It 20100: loss = 3.88149247e-02 lambda = [-3.1113074 -1.0848075]\n",
            "It 20150: loss = 3.87371369e-02 lambda = [-3.1092563 -1.0849179]\n",
            "It 20200: loss = 3.87108065e-02 lambda = [-3.1070366 -1.0849489]\n",
            "It 20250: loss = 3.85956839e-02 lambda = [-3.1047273 -1.0852816]\n",
            "It 20300: loss = 3.85295078e-02 lambda = [-3.1027236 -1.0853738]\n",
            "It 20350: loss = 3.84899341e-02 lambda = [-3.1003911 -1.0854404]\n",
            "It 20400: loss = 3.83829251e-02 lambda = [-3.0981019 -1.0857956]\n",
            "It 20450: loss = 3.83085310e-02 lambda = [-3.0961163 -1.085949 ]\n",
            "It 20500: loss = 3.82737331e-02 lambda = [-3.093655  -1.0859591]\n",
            "It 20550: loss = 3.82343419e-02 lambda = [-3.091315  -1.0864433]\n",
            "It 20600: loss = 3.80922481e-02 lambda = [-3.089291 -1.086436]\n",
            "It 20650: loss = 3.80142331e-02 lambda = [-3.0866952 -1.086687 ]\n",
            "It 20700: loss = 3.79552841e-02 lambda = [-3.0847573 -1.0866947]\n",
            "It 20750: loss = 3.78638580e-02 lambda = [-3.0818217 -1.0870142]\n",
            "It 20800: loss = 3.77940051e-02 lambda = [-3.0799031 -1.087054 ]\n",
            "It 20850: loss = 3.77089903e-02 lambda = [-3.0771377 -1.0872662]\n",
            "It 20900: loss = 3.77378203e-02 lambda = [-3.07446   -1.0872713]\n",
            "It 20950: loss = 3.75494584e-02 lambda = [-3.0723395 -1.0873762]\n",
            "It 21000: loss = 3.74629833e-02 lambda = [-3.0694647 -1.0875596]\n",
            "It 21050: loss = 3.73875462e-02 lambda = [-3.0671234 -1.0875683]\n",
            "It 21100: loss = 3.73944752e-02 lambda = [-3.0641956 -1.0876467]\n",
            "It 21150: loss = 3.72001529e-02 lambda = [-3.0614185 -1.0876911]\n",
            "It 21200: loss = 3.71092856e-02 lambda = [-3.05876   -1.0874932]\n",
            "It 21250: loss = 3.70134823e-02 lambda = [-3.055501  -1.0877374]\n",
            "It 21300: loss = 3.69608440e-02 lambda = [-3.0526838 -1.087664 ]\n",
            "It 21350: loss = 3.68275791e-02 lambda = [-3.0493808 -1.0877787]\n",
            "It 21400: loss = 3.67612839e-02 lambda = [-3.047021  -1.0876422]\n",
            "It 21450: loss = 3.66487280e-02 lambda = [-3.043211  -1.0880255]\n",
            "It 21500: loss = 3.65596376e-02 lambda = [-3.0398846 -1.0883123]\n",
            "It 21550: loss = 3.65894884e-02 lambda = [-3.0368698 -1.0878444]\n",
            "It 21600: loss = 3.63883823e-02 lambda = [-3.0336404 -1.0889102]\n",
            "It 21650: loss = 3.63032892e-02 lambda = [-3.030231  -1.0894331]\n",
            "It 21700: loss = 3.67328376e-02 lambda = [-3.0271106 -1.0899237]\n",
            "It 21750: loss = 3.61416787e-02 lambda = [-3.0244205 -1.090233 ]\n",
            "It 21800: loss = 3.60610522e-02 lambda = [-3.0210364 -1.0908619]\n",
            "It 21850: loss = 3.59812714e-02 lambda = [-3.0178928 -1.0914412]\n",
            "It 21900: loss = 3.59490812e-02 lambda = [-3.015352 -1.091155]\n",
            "It 21950: loss = 3.58269885e-02 lambda = [-3.0119684 -1.0924944]\n",
            "It 22000: loss = 3.57502513e-02 lambda = [-3.0087085 -1.0931439]\n",
            "It 22050: loss = 3.56730297e-02 lambda = [-3.0055451 -1.0937798]\n",
            "It 22100: loss = 3.56239006e-02 lambda = [-3.0033257 -1.0941583]\n",
            "It 22150: loss = 3.55254337e-02 lambda = [-2.9995484 -1.0949718]\n",
            "It 22200: loss = 3.54518779e-02 lambda = [-2.9962783 -1.0956829]\n",
            "It 22250: loss = 3.53782922e-02 lambda = [-2.9934652 -1.0962485]\n",
            "It 22300: loss = 3.53537314e-02 lambda = [-2.989654  -1.0969625]\n",
            "It 22350: loss = 3.52335609e-02 lambda = [-2.9868743 -1.0976636]\n",
            "It 22400: loss = 3.51551473e-02 lambda = [-2.9831905 -1.0984567]\n",
            "It 22450: loss = 3.51796225e-02 lambda = [-2.9800942 -1.0984769]\n",
            "It 22500: loss = 3.50061283e-02 lambda = [-2.976541  -1.0998417]\n",
            "It 22550: loss = 3.50302830e-02 lambda = [-2.972869  -1.1006591]\n",
            "It 22600: loss = 3.49192768e-02 lambda = [-2.9693549 -1.1014552]\n",
            "It 22650: loss = 3.47823128e-02 lambda = [-2.9659317 -1.1021575]\n",
            "It 22700: loss = 3.47017497e-02 lambda = [-2.961811 -1.103094]\n",
            "It 22750: loss = 3.46491933e-02 lambda = [-2.9589863 -1.1037118]\n",
            "It 22800: loss = 3.45472954e-02 lambda = [-2.9543512 -1.1047145]\n",
            "It 22850: loss = 3.44680287e-02 lambda = [-2.9502556 -1.1056492]\n",
            "It 22900: loss = 3.43897156e-02 lambda = [-2.947065 -1.106288]\n",
            "It 22950: loss = 3.43096666e-02 lambda = [-2.9423227 -1.1074717]\n",
            "It 23000: loss = 3.42661440e-02 lambda = [-2.938172  -1.1081841]\n",
            "It 23050: loss = 3.41478288e-02 lambda = [-2.9339807 -1.1094673]\n",
            "It 23100: loss = 3.40971425e-02 lambda = [-2.9294872 -1.1106349]\n",
            "It 23150: loss = 3.39826867e-02 lambda = [-2.9255166 -1.1115614]\n",
            "It 23200: loss = 3.38944383e-02 lambda = [-2.9205549 -1.1128324]\n",
            "It 23250: loss = 3.38246785e-02 lambda = [-2.916445  -1.1137078]\n",
            "It 23300: loss = 3.37196328e-02 lambda = [-2.9114764 -1.1151421]\n",
            "It 23350: loss = 3.36322784e-02 lambda = [-2.9078844 -1.1160203]\n",
            "It 23400: loss = 3.35434712e-02 lambda = [-2.902312  -1.1175523]\n",
            "It 23450: loss = 3.34567428e-02 lambda = [-2.897581 -1.11882 ]\n",
            "It 23500: loss = 3.33772115e-02 lambda = [-2.8926177 -1.1202691]\n",
            "Timeout is reached. Time elapsed: 100.00219583511353 seconds\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration: 5 Initial lambda: [0.0, 0.0]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "L-BFGS\n",
            "\n",
            "It 00000: loss = 2.69845843e-01 lambda = [ 2.2881886e-05 -1.2256930e-05]\n",
            "It 00050: loss = 1.40209675e-01 lambda = [-1.5025238 -1.1762025]\n",
            "It 00100: loss = 9.39540938e-02 lambda = [-3.3162136 -0.8656941]\n",
            "It 00150: loss = 2.46926583e-02 lambda = [-4.6486278  0.4999081]\n",
            "It 00200: loss = 7.46512134e-03 lambda = [-5.2458553   0.69308627]\n",
            "It 00250: loss = 2.09515193e-03 lambda = [-5.5734653  0.8497301]\n",
            "It 00300: loss = 9.75903880e-04 lambda = [-5.871353  0.933519]\n",
            "It 00350: loss = 7.54234963e-04 lambda = [-5.9337707   0.96045667]\n",
            "It 00400: loss = 4.95845801e-04 lambda = [-5.9977455  0.996339 ]\n",
            "It 00450: loss = 3.85591033e-04 lambda = [-6.0947237  1.039108 ]\n",
            "It 00500: loss = 3.45202046e-04 lambda = [-6.0981793  1.035516 ]\n",
            "It 00550: loss = 3.03549285e-04 lambda = [-6.112107   1.0490241]\n",
            "It 00600: loss = 2.76628300e-04 lambda = [-6.0887814  1.0397468]\n",
            "It 00650: loss = 2.05922872e-04 lambda = [-6.0988374  1.0404402]\n",
            "It 00700: loss = 1.67036123e-04 lambda = [-6.095668   1.0351413]\n",
            "It 00750: loss = 1.36396644e-04 lambda = [-6.0679817  1.0307134]\n",
            "It 00800: loss = 1.10187553e-04 lambda = [-6.0362134  1.0113037]\n",
            "\n",
            "\n",
            "SGD\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: loss = 4.56346035e-01 lambda = [ 1.2582657e-05 -6.7400360e-06]\n",
            "It 00050: loss = 2.31394961e-01 lambda = [-1.31950525e-04 -1.01661235e-05]\n",
            "It 00100: loss = 2.26540521e-01 lambda = [-3.1447440e-04 -2.4664903e-05]\n",
            "It 00150: loss = 2.18628079e-01 lambda = [-8.3503494e-04 -8.8022178e-05]\n",
            "It 00200: loss = 2.07243830e-01 lambda = [-0.00211166 -0.00030056]\n",
            "It 00250: loss = 1.95173606e-01 lambda = [-0.00456173 -0.00083784]\n",
            "It 00300: loss = 1.87038779e-01 lambda = [-0.00823277 -0.00183351]\n",
            "It 00350: loss = 1.83001310e-01 lambda = [-0.01302061 -0.00330173]\n",
            "It 00400: loss = 1.80606976e-01 lambda = [-0.0188256  -0.00518558]\n",
            "It 00450: loss = 1.78594440e-01 lambda = [-0.02554251 -0.00743306]\n",
            "It 00500: loss = 1.76674202e-01 lambda = [-0.03310047 -0.01003447]\n",
            "It 00550: loss = 1.74829230e-01 lambda = [-0.04146529 -0.01301344]\n",
            "It 00600: loss = 1.73079655e-01 lambda = [-0.05062113 -0.01640821]\n",
            "It 00650: loss = 1.71440691e-01 lambda = [-0.06055309 -0.0202582 ]\n",
            "It 00700: loss = 1.69920459e-01 lambda = [-0.07123681 -0.02459661]\n",
            "It 00750: loss = 1.68522239e-01 lambda = [-0.08263473 -0.02944681]\n",
            "It 00800: loss = 1.67245328e-01 lambda = [-0.09469639 -0.03482062]\n",
            "It 00850: loss = 1.66086152e-01 lambda = [-0.10736056 -0.04071791]\n",
            "It 00900: loss = 1.65038511e-01 lambda = [-0.12055808 -0.04712678]\n",
            "It 00950: loss = 1.64094314e-01 lambda = [-0.1342148  -0.05402453]\n",
            "It 01000: loss = 1.63244292e-01 lambda = [-0.14825444 -0.06137914]\n",
            "It 01050: loss = 1.62478507e-01 lambda = [-0.16260104 -0.06915122]\n",
            "It 01100: loss = 1.61786914e-01 lambda = [-0.17718092 -0.07729605]\n",
            "It 01150: loss = 1.61159843e-01 lambda = [-0.19192459 -0.0857657 ]\n",
            "It 01200: loss = 1.60588369e-01 lambda = [-0.20676751 -0.094511  ]\n",
            "It 01250: loss = 1.60064414e-01 lambda = [-0.22165094 -0.10348307]\n",
            "It 01300: loss = 1.59580916e-01 lambda = [-0.23652218 -0.11263461]\n",
            "It 01350: loss = 1.59131750e-01 lambda = [-0.25133464 -0.12192088]\n",
            "It 01400: loss = 1.58711702e-01 lambda = [-0.26604748 -0.13130036]\n",
            "It 01450: loss = 1.58316433e-01 lambda = [-0.2806255  -0.14073494]\n",
            "It 01500: loss = 1.57942310e-01 lambda = [-0.29503852 -0.15019032]\n",
            "It 01550: loss = 1.57586321e-01 lambda = [-0.30926096 -0.15963556]\n",
            "It 01600: loss = 1.57246083e-01 lambda = [-0.3232713  -0.16904354]\n",
            "It 01650: loss = 1.56919599e-01 lambda = [-0.33705202 -0.1783903 ]\n",
            "It 01700: loss = 1.56605169e-01 lambda = [-0.35058853 -0.1876551 ]\n",
            "It 01750: loss = 1.56301543e-01 lambda = [-0.3638692  -0.19681984]\n",
            "It 01800: loss = 1.56007618e-01 lambda = [-0.37688482 -0.2058691 ]\n",
            "It 01850: loss = 1.55722514e-01 lambda = [-0.38962847 -0.21478966]\n",
            "It 01900: loss = 1.55445546e-01 lambda = [-0.40209493 -0.2235705 ]\n",
            "It 01950: loss = 1.55176073e-01 lambda = [-0.41428062 -0.23220235]\n",
            "It 02000: loss = 1.54913709e-01 lambda = [-0.4261834  -0.24067765]\n",
            "It 02050: loss = 1.54657990e-01 lambda = [-0.4378023  -0.24899024]\n",
            "It 02100: loss = 1.54408664e-01 lambda = [-0.4491373  -0.25713512]\n",
            "It 02150: loss = 1.54165387e-01 lambda = [-0.46018937 -0.2651086 ]\n",
            "It 02200: loss = 1.53927982e-01 lambda = [-0.47096014 -0.27290773]\n",
            "It 02250: loss = 1.53696299e-01 lambda = [-0.48145196 -0.28053066]\n",
            "It 02300: loss = 1.53470084e-01 lambda = [-0.49166772 -0.2879762 ]\n",
            "It 02350: loss = 1.53249249e-01 lambda = [-0.5016106  -0.29524377]\n",
            "It 02400: loss = 1.53033689e-01 lambda = [-0.51128435 -0.30233344]\n",
            "It 02450: loss = 1.52823240e-01 lambda = [-0.520693   -0.30924574]\n",
            "It 02500: loss = 1.52617827e-01 lambda = [-0.5298408 -0.3159817]\n",
            "It 02550: loss = 1.52417406e-01 lambda = [-0.53873247 -0.32254258]\n",
            "It 02600: loss = 1.52221799e-01 lambda = [-0.5473727  -0.32893023]\n",
            "It 02650: loss = 1.52031034e-01 lambda = [-0.555766  -0.3351466]\n",
            "It 02700: loss = 1.51844919e-01 lambda = [-0.56391746 -0.3411939 ]\n",
            "It 02750: loss = 1.51663452e-01 lambda = [-0.5718321 -0.3470745]\n",
            "It 02800: loss = 1.51486546e-01 lambda = [-0.57951516 -0.35279107]\n",
            "It 02850: loss = 1.51314110e-01 lambda = [-0.5869717  -0.35834637]\n",
            "It 02900: loss = 1.51146114e-01 lambda = [-0.5942069  -0.36374328]\n",
            "It 02950: loss = 1.50982425e-01 lambda = [-0.601226   -0.36898476]\n",
            "It 03000: loss = 1.50822997e-01 lambda = [-0.608034   -0.37407395]\n",
            "It 03050: loss = 1.50742620e-01 lambda = [-0.61139107 -0.37658525]\n",
            "It 03100: loss = 1.50663495e-01 lambda = [-0.61475563 -0.37910336]\n",
            "It 03150: loss = 1.50584012e-01 lambda = [-0.6181276  -0.38162807]\n",
            "It 03200: loss = 1.50504231e-01 lambda = [-0.62150705 -0.3841595 ]\n",
            "It 03250: loss = 1.50424048e-01 lambda = [-0.6248937 -0.3866975]\n",
            "It 03300: loss = 1.50343567e-01 lambda = [-0.628288  -0.3892422]\n",
            "It 03350: loss = 1.50262713e-01 lambda = [-0.63168955 -0.39179343]\n",
            "It 03400: loss = 1.50181517e-01 lambda = [-0.6350986  -0.39435127]\n",
            "It 03450: loss = 1.50099963e-01 lambda = [-0.6385149  -0.39691564]\n",
            "It 03500: loss = 1.50018066e-01 lambda = [-0.6419388 -0.3994865]\n",
            "It 03550: loss = 1.49935812e-01 lambda = [-0.64536995 -0.40206394]\n",
            "It 03600: loss = 1.49853215e-01 lambda = [-0.64880866 -0.4046478 ]\n",
            "It 03650: loss = 1.49770245e-01 lambda = [-0.6522546  -0.40723807]\n",
            "It 03700: loss = 1.49686918e-01 lambda = [-0.65570813 -0.40983483]\n",
            "It 03750: loss = 1.49603218e-01 lambda = [-0.6591688  -0.41243798]\n",
            "It 03800: loss = 1.49519175e-01 lambda = [-0.6626372  -0.41504744]\n",
            "It 03850: loss = 1.49434760e-01 lambda = [-0.66611266 -0.41766325]\n",
            "It 03900: loss = 1.49349958e-01 lambda = [-0.6695958  -0.42028537]\n",
            "It 03950: loss = 1.49264798e-01 lambda = [-0.6730861  -0.42291382]\n",
            "It 04000: loss = 1.49179265e-01 lambda = [-0.67658406 -0.42554846]\n",
            "It 04050: loss = 1.49093345e-01 lambda = [-0.6800892 -0.4281893]\n",
            "It 04100: loss = 1.49007052e-01 lambda = [-0.6836019  -0.43083635]\n",
            "It 04150: loss = 1.48920372e-01 lambda = [-0.6871218 -0.4334896]\n",
            "It 04200: loss = 1.48833364e-01 lambda = [-0.6906493  -0.43614897]\n",
            "It 04250: loss = 1.48745924e-01 lambda = [-0.694184   -0.43881443]\n",
            "It 04300: loss = 1.48658127e-01 lambda = [-0.6977262  -0.44148594]\n",
            "It 04350: loss = 1.48569942e-01 lambda = [-0.70127577 -0.4441635 ]\n",
            "It 04400: loss = 1.48481309e-01 lambda = [-0.7048327  -0.44684702]\n",
            "It 04450: loss = 1.48392364e-01 lambda = [-0.70839703 -0.4495365 ]\n",
            "It 04500: loss = 1.48303002e-01 lambda = [-0.71196866 -0.4522319 ]\n",
            "It 04550: loss = 1.48213267e-01 lambda = [-0.7155478  -0.45493323]\n",
            "It 04600: loss = 1.48123115e-01 lambda = [-0.71913415 -0.45764035]\n",
            "It 04650: loss = 1.48032591e-01 lambda = [-0.722728  -0.4603533]\n",
            "It 04700: loss = 1.47941694e-01 lambda = [-0.726329   -0.46307203]\n",
            "It 04750: loss = 1.47850350e-01 lambda = [-0.7299376 -0.4657965]\n",
            "It 04800: loss = 1.47758633e-01 lambda = [-0.7335533  -0.46852666]\n",
            "It 04850: loss = 1.47666529e-01 lambda = [-0.7371766  -0.47126243]\n",
            "It 04900: loss = 1.47573993e-01 lambda = [-0.740807   -0.47400376]\n",
            "It 04950: loss = 1.47481099e-01 lambda = [-0.74444497 -0.47675073]\n",
            "It 05000: loss = 1.47387773e-01 lambda = [-0.7480901  -0.47950318]\n",
            "It 05050: loss = 1.47294074e-01 lambda = [-0.7517426  -0.48226106]\n",
            "It 05100: loss = 1.47199973e-01 lambda = [-0.7554024 -0.4850244]\n",
            "It 05150: loss = 1.47105470e-01 lambda = [-0.75906944 -0.48779303]\n",
            "It 05200: loss = 1.47010535e-01 lambda = [-0.76274383 -0.49056697]\n",
            "It 05250: loss = 1.46915227e-01 lambda = [-0.76642543 -0.49334624]\n",
            "It 05300: loss = 1.46819487e-01 lambda = [-0.7701144  -0.49613068]\n",
            "It 05350: loss = 1.46723375e-01 lambda = [-0.77381045 -0.4989203 ]\n",
            "It 05400: loss = 1.46626830e-01 lambda = [-0.777514   -0.50171506]\n",
            "It 05450: loss = 1.46529883e-01 lambda = [-0.78122455 -0.5045149 ]\n",
            "It 05500: loss = 1.46432549e-01 lambda = [-0.7849424 -0.5073196]\n",
            "It 05550: loss = 1.46334782e-01 lambda = [-0.7886675 -0.5101291]\n",
            "It 05600: loss = 1.46236613e-01 lambda = [-0.79239964 -0.51294374]\n",
            "It 05650: loss = 1.46138072e-01 lambda = [-0.7961392  -0.51576304]\n",
            "It 05700: loss = 1.46039099e-01 lambda = [-0.79988575 -0.518587  ]\n",
            "It 05750: loss = 1.45939738e-01 lambda = [-0.80363953 -0.5214158 ]\n",
            "It 05800: loss = 1.45839959e-01 lambda = [-0.80740047 -0.52424896]\n",
            "It 05850: loss = 1.45739794e-01 lambda = [-0.81116843 -0.52708703]\n",
            "It 05900: loss = 1.45639196e-01 lambda = [-0.81494373 -0.5299291 ]\n",
            "It 05950: loss = 1.45538241e-01 lambda = [-0.81872594 -0.532776  ]\n",
            "It 06000: loss = 1.45436853e-01 lambda = [-0.82251513 -0.5356269 ]\n",
            "It 06050: loss = 1.45335078e-01 lambda = [-0.8263115 -0.5384822]\n",
            "It 06100: loss = 1.45232886e-01 lambda = [-0.8301148 -0.5413416]\n",
            "It 06150: loss = 1.45130306e-01 lambda = [-0.8339251  -0.54420483]\n",
            "It 06200: loss = 1.45027325e-01 lambda = [-0.83774245 -0.5470725 ]\n",
            "It 06250: loss = 1.44923970e-01 lambda = [-0.84156656 -0.5499439 ]\n",
            "It 06300: loss = 1.44820213e-01 lambda = [-0.8453977  -0.55281895]\n",
            "It 06350: loss = 1.44716054e-01 lambda = [-0.8492358  -0.55569786]\n",
            "It 06400: loss = 1.44611493e-01 lambda = [-0.85308063 -0.5585806 ]\n",
            "It 06450: loss = 1.44506574e-01 lambda = [-0.8569322 -0.5614667]\n",
            "It 06500: loss = 1.44401267e-01 lambda = [-0.8607908 -0.5643562]\n",
            "It 06550: loss = 1.44295543e-01 lambda = [-0.86465603 -0.56724906]\n",
            "It 06600: loss = 1.44189477e-01 lambda = [-0.86852795 -0.5701452 ]\n",
            "It 06650: loss = 1.44083038e-01 lambda = [-0.87240666 -0.5730445 ]\n",
            "It 06700: loss = 1.43976197e-01 lambda = [-0.8762921  -0.57594687]\n",
            "It 06750: loss = 1.43868998e-01 lambda = [-0.8801841  -0.57885224]\n",
            "It 06800: loss = 1.43761426e-01 lambda = [-0.8840827  -0.58176047]\n",
            "It 06850: loss = 1.43653482e-01 lambda = [-0.88798773 -0.58467144]\n",
            "It 06900: loss = 1.43545151e-01 lambda = [-0.89189947 -0.58758503]\n",
            "It 06950: loss = 1.43436506e-01 lambda = [-0.8958177 -0.590501 ]\n",
            "It 07000: loss = 1.43327489e-01 lambda = [-0.8997423 -0.5934192]\n",
            "It 07050: loss = 1.43271759e-01 lambda = [-0.90170634 -0.5948795 ]\n",
            "It 07100: loss = 1.43217012e-01 lambda = [-0.9036733 -0.5963398]\n",
            "It 07150: loss = 1.43162206e-01 lambda = [-0.90564066 -0.59780014]\n",
            "It 07200: loss = 1.43107295e-01 lambda = [-0.9076106 -0.5992611]\n",
            "It 07250: loss = 1.43052310e-01 lambda = [-0.9095813 -0.6007244]\n",
            "It 07300: loss = 1.42997220e-01 lambda = [-0.9115542 -0.6021877]\n",
            "It 07350: loss = 1.42942101e-01 lambda = [-0.91352814 -0.603651  ]\n",
            "It 07400: loss = 1.42886847e-01 lambda = [-0.91550404 -0.6051143 ]\n",
            "It 07450: loss = 1.42831549e-01 lambda = [-0.9174812 -0.6065776]\n",
            "It 07500: loss = 1.42776147e-01 lambda = [-0.91946006 -0.60804087]\n",
            "It 07550: loss = 1.42720670e-01 lambda = [-0.92144036 -0.60950595]\n",
            "It 07600: loss = 1.42665088e-01 lambda = [-0.9234222 -0.6109722]\n",
            "It 07650: loss = 1.42609432e-01 lambda = [-0.9254057 -0.6124385]\n",
            "It 07700: loss = 1.42553702e-01 lambda = [-0.9273905 -0.6139048]\n",
            "It 07750: loss = 1.42497852e-01 lambda = [-0.929377   -0.61537105]\n",
            "It 07800: loss = 1.42441943e-01 lambda = [-0.93136483 -0.6168373 ]\n",
            "It 07850: loss = 1.42385960e-01 lambda = [-0.9333543 -0.6183036]\n",
            "It 07900: loss = 1.42329916e-01 lambda = [-0.9353451 -0.6197699]\n",
            "It 07950: loss = 1.42273799e-01 lambda = [-0.9373376  -0.62123615]\n",
            "It 08000: loss = 1.42217577e-01 lambda = [-0.93933135 -0.6227028 ]\n",
            "It 08050: loss = 1.42161280e-01 lambda = [-0.94132674 -0.62417203]\n",
            "It 08100: loss = 1.42104924e-01 lambda = [-0.9433235 -0.6256413]\n",
            "It 08150: loss = 1.42048493e-01 lambda = [-0.9453217  -0.62711054]\n",
            "It 08200: loss = 1.41991973e-01 lambda = [-0.9473214 -0.6285798]\n",
            "It 08250: loss = 1.41935378e-01 lambda = [-0.9493224  -0.63004905]\n",
            "It 08300: loss = 1.41878724e-01 lambda = [-0.9513251 -0.6315183]\n",
            "It 08350: loss = 1.41822010e-01 lambda = [-0.95332885 -0.63298756]\n",
            "It 08400: loss = 1.41765207e-01 lambda = [-0.95533454 -0.6344568 ]\n",
            "It 08450: loss = 1.41708359e-01 lambda = [-0.95734084 -0.63592607]\n",
            "It 08500: loss = 1.41651437e-01 lambda = [-0.9593495 -0.6373953]\n",
            "It 08550: loss = 1.41594455e-01 lambda = [-0.9613583 -0.6388646]\n",
            "It 08600: loss = 1.41537398e-01 lambda = [-0.96336997 -0.64033383]\n",
            "It 08650: loss = 1.41480297e-01 lambda = [-0.9653816 -0.6418031]\n",
            "It 08700: loss = 1.41423106e-01 lambda = [-0.9673959  -0.64327234]\n",
            "It 08750: loss = 1.41365856e-01 lambda = [-0.96941054 -0.6447416 ]\n",
            "It 08800: loss = 1.41308531e-01 lambda = [-0.97142714 -0.64621085]\n",
            "It 08850: loss = 1.41251147e-01 lambda = [-0.97344476 -0.6476801 ]\n",
            "It 08900: loss = 1.41193688e-01 lambda = [-0.9754636  -0.64914936]\n",
            "It 08950: loss = 1.41136184e-01 lambda = [-0.9774842 -0.6506186]\n",
            "It 09000: loss = 1.41078636e-01 lambda = [-0.97950524 -0.65208787]\n",
            "It 09050: loss = 1.41020983e-01 lambda = [-0.9815288 -0.6535571]\n",
            "It 09100: loss = 1.40963286e-01 lambda = [-0.9835524 -0.6550264]\n",
            "It 09150: loss = 1.40905544e-01 lambda = [-0.9855784 -0.6564946]\n",
            "It 09200: loss = 1.40847757e-01 lambda = [-0.987605  -0.6579609]\n",
            "It 09250: loss = 1.40789896e-01 lambda = [-0.9896329  -0.65942717]\n",
            "It 09300: loss = 1.40731990e-01 lambda = [-0.99166244 -0.66089344]\n",
            "It 09350: loss = 1.40674070e-01 lambda = [-0.9936921 -0.6623597]\n",
            "It 09400: loss = 1.40616059e-01 lambda = [-0.9957246 -0.663826 ]\n",
            "It 09450: loss = 1.40558004e-01 lambda = [-0.99775714 -0.66529226]\n",
            "It 09500: loss = 1.40499905e-01 lambda = [-0.9997914  -0.66675854]\n",
            "It 09550: loss = 1.40441760e-01 lambda = [-1.0018263 -0.6682248]\n",
            "It 09600: loss = 1.40383527e-01 lambda = [-1.0038648 -0.6696891]\n",
            "It 09650: loss = 1.40325293e-01 lambda = [-1.0059032 -0.6711524]\n",
            "It 09700: loss = 1.40267015e-01 lambda = [-1.0079417 -0.6726157]\n",
            "It 09750: loss = 1.40208691e-01 lambda = [-1.0099802 -0.674079 ]\n",
            "It 09800: loss = 1.40150338e-01 lambda = [-1.0120199 -0.6755423]\n",
            "It 09850: loss = 1.40091881e-01 lambda = [-1.0140643 -0.6770056]\n",
            "It 09900: loss = 1.40033409e-01 lambda = [-1.0161088 -0.6784662]\n",
            "It 09950: loss = 1.39974892e-01 lambda = [-1.0181532 -0.6799265]\n",
            "It 10000: loss = 1.39916375e-01 lambda = [-1.0201976 -0.6813868]\n",
            "It 10050: loss = 1.39857829e-01 lambda = [-1.0222421  -0.68284714]\n",
            "It 10100: loss = 1.39799207e-01 lambda = [-1.0242912  -0.68430656]\n",
            "It 10150: loss = 1.39740556e-01 lambda = [-1.0263416 -0.6857639]\n",
            "It 10200: loss = 1.39681876e-01 lambda = [-1.028392  -0.6872212]\n",
            "It 10250: loss = 1.39623180e-01 lambda = [-1.0304424  -0.68867856]\n",
            "It 10300: loss = 1.39564469e-01 lambda = [-1.0324928  -0.69013476]\n",
            "It 10350: loss = 1.39505744e-01 lambda = [-1.0345433 -0.6915891]\n",
            "It 10400: loss = 1.39446944e-01 lambda = [-1.0365996 -0.6930435]\n",
            "It 10450: loss = 1.39388084e-01 lambda = [-1.038656  -0.6944978]\n",
            "It 10500: loss = 1.39329255e-01 lambda = [-1.0407124  -0.69594944]\n",
            "It 10550: loss = 1.39270395e-01 lambda = [-1.0427687 -0.6974008]\n",
            "It 10600: loss = 1.39211535e-01 lambda = [-1.0448251 -0.6988522]\n",
            "It 10650: loss = 1.39152646e-01 lambda = [-1.0468814  -0.70030123]\n",
            "It 10700: loss = 1.39093712e-01 lambda = [-1.0489424 -0.7017496]\n",
            "It 10750: loss = 1.39034718e-01 lambda = [-1.0510048 -0.703198 ]\n",
            "It 10800: loss = 1.38975739e-01 lambda = [-1.0530671 -0.7046437]\n",
            "It 10850: loss = 1.38916731e-01 lambda = [-1.0551294  -0.70608914]\n",
            "It 10900: loss = 1.38857767e-01 lambda = [-1.0571917  -0.70753396]\n",
            "It 10950: loss = 1.38798803e-01 lambda = [-1.059254  -0.7089764]\n",
            "It 11000: loss = 1.38739809e-01 lambda = [-1.0613164 -0.7104188]\n",
            "It 11050: loss = 1.38680756e-01 lambda = [-1.0633842 -0.7118592]\n",
            "It 11100: loss = 1.38621718e-01 lambda = [-1.0654525 -0.7132987]\n",
            "It 11150: loss = 1.38562649e-01 lambda = [-1.0675207 -0.7147372]\n",
            "It 11200: loss = 1.38503626e-01 lambda = [-1.069589   -0.71617365]\n",
            "It 11250: loss = 1.38444588e-01 lambda = [-1.0716573  -0.71760994]\n",
            "It 11300: loss = 1.38385564e-01 lambda = [-1.0737256  -0.71904343]\n",
            "It 11350: loss = 1.38326526e-01 lambda = [-1.0757939 -0.7204769]\n",
            "It 11400: loss = 1.38267532e-01 lambda = [-1.0778632 -0.7219077]\n",
            "It 11450: loss = 1.38208464e-01 lambda = [-1.0799375 -0.7233382]\n",
            "It 11500: loss = 1.38149410e-01 lambda = [-1.0820117 -0.7247661]\n",
            "It 11550: loss = 1.38090372e-01 lambda = [-1.084086  -0.7261936]\n",
            "It 11600: loss = 1.38031363e-01 lambda = [-1.0861602  -0.72761846]\n",
            "It 11650: loss = 1.37972370e-01 lambda = [-1.0882344  -0.72904295]\n",
            "It 11700: loss = 1.37913421e-01 lambda = [-1.0903087 -0.7304645]\n",
            "It 11750: loss = 1.37854457e-01 lambda = [-1.0923829  -0.73188555]\n",
            "It 11800: loss = 1.37795538e-01 lambda = [-1.0944571  -0.73330414]\n",
            "It 11850: loss = 1.37736633e-01 lambda = [-1.0965314  -0.73472154]\n",
            "It 11900: loss = 1.37677670e-01 lambda = [-1.0986108  -0.73613715]\n",
            "It 11950: loss = 1.37618735e-01 lambda = [-1.100691  -0.7375507]\n",
            "It 12000: loss = 1.37559831e-01 lambda = [-1.1027712 -0.7389632]\n",
            "It 12050: loss = 1.37500942e-01 lambda = [-1.1048514  -0.74037284]\n",
            "It 12100: loss = 1.37442097e-01 lambda = [-1.1069316  -0.74178123]\n",
            "It 12150: loss = 1.37383252e-01 lambda = [-1.1090118 -0.7431879]\n",
            "It 12200: loss = 1.37324452e-01 lambda = [-1.111092  -0.7445921]\n",
            "It 12250: loss = 1.37265682e-01 lambda = [-1.1131722  -0.74599487]\n",
            "It 12300: loss = 1.37206957e-01 lambda = [-1.1152524 -0.7473956]\n",
            "It 12350: loss = 1.37148276e-01 lambda = [-1.1173326  -0.74879384]\n",
            "It 12400: loss = 1.37089610e-01 lambda = [-1.1194128  -0.75019056]\n",
            "It 12450: loss = 1.37030974e-01 lambda = [-1.121493  -0.7515853]\n",
            "It 12500: loss = 1.36972398e-01 lambda = [-1.1235737 -0.7529773]\n",
            "It 12550: loss = 1.36913791e-01 lambda = [-1.1256598  -0.75436753]\n",
            "It 12600: loss = 1.36855215e-01 lambda = [-1.127746  -0.7557559]\n",
            "It 12650: loss = 1.36796683e-01 lambda = [-1.1298321 -0.7571417]\n",
            "It 12700: loss = 1.36738196e-01 lambda = [-1.1319183  -0.75852513]\n",
            "It 12750: loss = 1.36679783e-01 lambda = [-1.1340045  -0.75990653]\n",
            "It 12800: loss = 1.36621416e-01 lambda = [-1.1360906  -0.76128584]\n",
            "It 12850: loss = 1.36563078e-01 lambda = [-1.1381768 -0.7626627]\n",
            "It 12900: loss = 1.36504799e-01 lambda = [-1.140263  -0.7640369]\n",
            "It 12950: loss = 1.36446550e-01 lambda = [-1.1423491 -0.7654088]\n",
            "It 13000: loss = 1.36388361e-01 lambda = [-1.1444353  -0.76677847]\n",
            "It 13050: loss = 1.36330247e-01 lambda = [-1.1465214  -0.76814574]\n",
            "It 13100: loss = 1.36272207e-01 lambda = [-1.1486076 -0.7695106]\n",
            "It 13150: loss = 1.36214226e-01 lambda = [-1.1506938 -0.7708726]\n",
            "It 13200: loss = 1.36156321e-01 lambda = [-1.1527799  -0.77223206]\n",
            "It 13250: loss = 1.36098415e-01 lambda = [-1.1548661 -0.773589 ]\n",
            "It 13300: loss = 1.36040613e-01 lambda = [-1.1569523 -0.7749434]\n",
            "It 13350: loss = 1.35982856e-01 lambda = [-1.1590384  -0.77629524]\n",
            "It 13400: loss = 1.35925159e-01 lambda = [-1.1611246 -0.7776444]\n",
            "It 13450: loss = 1.35867536e-01 lambda = [-1.1632107  -0.77899086]\n",
            "It 13500: loss = 1.35809973e-01 lambda = [-1.1652969 -0.7803346]\n",
            "It 13550: loss = 1.35752484e-01 lambda = [-1.1673831 -0.7816756]\n",
            "It 13600: loss = 1.35695100e-01 lambda = [-1.1694692 -0.7830137]\n",
            "It 13650: loss = 1.35637775e-01 lambda = [-1.1715554 -0.7843489]\n",
            "It 13700: loss = 1.35580540e-01 lambda = [-1.1736416  -0.78568125]\n",
            "It 13750: loss = 1.35523364e-01 lambda = [-1.1757277 -0.7870107]\n",
            "It 13800: loss = 1.35466233e-01 lambda = [-1.1778139 -0.7883373]\n",
            "It 13850: loss = 1.35409191e-01 lambda = [-1.1799    -0.7896609]\n",
            "It 13900: loss = 1.35352224e-01 lambda = [-1.1819862 -0.7909815]\n",
            "It 13950: loss = 1.35295331e-01 lambda = [-1.1840724  -0.79229903]\n",
            "It 14000: loss = 1.35238543e-01 lambda = [-1.1861585  -0.79361355]\n",
            "It 14050: loss = 1.35209605e-01 lambda = [-1.1872016 -0.7942692]\n",
            "It 14100: loss = 1.35181263e-01 lambda = [-1.1882447  -0.79492486]\n",
            "It 14150: loss = 1.35152936e-01 lambda = [-1.1892878  -0.79558045]\n",
            "It 14200: loss = 1.35124609e-01 lambda = [-1.1903309 -0.7962331]\n",
            "It 14250: loss = 1.35096341e-01 lambda = [-1.191374  -0.7968858]\n",
            "It 14300: loss = 1.35068074e-01 lambda = [-1.192417   -0.79753846]\n",
            "It 14350: loss = 1.35039836e-01 lambda = [-1.1934601 -0.7981904]\n",
            "It 14400: loss = 1.35011613e-01 lambda = [-1.1945032 -0.7988401]\n",
            "It 14450: loss = 1.34983405e-01 lambda = [-1.1955463 -0.7994898]\n",
            "It 14500: loss = 1.34955227e-01 lambda = [-1.1965894 -0.8001395]\n",
            "It 14550: loss = 1.34927079e-01 lambda = [-1.1976324  -0.80078757]\n",
            "It 14600: loss = 1.34898961e-01 lambda = [-1.1986755 -0.8014343]\n",
            "It 14650: loss = 1.34870842e-01 lambda = [-1.1997186 -0.802081 ]\n",
            "It 14700: loss = 1.34842739e-01 lambda = [-1.2007617 -0.8027277]\n",
            "It 14750: loss = 1.34814680e-01 lambda = [-1.2018048 -0.8033717]\n",
            "It 14800: loss = 1.34786636e-01 lambda = [-1.2028478  -0.80401546]\n",
            "It 14850: loss = 1.34758607e-01 lambda = [-1.2038909 -0.8046592]\n",
            "It 14900: loss = 1.34730622e-01 lambda = [-1.204934   -0.80530196]\n",
            "It 14950: loss = 1.34702623e-01 lambda = [-1.2059771 -0.8059427]\n",
            "It 15000: loss = 1.34674683e-01 lambda = [-1.2070202  -0.80658346]\n",
            "It 15050: loss = 1.34646758e-01 lambda = [-1.2080632 -0.8072242]\n",
            "It 15100: loss = 1.34618863e-01 lambda = [-1.2091063 -0.8078626]\n",
            "It 15150: loss = 1.34590983e-01 lambda = [-1.2101494  -0.80850035]\n",
            "It 15200: loss = 1.34563103e-01 lambda = [-1.2111925 -0.8091381]\n",
            "It 15250: loss = 1.34535283e-01 lambda = [-1.2122356  -0.80977494]\n",
            "It 15300: loss = 1.34507507e-01 lambda = [-1.2132787 -0.8104097]\n",
            "It 15350: loss = 1.34479731e-01 lambda = [-1.2143217 -0.8110445]\n",
            "It 15400: loss = 1.34451956e-01 lambda = [-1.2153648 -0.8116793]\n",
            "It 15450: loss = 1.34424239e-01 lambda = [-1.2164079 -0.8123114]\n",
            "It 15500: loss = 1.34396523e-01 lambda = [-1.217451  -0.8129432]\n",
            "It 15550: loss = 1.34368822e-01 lambda = [-1.218494 -0.813575]\n",
            "It 15600: loss = 1.34341165e-01 lambda = [-1.2195371 -0.8142053]\n",
            "It 15650: loss = 1.34313539e-01 lambda = [-1.2205802 -0.8148341]\n",
            "It 15700: loss = 1.34285897e-01 lambda = [-1.2216233  -0.81546295]\n",
            "It 15750: loss = 1.34258300e-01 lambda = [-1.2226664 -0.8160912]\n",
            "It 15800: loss = 1.34230733e-01 lambda = [-1.2237095 -0.816717 ]\n",
            "It 15850: loss = 1.34203166e-01 lambda = [-1.2247525 -0.8173429]\n",
            "It 15900: loss = 1.34175643e-01 lambda = [-1.2257956 -0.8179687]\n",
            "It 15950: loss = 1.34148166e-01 lambda = [-1.2268387  -0.81859183]\n",
            "It 16000: loss = 1.34120747e-01 lambda = [-1.2278782 -0.8192147]\n",
            "It 16050: loss = 1.34093389e-01 lambda = [-1.2289153  -0.81983757]\n",
            "It 16100: loss = 1.34066060e-01 lambda = [-1.2299525 -0.8204584]\n",
            "It 16150: loss = 1.34038761e-01 lambda = [-1.2309896 -0.8210783]\n",
            "It 16200: loss = 1.34011477e-01 lambda = [-1.2320267 -0.8216982]\n",
            "It 16250: loss = 1.33984238e-01 lambda = [-1.2330638 -0.8223167]\n",
            "It 16300: loss = 1.33957013e-01 lambda = [-1.2341009 -0.8229336]\n",
            "It 16350: loss = 1.33929819e-01 lambda = [-1.235138  -0.8235505]\n",
            "It 16400: loss = 1.33902669e-01 lambda = [-1.2361752 -0.8241666]\n",
            "It 16450: loss = 1.33875534e-01 lambda = [-1.2372123 -0.8247805]\n",
            "It 16500: loss = 1.33848399e-01 lambda = [-1.2382494  -0.82539445]\n",
            "It 16550: loss = 1.33821309e-01 lambda = [-1.2392865  -0.82600796]\n",
            "It 16600: loss = 1.33794263e-01 lambda = [-1.2403237 -0.8266189]\n",
            "It 16650: loss = 1.33767188e-01 lambda = [-1.2413608  -0.82722986]\n",
            "It 16700: loss = 1.33740187e-01 lambda = [-1.2423979 -0.8278407]\n",
            "It 16750: loss = 1.33713186e-01 lambda = [-1.243435   -0.82844865]\n",
            "It 16800: loss = 1.33686244e-01 lambda = [-1.2444721 -0.8290566]\n",
            "It 16850: loss = 1.33659318e-01 lambda = [-1.2455093 -0.8296646]\n",
            "It 16900: loss = 1.33632407e-01 lambda = [-1.2465464  -0.83026963]\n",
            "It 16950: loss = 1.33605540e-01 lambda = [-1.2475835 -0.8308746]\n",
            "It 17000: loss = 1.33578688e-01 lambda = [-1.2486206 -0.8314796]\n",
            "It 17050: loss = 1.33551896e-01 lambda = [-1.2496578  -0.83208185]\n",
            "It 17100: loss = 1.33525118e-01 lambda = [-1.2506949  -0.83268386]\n",
            "It 17150: loss = 1.33498356e-01 lambda = [-1.251732   -0.83328587]\n",
            "It 17200: loss = 1.33471623e-01 lambda = [-1.2527691  -0.83388513]\n",
            "It 17250: loss = 1.33444935e-01 lambda = [-1.2538062  -0.83448416]\n",
            "It 17300: loss = 1.33418247e-01 lambda = [-1.2548434 -0.8350832]\n",
            "It 17350: loss = 1.33391619e-01 lambda = [-1.2558805 -0.8356794]\n",
            "It 17400: loss = 1.33365020e-01 lambda = [-1.2569176  -0.83627546]\n",
            "It 17450: loss = 1.33338436e-01 lambda = [-1.2579547 -0.8368715]\n",
            "It 17500: loss = 1.33311898e-01 lambda = [-1.2589918  -0.83746463]\n",
            "It 17550: loss = 1.33285373e-01 lambda = [-1.260029  -0.8380577]\n",
            "It 17600: loss = 1.33258864e-01 lambda = [-1.2610661 -0.8386506]\n",
            "It 17650: loss = 1.33232415e-01 lambda = [-1.2621032 -0.8392407]\n",
            "It 17700: loss = 1.33205935e-01 lambda = [-1.2631403  -0.83983076]\n",
            "It 17750: loss = 1.33179516e-01 lambda = [-1.2641774 -0.8404204]\n",
            "It 17800: loss = 1.33153126e-01 lambda = [-1.2652146  -0.84100753]\n",
            "It 17850: loss = 1.33126751e-01 lambda = [-1.2662507  -0.84159464]\n",
            "It 17900: loss = 1.33100495e-01 lambda = [-1.2672819  -0.84218097]\n",
            "It 17950: loss = 1.33074254e-01 lambda = [-1.268313  -0.8427651]\n",
            "It 18000: loss = 1.33048043e-01 lambda = [-1.2693442 -0.8433492]\n",
            "It 18050: loss = 1.33021861e-01 lambda = [-1.2703754  -0.84393215]\n",
            "It 18100: loss = 1.32995740e-01 lambda = [-1.2714065 -0.8445133]\n",
            "It 18150: loss = 1.32969633e-01 lambda = [-1.2724377  -0.84509444]\n",
            "It 18200: loss = 1.32943571e-01 lambda = [-1.2734689 -0.845674 ]\n",
            "It 18250: loss = 1.32917508e-01 lambda = [-1.2745     -0.84625214]\n",
            "It 18300: loss = 1.32891491e-01 lambda = [-1.2755312 -0.8468303]\n",
            "It 18350: loss = 1.32865489e-01 lambda = [-1.2765623  -0.84740627]\n",
            "It 18400: loss = 1.32839546e-01 lambda = [-1.2775935  -0.84798145]\n",
            "It 18450: loss = 1.32813603e-01 lambda = [-1.2786247  -0.84855664]\n",
            "It 18500: loss = 1.32787719e-01 lambda = [-1.2796558 -0.849129 ]\n",
            "It 18550: loss = 1.32761866e-01 lambda = [-1.280687  -0.8497012]\n",
            "It 18600: loss = 1.32736042e-01 lambda = [-1.2817181  -0.85027295]\n",
            "It 18650: loss = 1.32710263e-01 lambda = [-1.2827493 -0.8508422]\n",
            "It 18700: loss = 1.32684484e-01 lambda = [-1.2837805 -0.8514114]\n",
            "It 18750: loss = 1.32658750e-01 lambda = [-1.2848116  -0.85197943]\n",
            "It 18800: loss = 1.32633045e-01 lambda = [-1.2858428 -0.8525457]\n",
            "It 18850: loss = 1.32607341e-01 lambda = [-1.2868739 -0.8531119]\n",
            "It 18900: loss = 1.32581681e-01 lambda = [-1.2879051  -0.85367626]\n",
            "It 18950: loss = 1.32556066e-01 lambda = [-1.2889363 -0.8542395]\n",
            "It 19000: loss = 1.32530451e-01 lambda = [-1.2899674 -0.8548028]\n",
            "It 19050: loss = 1.32504895e-01 lambda = [-1.2909986 -0.8553633]\n",
            "It 19100: loss = 1.32479355e-01 lambda = [-1.2920297 -0.8559236]\n",
            "It 19150: loss = 1.32453844e-01 lambda = [-1.2930609 -0.8564832]\n",
            "It 19200: loss = 1.32428378e-01 lambda = [-1.2940907 -0.8570405]\n",
            "It 19250: loss = 1.32403001e-01 lambda = [-1.295116  -0.8575978]\n",
            "It 19300: loss = 1.32377654e-01 lambda = [-1.2961411 -0.8581536]\n",
            "It 19350: loss = 1.32352337e-01 lambda = [-1.2971663 -0.8587079]\n",
            "It 19400: loss = 1.32327050e-01 lambda = [-1.2981915 -0.8592622]\n",
            "It 19450: loss = 1.32301807e-01 lambda = [-1.2992167  -0.85981405]\n",
            "It 19500: loss = 1.32276610e-01 lambda = [-1.300242  -0.8603654]\n",
            "It 19550: loss = 1.32251441e-01 lambda = [-1.3012671  -0.86091626]\n",
            "It 19600: loss = 1.32226303e-01 lambda = [-1.3022923 -0.8614646]\n",
            "It 19650: loss = 1.32201195e-01 lambda = [-1.3033175 -0.862013 ]\n",
            "It 19700: loss = 1.32176116e-01 lambda = [-1.3043427  -0.86255985]\n",
            "It 19750: loss = 1.32151067e-01 lambda = [-1.305368   -0.86310524]\n",
            "It 19800: loss = 1.32126048e-01 lambda = [-1.3063931 -0.8636506]\n",
            "It 19850: loss = 1.32101059e-01 lambda = [-1.3074183  -0.86419344]\n",
            "It 19900: loss = 1.32076100e-01 lambda = [-1.3084435  -0.86473584]\n",
            "It 19950: loss = 1.32051140e-01 lambda = [-1.3094687 -0.8652776]\n",
            "It 20000: loss = 1.32026255e-01 lambda = [-1.310494 -0.865817]\n",
            "It 20050: loss = 1.32001370e-01 lambda = [-1.3115191  -0.86635643]\n",
            "It 20100: loss = 1.31976530e-01 lambda = [-1.3125443  -0.86689407]\n",
            "It 20150: loss = 1.31951690e-01 lambda = [-1.3135695 -0.8674305]\n",
            "It 20200: loss = 1.31926909e-01 lambda = [-1.3145947 -0.8679669]\n",
            "It 20250: loss = 1.31902128e-01 lambda = [-1.31562    -0.86850035]\n",
            "It 20300: loss = 1.31877407e-01 lambda = [-1.3166451 -0.8690338]\n",
            "It 20350: loss = 1.31852746e-01 lambda = [-1.3176672 -0.869566 ]\n",
            "It 20400: loss = 1.31828159e-01 lambda = [-1.3186865 -0.8700965]\n",
            "It 20450: loss = 1.31803602e-01 lambda = [-1.3197057 -0.870627 ]\n",
            "It 20500: loss = 1.31779075e-01 lambda = [-1.320725   -0.87115496]\n",
            "It 20550: loss = 1.31754592e-01 lambda = [-1.3217442  -0.87168247]\n",
            "It 20600: loss = 1.31730139e-01 lambda = [-1.3227634 -0.8722092]\n",
            "It 20650: loss = 1.31705731e-01 lambda = [-1.3237827 -0.8727337]\n",
            "It 20700: loss = 1.31681323e-01 lambda = [-1.3248019  -0.87325823]\n",
            "It 20750: loss = 1.31656975e-01 lambda = [-1.3258212 -0.8737807]\n",
            "It 20800: loss = 1.31632656e-01 lambda = [-1.3268404  -0.87430227]\n",
            "It 20850: loss = 1.31608352e-01 lambda = [-1.3278596  -0.87482345]\n",
            "It 20900: loss = 1.31584063e-01 lambda = [-1.3288789 -0.875342 ]\n",
            "It 20950: loss = 1.31559849e-01 lambda = [-1.3298981 -0.8758606]\n",
            "It 21000: loss = 1.31535619e-01 lambda = [-1.3309174 -0.8763774]\n",
            "It 21050: loss = 1.31511450e-01 lambda = [-1.3319366 -0.876893 ]\n",
            "It 21100: loss = 1.31487310e-01 lambda = [-1.3329558  -0.87740844]\n",
            "It 21150: loss = 1.31463200e-01 lambda = [-1.3339751  -0.87792104]\n",
            "It 21200: loss = 1.31439105e-01 lambda = [-1.3349943  -0.87843364]\n",
            "It 21250: loss = 1.31415054e-01 lambda = [-1.3360136 -0.8789447]\n",
            "It 21300: loss = 1.31391034e-01 lambda = [-1.3370328 -0.8794543]\n",
            "It 21350: loss = 1.31367058e-01 lambda = [-1.3380498  -0.87996393]\n",
            "It 21400: loss = 1.31343186e-01 lambda = [-1.339063   -0.88047063]\n",
            "It 21450: loss = 1.31319314e-01 lambda = [-1.3400763 -0.8809773]\n",
            "It 21500: loss = 1.31295487e-01 lambda = [-1.3410896  -0.88148254]\n",
            "It 21550: loss = 1.31271690e-01 lambda = [-1.3421029 -0.8819862]\n",
            "It 21600: loss = 1.31247923e-01 lambda = [-1.3431162  -0.88248986]\n",
            "It 21650: loss = 1.31224215e-01 lambda = [-1.3441294  -0.88299066]\n",
            "It 21700: loss = 1.31200522e-01 lambda = [-1.3451427  -0.88349134]\n",
            "It 21750: loss = 1.31176844e-01 lambda = [-1.346156  -0.8839907]\n",
            "It 21800: loss = 1.31153181e-01 lambda = [-1.3471693 -0.8844884]\n",
            "It 21850: loss = 1.31129563e-01 lambda = [-1.3481826 -0.8849861]\n",
            "It 21900: loss = 1.31105989e-01 lambda = [-1.3491958  -0.88548106]\n",
            "It 21950: loss = 1.31082416e-01 lambda = [-1.3502091 -0.8859758]\n",
            "It 22000: loss = 1.31058902e-01 lambda = [-1.3512224  -0.88646924]\n",
            "It 22050: loss = 1.31035417e-01 lambda = [-1.3522357 -0.886961 ]\n",
            "It 22100: loss = 1.31011933e-01 lambda = [-1.353249  -0.8874527]\n",
            "It 22150: loss = 1.30988494e-01 lambda = [-1.3542622  -0.88794166]\n",
            "It 22200: loss = 1.30965099e-01 lambda = [-1.3552755 -0.8884304]\n",
            "It 22250: loss = 1.30941719e-01 lambda = [-1.3562888  -0.88891786]\n",
            "It 22300: loss = 1.30918413e-01 lambda = [-1.3572979  -0.88940364]\n",
            "It 22350: loss = 1.30895168e-01 lambda = [-1.3583052 -0.8898894]\n",
            "It 22400: loss = 1.30871981e-01 lambda = [-1.3593125  -0.89037234]\n",
            "It 22450: loss = 1.30848780e-01 lambda = [-1.3603199  -0.89085513]\n",
            "It 22500: loss = 1.30825654e-01 lambda = [-1.3613272  -0.89133644]\n",
            "It 22550: loss = 1.30802542e-01 lambda = [-1.3623345  -0.89181626]\n",
            "It 22600: loss = 1.30779445e-01 lambda = [-1.3633418 -0.892296 ]\n",
            "It 22650: loss = 1.30756378e-01 lambda = [-1.3643491  -0.89277285]\n",
            "It 22700: loss = 1.30733341e-01 lambda = [-1.3653564 -0.8932497]\n",
            "It 22750: loss = 1.30710363e-01 lambda = [-1.3663638 -0.8937249]\n",
            "It 22800: loss = 1.30687386e-01 lambda = [-1.3673711 -0.8941988]\n",
            "It 22850: loss = 1.30664438e-01 lambda = [-1.3683784  -0.89467245]\n",
            "It 22900: loss = 1.30641535e-01 lambda = [-1.3693857  -0.89514333]\n",
            "It 22950: loss = 1.30618662e-01 lambda = [-1.370393  -0.8956142]\n",
            "It 23000: loss = 1.30595788e-01 lambda = [-1.3714004 -0.8960833]\n",
            "It 23050: loss = 1.30572975e-01 lambda = [-1.3724077 -0.8965512]\n",
            "It 23100: loss = 1.30550161e-01 lambda = [-1.373415  -0.8970187]\n",
            "It 23150: loss = 1.30527407e-01 lambda = [-1.3744212 -0.8974836]\n",
            "It 23200: loss = 1.30504742e-01 lambda = [-1.3754226 -0.8979485]\n",
            "It 23250: loss = 1.30482122e-01 lambda = [-1.376424   -0.89841145]\n",
            "It 23300: loss = 1.30459517e-01 lambda = [-1.3774253 -0.8988734]\n",
            "It 23350: loss = 1.30436942e-01 lambda = [-1.3784267 -0.8993347]\n",
            "It 23400: loss = 1.30414397e-01 lambda = [-1.379428  -0.8997937]\n",
            "It 23450: loss = 1.30391866e-01 lambda = [-1.3804294  -0.90025264]\n",
            "It 23500: loss = 1.30369365e-01 lambda = [-1.3814307 -0.9007094]\n",
            "It 23550: loss = 1.30346909e-01 lambda = [-1.3824321  -0.90116537]\n",
            "It 23600: loss = 1.30324483e-01 lambda = [-1.3834335  -0.90162045]\n",
            "It 23650: loss = 1.30302086e-01 lambda = [-1.3844348  -0.90207344]\n",
            "It 23700: loss = 1.30279690e-01 lambda = [-1.3854362  -0.90252644]\n",
            "It 23750: loss = 1.30257353e-01 lambda = [-1.3864375  -0.90297693]\n",
            "It 23800: loss = 1.30235031e-01 lambda = [-1.3874389  -0.90342695]\n",
            "It 23850: loss = 1.30212739e-01 lambda = [-1.3884403 -0.9038758]\n",
            "It 23900: loss = 1.30190492e-01 lambda = [-1.3894416  -0.90432286]\n",
            "It 23950: loss = 1.30168259e-01 lambda = [-1.390443  -0.9047699]\n",
            "It 24000: loss = 1.30146086e-01 lambda = [-1.3914417 -0.9052142]\n",
            "It 24050: loss = 1.30123988e-01 lambda = [-1.3924371  -0.90565825]\n",
            "It 24100: loss = 1.30101934e-01 lambda = [-1.3934325 -0.9061009]\n",
            "It 24150: loss = 1.30079895e-01 lambda = [-1.3944279 -0.906542 ]\n",
            "It 24200: loss = 1.30057871e-01 lambda = [-1.3954233 -0.9069831]\n",
            "Timeout is reached. Time elapsed: 100.00417304039001 seconds\n",
            "\n",
            "\n",
            "Adam\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: loss = 4.56346035e-01 lambda = [ 0.09755131 -0.0955213 ]\n",
            "It 00050: loss = 1.45564586e-01 lambda = [-0.7455477 -1.910676 ]\n",
            "It 00100: loss = 9.77107957e-02 lambda = [-3.8421402e+00  2.7924553e-03]\n",
            "It 00150: loss = 6.04401194e-02 lambda = [-4.7194324  0.4288603]\n",
            "It 00200: loss = 9.71782953e-02 lambda = [-3.6795242 -0.2517545]\n",
            "It 00250: loss = 3.63141224e-02 lambda = [-4.4202404   0.46090537]\n",
            "It 00300: loss = 3.16084214e-02 lambda = [-4.6817937   0.52365845]\n",
            "It 00350: loss = 6.99080229e-02 lambda = [-4.6766324   0.23110762]\n",
            "It 00400: loss = 1.28091246e-01 lambda = [-4.8144646   0.16661903]\n",
            "It 00450: loss = 3.45828496e-02 lambda = [-4.754606   0.4491696]\n",
            "It 00500: loss = 9.01752189e-02 lambda = [-4.463175    0.13236941]\n",
            "It 00550: loss = 9.63665098e-02 lambda = [-4.551827    0.32668254]\n",
            "It 00600: loss = 7.74962083e-02 lambda = [-4.707782    0.42245156]\n",
            "It 00650: loss = 3.45207751e-02 lambda = [-4.8572125   0.51464343]\n",
            "It 00700: loss = 1.66919045e-02 lambda = [-4.985558    0.58014107]\n",
            "It 00750: loss = 7.67799653e-03 lambda = [-5.1135736   0.64921945]\n",
            "It 00800: loss = 5.21866512e-03 lambda = [-5.212075   0.6925873]\n",
            "It 00850: loss = 6.80281781e-03 lambda = [-5.2832756   0.71541935]\n",
            "It 00900: loss = 5.34972642e-03 lambda = [-5.3479767  0.7412217]\n",
            "It 00950: loss = 1.15376953e-02 lambda = [-5.401701    0.76126885]\n",
            "It 01000: loss = 6.65171305e-03 lambda = [-5.4703374   0.79625577]\n",
            "It 01050: loss = 1.25228148e-03 lambda = [-5.51221    0.8132744]\n",
            "It 01100: loss = 3.78519483e-03 lambda = [-5.54543    0.8220521]\n",
            "It 01150: loss = 8.11152277e-04 lambda = [-5.5931106   0.84426033]\n",
            "It 01200: loss = 2.29093572e-03 lambda = [-5.6232486  0.855279 ]\n",
            "It 01250: loss = 7.30109401e-04 lambda = [-5.658804    0.87043685]\n",
            "It 01300: loss = 4.17139963e-04 lambda = [-5.6876006  0.8812349]\n",
            "It 01350: loss = 4.17457253e-04 lambda = [-5.7116623  0.8911027]\n",
            "It 01400: loss = 2.56256026e-04 lambda = [-5.73729    0.9002613]\n",
            "It 01450: loss = 4.91362647e-04 lambda = [-5.7582     0.9073287]\n",
            "It 01500: loss = 1.74709770e-04 lambda = [-5.778148   0.9155899]\n",
            "It 01550: loss = 5.53252990e-04 lambda = [-5.7955675  0.921519 ]\n",
            "It 01600: loss = 1.43495097e-04 lambda = [-5.811552   0.9280301]\n",
            "It 01650: loss = 1.11064299e-04 lambda = [-5.826022    0.93339187]\n",
            "It 01700: loss = 9.52716582e-05 lambda = [-5.839134    0.93830365]\n",
            "It 01750: loss = 8.31356447e-05 lambda = [-5.8510365   0.94279855]\n",
            "It 01800: loss = 7.37237351e-05 lambda = [-5.86189    0.9468982]\n",
            "It 01850: loss = 6.58250501e-05 lambda = [-5.871795    0.95065355]\n",
            "It 01900: loss = 5.91440839e-05 lambda = [-5.8808537   0.95409733]\n",
            "It 01950: loss = 5.34576902e-05 lambda = [-5.88915    0.9572596]\n",
            "It 02000: loss = 4.85885139e-05 lambda = [-5.8967633   0.96016663]\n",
            "It 02050: loss = 4.44018442e-05 lambda = [-5.903751    0.96284175]\n",
            "It 02100: loss = 4.07806037e-05 lambda = [-5.910178   0.9653056]\n",
            "It 02150: loss = 3.76373282e-05 lambda = [-5.916099    0.96757764]\n",
            "It 02200: loss = 3.48967915e-05 lambda = [-5.921557    0.96967506]\n",
            "It 02250: loss = 3.24960129e-05 lambda = [-5.9265933   0.97161275]\n",
            "It 02300: loss = 3.03887628e-05 lambda = [-5.931245    0.97340465]\n",
            "It 02350: loss = 2.85305905e-05 lambda = [-5.935548    0.97506315]\n",
            "It 02400: loss = 2.68845270e-05 lambda = [-5.9395285  0.9765993]\n",
            "It 02450: loss = 2.54227725e-05 lambda = [-5.943217   0.9780236]\n",
            "It 02500: loss = 2.41210982e-05 lambda = [-5.9466357   0.97934496]\n",
            "It 02550: loss = 2.29590714e-05 lambda = [-5.9498105  0.9805718]\n",
            "It 02600: loss = 2.19150133e-05 lambda = [-5.952758   0.9817123]\n",
            "It 02650: loss = 2.09757127e-05 lambda = [-5.9554973  0.9827727]\n",
            "It 02700: loss = 2.01290932e-05 lambda = [-5.9580455   0.98375976]\n",
            "It 02750: loss = 1.93604938e-05 lambda = [-5.9604177  0.9846793]\n",
            "It 02800: loss = 1.86638918e-05 lambda = [-5.9626284  0.9855362]\n",
            "It 02850: loss = 1.80297884e-05 lambda = [-5.9646897   0.98633564]\n",
            "It 02900: loss = 1.74506022e-05 lambda = [-5.9666123  0.9870816]\n",
            "It 02950: loss = 1.69187933e-05 lambda = [-5.96841     0.98777866]\n",
            "It 03000: loss = 1.64310877e-05 lambda = [-5.970089    0.98843044]\n",
            "It 03050: loss = 1.61938951e-05 lambda = [-5.9708996   0.98874384]\n",
            "It 03100: loss = 1.59637311e-05 lambda = [-5.97171     0.98905677]\n",
            "It 03150: loss = 1.57382474e-05 lambda = [-5.9725103  0.9893682]\n",
            "It 03200: loss = 1.55146554e-05 lambda = [-5.973297   0.9896778]\n",
            "It 03250: loss = 1.52923913e-05 lambda = [-5.974084    0.98998487]\n",
            "It 03300: loss = 1.50740125e-05 lambda = [-5.9748707  0.9902896]\n",
            "It 03350: loss = 1.48576592e-05 lambda = [-5.9756575   0.99059314]\n",
            "It 03400: loss = 1.46444090e-05 lambda = [-5.9764333  0.9908945]\n",
            "It 03450: loss = 1.44347068e-05 lambda = [-5.977196   0.9911929]\n",
            "It 03500: loss = 1.42269437e-05 lambda = [-5.977959    0.99148834]\n",
            "It 03550: loss = 1.40223092e-05 lambda = [-5.9787154  0.991781 ]\n",
            "It 03600: loss = 1.38204150e-05 lambda = [-5.9794545   0.99207044]\n",
            "It 03650: loss = 1.36221306e-05 lambda = [-5.9801936   0.99235606]\n",
            "It 03700: loss = 1.34259080e-05 lambda = [-5.9809165   0.99263823]\n",
            "It 03750: loss = 1.32329960e-05 lambda = [-5.9816318  0.9929162]\n",
            "It 03800: loss = 1.30425424e-05 lambda = [-5.982336    0.99319005]\n",
            "It 03850: loss = 1.28559877e-05 lambda = [-5.9830275   0.99345934]\n",
            "It 03900: loss = 1.26717377e-05 lambda = [-5.98371    0.9937239]\n",
            "It 03950: loss = 1.24895441e-05 lambda = [-5.9843774  0.9939839]\n",
            "It 04000: loss = 1.23110131e-05 lambda = [-5.9850335  0.9942391]\n",
            "It 04050: loss = 1.21358244e-05 lambda = [-5.9856772   0.99448895]\n",
            "It 04100: loss = 1.19614606e-05 lambda = [-5.9863048   0.99473387]\n",
            "It 04150: loss = 1.17912023e-05 lambda = [-5.9869237   0.99497306]\n",
            "It 04200: loss = 1.16230967e-05 lambda = [-5.9875207   0.99520695]\n",
            "It 04250: loss = 1.14569466e-05 lambda = [-5.988109   0.9954352]\n",
            "It 04300: loss = 1.12937996e-05 lambda = [-5.9886813  0.9956575]\n",
            "It 04350: loss = 1.11331265e-05 lambda = [-5.9892354   0.99587417]\n",
            "It 04400: loss = 1.09737639e-05 lambda = [-5.9897795   0.99608445]\n",
            "It 04450: loss = 1.08172580e-05 lambda = [-5.990304    0.99628884]\n",
            "It 04500: loss = 1.06625366e-05 lambda = [-5.990812  0.996487]\n",
            "It 04550: loss = 1.05107802e-05 lambda = [-5.9913073   0.99667907]\n",
            "It 04600: loss = 1.03609318e-05 lambda = [-5.9917846  0.9968651]\n",
            "It 04650: loss = 1.35044793e-05 lambda = [-5.9922123   0.99707454]\n",
            "It 04700: loss = 6.44564134e-05 lambda = [-5.9918933   0.99730635]\n",
            "It 04750: loss = 1.02581607e-05 lambda = [-5.9926834  0.9973793]\n",
            "It 04800: loss = 1.00054140e-05 lambda = [-5.9931746   0.99747294]\n",
            "It 04850: loss = 9.86330906e-06 lambda = [-5.993586   0.9975981]\n",
            "It 04900: loss = 1.28141201e-05 lambda = [-5.9939995   0.99769896]\n",
            "It 04950: loss = 8.71560478e-05 lambda = [-5.993302    0.99784034]\n",
            "It 05000: loss = 9.89134060e-06 lambda = [-5.9939866  0.9979864]\n",
            "It 05050: loss = 9.70765996e-06 lambda = [-5.9944415  0.998011 ]\n",
            "It 05100: loss = 9.56383428e-06 lambda = [-5.9947853   0.99808955]\n",
            "It 05150: loss = 9.42654333e-06 lambda = [-5.995095    0.99818677]\n",
            "It 05200: loss = 9.29314319e-06 lambda = [-5.995383   0.9982895]\n",
            "It 05250: loss = 4.14291717e-05 lambda = [-5.9946194  0.9980193]\n",
            "It 05300: loss = 1.19140668e-05 lambda = [-5.995395    0.99859494]\n",
            "It 05350: loss = 9.19835020e-06 lambda = [-5.9958153   0.99854964]\n",
            "It 05400: loss = 9.05138313e-06 lambda = [-5.9961023  0.9985961]\n",
            "It 05450: loss = 8.92405205e-06 lambda = [-5.996354   0.9986686]\n",
            "It 05500: loss = 1.83180528e-05 lambda = [-5.995638   0.9981739]\n",
            "It 05550: loss = 9.50297454e-06 lambda = [-5.996253  0.998898]\n",
            "It 05600: loss = 8.88667091e-06 lambda = [-5.9966326   0.99885315]\n",
            "It 05650: loss = 8.73694444e-06 lambda = [-5.9968696   0.99888885]\n",
            "It 05700: loss = 8.61122044e-06 lambda = [-5.9970775  0.998949 ]\n",
            "It 05750: loss = 1.32696892e-04 lambda = [-5.9963326   0.99856246]\n",
            "It 05800: loss = 9.36330707e-06 lambda = [-5.9970255  0.9991218]\n",
            "It 05850: loss = 8.54896280e-06 lambda = [-5.997322   0.9991039]\n",
            "It 05900: loss = 8.39593940e-06 lambda = [-5.997526   0.9991309]\n",
            "It 05950: loss = 2.44618786e-05 lambda = [-5.9977865   0.99909866]\n",
            "It 06000: loss = 5.55418301e-05 lambda = [-5.99708     0.99952996]\n",
            "It 06050: loss = 8.69314408e-06 lambda = [-5.9976125  0.9992999]\n",
            "It 06100: loss = 8.23666051e-06 lambda = [-5.997849   0.9992759]\n",
            "It 06150: loss = 8.10435904e-06 lambda = [-5.9980164  0.9993059]\n",
            "It 06200: loss = 2.34113977e-04 lambda = [-5.99847    0.9990345]\n",
            "It 06250: loss = 8.89795137e-06 lambda = [-5.9978023  0.9995604]\n",
            "It 06300: loss = 8.25267671e-06 lambda = [-5.9980907  0.9994452]\n",
            "It 06350: loss = 7.93768959e-06 lambda = [-5.9982824   0.99942315]\n",
            "It 06400: loss = 7.80817845e-06 lambda = [-5.998424   0.9994499]\n",
            "It 06450: loss = 3.96070362e-04 lambda = [-5.9972095  0.9994234]\n",
            "It 06500: loss = 8.20228524e-06 lambda = [-5.9982314  0.9995944]\n",
            "It 06550: loss = 7.79248148e-06 lambda = [-5.9984765   0.99953026]\n",
            "It 06600: loss = 7.65312325e-06 lambda = [-5.998621    0.99952865]\n",
            "It 06650: loss = 1.90466653e-05 lambda = [-5.998757   0.9995366]\n",
            "It 06700: loss = 3.59096302e-05 lambda = [-5.9984074  0.999622 ]\n",
            "It 06750: loss = 7.88073521e-06 lambda = [-5.9987016  0.9995823]\n",
            "It 06800: loss = 1.00003253e-05 lambda = [-5.9982195  0.9994686]\n",
            "It 06850: loss = 8.01928672e-06 lambda = [-5.9987125  0.9996174]\n",
            "It 06900: loss = 1.75265450e-05 lambda = [-5.998804   0.9996769]\n",
            "It 06950: loss = 1.52841967e-05 lambda = [-5.9985805  0.9997459]\n",
            "It 07000: loss = 7.57940006e-06 lambda = [-5.998856   0.9996443]\n",
            "It 07050: loss = 7.19269156e-06 lambda = [-5.9989176   0.99964285]\n",
            "It 07100: loss = 7.12806514e-06 lambda = [-5.9989753   0.99964356]\n",
            "It 07150: loss = 7.06415904e-06 lambda = [-5.999023   0.9996509]\n",
            "It 07200: loss = 7.00267356e-06 lambda = [-5.9990706   0.99966145]\n",
            "It 07250: loss = 6.94090977e-06 lambda = [-5.9991183  0.9996743]\n",
            "It 07300: loss = 6.87895863e-06 lambda = [-5.999166    0.99968857]\n",
            "It 07350: loss = 6.81837491e-06 lambda = [-5.9992137  0.9997042]\n",
            "It 07400: loss = 6.75768888e-06 lambda = [-5.9992614  0.9997198]\n",
            "It 07450: loss = 6.69748943e-06 lambda = [-5.999309    0.99973613]\n",
            "It 07500: loss = 6.63715491e-06 lambda = [-5.9993567  0.999753 ]\n",
            "It 07550: loss = 6.57611918e-06 lambda = [-5.9994044   0.99976975]\n",
            "It 07600: loss = 6.51619303e-06 lambda = [-5.999452    0.99978685]\n",
            "It 07650: loss = 6.45578803e-06 lambda = [-5.9995      0.99980426]\n",
            "It 07700: loss = 6.39545669e-06 lambda = [-5.9995475  0.9998214]\n",
            "It 07750: loss = 6.33490117e-06 lambda = [-5.999595    0.99983877]\n",
            "It 07800: loss = 6.27411146e-06 lambda = [-5.999643    0.99985623]\n",
            "It 07850: loss = 6.21363870e-06 lambda = [-5.999687    0.99987346]\n",
            "It 07900: loss = 6.15302315e-06 lambda = [-5.9997272   0.99988955]\n",
            "It 07950: loss = 6.09239214e-06 lambda = [-5.9997625   0.99990517]\n",
            "It 08000: loss = 6.03103581e-06 lambda = [-5.999798    0.99991935]\n",
            "It 08050: loss = 5.96978907e-06 lambda = [-5.9998307  0.9999329]\n",
            "It 08100: loss = 5.90851596e-06 lambda = [-5.9998627  0.999946 ]\n",
            "It 08150: loss = 5.84713052e-06 lambda = [-5.999894    0.99995846]\n",
            "It 08200: loss = 5.78579557e-06 lambda = [-5.999928    0.99997056]\n",
            "It 08250: loss = 5.72422596e-06 lambda = [-5.999955   0.9999824]\n",
            "It 08300: loss = 5.66272593e-06 lambda = [-5.999984   0.9999934]\n",
            "It 08350: loss = 5.59995533e-06 lambda = [-6.0000134  1.0000045]\n",
            "It 08400: loss = 5.54956705e-06 lambda = [-6.0000453  1.0000138]\n",
            "It 08450: loss = 6.17653086e-06 lambda = [-5.9999022  0.9999179]\n",
            "It 08500: loss = 5.58054717e-06 lambda = [-5.999983   1.0000305]\n",
            "It 08550: loss = 5.43507394e-06 lambda = [-6.000027   1.0000244]\n",
            "It 08600: loss = 1.39648055e-05 lambda = [-6.000045    0.99998367]\n",
            "It 08650: loss = 5.50944242e-06 lambda = [-6.0000753  1.0000136]\n",
            "It 08700: loss = 2.98337945e-05 lambda = [-5.999998   0.9999587]\n",
            "It 08750: loss = 5.31895603e-06 lambda = [-6.000013   1.0000434]\n",
            "It 08800: loss = 5.19871810e-06 lambda = [-6.0000625  1.0000328]\n",
            "It 08850: loss = 5.65542859e-06 lambda = [-6.0001073  1.0000218]\n",
            "It 08900: loss = 1.20627183e-05 lambda = [-5.9999223  1.0000889]\n",
            "It 08950: loss = 5.22373830e-06 lambda = [-6.0000205  1.0000502]\n",
            "It 09000: loss = 6.92916001e-05 lambda = [-6.000068    0.99999934]\n",
            "It 09050: loss = 5.47319178e-06 lambda = [-6.000085   1.0000257]\n",
            "It 09100: loss = 3.17130725e-05 lambda = [-5.999996   1.0001434]\n",
            "It 09150: loss = 1.14345248e-05 lambda = [-5.999962   1.0001172]\n",
            "It 09200: loss = 4.88993146e-06 lambda = [-6.0000625  1.0000408]\n",
            "It 09250: loss = 4.83332951e-06 lambda = [-6.0000978  1.0000378]\n",
            "It 09300: loss = 1.40809803e-04 lambda = [-6.000186   0.9999555]\n",
            "It 09350: loss = 4.99748830e-06 lambda = [-6.0000186  1.0000757]\n",
            "It 09400: loss = 4.78812490e-06 lambda = [-6.0000796  1.0000437]\n",
            "It 09450: loss = 3.36876183e-05 lambda = [-6.0002255   0.99992764]\n",
            "It 09500: loss = 4.69012457e-06 lambda = [-6.000037   1.0000677]\n",
            "It 09550: loss = 4.67062819e-06 lambda = [-6.0000772  1.0000466]\n",
            "It 09600: loss = 4.59394278e-06 lambda = [-6.0001106  1.0000414]\n",
            "It 09650: loss = 4.35010988e-05 lambda = [-6.0000486  0.9998855]\n",
            "It 09700: loss = 4.92586469e-06 lambda = [-6.000032   1.0000552]\n",
            "It 09750: loss = 2.89963900e-05 lambda = [-6.000084   1.0000335]\n",
            "It 09800: loss = 4.44623856e-06 lambda = [-6.0001054  1.0000287]\n",
            "It 09850: loss = 1.75574169e-04 lambda = [-6.000095   0.9997855]\n",
            "It 09900: loss = 4.41122893e-06 lambda = [-6.000033   1.0000404]\n",
            "It 09950: loss = 4.35923994e-06 lambda = [-6.0000772  1.000032 ]\n",
            "It 10000: loss = 4.30349564e-06 lambda = [-6.000109   1.0000304]\n",
            "It 10050: loss = 2.13025705e-04 lambda = [-6.000119    0.99974024]\n",
            "It 10100: loss = 4.65321955e-06 lambda = [-6.000023   1.0000408]\n",
            "It 10150: loss = 4.22422909e-06 lambda = [-6.000083   1.0000229]\n",
            "It 10200: loss = 4.28608928e-06 lambda = [-6.0001054  1.0000342]\n",
            "It 10250: loss = 4.74278477e-06 lambda = [-5.999975   0.9999964]\n",
            "It 10300: loss = 4.19036178e-06 lambda = [-6.0000224  1.0000272]\n",
            "It 10350: loss = 4.11291285e-06 lambda = [-6.000067   1.0000157]\n",
            "It 10400: loss = 4.06767958e-06 lambda = [-6.000093   1.0000175]\n",
            "It 10450: loss = 3.61118982e-05 lambda = [-6.000243   0.9998946]\n",
            "It 10500: loss = 1.14571931e-05 lambda = [-5.9999356  1.0000684]\n",
            "It 10550: loss = 4.03562080e-06 lambda = [-5.9999957  1.0000145]\n",
            "It 10600: loss = 3.98823295e-06 lambda = [-6.0000334  1.000001 ]\n",
            "It 10650: loss = 5.79874495e-06 lambda = [-6.0000377   0.99994713]\n",
            "It 10700: loss = 3.92560332e-06 lambda = [-6.00007     0.99999934]\n",
            "It 10750: loss = 1.25421775e-05 lambda = [-6.0000305  1.0000736]\n",
            "It 10800: loss = 1.08280010e-05 lambda = [-5.999913   1.0001084]\n",
            "It 10850: loss = 3.85818475e-06 lambda = [-6.0000296  1.0000083]\n",
            "It 10900: loss = 3.80614733e-06 lambda = [-6.0000625  1.0000035]\n",
            "It 10950: loss = 1.74102806e-05 lambda = [-6.0000224  1.0000049]\n",
            "It 11000: loss = 1.16435367e-05 lambda = [-6.0000606  0.9999801]\n",
            "It 11050: loss = 3.77051219e-06 lambda = [-6.0000663  1.0000069]\n",
            "It 11100: loss = 7.22127152e-06 lambda = [-5.9998636  1.0000044]\n",
            "It 11150: loss = 3.99816463e-06 lambda = [-5.9999948  1.0000147]\n",
            "It 11200: loss = 3.66347467e-06 lambda = [-6.0000496  0.9999978]\n",
            "It 11250: loss = 4.24176869e-06 lambda = [-6.0000587  1.0000175]\n",
            "It 11300: loss = 7.32841727e-06 lambda = [-5.999907   1.0000587]\n",
            "It 11350: loss = 3.73218199e-06 lambda = [-5.9999943  1.0000005]\n",
            "It 11400: loss = 9.83918835e-06 lambda = [-6.0000324   0.99994475]\n",
            "It 11450: loss = 3.59982278e-06 lambda = [-6.0000496  0.9999855]\n",
            "It 11500: loss = 1.55906135e-04 lambda = [-5.9998026  1.0002481]\n",
            "It 11550: loss = 6.46871831e-06 lambda = [-5.999987   0.9999855]\n",
            "It 11600: loss = 3.49740117e-06 lambda = [-6.0000134   0.99998754]\n",
            "It 11650: loss = 5.35162735e-06 lambda = [-6.0000334  1.0000029]\n",
            "It 11700: loss = 4.66760503e-06 lambda = [-6.0000067  1.0000238]\n",
            "It 11750: loss = 3.84129271e-06 lambda = [-6.0000443  1.0000113]\n",
            "It 11800: loss = 8.78739684e-06 lambda = [-6.000018   0.9999433]\n",
            "It 11850: loss = 3.39221515e-06 lambda = [-6.0000277  1.0000007]\n",
            "It 11900: loss = 6.91016794e-06 lambda = [-6.0001054   0.99995536]\n",
            "It 11950: loss = 8.62880370e-06 lambda = [-5.9999127  1.0000825]\n",
            "It 12000: loss = 3.33732487e-06 lambda = [-6.000016   0.9999949]\n",
            "It 12050: loss = 3.44630325e-06 lambda = [-6.00005    0.9999888]\n",
            "It 12100: loss = 2.44412920e-04 lambda = [-5.999768   1.0001748]\n",
            "It 12150: loss = 4.04590219e-06 lambda = [-5.9999766  1.0000222]\n",
            "It 12200: loss = 3.29880913e-06 lambda = [-6.00005    0.9999865]\n",
            "It 12250: loss = 1.99548340e-05 lambda = [-6.000016   0.9998322]\n",
            "It 12300: loss = 3.75317654e-06 lambda = [-6.000009   0.9999812]\n",
            "It 12350: loss = 3.20173103e-06 lambda = [-6.0000443   0.99998444]\n",
            "It 12400: loss = 3.90216097e-04 lambda = [-6.0002437   0.99968624]\n",
            "It 12450: loss = 3.74816773e-06 lambda = [-5.999964   1.0000148]\n",
            "It 12500: loss = 9.28145164e-06 lambda = [-6.0000124  0.999964 ]\n",
            "It 12550: loss = 3.18513821e-06 lambda = [-6.0000486   0.99997944]\n",
            "It 12600: loss = 5.02473558e-04 lambda = [-6.0004272  0.999564 ]\n",
            "It 12650: loss = 3.15623720e-06 lambda = [-5.99997    0.9999861]\n",
            "It 12700: loss = 3.11775034e-06 lambda = [-6.000016   0.9999768]\n",
            "It 12750: loss = 1.91042109e-05 lambda = [-5.9999666  1.0000024]\n",
            "It 12800: loss = 3.22378128e-06 lambda = [-6.000071   0.9999835]\n",
            "It 12850: loss = 1.58643725e-05 lambda = [-5.9998717  1.0000881]\n",
            "It 12900: loss = 3.22334995e-06 lambda = [-6.0000405   0.99999374]\n",
            "It 12950: loss = 3.03830961e-06 lambda = [-6.000083   0.9999884]\n",
            "It 13000: loss = 3.11252079e-05 lambda = [-5.9999313  0.9999443]\n",
            "It 13050: loss = 3.12954808e-06 lambda = [-6.000024   0.9999803]\n",
            "It 13100: loss = 3.75135187e-06 lambda = [-6.00009    0.9999718]\n",
            "It 13150: loss = 3.19439846e-06 lambda = [-5.9999614  1.000086 ]\n",
            "It 13200: loss = 2.98429040e-06 lambda = [-6.000051   1.0000091]\n",
            "It 13250: loss = 2.93213043e-06 lambda = [-6.000097   0.9999954]\n",
            "It 13300: loss = 3.46065208e-04 lambda = [-6.0002246   0.99974453]\n",
            "It 13350: loss = 5.05587514e-06 lambda = [-6.0000243   0.99999195]\n",
            "It 13400: loss = 2.90433331e-06 lambda = [-6.0000606   0.99999094]\n",
            "It 13450: loss = 2.09752652e-05 lambda = [-6.0000443   0.99996245]\n",
            "It 13500: loss = 5.72553836e-06 lambda = [-6.0001445  0.9999633]\n",
            "It 13550: loss = 1.25062888e-05 lambda = [-6.000077  0.999995]\n",
            "It 13600: loss = 2.92642903e-06 lambda = [-6.0000854  1.0000122]\n",
            "It 13650: loss = 5.70573047e-06 lambda = [-6.0001636   0.99996823]\n",
            "It 13700: loss = 7.18997444e-06 lambda = [-5.999978   1.0000978]\n",
            "It 13750: loss = 2.80513359e-06 lambda = [-6.0000806  1.0000091]\n",
            "It 13800: loss = 6.71322196e-05 lambda = [-6.0000596  1.000009 ]\n",
            "It 13850: loss = 4.90820967e-05 lambda = [-6.0002728   0.99985623]\n",
            "It 13900: loss = 5.15737565e-06 lambda = [-6.000041   1.0000547]\n",
            "It 13950: loss = 2.79136657e-06 lambda = [-6.0001144  1.0000067]\n",
            "It 14000: loss = 6.24025597e-06 lambda = [-6.000106   1.0000496]\n",
            "It 14050: loss = 2.74130889e-06 lambda = [-6.0001597  1.0000123]\n",
            "It 14100: loss = 2.69890734e-06 lambda = [-6.0001717  1.0000157]\n",
            "It 14150: loss = 2.68526628e-06 lambda = [-6.000183   1.0000196]\n",
            "It 14200: loss = 2.67225550e-06 lambda = [-6.0001917  1.0000235]\n",
            "It 14250: loss = 2.65868835e-06 lambda = [-6.0002     1.0000268]\n",
            "It 14300: loss = 2.64524647e-06 lambda = [-6.000209  1.00003 ]\n",
            "It 14350: loss = 2.63190213e-06 lambda = [-6.000217   1.0000333]\n",
            "It 14400: loss = 2.61844298e-06 lambda = [-6.000224  1.000036]\n",
            "It 14450: loss = 2.60441948e-06 lambda = [-6.00023   1.000039]\n",
            "It 14500: loss = 2.59097396e-06 lambda = [-6.000238   1.0000421]\n",
            "It 14550: loss = 2.57688794e-06 lambda = [-6.000246  1.000045]\n",
            "It 14600: loss = 2.56311091e-06 lambda = [-6.0002537  1.000048 ]\n",
            "It 14650: loss = 2.54872793e-06 lambda = [-6.000261   1.0000509]\n",
            "It 14700: loss = 2.53468625e-06 lambda = [-6.0002675  1.0000541]\n",
            "It 14750: loss = 2.51980669e-06 lambda = [-6.0002756  1.0000578]\n",
            "It 14800: loss = 2.50495577e-06 lambda = [-6.000284   1.0000604]\n",
            "It 14850: loss = 2.49043251e-06 lambda = [-6.0002933  1.0000638]\n",
            "It 14900: loss = 2.47544608e-06 lambda = [-6.0003014  1.0000666]\n",
            "It 14950: loss = 2.46060881e-06 lambda = [-6.00031    1.0000702]\n",
            "It 15000: loss = 2.44526404e-06 lambda = [-6.000319   1.0000736]\n",
            "It 15050: loss = 2.42978263e-06 lambda = [-6.0003233  1.0000767]\n",
            "It 15100: loss = 2.41420594e-06 lambda = [-6.0003285  1.0000793]\n",
            "It 15150: loss = 2.39875908e-06 lambda = [-6.0003357  1.0000817]\n",
            "It 15200: loss = 2.38292773e-06 lambda = [-6.000342   1.0000848]\n",
            "It 15250: loss = 2.36693563e-06 lambda = [-6.0003505  1.0000874]\n",
            "It 15300: loss = 2.35090806e-06 lambda = [-6.000356  1.00009 ]\n",
            "It 15350: loss = 2.33555488e-06 lambda = [-6.0003657  1.0000936]\n",
            "It 15400: loss = 5.36834204e-06 lambda = [-6.0003457  1.0000478]\n",
            "It 15450: loss = 2.41880866e-06 lambda = [-6.0003386  1.0000975]\n",
            "It 15500: loss = 2.30585533e-06 lambda = [-6.0003543  1.0000925]\n",
            "It 15550: loss = 2.28912722e-06 lambda = [-6.0003643  1.0000929]\n",
            "It 15600: loss = 3.72052928e-05 lambda = [-6.000265   1.0001345]\n",
            "It 15650: loss = 2.45605838e-06 lambda = [-6.0003457  1.0000997]\n",
            "It 15700: loss = 2.25455005e-06 lambda = [-6.000366   1.0000951]\n",
            "It 15750: loss = 7.23666199e-06 lambda = [-6.000363   1.0000618]\n",
            "It 15800: loss = 2.65035715e-06 lambda = [-6.0003324  1.0001123]\n",
            "It 15850: loss = 2.22497624e-06 lambda = [-6.000357   1.0000952]\n",
            "It 15900: loss = 2.20763877e-06 lambda = [-6.0003676  1.0000936]\n",
            "It 15950: loss = 5.44433969e-05 lambda = [-6.0002017  1.000204 ]\n",
            "It 16000: loss = 2.21584742e-06 lambda = [-6.000334   1.0001053]\n",
            "It 16050: loss = 1.67687831e-05 lambda = [-6.000346   1.0000994]\n",
            "It 16100: loss = 2.17748720e-06 lambda = [-6.0003614  1.0000942]\n",
            "It 16150: loss = 3.78297727e-06 lambda = [-6.0003977  1.0000682]\n",
            "It 16200: loss = 2.22005247e-06 lambda = [-6.0003524  1.000093 ]\n",
            "It 16250: loss = 2.14375814e-06 lambda = [-6.000351   1.0000932]\n",
            "It 16300: loss = 2.12111217e-06 lambda = [-6.0003614  1.0000926]\n",
            "It 16350: loss = 7.31753744e-06 lambda = [-6.0003333  1.0001203]\n",
            "It 16400: loss = 3.52680672e-06 lambda = [-6.0003386  1.0001225]\n",
            "It 16450: loss = 2.11289125e-06 lambda = [-6.0003686  1.0000668]\n",
            "It 16500: loss = 2.33994388e-06 lambda = [-6.000367   1.0000904]\n",
            "It 16550: loss = 1.66284026e-05 lambda = [-6.0002913  1.0001744]\n",
            "It 16600: loss = 2.57986449e-06 lambda = [-6.0003667  1.0000879]\n",
            "It 16650: loss = 2.04828871e-06 lambda = [-6.0003633  1.0000951]\n",
            "It 16700: loss = 4.70151317e-05 lambda = [-6.000452   0.9999791]\n",
            "It 16750: loss = 2.35949665e-06 lambda = [-6.0003657  1.0000869]\n",
            "It 16800: loss = 7.02044708e-05 lambda = [-6.0002174  1.0002291]\n",
            "It 16850: loss = 2.20972538e-06 lambda = [-6.0003576  1.000095 ]\n",
            "It 16900: loss = 2.03092645e-06 lambda = [-6.0003633  1.000099 ]\n",
            "It 16950: loss = 3.59288038e-06 lambda = [-6.0003333  1.0000983]\n",
            "It 17000: loss = 2.05492324e-06 lambda = [-6.0003486  1.0000995]\n",
            "It 17050: loss = 5.25016094e-06 lambda = [-6.000371   1.0000696]\n",
            "It 17100: loss = 2.97910137e-05 lambda = [-6.000405   1.0000265]\n",
            "It 17150: loss = 2.08468077e-06 lambda = [-6.0003476  1.0000997]\n",
            "It 17200: loss = 2.04621870e-06 lambda = [-6.000358   1.0000997]\n",
            "It 17250: loss = 2.78143398e-06 lambda = [-6.000337   1.0001028]\n",
            "It 17300: loss = 1.96840278e-06 lambda = [-6.0003576  1.0000902]\n",
            "It 17350: loss = 2.60504057e-05 lambda = [-6.000374   1.0000764]\n",
            "It 17400: loss = 9.62459580e-06 lambda = [-6.0002995  1.0001377]\n",
            "It 17450: loss = 4.02149226e-06 lambda = [-6.000333   1.0001221]\n",
            "It 17500: loss = 2.25519557e-06 lambda = [-6.0003667  1.0000855]\n",
            "It 17550: loss = 1.45716667e-05 lambda = [-6.00029    1.0001637]\n",
            "It 17600: loss = 2.30192973e-06 lambda = [-6.0003366  1.0001098]\n",
            "It 17650: loss = 1.52996236e-05 lambda = [-6.000361  1.000082]\n",
            "It 17700: loss = 7.92393257e-06 lambda = [-6.000381   1.0000396]\n",
            "It 17750: loss = 1.86762679e-06 lambda = [-6.000346   1.0000956]\n",
            "It 17800: loss = 3.27747375e-06 lambda = [-6.0003858  1.0000658]\n",
            "It 17850: loss = 2.00996601e-06 lambda = [-6.0003347  1.0001023]\n",
            "It 17900: loss = 1.82720714e-06 lambda = [-6.000348   1.0000898]\n",
            "It 17950: loss = 2.11120732e-05 lambda = [-6.000357   1.0000885]\n",
            "It 18000: loss = 1.21069870e-05 lambda = [-6.000254   1.0001488]\n",
            "It 18050: loss = 1.81910343e-06 lambda = [-6.000336   1.0000931]\n",
            "It 18100: loss = 1.79304834e-06 lambda = [-6.0003533  1.0000862]\n",
            "It 18150: loss = 1.03916218e-05 lambda = [-6.0003023  1.000082 ]\n",
            "It 18200: loss = 1.78133087e-06 lambda = [-6.0003266  1.0000912]\n",
            "It 18250: loss = 1.76989965e-06 lambda = [-6.0003433  1.0000832]\n",
            "It 18300: loss = 1.15937219e-05 lambda = [-6.0003586  1.0000757]\n",
            "It 18350: loss = 1.77799791e-06 lambda = [-6.000343   1.0000793]\n",
            "It 18400: loss = 2.37941822e-05 lambda = [-6.000251   1.0001794]\n",
            "It 18450: loss = 1.91558365e-06 lambda = [-6.0003304  1.0000933]\n",
            "It 18500: loss = 1.77174843e-06 lambda = [-6.0003476  1.0000803]\n",
            "It 18550: loss = 6.10445340e-06 lambda = [-6.0002675  1.0001336]\n",
            "It 18600: loss = 1.71816509e-06 lambda = [-6.0003276  1.0000839]\n",
            "It 18650: loss = 1.71281738e-06 lambda = [-6.000339   1.0000805]\n",
            "It 18700: loss = 3.88744193e-05 lambda = [-6.000461   0.9999517]\n",
            "It 18750: loss = 1.98811244e-06 lambda = [-6.0003304  1.0000737]\n",
            "It 18800: loss = 1.68877239e-06 lambda = [-6.000329   1.0000784]\n",
            "It 18850: loss = 1.70295380e-06 lambda = [-6.00034    1.0000744]\n",
            "It 18900: loss = 2.14050283e-06 lambda = [-6.000279   1.0001048]\n",
            "It 18950: loss = 1.69305122e-06 lambda = [-6.0003114  1.0000765]\n",
            "It 19000: loss = 1.66146185e-06 lambda = [-6.000321   1.0000731]\n",
            "It 19050: loss = 1.66851100e-06 lambda = [-6.000327  1.000073]\n",
            "It 19100: loss = 3.44552063e-05 lambda = [-6.0002227  1.000161 ]\n",
            "It 19150: loss = 2.13678436e-06 lambda = [-6.000331  1.000064]\n",
            "It 19200: loss = 4.82732867e-06 lambda = [-6.0002847  1.0000827]\n",
            "It 19250: loss = 1.67488133e-06 lambda = [-6.000318   1.0000697]\n",
            "It 19300: loss = 2.70622763e-06 lambda = [-6.000299   1.0000938]\n",
            "It 19350: loss = 1.61956109e-06 lambda = [-6.0002737  1.0000981]\n",
            "It 19400: loss = 1.61259322e-06 lambda = [-6.0002985  1.0000693]\n",
            "It 19450: loss = 1.59979970e-06 lambda = [-6.0003076  1.0000653]\n",
            "It 19500: loss = 1.88232627e-06 lambda = [-6.0002966  1.0000688]\n",
            "It 19550: loss = 1.92824496e-06 lambda = [-6.0002894  1.0000703]\n",
            "It 19600: loss = 1.64941878e-06 lambda = [-6.0002966  1.000071 ]\n",
            "It 19650: loss = 4.42766068e-05 lambda = [-6.000217   1.0001198]\n",
            "It 19700: loss = 2.01532976e-06 lambda = [-6.00029    1.0000585]\n",
            "It 19750: loss = 1.56333158e-06 lambda = [-6.00029    1.0000619]\n",
            "It 19800: loss = 1.57656257e-06 lambda = [-6.000293   1.0000626]\n",
            "It 19850: loss = 7.15974966e-06 lambda = [-6.0002103  1.0001171]\n",
            "It 19900: loss = 1.68267127e-06 lambda = [-6.0002747  1.0000565]\n",
            "It 19950: loss = 1.99380020e-06 lambda = [-6.0002794  1.0000528]\n",
            "It 20000: loss = 1.52886059e-06 lambda = [-6.000284  1.000054]\n",
            "It 20050: loss = 5.02641633e-05 lambda = [-6.0003324  0.9999474]\n",
            "It 20100: loss = 1.59612409e-06 lambda = [-6.000264  1.000053]\n",
            "It 20150: loss = 1.51164465e-06 lambda = [-6.0002713  1.0000523]\n",
            "It 20200: loss = 7.84463100e-06 lambda = [-6.0002637  1.0000598]\n",
            "It 20250: loss = 6.96359211e-06 lambda = [-6.000315   1.0000006]\n",
            "It 20300: loss = 2.04779144e-06 lambda = [-6.0002437  1.0000684]\n",
            "It 20350: loss = 3.69920199e-05 lambda = [-6.000382    0.99992615]\n",
            "It 20400: loss = 1.67267569e-06 lambda = [-6.0002418  1.0000564]\n",
            "It 20450: loss = 1.47344974e-06 lambda = [-6.000255   1.0000454]\n",
            "It 20500: loss = 6.50822549e-05 lambda = [-6.000412   0.9998812]\n",
            "It 20550: loss = 1.56187991e-06 lambda = [-6.000227   1.0000519]\n",
            "It 20600: loss = 1.46492255e-06 lambda = [-6.00024    1.0000391]\n",
            "It 20650: loss = 4.05131004e-06 lambda = [-6.0002375  1.0000339]\n",
            "It 20700: loss = 8.23483861e-05 lambda = [-6.000102   1.0001478]\n",
            "It 20750: loss = 1.95575399e-06 lambda = [-6.000228   1.0000318]\n",
            "It 20800: loss = 1.43560180e-06 lambda = [-6.0002284  1.0000356]\n",
            "It 20850: loss = 1.45812135e-06 lambda = [-6.0002313  1.0000362]\n",
            "It 20900: loss = 1.42965962e-06 lambda = [-6.0001764  1.0000634]\n",
            "It 20950: loss = 1.46359730e-06 lambda = [-6.000209   1.0000365]\n",
            "It 21000: loss = 2.06540540e-06 lambda = [-6.0002184  1.0000196]\n",
            "It 21050: loss = 1.47802007e-06 lambda = [-6.0002275  1.0000224]\n",
            "It 21100: loss = 2.53559642e-06 lambda = [-6.0001884  1.000041 ]\n",
            "It 21150: loss = 1.40011105e-06 lambda = [-6.0002036  1.0000298]\n",
            "It 21200: loss = 1.38891096e-06 lambda = [-6.000212   1.0000256]\n",
            "It 21250: loss = 2.74577951e-06 lambda = [-6.0002503  0.9999395]\n",
            "It 21300: loss = 1.78300468e-06 lambda = [-6.0001717  1.0000327]\n",
            "It 21350: loss = 1.38027474e-06 lambda = [-6.0001907  1.0000209]\n",
            "It 21400: loss = 1.40862642e-06 lambda = [-6.0001965  1.0000148]\n",
            "It 21450: loss = 1.37594691e-06 lambda = [-6.0001974  1.0000204]\n",
            "It 21500: loss = 4.95077848e-06 lambda = [-6.0002065  0.9999678]\n",
            "It 21550: loss = 1.39478561e-06 lambda = [-6.000174   1.0000255]\n",
            "It 21600: loss = 1.35139805e-06 lambda = [-6.0001864  1.0000175]\n",
            "It 21650: loss = 1.34378467e-06 lambda = [-6.0001907  1.0000143]\n",
            "It 21700: loss = 4.77664325e-05 lambda = [-6.0000095  1.000138 ]\n",
            "It 21750: loss = 1.64594212e-06 lambda = [-6.0001483  1.0000317]\n",
            "It 21800: loss = 1.33236097e-06 lambda = [-6.0001726  1.0000123]\n",
            "It 21850: loss = 7.46235901e-06 lambda = [-6.0001845  0.9999904]\n",
            "It 21900: loss = 1.50103813e-06 lambda = [-6.000185    0.99999774]\n",
            "It 21950: loss = 4.71578005e-06 lambda = [-6.0001273  1.0000424]\n",
            "It 22000: loss = 1.34884874e-06 lambda = [-6.000164   1.0000072]\n",
            "It 22050: loss = 1.81975463e-06 lambda = [-6.0001526  1.0000216]\n",
            "It 22100: loss = 1.35122775e-06 lambda = [-6.000153   1.0000057]\n",
            "It 22150: loss = 1.29986222e-06 lambda = [-6.000151   1.0000061]\n",
            "It 22200: loss = 1.49804819e-05 lambda = [-6.0001516  1.0000055]\n",
            "It 22250: loss = 4.19614262e-05 lambda = [-6.00005    1.0000882]\n",
            "It 22300: loss = 1.34001584e-06 lambda = [-6.00015    1.0000002]\n",
            "It 22350: loss = 9.87093699e-06 lambda = [-6.000093   1.0000615]\n",
            "It 22400: loss = 1.38663097e-06 lambda = [-6.0001364  1.000009 ]\n",
            "It 22450: loss = 1.28292572e-06 lambda = [-6.000143   1.0000023]\n",
            "It 22500: loss = 3.46678135e-05 lambda = [-6.0001984  0.999902 ]\n",
            "It 22550: loss = 1.35601897e-06 lambda = [-6.000128   0.9999953]\n",
            "It 22600: loss = 1.70506894e-06 lambda = [-6.000124   1.0000045]\n",
            "Timeout is reached. Time elapsed: 100.01132869720459 seconds\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration: 5 Initial lambda: [1.0, -6.0]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "L-BFGS\n",
            "\n",
            "It 00000: loss = 2.67048120e-01 lambda = [ 0.9998147 -6.0000124]\n",
            "It 00050: loss = 1.29780829e-01 lambda = [ 0.59170824 -5.981559  ]\n",
            "It 00100: loss = 1.09371804e-01 lambda = [-0.37004328 -5.8818207 ]\n",
            "It 00150: loss = 1.01680674e-01 lambda = [-1.390938  -5.4451003]\n",
            "It 00200: loss = 9.39875692e-02 lambda = [-1.8496022 -4.9092774]\n",
            "It 00250: loss = 9.01392326e-02 lambda = [-1.8803849 -4.2993045]\n",
            "It 00300: loss = 8.67546126e-02 lambda = [-1.9407762 -3.629306 ]\n",
            "It 00350: loss = 8.31813663e-02 lambda = [-2.142711  -2.7625465]\n",
            "It 00400: loss = 8.00548419e-02 lambda = [-2.5380132 -2.1242197]\n",
            "It 00450: loss = 7.73173049e-02 lambda = [-3.0996041 -1.6513933]\n",
            "It 00500: loss = 7.57364631e-02 lambda = [-3.58241   -1.3938212]\n",
            "It 00550: loss = 7.48912245e-02 lambda = [-3.7255843 -1.304566 ]\n",
            "It 00600: loss = 7.40717798e-02 lambda = [-3.9918606 -1.0769066]\n",
            "It 00650: loss = 7.28606284e-02 lambda = [-3.9982934 -0.9219966]\n",
            "It 00700: loss = 7.21671879e-02 lambda = [-3.84245   -0.9101839]\n",
            "It 00750: loss = 7.17913732e-02 lambda = [-3.7872064  -0.92709357]\n",
            "It 00800: loss = 7.13636950e-02 lambda = [-3.7000444 -0.9634331]\n",
            "It 00850: loss = 7.11139441e-02 lambda = [-3.6421006 -0.9761569]\n",
            "It 00900: loss = 7.07685128e-02 lambda = [-3.681907  -0.9636887]\n",
            "It 00950: loss = 7.04510137e-02 lambda = [-3.7557015  -0.94623333]\n",
            "It 01000: loss = 7.02107772e-02 lambda = [-3.7957168 -0.9568586]\n",
            "It 01050: loss = 6.98513240e-02 lambda = [-3.7818406 -0.9575722]\n",
            "It 01100: loss = 6.94852024e-02 lambda = [-3.7535057 -0.9354738]\n",
            "It 01150: loss = 6.93268031e-02 lambda = [-3.7589056  -0.94347686]\n",
            "It 01200: loss = 6.91310912e-02 lambda = [-3.7602432 -0.9869263]\n",
            "It 01250: loss = 6.89162686e-02 lambda = [-3.7418315  -0.99806917]\n",
            "It 01300: loss = 6.87312335e-02 lambda = [-3.7180302  -0.99942607]\n",
            "It 01350: loss = 6.86145425e-02 lambda = [-3.7142658 -1.0243117]\n",
            "It 01400: loss = 6.85494617e-02 lambda = [-3.7056918 -1.0305853]\n",
            "It 01450: loss = 6.84605464e-02 lambda = [-3.701073  -1.0297638]\n",
            "It 01500: loss = 6.82882518e-02 lambda = [-3.714433  -1.0308473]\n",
            "It 01550: loss = 6.81341738e-02 lambda = [-3.7341847 -1.0454916]\n",
            "It 01600: loss = 6.79210424e-02 lambda = [-3.7488728 -1.0326368]\n",
            "It 01650: loss = 6.77525997e-02 lambda = [-3.7525983 -1.0295936]\n",
            "It 01700: loss = 6.76125139e-02 lambda = [-3.7439475 -1.0267171]\n",
            "It 01750: loss = 6.74834400e-02 lambda = [-3.7314584 -1.0199308]\n",
            "It 01800: loss = 6.73360303e-02 lambda = [-3.7218628  -0.99919146]\n",
            "It 01850: loss = 6.71201050e-02 lambda = [-3.7291188  -0.99757427]\n",
            "It 01900: loss = 6.69579580e-02 lambda = [-3.7355337 -1.0024261]\n",
            "Timeout is reached. Time elapsed: 100.01621437072754\n",
            "\n",
            "\n",
            "SGD\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: loss = 4.56384182e-01 lambda = [ 0.99989974 -6.0000067 ]\n",
            "It 00050: loss = 2.31397107e-01 lambda = [ 0.9997199 -6.000009 ]\n",
            "It 00100: loss = 2.26563215e-01 lambda = [ 0.9995346 -6.000023 ]\n",
            "It 00150: loss = 2.18653291e-01 lambda = [ 0.9990119 -6.0000863]\n",
            "It 00200: loss = 2.07082763e-01 lambda = [ 0.9977511 -6.0002975]\n",
            "It 00250: loss = 1.94456071e-01 lambda = [ 0.9953775 -6.0008273]\n",
            "It 00300: loss = 1.85665652e-01 lambda = [ 0.99187464 -6.001805  ]\n",
            "It 00350: loss = 1.81073427e-01 lambda = [ 0.9873639 -6.003245 ]\n",
            "It 00400: loss = 1.78092167e-01 lambda = [ 0.98200846 -6.005077  ]\n",
            "It 00450: loss = 1.75351188e-01 lambda = [ 0.9759765 -6.007214 ]\n",
            "It 00500: loss = 1.72534779e-01 lambda = [ 0.96936536 -6.0096025 ]\n",
            "It 00550: loss = 1.69631615e-01 lambda = [ 0.9622155 -6.012218 ]\n",
            "It 00600: loss = 1.66675270e-01 lambda = [ 0.9545518 -6.015043 ]\n",
            "It 00650: loss = 1.63703308e-01 lambda = [ 0.9464137 -6.018045 ]\n",
            "It 00700: loss = 1.60763100e-01 lambda = [ 0.93787  -6.021162]\n",
            "It 00750: loss = 1.57916486e-01 lambda = [ 0.92902184 -6.0242987 ]\n",
            "It 00800: loss = 1.55235112e-01 lambda = [ 0.91999066 -6.027333  ]\n",
            "It 00850: loss = 1.52787253e-01 lambda = [ 0.91090286 -6.0301423 ]\n",
            "It 00900: loss = 1.50622070e-01 lambda = [ 0.90187037 -6.0326233 ]\n",
            "It 00950: loss = 1.48759723e-01 lambda = [ 0.89297956 -6.034714  ]\n",
            "It 01000: loss = 1.47191137e-01 lambda = [ 0.8842921 -6.036397 ]\n",
            "It 01050: loss = 1.45884514e-01 lambda = [ 0.87584823 -6.037695  ]\n",
            "It 01100: loss = 1.44795477e-01 lambda = [ 0.8676715 -6.038656 ]\n",
            "It 01150: loss = 1.43876836e-01 lambda = [ 0.85977256 -6.0393405 ]\n",
            "It 01200: loss = 1.43086046e-01 lambda = [ 0.85215235 -6.039815  ]\n",
            "It 01250: loss = 1.42388999e-01 lambda = [ 0.84480536 -6.0401387 ]\n",
            "It 01300: loss = 1.41760379e-01 lambda = [ 0.8377225 -6.0403647]\n",
            "It 01350: loss = 1.41182542e-01 lambda = [ 0.83089364 -6.0405354 ]\n",
            "It 01400: loss = 1.40643656e-01 lambda = [ 0.8243081 -6.0406785]\n",
            "It 01450: loss = 1.40135989e-01 lambda = [ 0.817956  -6.0408216]\n",
            "It 01500: loss = 1.39654621e-01 lambda = [ 0.81182826 -6.0409646 ]\n",
            "It 01550: loss = 1.39196470e-01 lambda = [ 0.8059164 -6.041127 ]\n",
            "It 01600: loss = 1.38759583e-01 lambda = [ 0.80021274 -6.041305  ]\n",
            "It 01650: loss = 1.38342828e-01 lambda = [ 0.79470986 -6.041498  ]\n",
            "It 01700: loss = 1.37945354e-01 lambda = [ 0.7894009 -6.0417128]\n",
            "It 01750: loss = 1.37566626e-01 lambda = [ 0.7842793 -6.0419364]\n",
            "It 01800: loss = 1.37206212e-01 lambda = [ 0.7793387 -6.042175 ]\n",
            "It 01850: loss = 1.36863664e-01 lambda = [ 0.7745731 -6.042413 ]\n",
            "It 01900: loss = 1.36538506e-01 lambda = [ 0.7699764 -6.0426517]\n",
            "It 01950: loss = 1.36230290e-01 lambda = [ 0.76554286 -6.04289   ]\n",
            "It 02000: loss = 1.35938451e-01 lambda = [ 0.76126677 -6.0431285 ]\n",
            "It 02050: loss = 1.35662377e-01 lambda = [ 0.7571436 -6.043367 ]\n",
            "It 02100: loss = 1.35401383e-01 lambda = [ 0.7531663 -6.043595 ]\n",
            "It 02150: loss = 1.35154843e-01 lambda = [ 0.74933064 -6.0438094 ]\n",
            "It 02200: loss = 1.34921983e-01 lambda = [ 0.7456313 -6.0440235]\n",
            "It 02250: loss = 1.34702116e-01 lambda = [ 0.74206346 -6.0442142 ]\n",
            "It 02300: loss = 1.34494528e-01 lambda = [ 0.7386224 -6.044405 ]\n",
            "It 02350: loss = 1.34298474e-01 lambda = [ 0.7353035 -6.044573 ]\n",
            "It 02400: loss = 1.34113282e-01 lambda = [ 0.7321025 -6.0447397]\n",
            "It 02450: loss = 1.33938268e-01 lambda = [ 0.72901493 -6.044884  ]\n",
            "It 02500: loss = 1.33772790e-01 lambda = [ 0.7260368 -6.0450273]\n",
            "It 02550: loss = 1.33616239e-01 lambda = [ 0.72316396 -6.0451493 ]\n",
            "It 02600: loss = 1.33468047e-01 lambda = [ 0.7203928 -6.0452685]\n",
            "It 02650: loss = 1.33327633e-01 lambda = [ 0.71771955 -6.0453725 ]\n",
            "It 02700: loss = 1.33194551e-01 lambda = [ 0.71514064 -6.045468  ]\n",
            "It 02750: loss = 1.33068293e-01 lambda = [ 0.7126527 -6.0455604]\n",
            "It 02800: loss = 1.32948384e-01 lambda = [ 0.7102524 -6.045632 ]\n",
            "It 02850: loss = 1.32834494e-01 lambda = [ 0.70793647 -6.0457034 ]\n",
            "It 02900: loss = 1.32726192e-01 lambda = [ 0.7057021 -6.045772 ]\n",
            "It 02950: loss = 1.32623136e-01 lambda = [ 0.7035463 -6.0458198]\n",
            "It 03000: loss = 1.32524997e-01 lambda = [ 0.7014661 -6.0458674]\n",
            "It 03050: loss = 1.32476330e-01 lambda = [ 0.70044386 -6.0458913 ]\n",
            "It 03100: loss = 1.32428899e-01 lambda = [ 0.69942164 -6.045915  ]\n",
            "It 03150: loss = 1.32381827e-01 lambda = [ 0.6983994 -6.045939 ]\n",
            "It 03200: loss = 1.32335022e-01 lambda = [ 0.6973772 -6.045963 ]\n",
            "It 03250: loss = 1.32288530e-01 lambda = [ 0.6963575 -6.0459867]\n",
            "It 03300: loss = 1.32242322e-01 lambda = [ 0.69533825 -6.0460105 ]\n",
            "It 03350: loss = 1.32196397e-01 lambda = [ 0.694319  -6.0460343]\n",
            "It 03400: loss = 1.32150769e-01 lambda = [ 0.6932998 -6.046058 ]\n",
            "It 03450: loss = 1.32105380e-01 lambda = [ 0.69228053 -6.046082  ]\n",
            "It 03500: loss = 1.32060289e-01 lambda = [ 0.6912613 -6.0460997]\n",
            "It 03550: loss = 1.32015467e-01 lambda = [ 0.69024205 -6.0460997 ]\n",
            "It 03600: loss = 1.31970897e-01 lambda = [ 0.6892228 -6.0460997]\n",
            "It 03650: loss = 1.31926596e-01 lambda = [ 0.6882036 -6.0460997]\n",
            "It 03700: loss = 1.31882519e-01 lambda = [ 0.68718433 -6.0460997 ]\n",
            "It 03750: loss = 1.31838724e-01 lambda = [ 0.68616617 -6.0460997 ]\n",
            "It 03800: loss = 1.31795153e-01 lambda = [ 0.6851499 -6.0460997]\n",
            "It 03850: loss = 1.31751850e-01 lambda = [ 0.68413365 -6.0460997 ]\n",
            "It 03900: loss = 1.31708741e-01 lambda = [ 0.6831174 -6.0460997]\n",
            "It 03950: loss = 1.31665885e-01 lambda = [ 0.68210113 -6.0460997 ]\n",
            "It 04000: loss = 1.31623268e-01 lambda = [ 0.6810849 -6.0460997]\n",
            "It 04050: loss = 1.31580830e-01 lambda = [ 0.6800686 -6.0460997]\n",
            "It 04100: loss = 1.31538644e-01 lambda = [ 0.67905235 -6.0460997 ]\n",
            "It 04150: loss = 1.31496683e-01 lambda = [ 0.6780361 -6.0460997]\n",
            "It 04200: loss = 1.31454885e-01 lambda = [ 0.67701983 -6.0460997 ]\n",
            "It 04250: loss = 1.31413326e-01 lambda = [ 0.6760036 -6.0460997]\n",
            "It 04300: loss = 1.31371945e-01 lambda = [ 0.6749874 -6.0460997]\n",
            "It 04350: loss = 1.31330773e-01 lambda = [ 0.6739741 -6.0460997]\n",
            "It 04400: loss = 1.31289795e-01 lambda = [ 0.6729608 -6.0460997]\n",
            "It 04450: loss = 1.31249040e-01 lambda = [ 0.67194754 -6.0460997 ]\n",
            "It 04500: loss = 1.31208435e-01 lambda = [ 0.67093426 -6.0460997 ]\n",
            "It 04550: loss = 1.31168023e-01 lambda = [ 0.669921  -6.0460997]\n",
            "It 04600: loss = 1.31127760e-01 lambda = [ 0.6689077 -6.0460944]\n",
            "It 04650: loss = 1.31087691e-01 lambda = [ 0.6678944 -6.0460706]\n",
            "It 04700: loss = 1.31047800e-01 lambda = [ 0.66688114 -6.0460467 ]\n",
            "It 04750: loss = 1.31008059e-01 lambda = [ 0.66586787 -6.046023  ]\n",
            "It 04800: loss = 1.30968481e-01 lambda = [ 0.6648546 -6.045999 ]\n",
            "It 04850: loss = 1.30929083e-01 lambda = [ 0.6638413 -6.045975 ]\n",
            "It 04900: loss = 1.30889833e-01 lambda = [ 0.662828  -6.0459514]\n",
            "It 04950: loss = 1.30850732e-01 lambda = [ 0.6618161 -6.0459275]\n",
            "It 05000: loss = 1.30811781e-01 lambda = [ 0.6608058 -6.0459037]\n",
            "It 05050: loss = 1.30772978e-01 lambda = [ 0.6597955 -6.04588  ]\n",
            "It 05100: loss = 1.30734324e-01 lambda = [ 0.6587852 -6.045856 ]\n",
            "It 05150: loss = 1.30695805e-01 lambda = [ 0.6577749 -6.045832 ]\n",
            "It 05200: loss = 1.30657434e-01 lambda = [ 0.6567646 -6.0458083]\n",
            "It 05250: loss = 1.30619198e-01 lambda = [ 0.6557543 -6.0457845]\n",
            "It 05300: loss = 1.30581066e-01 lambda = [ 0.654744  -6.0457606]\n",
            "It 05350: loss = 1.30543083e-01 lambda = [ 0.65373373 -6.045737  ]\n",
            "It 05400: loss = 1.30505234e-01 lambda = [ 0.65272343 -6.045713  ]\n",
            "It 05450: loss = 1.30467489e-01 lambda = [ 0.65171313 -6.045689  ]\n",
            "It 05500: loss = 1.30429864e-01 lambda = [ 0.65070283 -6.0456653 ]\n",
            "It 05550: loss = 1.30392388e-01 lambda = [ 0.64969254 -6.0456414 ]\n",
            "It 05600: loss = 1.30355015e-01 lambda = [ 0.6486824 -6.0456176]\n",
            "It 05650: loss = 1.30317733e-01 lambda = [ 0.6476751 -6.0455937]\n",
            "It 05700: loss = 1.30280599e-01 lambda = [ 0.6466678 -6.04557  ]\n",
            "It 05750: loss = 1.30243570e-01 lambda = [ 0.64566046 -6.045546  ]\n",
            "It 05800: loss = 1.30206615e-01 lambda = [ 0.64465314 -6.045522  ]\n",
            "It 05850: loss = 1.30169779e-01 lambda = [ 0.6436458 -6.0454984]\n",
            "It 05900: loss = 1.30133063e-01 lambda = [ 0.6426385 -6.0454745]\n",
            "It 05950: loss = 1.30096421e-01 lambda = [ 0.6416312 -6.045438 ]\n",
            "It 06000: loss = 1.30059898e-01 lambda = [ 0.64062387 -6.04539   ]\n",
            "It 06050: loss = 1.30023450e-01 lambda = [ 0.63961655 -6.0453424 ]\n",
            "It 06100: loss = 1.29987091e-01 lambda = [ 0.63860923 -6.045295  ]\n",
            "It 06150: loss = 1.29950836e-01 lambda = [ 0.6376019 -6.045247 ]\n",
            "It 06200: loss = 1.29914656e-01 lambda = [ 0.6365946 -6.0451994]\n",
            "It 06250: loss = 1.29878581e-01 lambda = [ 0.6355873 -6.0451517]\n",
            "It 06300: loss = 1.29842579e-01 lambda = [ 0.63457996 -6.045104  ]\n",
            "It 06350: loss = 1.29806668e-01 lambda = [ 0.63357383 -6.0450563 ]\n",
            "It 06400: loss = 1.29770860e-01 lambda = [ 0.6325695 -6.0450087]\n",
            "It 06450: loss = 1.29735097e-01 lambda = [ 0.63156515 -6.044961  ]\n",
            "It 06500: loss = 1.29699439e-01 lambda = [ 0.6305608 -6.0449133]\n",
            "It 06550: loss = 1.29663840e-01 lambda = [ 0.6295565 -6.0448656]\n",
            "It 06600: loss = 1.29628330e-01 lambda = [ 0.62855214 -6.044818  ]\n",
            "It 06650: loss = 1.29592881e-01 lambda = [ 0.6275478 -6.0447702]\n",
            "It 06700: loss = 1.29557505e-01 lambda = [ 0.62654346 -6.0447226 ]\n",
            "It 06750: loss = 1.29522189e-01 lambda = [ 0.6255391 -6.044675 ]\n",
            "It 06800: loss = 1.29486978e-01 lambda = [ 0.6245348 -6.044627 ]\n",
            "It 06850: loss = 1.29451796e-01 lambda = [ 0.62353045 -6.0445795 ]\n",
            "It 06900: loss = 1.29416689e-01 lambda = [ 0.6225261 -6.044532 ]\n",
            "It 06950: loss = 1.29381657e-01 lambda = [ 0.6215218 -6.044484 ]\n",
            "It 07000: loss = 1.29346684e-01 lambda = [ 0.62051743 -6.0444365 ]\n",
            "It 07050: loss = 1.29328877e-01 lambda = [ 0.62001675 -6.0444126 ]\n",
            "It 07100: loss = 1.29311427e-01 lambda = [ 0.6195161 -6.044389 ]\n",
            "It 07150: loss = 1.29293978e-01 lambda = [ 0.6190154 -6.044365 ]\n",
            "It 07200: loss = 1.29276574e-01 lambda = [ 0.6185147 -6.044341 ]\n",
            "It 07250: loss = 1.29259184e-01 lambda = [ 0.61801404 -6.0443172 ]\n",
            "It 07300: loss = 1.29241794e-01 lambda = [ 0.61751336 -6.0442934 ]\n",
            "It 07350: loss = 1.29224420e-01 lambda = [ 0.6170127 -6.0442696]\n",
            "It 07400: loss = 1.29207075e-01 lambda = [ 0.616512  -6.0442457]\n",
            "It 07450: loss = 1.29189730e-01 lambda = [ 0.6160113 -6.044222 ]\n",
            "It 07500: loss = 1.29172400e-01 lambda = [ 0.61551064 -6.044198  ]\n",
            "It 07550: loss = 1.29155070e-01 lambda = [ 0.61500996 -6.044174  ]\n",
            "It 07600: loss = 1.29137784e-01 lambda = [ 0.6145093 -6.0441504]\n",
            "It 07650: loss = 1.29120499e-01 lambda = [ 0.6140086 -6.0441265]\n",
            "It 07700: loss = 1.29103228e-01 lambda = [ 0.6135079 -6.0441027]\n",
            "It 07750: loss = 1.29085973e-01 lambda = [ 0.61300725 -6.044079  ]\n",
            "It 07800: loss = 1.29068702e-01 lambda = [ 0.61250657 -6.044055  ]\n",
            "It 07850: loss = 1.29051462e-01 lambda = [ 0.6120059 -6.044031 ]\n",
            "It 07900: loss = 1.29034206e-01 lambda = [ 0.6115052 -6.0440073]\n",
            "It 07950: loss = 1.29016995e-01 lambda = [ 0.61100453 -6.0439835 ]\n",
            "It 08000: loss = 1.28999799e-01 lambda = [ 0.61050385 -6.0439596 ]\n",
            "It 08050: loss = 1.28982589e-01 lambda = [ 0.6100032 -6.043936 ]\n",
            "It 08100: loss = 1.28965408e-01 lambda = [ 0.6095025 -6.043912 ]\n",
            "It 08150: loss = 1.28948271e-01 lambda = [ 0.6090018 -6.043888 ]\n",
            "It 08200: loss = 1.28931105e-01 lambda = [ 0.60850114 -6.0438643 ]\n",
            "It 08250: loss = 1.28913969e-01 lambda = [ 0.60800046 -6.0438404 ]\n",
            "It 08300: loss = 1.28896832e-01 lambda = [ 0.6074998 -6.0438166]\n",
            "It 08350: loss = 1.28879726e-01 lambda = [ 0.6069991 -6.0437927]\n",
            "It 08400: loss = 1.28862634e-01 lambda = [ 0.6064984 -6.043769 ]\n",
            "It 08450: loss = 1.28845528e-01 lambda = [ 0.60599774 -6.043745  ]\n",
            "It 08500: loss = 1.28828436e-01 lambda = [ 0.60549706 -6.043721  ]\n",
            "It 08550: loss = 1.28811374e-01 lambda = [ 0.6049964 -6.0436974]\n",
            "It 08600: loss = 1.28794327e-01 lambda = [ 0.6044957 -6.0436735]\n",
            "It 08650: loss = 1.28777266e-01 lambda = [ 0.603995  -6.0436497]\n",
            "It 08700: loss = 1.28760234e-01 lambda = [ 0.60349435 -6.043626  ]\n",
            "It 08750: loss = 1.28743216e-01 lambda = [ 0.60299367 -6.043602  ]\n",
            "It 08800: loss = 1.28726199e-01 lambda = [ 0.602493 -6.043578]\n",
            "It 08850: loss = 1.28709167e-01 lambda = [ 0.6019923 -6.0435543]\n",
            "It 08900: loss = 1.28692180e-01 lambda = [ 0.60149163 -6.0435305 ]\n",
            "It 08950: loss = 1.28675193e-01 lambda = [ 0.60099095 -6.0435066 ]\n",
            "It 09000: loss = 1.28658205e-01 lambda = [ 0.6004903 -6.043483 ]\n",
            "It 09050: loss = 1.28641218e-01 lambda = [ 0.5999896 -6.043459 ]\n",
            "It 09100: loss = 1.28624275e-01 lambda = [ 0.5994889 -6.043435 ]\n",
            "It 09150: loss = 1.28607303e-01 lambda = [ 0.59898823 -6.0434113 ]\n",
            "It 09200: loss = 1.28590345e-01 lambda = [ 0.59848756 -6.0433874 ]\n",
            "It 09250: loss = 1.28573388e-01 lambda = [ 0.5979869 -6.0433636]\n",
            "It 09300: loss = 1.28556460e-01 lambda = [ 0.5974862 -6.0433397]\n",
            "It 09350: loss = 1.28539547e-01 lambda = [ 0.5969865 -6.043316 ]\n",
            "It 09400: loss = 1.28522635e-01 lambda = [ 0.5964888 -6.043292 ]\n",
            "It 09450: loss = 1.28505737e-01 lambda = [ 0.5959911 -6.043268 ]\n",
            "It 09500: loss = 1.28488868e-01 lambda = [ 0.5954934 -6.0432444]\n",
            "It 09550: loss = 1.28472000e-01 lambda = [ 0.5949957 -6.0432205]\n",
            "It 09600: loss = 1.28455147e-01 lambda = [ 0.594498  -6.0431967]\n",
            "It 09650: loss = 1.28438279e-01 lambda = [ 0.5940003 -6.043173 ]\n",
            "It 09700: loss = 1.28421426e-01 lambda = [ 0.5935026 -6.043149 ]\n",
            "It 09750: loss = 1.28404602e-01 lambda = [ 0.5930049 -6.043125 ]\n",
            "It 09800: loss = 1.28387764e-01 lambda = [ 0.5925072 -6.0431013]\n",
            "It 09850: loss = 1.28370956e-01 lambda = [ 0.5920095 -6.0430775]\n",
            "It 09900: loss = 1.28354162e-01 lambda = [ 0.5915118 -6.0430536]\n",
            "It 09950: loss = 1.28337353e-01 lambda = [ 0.5910141 -6.04303  ]\n",
            "It 10000: loss = 1.28320575e-01 lambda = [ 0.5905164 -6.043006 ]\n",
            "It 10050: loss = 1.28303766e-01 lambda = [ 0.5900187 -6.042982 ]\n",
            "It 10100: loss = 1.28287002e-01 lambda = [ 0.589521  -6.0429583]\n",
            "It 10150: loss = 1.28270209e-01 lambda = [ 0.5890233 -6.0429344]\n",
            "It 10200: loss = 1.28253445e-01 lambda = [ 0.5885256 -6.0429106]\n",
            "It 10250: loss = 1.28236651e-01 lambda = [ 0.5880279 -6.0428867]\n",
            "It 10300: loss = 1.28219888e-01 lambda = [ 0.5875302 -6.042863 ]\n",
            "It 10350: loss = 1.28203154e-01 lambda = [ 0.5870325 -6.042839 ]\n",
            "It 10400: loss = 1.28186405e-01 lambda = [ 0.5865348 -6.042815 ]\n",
            "It 10450: loss = 1.28169686e-01 lambda = [ 0.5860371 -6.0427914]\n",
            "It 10500: loss = 1.28152966e-01 lambda = [ 0.5855394 -6.0427675]\n",
            "It 10550: loss = 1.28136247e-01 lambda = [ 0.5850417 -6.0427437]\n",
            "It 10600: loss = 1.28119543e-01 lambda = [ 0.584544 -6.04272 ]\n",
            "It 10650: loss = 1.28102839e-01 lambda = [ 0.5840463 -6.042696 ]\n",
            "It 10700: loss = 1.28086150e-01 lambda = [ 0.5835486 -6.042672 ]\n",
            "It 10750: loss = 1.28069460e-01 lambda = [ 0.5830509 -6.0426483]\n",
            "It 10800: loss = 1.28052771e-01 lambda = [ 0.5825532 -6.0426245]\n",
            "It 10850: loss = 1.28036082e-01 lambda = [ 0.5820555 -6.0426006]\n",
            "It 10900: loss = 1.28019437e-01 lambda = [ 0.5815578 -6.042577 ]\n",
            "It 10950: loss = 1.28002763e-01 lambda = [ 0.5810601 -6.042553 ]\n",
            "It 11000: loss = 1.27986103e-01 lambda = [ 0.5805624 -6.042529 ]\n",
            "It 11050: loss = 1.27969474e-01 lambda = [ 0.5800647 -6.0425053]\n",
            "It 11100: loss = 1.27952829e-01 lambda = [ 0.579567  -6.0424814]\n",
            "It 11150: loss = 1.27936170e-01 lambda = [ 0.5790693 -6.0424576]\n",
            "It 11200: loss = 1.27919525e-01 lambda = [ 0.5785716 -6.0424337]\n",
            "It 11250: loss = 1.27902880e-01 lambda = [ 0.5780739 -6.04241  ]\n",
            "It 11300: loss = 1.27886251e-01 lambda = [ 0.5775762 -6.042386 ]\n",
            "It 11350: loss = 1.27869621e-01 lambda = [ 0.5770785 -6.042362 ]\n",
            "It 11400: loss = 1.27852991e-01 lambda = [ 0.5765808 -6.0423384]\n",
            "It 11450: loss = 1.27836391e-01 lambda = [ 0.5760831 -6.0423145]\n",
            "It 11500: loss = 1.27819777e-01 lambda = [ 0.5755854 -6.0422907]\n",
            "It 11550: loss = 1.27803192e-01 lambda = [ 0.5750877 -6.042267 ]\n",
            "It 11600: loss = 1.27786592e-01 lambda = [ 0.57459  -6.042243]\n",
            "It 11650: loss = 1.27770022e-01 lambda = [ 0.5740923 -6.042219 ]\n",
            "It 11700: loss = 1.27753466e-01 lambda = [ 0.5735946 -6.0421953]\n",
            "It 11750: loss = 1.27736881e-01 lambda = [ 0.57309693 -6.0421715 ]\n",
            "It 11800: loss = 1.27720311e-01 lambda = [ 0.57259923 -6.0421476 ]\n",
            "It 11850: loss = 1.27703756e-01 lambda = [ 0.57210153 -6.042124  ]\n",
            "It 11900: loss = 1.27687186e-01 lambda = [ 0.57160383 -6.0421    ]\n",
            "It 11950: loss = 1.27670631e-01 lambda = [ 0.57110614 -6.042076  ]\n",
            "It 12000: loss = 1.27654076e-01 lambda = [ 0.57060844 -6.0420523 ]\n",
            "It 12050: loss = 1.27637535e-01 lambda = [ 0.570112  -6.0420284]\n",
            "It 12100: loss = 1.27621025e-01 lambda = [ 0.5696173 -6.0420046]\n",
            "It 12150: loss = 1.27604499e-01 lambda = [ 0.56912255 -6.0419807 ]\n",
            "It 12200: loss = 1.27587974e-01 lambda = [ 0.56862783 -6.041957  ]\n",
            "It 12250: loss = 1.27571464e-01 lambda = [ 0.5681331 -6.041933 ]\n",
            "It 12300: loss = 1.27554923e-01 lambda = [ 0.5676384 -6.041909 ]\n",
            "It 12350: loss = 1.27538398e-01 lambda = [ 0.5671437 -6.0418854]\n",
            "It 12400: loss = 1.27521887e-01 lambda = [ 0.56664896 -6.0418615 ]\n",
            "It 12450: loss = 1.27505362e-01 lambda = [ 0.56615424 -6.0418377 ]\n",
            "It 12500: loss = 1.27488852e-01 lambda = [ 0.5656595 -6.041814 ]\n",
            "It 12550: loss = 1.27472341e-01 lambda = [ 0.5651648 -6.04179  ]\n",
            "It 12600: loss = 1.27455860e-01 lambda = [ 0.5646701 -6.041766 ]\n",
            "It 12650: loss = 1.27439380e-01 lambda = [ 0.56417537 -6.0417423 ]\n",
            "It 12700: loss = 1.27422884e-01 lambda = [ 0.56368065 -6.0417185 ]\n",
            "It 12750: loss = 1.27406418e-01 lambda = [ 0.56318593 -6.0416946 ]\n",
            "It 12800: loss = 1.27389938e-01 lambda = [ 0.5626912 -6.041671 ]\n",
            "It 12850: loss = 1.27373457e-01 lambda = [ 0.5621965 -6.041647 ]\n",
            "It 12900: loss = 1.27356976e-01 lambda = [ 0.5617018 -6.041623 ]\n",
            "It 12950: loss = 1.27340510e-01 lambda = [ 0.56120706 -6.0415993 ]\n",
            "It 13000: loss = 1.27324045e-01 lambda = [ 0.56071234 -6.0415754 ]\n",
            "It 13050: loss = 1.27307579e-01 lambda = [ 0.5602176 -6.0415516]\n",
            "It 13100: loss = 1.27291128e-01 lambda = [ 0.5597229 -6.0415277]\n",
            "It 13150: loss = 1.27274662e-01 lambda = [ 0.5592282 -6.041504 ]\n",
            "It 13200: loss = 1.27258241e-01 lambda = [ 0.55873346 -6.04148   ]\n",
            "It 13250: loss = 1.27241790e-01 lambda = [ 0.55823874 -6.041456  ]\n",
            "It 13300: loss = 1.27225339e-01 lambda = [ 0.557744  -6.0414324]\n",
            "It 13350: loss = 1.27208889e-01 lambda = [ 0.5572493 -6.0414085]\n",
            "It 13400: loss = 1.27192438e-01 lambda = [ 0.5567546 -6.0413847]\n",
            "It 13450: loss = 1.27175972e-01 lambda = [ 0.5562599 -6.041361 ]\n",
            "It 13500: loss = 1.27159536e-01 lambda = [ 0.55576515 -6.041337  ]\n",
            "It 13550: loss = 1.27143085e-01 lambda = [ 0.55527043 -6.041313  ]\n",
            "It 13600: loss = 1.27126649e-01 lambda = [ 0.5547757 -6.0412893]\n",
            "It 13650: loss = 1.27110213e-01 lambda = [ 0.554281  -6.0412655]\n",
            "It 13700: loss = 1.27093777e-01 lambda = [ 0.5537863 -6.0412416]\n",
            "It 13750: loss = 1.27077356e-01 lambda = [ 0.55329156 -6.041218  ]\n",
            "It 13800: loss = 1.27060920e-01 lambda = [ 0.55279684 -6.041194  ]\n",
            "It 13850: loss = 1.27044529e-01 lambda = [ 0.5523021 -6.04117  ]\n",
            "It 13900: loss = 1.27028093e-01 lambda = [ 0.5518074 -6.0411463]\n",
            "It 13950: loss = 1.27011687e-01 lambda = [ 0.5513127 -6.0411224]\n",
            "It 14000: loss = 1.26995295e-01 lambda = [ 0.55081797 -6.0410986 ]\n",
            "It 14050: loss = 1.26986891e-01 lambda = [ 0.5505706 -6.0410748]\n",
            "It 14100: loss = 1.26978666e-01 lambda = [ 0.55032325 -6.041051  ]\n",
            "It 14150: loss = 1.26970440e-01 lambda = [ 0.5500759 -6.041027 ]\n",
            "It 14200: loss = 1.26962215e-01 lambda = [ 0.5498285 -6.041003 ]\n",
            "It 14250: loss = 1.26954004e-01 lambda = [ 0.54958117 -6.0409794 ]\n",
            "It 14300: loss = 1.26945779e-01 lambda = [ 0.5493338 -6.0409555]\n",
            "It 14350: loss = 1.26937568e-01 lambda = [ 0.54908645 -6.0409317 ]\n",
            "It 14400: loss = 1.26929343e-01 lambda = [ 0.5488391 -6.040908 ]\n",
            "It 14450: loss = 1.26921117e-01 lambda = [ 0.54859173 -6.040884  ]\n",
            "It 14500: loss = 1.26912892e-01 lambda = [ 0.5483444 -6.04086  ]\n",
            "It 14550: loss = 1.26904666e-01 lambda = [ 0.548097  -6.0408363]\n",
            "It 14600: loss = 1.26896456e-01 lambda = [ 0.54784966 -6.0408125 ]\n",
            "It 14650: loss = 1.26888230e-01 lambda = [ 0.5476023 -6.0407887]\n",
            "It 14700: loss = 1.26880020e-01 lambda = [ 0.54735494 -6.040765  ]\n",
            "It 14750: loss = 1.26871809e-01 lambda = [ 0.5471076 -6.040741 ]\n",
            "It 14800: loss = 1.26863599e-01 lambda = [ 0.5468602 -6.040717 ]\n",
            "It 14850: loss = 1.26855373e-01 lambda = [ 0.54661286 -6.0406933 ]\n",
            "It 14900: loss = 1.26847178e-01 lambda = [ 0.5463655 -6.0406694]\n",
            "It 14950: loss = 1.26838967e-01 lambda = [ 0.54611814 -6.0406456 ]\n",
            "It 15000: loss = 1.26830757e-01 lambda = [ 0.5458708 -6.0406218]\n",
            "It 15050: loss = 1.26822546e-01 lambda = [ 0.5456234 -6.040598 ]\n",
            "It 15100: loss = 1.26814350e-01 lambda = [ 0.54537606 -6.040574  ]\n",
            "It 15150: loss = 1.26806155e-01 lambda = [ 0.5451287 -6.04055  ]\n",
            "It 15200: loss = 1.26797944e-01 lambda = [ 0.54488134 -6.0405264 ]\n",
            "It 15250: loss = 1.26789749e-01 lambda = [ 0.544634  -6.0405025]\n",
            "It 15300: loss = 1.26781553e-01 lambda = [ 0.5443866 -6.0404787]\n",
            "It 15350: loss = 1.26773342e-01 lambda = [ 0.54413927 -6.040455  ]\n",
            "It 15400: loss = 1.26765147e-01 lambda = [ 0.5438919 -6.040431 ]\n",
            "It 15450: loss = 1.26756936e-01 lambda = [ 0.54364455 -6.040407  ]\n",
            "It 15500: loss = 1.26748741e-01 lambda = [ 0.5433972 -6.0403833]\n",
            "It 15550: loss = 1.26740530e-01 lambda = [ 0.5431498 -6.0403595]\n",
            "It 15600: loss = 1.26732349e-01 lambda = [ 0.54290247 -6.0403357 ]\n",
            "It 15650: loss = 1.26724139e-01 lambda = [ 0.5426551 -6.040312 ]\n",
            "It 15700: loss = 1.26715943e-01 lambda = [ 0.54240775 -6.040288  ]\n",
            "It 15750: loss = 1.26707748e-01 lambda = [ 0.5421604 -6.040264 ]\n",
            "It 15800: loss = 1.26699537e-01 lambda = [ 0.54191303 -6.0402403 ]\n",
            "It 15850: loss = 1.26691341e-01 lambda = [ 0.5416657 -6.0402164]\n",
            "It 15900: loss = 1.26683146e-01 lambda = [ 0.5414183 -6.0401926]\n",
            "It 15950: loss = 1.26674935e-01 lambda = [ 0.54117095 -6.040169  ]\n",
            "It 16000: loss = 1.26666754e-01 lambda = [ 0.5409236 -6.040145 ]\n",
            "It 16050: loss = 1.26658529e-01 lambda = [ 0.54067624 -6.040121  ]\n",
            "It 16100: loss = 1.26650333e-01 lambda = [ 0.5404289 -6.040097 ]\n",
            "It 16150: loss = 1.26642138e-01 lambda = [ 0.5401815 -6.0400734]\n",
            "It 16200: loss = 1.26633957e-01 lambda = [ 0.53993416 -6.0400496 ]\n",
            "It 16250: loss = 1.26625746e-01 lambda = [ 0.5396868 -6.0400257]\n",
            "It 16300: loss = 1.26617551e-01 lambda = [ 0.53943944 -6.040002  ]\n",
            "It 16350: loss = 1.26609355e-01 lambda = [ 0.5391921 -6.039978 ]\n",
            "It 16400: loss = 1.26601160e-01 lambda = [ 0.5389447 -6.039954 ]\n",
            "It 16450: loss = 1.26592949e-01 lambda = [ 0.53869736 -6.0399303 ]\n",
            "It 16500: loss = 1.26584753e-01 lambda = [ 0.53845   -6.0399065]\n",
            "It 16550: loss = 1.26576558e-01 lambda = [ 0.53820264 -6.0398827 ]\n",
            "It 16600: loss = 1.26568362e-01 lambda = [ 0.5379553 -6.039859 ]\n",
            "It 16650: loss = 1.26560166e-01 lambda = [ 0.5377079 -6.039835 ]\n",
            "It 16700: loss = 1.26551971e-01 lambda = [ 0.53746057 -6.039811  ]\n",
            "It 16750: loss = 1.26543775e-01 lambda = [ 0.5372132 -6.0397873]\n",
            "It 16800: loss = 1.26535580e-01 lambda = [ 0.53696585 -6.0397635 ]\n",
            "It 16850: loss = 1.26527399e-01 lambda = [ 0.5367185 -6.0397396]\n",
            "It 16900: loss = 1.26519188e-01 lambda = [ 0.5364711 -6.039716 ]\n",
            "It 16950: loss = 1.26511008e-01 lambda = [ 0.53622377 -6.039692  ]\n",
            "It 17000: loss = 1.26502812e-01 lambda = [ 0.5359764 -6.039668 ]\n",
            "It 17050: loss = 1.26494616e-01 lambda = [ 0.53572905 -6.0396442 ]\n",
            "It 17100: loss = 1.26486436e-01 lambda = [ 0.5354817 -6.0396204]\n",
            "It 17150: loss = 1.26478225e-01 lambda = [ 0.53523433 -6.0395966 ]\n",
            "It 17200: loss = 1.26470029e-01 lambda = [ 0.534987  -6.0395727]\n",
            "It 17250: loss = 1.26461834e-01 lambda = [ 0.5347396 -6.039549 ]\n",
            "It 17300: loss = 1.26453638e-01 lambda = [ 0.53449225 -6.039525  ]\n",
            "It 17350: loss = 1.26445472e-01 lambda = [ 0.5342449 -6.039501 ]\n",
            "It 17400: loss = 1.26437292e-01 lambda = [ 0.53399754 -6.0394773 ]\n",
            "It 17450: loss = 1.26429111e-01 lambda = [ 0.5337502 -6.0394535]\n",
            "It 17500: loss = 1.26420930e-01 lambda = [ 0.5335028 -6.0394297]\n",
            "It 17550: loss = 1.26412749e-01 lambda = [ 0.53325546 -6.039406  ]\n",
            "It 17600: loss = 1.26404569e-01 lambda = [ 0.5330081 -6.039382 ]\n",
            "It 17650: loss = 1.26396388e-01 lambda = [ 0.53276074 -6.039358  ]\n",
            "It 17700: loss = 1.26388222e-01 lambda = [ 0.5325134 -6.0393343]\n",
            "It 17750: loss = 1.26380056e-01 lambda = [ 0.532266  -6.0393105]\n",
            "It 17800: loss = 1.26371831e-01 lambda = [ 0.53201866 -6.0392866 ]\n",
            "It 17850: loss = 1.26363665e-01 lambda = [ 0.5317736 -6.039263 ]\n",
            "It 17900: loss = 1.26355514e-01 lambda = [ 0.53152925 -6.039239  ]\n",
            "It 17950: loss = 1.26347363e-01 lambda = [ 0.53128487 -6.039215  ]\n",
            "It 18000: loss = 1.26339182e-01 lambda = [ 0.5310405 -6.0391912]\n",
            "It 18050: loss = 1.26331002e-01 lambda = [ 0.5307961 -6.0391674]\n",
            "It 18100: loss = 1.26322851e-01 lambda = [ 0.53055173 -6.0391436 ]\n",
            "It 18150: loss = 1.26314685e-01 lambda = [ 0.53030735 -6.0391197 ]\n",
            "It 18200: loss = 1.26306504e-01 lambda = [ 0.530063 -6.039096]\n",
            "It 18250: loss = 1.26298338e-01 lambda = [ 0.5298186 -6.039072 ]\n",
            "It 18300: loss = 1.26290157e-01 lambda = [ 0.5295742 -6.039048 ]\n",
            "It 18350: loss = 1.26281977e-01 lambda = [ 0.52932984 -6.0390244 ]\n",
            "It 18400: loss = 1.26273781e-01 lambda = [ 0.52908546 -6.0390005 ]\n",
            "It 18450: loss = 1.26265600e-01 lambda = [ 0.5288411 -6.0389767]\n",
            "It 18500: loss = 1.26257420e-01 lambda = [ 0.5285967 -6.038953 ]\n",
            "It 18550: loss = 1.26249224e-01 lambda = [ 0.5283523 -6.038929 ]\n",
            "It 18600: loss = 1.26241058e-01 lambda = [ 0.52810794 -6.038905  ]\n",
            "It 18650: loss = 1.26232862e-01 lambda = [ 0.52786356 -6.0388813 ]\n",
            "It 18700: loss = 1.26224682e-01 lambda = [ 0.5276192 -6.0388575]\n",
            "It 18750: loss = 1.26216486e-01 lambda = [ 0.5273748 -6.0388336]\n",
            "It 18800: loss = 1.26208305e-01 lambda = [ 0.5271304 -6.03881  ]\n",
            "It 18850: loss = 1.26200110e-01 lambda = [ 0.52688605 -6.038786  ]\n",
            "It 18900: loss = 1.26191914e-01 lambda = [ 0.52664167 -6.038762  ]\n",
            "It 18950: loss = 1.26183718e-01 lambda = [ 0.5263973 -6.0387383]\n",
            "It 19000: loss = 1.26175523e-01 lambda = [ 0.5261529 -6.0387144]\n",
            "It 19050: loss = 1.26167357e-01 lambda = [ 0.5259085 -6.0386906]\n",
            "It 19100: loss = 1.26159146e-01 lambda = [ 0.52566415 -6.0386667 ]\n",
            "It 19150: loss = 1.26150966e-01 lambda = [ 0.5254198 -6.038643 ]\n",
            "It 19200: loss = 1.26142770e-01 lambda = [ 0.5251754 -6.038619 ]\n",
            "It 19250: loss = 1.26134574e-01 lambda = [ 0.524931 -6.038595]\n",
            "It 19300: loss = 1.26126379e-01 lambda = [ 0.52468663 -6.0385714 ]\n",
            "It 19350: loss = 1.26118198e-01 lambda = [ 0.52444226 -6.0385475 ]\n",
            "It 19400: loss = 1.26110032e-01 lambda = [ 0.5241979 -6.0385237]\n",
            "It 19450: loss = 1.26101837e-01 lambda = [ 0.5239535 -6.0385   ]\n",
            "It 19500: loss = 1.26093656e-01 lambda = [ 0.5237091 -6.038476 ]\n",
            "It 19550: loss = 1.26085460e-01 lambda = [ 0.52346474 -6.038452  ]\n",
            "It 19600: loss = 1.26077279e-01 lambda = [ 0.52322036 -6.0384283 ]\n",
            "It 19650: loss = 1.26069099e-01 lambda = [ 0.522976  -6.0384045]\n",
            "It 19700: loss = 1.26060888e-01 lambda = [ 0.5227316 -6.0383806]\n",
            "It 19750: loss = 1.26052707e-01 lambda = [ 0.5224872 -6.038357 ]\n",
            "It 19800: loss = 1.26044527e-01 lambda = [ 0.52224284 -6.038333  ]\n",
            "It 19850: loss = 1.26036346e-01 lambda = [ 0.52199847 -6.038309  ]\n",
            "It 19900: loss = 1.26028150e-01 lambda = [ 0.5217541 -6.0382853]\n",
            "It 19950: loss = 1.26019970e-01 lambda = [ 0.5215097 -6.0382614]\n",
            "It 20000: loss = 1.26011789e-01 lambda = [ 0.5212653 -6.0382376]\n",
            "It 20050: loss = 1.26003593e-01 lambda = [ 0.52102095 -6.0382137 ]\n",
            "It 20100: loss = 1.25995412e-01 lambda = [ 0.52077657 -6.03819   ]\n",
            "It 20150: loss = 1.25987217e-01 lambda = [ 0.5205322 -6.038166 ]\n",
            "It 20200: loss = 1.25979051e-01 lambda = [ 0.5202878 -6.038142 ]\n",
            "It 20250: loss = 1.25970855e-01 lambda = [ 0.52004343 -6.0381184 ]\n",
            "It 20300: loss = 1.25962675e-01 lambda = [ 0.51979905 -6.0380945 ]\n",
            "It 20350: loss = 1.25954479e-01 lambda = [ 0.5195547 -6.0380707]\n",
            "It 20400: loss = 1.25946313e-01 lambda = [ 0.5193103 -6.038047 ]\n",
            "It 20450: loss = 1.25938118e-01 lambda = [ 0.5190659 -6.038023 ]\n",
            "It 20500: loss = 1.25929937e-01 lambda = [ 0.51882154 -6.037999  ]\n",
            "It 20550: loss = 1.25921756e-01 lambda = [ 0.51857716 -6.0379753 ]\n",
            "It 20600: loss = 1.25913590e-01 lambda = [ 0.5183328 -6.0379515]\n",
            "It 20650: loss = 1.25905395e-01 lambda = [ 0.5180884 -6.0379276]\n",
            "It 20700: loss = 1.25897214e-01 lambda = [ 0.517844 -6.037904]\n",
            "It 20750: loss = 1.25889018e-01 lambda = [ 0.51759964 -6.03788   ]\n",
            "It 20800: loss = 1.25880852e-01 lambda = [ 0.51735526 -6.037856  ]\n",
            "It 20850: loss = 1.25872642e-01 lambda = [ 0.5171109 -6.0378323]\n",
            "It 20900: loss = 1.25864446e-01 lambda = [ 0.5168665 -6.0378084]\n",
            "It 20950: loss = 1.25856251e-01 lambda = [ 0.5166221 -6.0377846]\n",
            "It 21000: loss = 1.25848070e-01 lambda = [ 0.51637775 -6.0377607 ]\n",
            "It 21050: loss = 1.25839874e-01 lambda = [ 0.51613337 -6.037737  ]\n",
            "It 21100: loss = 1.25831693e-01 lambda = [ 0.515889 -6.037713]\n",
            "It 21150: loss = 1.25823498e-01 lambda = [ 0.5156446 -6.037689 ]\n",
            "It 21200: loss = 1.25815302e-01 lambda = [ 0.51540023 -6.0376654 ]\n",
            "It 21250: loss = 1.25807136e-01 lambda = [ 0.51515585 -6.0376415 ]\n",
            "It 21300: loss = 1.25798926e-01 lambda = [ 0.5149115 -6.0376177]\n",
            "It 21350: loss = 1.25790745e-01 lambda = [ 0.5146671 -6.037594 ]\n",
            "It 21400: loss = 1.25782564e-01 lambda = [ 0.5144227 -6.03757  ]\n",
            "It 21450: loss = 1.25774369e-01 lambda = [ 0.51417834 -6.037546  ]\n",
            "It 21500: loss = 1.25766188e-01 lambda = [ 0.51393396 -6.0375223 ]\n",
            "It 21550: loss = 1.25758007e-01 lambda = [ 0.5136896 -6.0374985]\n",
            "It 21600: loss = 1.25749826e-01 lambda = [ 0.5134452 -6.0374746]\n",
            "It 21650: loss = 1.25741631e-01 lambda = [ 0.5132008 -6.037451 ]\n",
            "It 21700: loss = 1.25733435e-01 lambda = [ 0.51295644 -6.037427  ]\n",
            "It 21750: loss = 1.25725254e-01 lambda = [ 0.51271206 -6.037403  ]\n",
            "It 21800: loss = 1.25717074e-01 lambda = [ 0.5124677 -6.0373793]\n",
            "It 21850: loss = 1.25708893e-01 lambda = [ 0.5122233 -6.0373554]\n",
            "It 21900: loss = 1.25700682e-01 lambda = [ 0.5119789 -6.0373316]\n",
            "It 21950: loss = 1.25692502e-01 lambda = [ 0.51173455 -6.0373077 ]\n",
            "It 22000: loss = 1.25684321e-01 lambda = [ 0.51149017 -6.037284  ]\n",
            "It 22050: loss = 1.25676125e-01 lambda = [ 0.5112458 -6.03726  ]\n",
            "It 22100: loss = 1.25667930e-01 lambda = [ 0.5110014 -6.037236 ]\n",
            "It 22150: loss = 1.25659749e-01 lambda = [ 0.510757  -6.0372124]\n",
            "It 22200: loss = 1.25651568e-01 lambda = [ 0.51051265 -6.0371885 ]\n",
            "It 22250: loss = 1.25643358e-01 lambda = [ 0.5102683 -6.0371647]\n",
            "It 22300: loss = 1.25635177e-01 lambda = [ 0.5100239 -6.037141 ]\n",
            "It 22350: loss = 1.25626996e-01 lambda = [ 0.5097795 -6.037117 ]\n",
            "It 22400: loss = 1.25618815e-01 lambda = [ 0.50953513 -6.037093  ]\n",
            "It 22450: loss = 1.25610605e-01 lambda = [ 0.50929075 -6.0370693 ]\n",
            "It 22500: loss = 1.25602424e-01 lambda = [ 0.5090464 -6.0370455]\n",
            "It 22550: loss = 1.25594229e-01 lambda = [ 0.508802  -6.0370216]\n",
            "It 22600: loss = 1.25586033e-01 lambda = [ 0.5085576 -6.036998 ]\n",
            "It 22650: loss = 1.25577837e-01 lambda = [ 0.50831324 -6.036974  ]\n",
            "It 22700: loss = 1.25569656e-01 lambda = [ 0.50806886 -6.03695   ]\n",
            "It 22750: loss = 1.25561446e-01 lambda = [ 0.5078245 -6.0369263]\n",
            "It 22800: loss = 1.25553280e-01 lambda = [ 0.5075801 -6.0369024]\n",
            "It 22850: loss = 1.25545084e-01 lambda = [ 0.5073357 -6.0368786]\n",
            "It 22900: loss = 1.25536889e-01 lambda = [ 0.50709134 -6.0368547 ]\n",
            "It 22950: loss = 1.25528678e-01 lambda = [ 0.50684696 -6.036831  ]\n",
            "It 23000: loss = 1.25520483e-01 lambda = [ 0.5066026 -6.036807 ]\n",
            "It 23050: loss = 1.25512287e-01 lambda = [ 0.5063582 -6.036783 ]\n",
            "It 23100: loss = 1.25504091e-01 lambda = [ 0.5061138 -6.0367594]\n",
            "It 23150: loss = 1.25495896e-01 lambda = [ 0.50586945 -6.0367355 ]\n",
            "It 23200: loss = 1.25487670e-01 lambda = [ 0.50562507 -6.0367117 ]\n",
            "It 23250: loss = 1.25479475e-01 lambda = [ 0.5053807 -6.036688 ]\n",
            "It 23300: loss = 1.25471279e-01 lambda = [ 0.5051363 -6.036664 ]\n",
            "It 23350: loss = 1.25463068e-01 lambda = [ 0.50489193 -6.03664   ]\n",
            "It 23400: loss = 1.25454843e-01 lambda = [ 0.50464755 -6.0366163 ]\n",
            "It 23450: loss = 1.25446647e-01 lambda = [ 0.5044032 -6.0365925]\n",
            "Timeout is reached. Time elapsed: 100.00208353996277 seconds\n",
            "\n",
            "\n",
            "Adam\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: loss = 4.56384182e-01 lambda = [ 0.90031135 -6.0954337 ]\n",
            "It 00050: loss = 1.62875697e-01 lambda = [ 0.36517796 -5.541778  ]\n",
            "It 00100: loss = 1.17023550e-01 lambda = [-1.495985  -2.9026606]\n",
            "It 00150: loss = 8.93170685e-02 lambda = [-3.8158958 -0.6677612]\n",
            "It 00200: loss = 2.69037008e-01 lambda = [-4.5256257   0.30041763]\n",
            "It 00250: loss = 6.07307367e-02 lambda = [-4.5017686   0.45447946]\n",
            "It 00300: loss = 4.07819897e-02 lambda = [-5.0309024  0.5635729]\n",
            "It 00350: loss = 7.35590756e-02 lambda = [-5.0793223   0.24710493]\n",
            "It 00400: loss = 1.37807712e-01 lambda = [-4.6094723   0.53540397]\n",
            "It 00450: loss = 7.06930310e-02 lambda = [-4.6229515   0.38864046]\n",
            "It 00500: loss = 7.33787939e-02 lambda = [-4.8360534  0.3280224]\n",
            "It 00550: loss = 2.54442096e-01 lambda = [-4.455496    0.56383574]\n",
            "It 00600: loss = 4.45974767e-02 lambda = [-4.460455    0.36873448]\n",
            "It 00650: loss = 8.74657035e-02 lambda = [-4.610507    0.29893884]\n",
            "It 00700: loss = 1.23216122e-01 lambda = [-4.641206    0.19434746]\n",
            "It 00750: loss = 4.46542799e-02 lambda = [-4.6285114   0.35370994]\n",
            "It 00800: loss = 7.38847628e-02 lambda = [-4.7098727   0.18378127]\n",
            "It 00850: loss = 1.08915158e-02 lambda = [-4.801308   0.5385875]\n",
            "It 00900: loss = 6.87253177e-02 lambda = [-4.850326    0.30817613]\n",
            "It 00950: loss = 9.00818873e-03 lambda = [-4.9360685   0.59611106]\n",
            "It 01000: loss = 4.34479006e-02 lambda = [-4.976791    0.47626096]\n",
            "It 01050: loss = 1.19915254e-01 lambda = [-5.0612216   0.54849654]\n",
            "It 01100: loss = 1.69317685e-02 lambda = [-5.1056747  0.6399021]\n",
            "It 01150: loss = 2.81030242e-03 lambda = [-5.222881    0.70313597]\n",
            "It 01200: loss = 1.63502491e-03 lambda = [-5.299775   0.7376107]\n",
            "It 01250: loss = 1.29287830e-03 lambda = [-5.3660307  0.7617149]\n",
            "It 01300: loss = 1.05806766e-03 lambda = [-5.4237995  0.7814551]\n",
            "It 01350: loss = 8.76288628e-04 lambda = [-5.4742913  0.7992448]\n",
            "It 01400: loss = 7.32774497e-04 lambda = [-5.5189643  0.8153227]\n",
            "It 01450: loss = 6.18130318e-04 lambda = [-5.558789    0.82982093]\n",
            "It 01500: loss = 5.25698648e-04 lambda = [-5.5944433   0.84289885]\n",
            "It 01550: loss = 4.50586958e-04 lambda = [-5.626457    0.85471255]\n",
            "It 01600: loss = 3.89103312e-04 lambda = [-5.655272    0.86540204]\n",
            "It 01650: loss = 3.38438287e-04 lambda = [-5.6812634   0.87509066]\n",
            "It 01700: loss = 2.96417915e-04 lambda = [-5.704755   0.8838864]\n",
            "It 01750: loss = 2.61358684e-04 lambda = [-5.7260227   0.89188445]\n",
            "It 01800: loss = 2.31927348e-04 lambda = [-5.745315   0.8991679]\n",
            "It 01850: loss = 2.07072706e-04 lambda = [-5.762845    0.90581113]\n",
            "It 01900: loss = 1.85958546e-04 lambda = [-5.7787976  0.9118796]\n",
            "It 01950: loss = 1.67911538e-04 lambda = [-5.7933426   0.91743165]\n",
            "It 02000: loss = 1.52395136e-04 lambda = [-5.8066235   0.92251915]\n",
            "It 02050: loss = 1.38968288e-04 lambda = [-5.8187723  0.9271888]\n",
            "It 02100: loss = 1.27273743e-04 lambda = [-5.829906   0.9314821]\n",
            "It 02150: loss = 1.17026655e-04 lambda = [-5.8401237   0.93543655]\n",
            "It 02200: loss = 1.07985950e-04 lambda = [-5.8495183   0.93908525]\n",
            "It 02250: loss = 9.99591866e-05 lambda = [-5.8581724   0.94245803]\n",
            "It 02300: loss = 9.27876463e-05 lambda = [-5.8661585  0.945582 ]\n",
            "It 02350: loss = 8.63392343e-05 lambda = [-5.873543    0.94848096]\n",
            "It 02400: loss = 8.05078380e-05 lambda = [-5.880382    0.95117664]\n",
            "It 02450: loss = 7.52037304e-05 lambda = [-5.8867283  0.9536884]\n",
            "It 02500: loss = 7.03557598e-05 lambda = [-5.8926334   0.95603365]\n",
            "It 02550: loss = 6.59020006e-05 lambda = [-5.8981366  0.9582284]\n",
            "It 02600: loss = 6.17973565e-05 lambda = [-5.9032755   0.96028703]\n",
            "It 02650: loss = 5.80010856e-05 lambda = [-5.9080844   0.96222097]\n",
            "It 02700: loss = 5.44817194e-05 lambda = [-5.9125934   0.96404195]\n",
            "It 02750: loss = 5.12152656e-05 lambda = [-5.9168305  0.9657602]\n",
            "It 02800: loss = 4.81791831e-05 lambda = [-5.920819   0.9673843]\n",
            "It 02850: loss = 4.53588400e-05 lambda = [-5.9245796   0.96892184]\n",
            "It 02900: loss = 4.27391715e-05 lambda = [-5.9281344   0.97037995]\n",
            "It 02950: loss = 4.03088416e-05 lambda = [-5.9314985   0.97176474]\n",
            "It 03000: loss = 3.80576894e-05 lambda = [-5.9346867   0.97308123]\n",
            "It 03050: loss = 3.69627160e-05 lambda = [-5.9362364   0.97372305]\n",
            "It 03100: loss = 3.59010155e-05 lambda = [-5.937786   0.9743681]\n",
            "It 03150: loss = 3.48506219e-05 lambda = [-5.939356   0.9750163]\n",
            "It 03200: loss = 3.38131467e-05 lambda = [-5.9409294  0.9756678]\n",
            "It 03250: loss = 3.27921371e-05 lambda = [-5.942503  0.976322]\n",
            "It 03300: loss = 3.17894810e-05 lambda = [-5.9440765  0.9769778]\n",
            "It 03350: loss = 3.08060626e-05 lambda = [-5.94565    0.9776355]\n",
            "It 03400: loss = 2.98431605e-05 lambda = [-5.9472237  0.9782939]\n",
            "It 03450: loss = 2.89025538e-05 lambda = [-5.948797   0.9789525]\n",
            "It 03500: loss = 2.79848246e-05 lambda = [-5.950371    0.97961044]\n",
            "It 03550: loss = 2.70909804e-05 lambda = [-5.9519444   0.98026645]\n",
            "It 03600: loss = 2.62223202e-05 lambda = [-5.953518   0.9809219]\n",
            "It 03650: loss = 2.53789858e-05 lambda = [-5.9550915   0.98157513]\n",
            "It 03700: loss = 2.45603078e-05 lambda = [-5.9566646  0.9822262]\n",
            "It 03750: loss = 2.37718850e-05 lambda = [-5.9582148  0.9828739]\n",
            "It 03800: loss = 2.30088062e-05 lambda = [-5.9597645  0.9835164]\n",
            "It 03850: loss = 2.22730450e-05 lambda = [-5.9612985  0.9841536]\n",
            "It 03900: loss = 2.15636665e-05 lambda = [-5.9628243  0.9847844]\n",
            "It 03950: loss = 2.08817728e-05 lambda = [-5.9643273   0.98540753]\n",
            "It 04000: loss = 2.02263382e-05 lambda = [-5.965815    0.98602235]\n",
            "It 04050: loss = 1.95957637e-05 lambda = [-5.9672837   0.98662794]\n",
            "It 04100: loss = 1.89906768e-05 lambda = [-5.96873     0.98722285]\n",
            "It 04150: loss = 1.84099990e-05 lambda = [-5.970152   0.9878069]\n",
            "It 04200: loss = 1.78528717e-05 lambda = [-5.971548    0.98837906]\n",
            "It 04250: loss = 1.73188619e-05 lambda = [-5.972916   0.9889384]\n",
            "It 04300: loss = 1.68073566e-05 lambda = [-5.9742546   0.98948425]\n",
            "It 04350: loss = 1.63170025e-05 lambda = [-5.9755588   0.99001634]\n",
            "It 04400: loss = 1.58477105e-05 lambda = [-5.9768314  0.9905336]\n",
            "It 04450: loss = 1.53990532e-05 lambda = [-5.978067    0.99103594]\n",
            "It 04500: loss = 1.49688512e-05 lambda = [-5.9792686  0.9915227]\n",
            "It 04550: loss = 1.45580052e-05 lambda = [-5.9804296   0.99199384]\n",
            "It 04600: loss = 1.41655128e-05 lambda = [-5.981555    0.99244857]\n",
            "It 04650: loss = 1.37904326e-05 lambda = [-5.98264    0.9928871]\n",
            "It 04700: loss = 1.34321908e-05 lambda = [-5.9836817   0.99330914]\n",
            "It 04750: loss = 2.71172496e-04 lambda = [-5.9844017   0.99394315]\n",
            "It 04800: loss = 2.20875190e-05 lambda = [-5.985522   0.9940228]\n",
            "It 04850: loss = 1.26157329e-05 lambda = [-5.986341  0.994353]\n",
            "It 04900: loss = 1.22792590e-05 lambda = [-5.9871764  0.994683 ]\n",
            "It 04950: loss = 1.34777993e-05 lambda = [-5.987997   0.9949907]\n",
            "It 05000: loss = 2.25259409e-05 lambda = [-5.988583   0.9951038]\n",
            "It 05050: loss = 1.16638712e-05 lambda = [-5.989193    0.99546045]\n",
            "It 05100: loss = 1.13903725e-05 lambda = [-5.98983     0.99572265]\n",
            "It 05150: loss = 1.11497957e-05 lambda = [-5.990447    0.99598515]\n",
            "It 05200: loss = 2.04922887e-03 lambda = [-5.9916945   0.99544024]\n",
            "It 05250: loss = 2.26879256e-05 lambda = [-5.9913273   0.99647593]\n",
            "It 05300: loss = 1.07889728e-05 lambda = [-5.9918165   0.99650717]\n",
            "It 05350: loss = 1.04959599e-05 lambda = [-5.99228    0.9966988]\n",
            "It 05400: loss = 1.02937474e-05 lambda = [-5.99274    0.9969106]\n",
            "It 05450: loss = 8.22224683e-05 lambda = [-5.9930205   0.99727744]\n",
            "It 05500: loss = 1.52199927e-05 lambda = [-5.9933934  0.9972704]\n",
            "It 05550: loss = 1.00125317e-05 lambda = [-5.9937224  0.9972796]\n",
            "It 05600: loss = 9.76692900e-06 lambda = [-5.994063   0.9974286]\n",
            "It 05650: loss = 9.58977125e-06 lambda = [-5.994408   0.9975999]\n",
            "It 05700: loss = 9.93856927e-04 lambda = [-5.995361   0.9971302]\n",
            "It 05750: loss = 1.52584744e-05 lambda = [-5.9948807  0.9978825]\n",
            "It 05800: loss = 9.42901534e-06 lambda = [-5.9950986   0.99783593]\n",
            "It 05850: loss = 3.63773492e-04 lambda = [-5.9951277  0.997799 ]\n",
            "It 05900: loss = 9.32397779e-06 lambda = [-5.995471   0.9981623]\n",
            "It 05950: loss = 8.96222627e-06 lambda = [-5.9958196  0.998232 ]\n",
            "It 06000: loss = 1.16771087e-04 lambda = [-5.9957013   0.99809885]\n",
            "It 06050: loss = 9.67402684e-06 lambda = [-5.996155  0.998288]\n",
            "It 06100: loss = 2.21575428e-05 lambda = [-5.9963436  0.9984155]\n",
            "It 06150: loss = 8.52758603e-06 lambda = [-5.996412   0.9986529]\n",
            "It 06200: loss = 1.49242405e-03 lambda = [-5.995944    0.99905366]\n",
            "It 06250: loss = 1.18539620e-05 lambda = [-5.996803    0.99864656]\n",
            "It 06300: loss = 8.29460441e-06 lambda = [-5.9969482   0.99863183]\n",
            "It 06350: loss = 8.31829766e-06 lambda = [-5.997115   0.9987308]\n",
            "It 06400: loss = 1.40960556e-05 lambda = [-5.9970465  0.9988956]\n",
            "It 06450: loss = 1.87579444e-05 lambda = [-5.9971538  0.9989486]\n",
            "It 06500: loss = 8.38291271e-06 lambda = [-5.9974947   0.99888027]\n",
            "It 06550: loss = 1.05467821e-04 lambda = [-5.997555    0.99857104]\n",
            "It 06600: loss = 8.59741704e-06 lambda = [-5.997631    0.99893916]\n",
            "It 06650: loss = 1.33594385e-05 lambda = [-5.99779     0.99899614]\n",
            "It 06700: loss = 3.93411246e-05 lambda = [-5.9976697   0.99916166]\n",
            "It 06750: loss = 5.22598275e-05 lambda = [-5.998043   0.9989713]\n",
            "It 06800: loss = 9.66730113e-06 lambda = [-5.997914   0.9991938]\n",
            "It 06850: loss = 7.34320611e-06 lambda = [-5.998036   0.9991086]\n",
            "It 06900: loss = 5.35153144e-04 lambda = [-5.997697    0.99908924]\n",
            "It 06950: loss = 1.96591136e-05 lambda = [-5.9981427   0.99910927]\n",
            "It 07000: loss = 1.00460138e-05 lambda = [-5.9980536   0.99926496]\n",
            "It 07050: loss = 7.08779817e-06 lambda = [-5.9981284  0.9992312]\n",
            "It 07100: loss = 7.02600846e-06 lambda = [-5.9982095  0.9992495]\n",
            "It 07150: loss = 6.97028645e-06 lambda = [-5.998281   0.9992797]\n",
            "It 07200: loss = 6.91615560e-06 lambda = [-5.9983525   0.99931675]\n",
            "It 07250: loss = 6.86357862e-06 lambda = [-5.9984307   0.99935603]\n",
            "It 07300: loss = 6.81050778e-06 lambda = [-5.998517    0.99939686]\n",
            "It 07350: loss = 6.75790216e-06 lambda = [-5.998603   0.9994377]\n",
            "It 07400: loss = 6.70506552e-06 lambda = [-5.9986897   0.99947774]\n",
            "It 07450: loss = 6.65186781e-06 lambda = [-5.998773    0.99951726]\n",
            "It 07500: loss = 6.59860507e-06 lambda = [-5.998856   0.9995555]\n",
            "It 07550: loss = 6.54570295e-06 lambda = [-5.998936   0.9995923]\n",
            "It 07600: loss = 6.49210324e-06 lambda = [-5.9990106  0.9996275]\n",
            "It 07650: loss = 6.43815156e-06 lambda = [-5.9990826  0.9996606]\n",
            "It 07700: loss = 6.38396023e-06 lambda = [-5.9991546   0.99969274]\n",
            "It 07750: loss = 6.32940146e-06 lambda = [-5.999226    0.99972373]\n",
            "It 07800: loss = 6.27484633e-06 lambda = [-5.9992976   0.99975383]\n",
            "It 07850: loss = 6.21932168e-06 lambda = [-5.999369   0.9997832]\n",
            "It 07900: loss = 6.16380566e-06 lambda = [-5.9994407  0.9998124]\n",
            "It 07950: loss = 6.10802181e-06 lambda = [-5.999512    0.99984133]\n",
            "It 08000: loss = 6.05153764e-06 lambda = [-5.999583   0.9998699]\n",
            "It 08050: loss = 5.99490522e-06 lambda = [-5.999643   0.9998972]\n",
            "It 08100: loss = 5.93790674e-06 lambda = [-5.9996967  0.9999226]\n",
            "It 08150: loss = 5.88042667e-06 lambda = [-5.999749    0.99994594]\n",
            "It 08200: loss = 5.82265602e-06 lambda = [-5.999801   0.9999681]\n",
            "It 08250: loss = 5.76416232e-06 lambda = [-5.999849    0.99998933]\n",
            "It 08300: loss = 5.70589282e-06 lambda = [-5.9998965  1.0000097]\n",
            "It 08350: loss = 5.64692982e-06 lambda = [-5.999944   1.0000293]\n",
            "It 08400: loss = 5.58779129e-06 lambda = [-5.999992   1.0000489]\n",
            "It 08450: loss = 4.55201807e-04 lambda = [-6.000386    0.99962324]\n",
            "It 08500: loss = 5.58278907e-06 lambda = [-6.000042   1.0000393]\n",
            "It 08550: loss = 5.52519350e-06 lambda = [-6.0000343  1.0000355]\n",
            "It 08600: loss = 1.15798530e-05 lambda = [-5.9999447  1.0001009]\n",
            "It 08650: loss = 5.40094970e-06 lambda = [-6.0000424  1.0000677]\n",
            "It 08700: loss = 5.68393625e-05 lambda = [-5.999927   1.0000172]\n",
            "It 08750: loss = 5.40624706e-06 lambda = [-6.000056   1.0000546]\n",
            "It 08800: loss = 5.23188646e-06 lambda = [-6.000071  1.000067]\n",
            "It 08850: loss = 1.73495573e-05 lambda = [-6.000036   1.0000967]\n",
            "It 08900: loss = 5.02258190e-04 lambda = [-6.0003624   0.99967515]\n",
            "It 08950: loss = 5.65050050e-06 lambda = [-6.000042   1.0000876]\n",
            "It 09000: loss = 5.03717638e-06 lambda = [-6.0000644  1.0000464]\n",
            "It 09050: loss = 4.96993471e-06 lambda = [-6.0000696  1.0000654]\n",
            "It 09100: loss = 4.92758227e-06 lambda = [-6.000091   1.0000863]\n",
            "It 09150: loss = 2.76957617e-05 lambda = [-6.000024   1.0001067]\n",
            "It 09200: loss = 2.50308331e-05 lambda = [-5.9999976  1.0001613]\n",
            "It 09250: loss = 6.07725633e-06 lambda = [-6.0001597  1.0000752]\n",
            "It 09300: loss = 1.52320426e-05 lambda = [-6.000178   1.0000459]\n",
            "It 09350: loss = 4.74489434e-06 lambda = [-6.0001235  1.0000864]\n",
            "It 09400: loss = 4.75609158e-06 lambda = [-6.000129   1.0001079]\n",
            "It 09450: loss = 5.06929155e-06 lambda = [-6.000069   1.0000986]\n",
            "It 09500: loss = 7.20642583e-06 lambda = [-6.0001173  1.0000762]\n",
            "It 09550: loss = 7.74594719e-06 lambda = [-6.0000777  1.0001366]\n",
            "It 09600: loss = 4.51342839e-06 lambda = [-6.0001235  1.0001118]\n",
            "It 09650: loss = 5.56867570e-04 lambda = [-6.0005856   0.99960315]\n",
            "It 09700: loss = 5.84123518e-06 lambda = [-6.0001345  1.0000799]\n",
            "It 09750: loss = 4.41818929e-06 lambda = [-6.000118  1.000073]\n",
            "It 09800: loss = 4.01702673e-05 lambda = [-6.0000424  1.0000565]\n",
            "It 09850: loss = 4.63541119e-06 lambda = [-6.00011    1.0001193]\n",
            "It 09900: loss = 4.32076786e-06 lambda = [-6.000146   1.0001332]\n",
            "It 09950: loss = 3.31887823e-05 lambda = [-6.000026   1.0001814]\n",
            "It 10000: loss = 4.23127494e-06 lambda = [-6.000138   1.0000885]\n",
            "It 10050: loss = 4.21657751e-06 lambda = [-6.000145   1.0001026]\n",
            "It 10100: loss = 1.79221443e-05 lambda = [-6.000094   1.0001602]\n",
            "It 10150: loss = 4.30927412e-06 lambda = [-6.0001698  1.0001352]\n",
            "It 10200: loss = 4.89415515e-06 lambda = [-6.000187   1.0000784]\n",
            "It 10250: loss = 4.14819988e-06 lambda = [-6.000181  1.000101]\n",
            "It 10300: loss = 4.00657018e-06 lambda = [-6.0001836  1.0001258]\n",
            "It 10350: loss = 3.21100350e-04 lambda = [-6.000394    0.99991804]\n",
            "It 10400: loss = 5.50331515e-06 lambda = [-6.0001426  1.000192 ]\n",
            "It 10450: loss = 1.95513683e-04 lambda = [-6.0004096  0.9998494]\n",
            "It 10500: loss = 4.08803317e-06 lambda = [-6.0002074  1.0001327]\n",
            "It 10550: loss = 3.99861392e-06 lambda = [-6.0002275  1.0001327]\n",
            "It 10600: loss = 1.04883356e-05 lambda = [-6.000131  1.00018 ]\n",
            "It 10650: loss = 3.89142178e-06 lambda = [-6.000222   1.0001254]\n",
            "It 10700: loss = 3.88803255e-06 lambda = [-6.0002275  1.0001446]\n",
            "It 10750: loss = 1.46039174e-05 lambda = [-6.0002093  1.0001535]\n",
            "It 10800: loss = 5.12762062e-06 lambda = [-6.000248   1.0001364]\n",
            "It 10850: loss = 8.38008873e-06 lambda = [-6.0002136  1.0001781]\n",
            "It 10900: loss = 3.65818391e-06 lambda = [-6.0002403  1.0001476]\n",
            "It 10950: loss = 2.76656065e-04 lambda = [-6.000505    0.99980795]\n",
            "It 11000: loss = 4.59548892e-06 lambda = [-6.0002594  1.0001185]\n",
            "It 11050: loss = 1.64664452e-04 lambda = [-6.000252  1.000087]\n",
            "It 11100: loss = 3.78118898e-06 lambda = [-6.0002165  1.0001851]\n",
            "It 11150: loss = 3.56904675e-05 lambda = [-6.0001183  1.0002184]\n",
            "It 11200: loss = 3.74875344e-06 lambda = [-6.000264   1.0001367]\n",
            "It 11250: loss = 4.05640603e-05 lambda = [-6.0002713  1.0001544]\n",
            "It 11300: loss = 8.22499169e-06 lambda = [-6.0002146  1.0002307]\n",
            "It 11350: loss = 3.67467760e-06 lambda = [-6.0001974  1.0001572]\n",
            "It 11400: loss = 3.70287694e-06 lambda = [-6.000263  1.000166]\n",
            "It 11450: loss = 8.66014962e-05 lambda = [-6.0004983  0.99995  ]\n",
            "It 11500: loss = 4.33940841e-06 lambda = [-6.0003104  1.0001228]\n",
            "It 11550: loss = 2.72897196e-05 lambda = [-6.0002027  1.0001379]\n",
            "It 11600: loss = 3.29250906e-06 lambda = [-6.000251   1.0001807]\n",
            "It 11650: loss = 2.34643332e-04 lambda = [-5.999923   1.0005187]\n",
            "It 11700: loss = 5.71538885e-06 lambda = [-6.000319   1.0001109]\n",
            "It 11750: loss = 3.24577991e-06 lambda = [-6.0002766  1.000148 ]\n",
            "It 11800: loss = 1.37486895e-05 lambda = [-6.00021    1.0002102]\n",
            "It 11850: loss = 3.18645448e-06 lambda = [-6.000282   1.0001931]\n",
            "It 11900: loss = 6.82540121e-05 lambda = [-6.0004215  0.9998837]\n",
            "It 11950: loss = 3.55254383e-06 lambda = [-6.0002866  1.000149 ]\n",
            "It 12000: loss = 3.09314464e-06 lambda = [-6.0002947  1.0001682]\n",
            "It 12050: loss = 2.85151735e-04 lambda = [-6.000272   1.0001756]\n",
            "It 12100: loss = 4.47448247e-06 lambda = [-6.0003004  1.0002134]\n",
            "It 12150: loss = 3.58045691e-05 lambda = [-6.0002246  1.0002215]\n",
            "It 12200: loss = 3.24773737e-06 lambda = [-6.0003266  1.0001515]\n",
            "It 12250: loss = 2.98494933e-06 lambda = [-6.0003185  1.0001826]\n",
            "It 12300: loss = 3.00598936e-06 lambda = [-6.0003405  1.0001965]\n",
            "It 12350: loss = 1.17652862e-05 lambda = [-6.0003347  1.0001572]\n",
            "It 12400: loss = 3.14509612e-06 lambda = [-6.000319   1.0001454]\n",
            "It 12450: loss = 1.34618813e-05 lambda = [-6.000274  1.0002  ]\n",
            "It 12500: loss = 2.89552872e-06 lambda = [-6.0003014  1.0001957]\n",
            "It 12550: loss = 2.85888336e-06 lambda = [-6.000337   1.0002071]\n",
            "It 12600: loss = 7.82547795e-05 lambda = [-5.9999723  1.0003452]\n",
            "It 12650: loss = 4.80496283e-06 lambda = [-6.000359   1.0000986]\n",
            "It 12700: loss = 3.05529011e-06 lambda = [-6.0003133  1.0001532]\n",
            "It 12750: loss = 1.09490129e-05 lambda = [-6.0002737  1.0002192]\n",
            "It 12800: loss = 2.78590096e-06 lambda = [-6.000309   1.0002018]\n",
            "It 12850: loss = 2.75270349e-06 lambda = [-6.000348   1.0002123]\n",
            "It 12900: loss = 1.08551458e-05 lambda = [-6.00031   1.000299]\n",
            "It 12950: loss = 1.14855557e-05 lambda = [-6.0004277  1.0001256]\n",
            "It 13000: loss = 2.73856085e-06 lambda = [-6.0003395  1.0001595]\n",
            "It 13050: loss = 1.36079061e-05 lambda = [-6.0002675  1.0002112]\n",
            "It 13100: loss = 2.73188584e-06 lambda = [-6.0003324  1.0002089]\n",
            "It 13150: loss = 2.64805226e-06 lambda = [-6.0003695  1.000219 ]\n",
            "It 13200: loss = 3.57613935e-05 lambda = [-6.00025    1.0003821]\n",
            "It 13250: loss = 2.71391059e-06 lambda = [-6.0003753  1.0001954]\n",
            "It 13300: loss = 2.65405515e-06 lambda = [-6.0003586  1.0001693]\n",
            "It 13350: loss = 3.69075824e-05 lambda = [-6.0002484  1.0002038]\n",
            "It 13400: loss = 2.61576633e-06 lambda = [-6.0003285  1.0002116]\n",
            "It 13450: loss = 2.55728673e-06 lambda = [-6.00037    1.0002195]\n",
            "It 13500: loss = 3.03631828e-06 lambda = [-6.000389   1.0002506]\n",
            "It 13550: loss = 1.68601182e-05 lambda = [-6.0004797  1.0001369]\n",
            "It 13600: loss = 2.54788552e-06 lambda = [-6.0003853  1.0001822]\n",
            "It 13650: loss = 2.49838467e-06 lambda = [-6.0003853  1.0002067]\n",
            "It 13700: loss = 2.00214636e-05 lambda = [-6.000322   1.0002469]\n",
            "It 13750: loss = 2.46470199e-06 lambda = [-6.0003967  1.0002383]\n",
            "It 13800: loss = 1.23108866e-05 lambda = [-6.000313   1.0001329]\n",
            "It 13850: loss = 2.82727729e-06 lambda = [-6.0003805  1.0001724]\n",
            "It 13900: loss = 2.43009026e-06 lambda = [-6.000383   1.0001937]\n",
            "It 13950: loss = 2.40518193e-06 lambda = [-6.0003977  1.0002168]\n",
            "It 14000: loss = 8.25287862e-06 lambda = [-6.0004263  1.0002308]\n",
            "It 14050: loss = 2.42458782e-06 lambda = [-6.0004377  1.0002418]\n",
            "It 14100: loss = 2.35934567e-06 lambda = [-6.000456   1.0002482]\n",
            "It 14150: loss = 2.34737558e-06 lambda = [-6.0004787  1.0002545]\n",
            "It 14200: loss = 2.33562560e-06 lambda = [-6.0004973  1.0002611]\n",
            "It 14250: loss = 2.32362095e-06 lambda = [-6.0005107  1.0002671]\n",
            "It 14300: loss = 2.31147555e-06 lambda = [-6.0005245  1.0002731]\n",
            "It 14350: loss = 2.29912803e-06 lambda = [-6.0005383  1.0002791]\n",
            "It 14400: loss = 2.28671411e-06 lambda = [-6.000552  1.000285]\n",
            "It 14450: loss = 2.27420787e-06 lambda = [-6.000565   1.0002906]\n",
            "It 14500: loss = 2.26143766e-06 lambda = [-6.0005784  1.000296 ]\n",
            "It 14550: loss = 2.24863015e-06 lambda = [-6.0005903  1.0003004]\n",
            "It 14600: loss = 2.23543680e-06 lambda = [-6.0006003  1.0003045]\n",
            "It 14650: loss = 2.22239942e-06 lambda = [-6.0006094  1.0003078]\n",
            "It 14700: loss = 2.20884090e-06 lambda = [-6.0006175  1.000311 ]\n",
            "It 14750: loss = 2.19534809e-06 lambda = [-6.0006266  1.0003134]\n",
            "It 14800: loss = 2.18151149e-06 lambda = [-6.0006337  1.0003155]\n",
            "It 14850: loss = 2.16754756e-06 lambda = [-6.0006404  1.0003177]\n",
            "It 14900: loss = 2.15349633e-06 lambda = [-6.000648   1.0003201]\n",
            "It 14950: loss = 2.13923863e-06 lambda = [-6.0006537  1.0003221]\n",
            "It 15000: loss = 2.12489044e-06 lambda = [-6.000661   1.0003237]\n",
            "It 15050: loss = 2.11044676e-06 lambda = [-6.000665   1.0003248]\n",
            "It 15100: loss = 2.09566747e-06 lambda = [-6.0006676  1.0003254]\n",
            "It 15150: loss = 2.08073970e-06 lambda = [-6.0006733  1.0003266]\n",
            "It 15200: loss = 2.06577283e-06 lambda = [-6.000678   1.0003276]\n",
            "It 15250: loss = 2.05057472e-06 lambda = [-6.000686   1.0003289]\n",
            "It 15300: loss = 2.03541299e-06 lambda = [-6.0006914  1.0003301]\n",
            "It 15350: loss = 2.02139904e-06 lambda = [-6.000697   1.0003302]\n",
            "It 15400: loss = 4.50519383e-06 lambda = [-6.0006356  1.0003667]\n",
            "It 15450: loss = 2.22400513e-06 lambda = [-6.0006857  1.0003341]\n",
            "It 15500: loss = 4.81682491e-06 lambda = [-6.000716   1.0002943]\n",
            "It 15550: loss = 1.99824490e-06 lambda = [-6.0006905  1.0003171]\n",
            "It 15600: loss = 5.06191318e-05 lambda = [-6.000547   1.0004591]\n",
            "It 15650: loss = 2.33253559e-06 lambda = [-6.000677   1.0003141]\n",
            "It 15700: loss = 1.93199344e-06 lambda = [-6.0006824  1.0003133]\n",
            "It 15750: loss = 5.44761497e-06 lambda = [-6.0006666  1.0003144]\n",
            "It 15800: loss = 1.93119286e-06 lambda = [-6.0006795  1.0003152]\n",
            "It 15850: loss = 5.86416063e-05 lambda = [-6.0007715  1.0001954]\n",
            "It 15900: loss = 2.27493319e-06 lambda = [-6.000667   1.0003088]\n",
            "It 15950: loss = 1.87267676e-06 lambda = [-6.0006742  1.0003058]\n",
            "It 16000: loss = 1.92944162e-06 lambda = [-6.0006742  1.0003114]\n",
            "It 16050: loss = 2.52215932e-06 lambda = [-6.000644   1.0003434]\n",
            "It 16100: loss = 1.83874781e-05 lambda = [-6.000764   1.0002158]\n",
            "It 16150: loss = 2.37542122e-06 lambda = [-6.000688   1.0002865]\n",
            "It 16200: loss = 1.90666424e-06 lambda = [-6.00068    1.0002981]\n",
            "It 16250: loss = 4.91184437e-06 lambda = [-6.0007105  1.0002581]\n",
            "It 16300: loss = 1.81986081e-06 lambda = [-6.0006685  1.0002922]\n",
            "It 16350: loss = 1.79196149e-06 lambda = [-6.000665   1.0003008]\n",
            "It 16400: loss = 3.75042850e-06 lambda = [-6.0006557  1.0003126]\n",
            "It 16450: loss = 3.46320267e-05 lambda = [-6.0007443  1.0001734]\n",
            "It 16500: loss = 1.92307152e-06 lambda = [-6.0006514  1.0002939]\n",
            "It 16550: loss = 1.74221884e-06 lambda = [-6.000659   1.0002928]\n",
            "It 16600: loss = 1.73420756e-06 lambda = [-6.0006585  1.0002996]\n",
            "It 16650: loss = 9.82403435e-06 lambda = [-6.0005994  1.0003331]\n",
            "It 16700: loss = 1.77359368e-06 lambda = [-6.0006433  1.0002824]\n",
            "It 16750: loss = 2.35345124e-05 lambda = [-6.000645   1.0002586]\n",
            "It 16800: loss = 1.80176914e-06 lambda = [-6.0006356  1.0002888]\n",
            "It 16850: loss = 1.68260510e-06 lambda = [-6.0006447  1.0002904]\n",
            "It 16900: loss = 1.11837828e-04 lambda = [-6.000792   1.0001112]\n",
            "It 16950: loss = 1.67247595e-06 lambda = [-6.0006366  1.0002705]\n",
            "It 17000: loss = 1.66054929e-06 lambda = [-6.0006356  1.0002728]\n",
            "It 17050: loss = 4.88254000e-06 lambda = [-6.000618   1.0002844]\n",
            "It 17100: loss = 1.67237022e-06 lambda = [-6.00063    1.0002818]\n",
            "It 17150: loss = 1.63419963e-06 lambda = [-6.0006347  1.0002857]\n",
            "It 17200: loss = 2.94301390e-06 lambda = [-6.0006275  1.0002693]\n",
            "It 17250: loss = 1.64856965e-06 lambda = [-6.0006332  1.0002611]\n",
            "It 17300: loss = 1.60415209e-06 lambda = [-6.0006247  1.0002714]\n",
            "It 17350: loss = 6.53652023e-06 lambda = [-6.000605   1.0002841]\n",
            "It 17400: loss = 1.62473975e-06 lambda = [-6.000624   1.0002749]\n",
            "It 17450: loss = 7.27921224e-06 lambda = [-6.0005984  1.0002815]\n",
            "It 17500: loss = 1.61052765e-06 lambda = [-6.000623   1.0002564]\n",
            "It 17550: loss = 1.56083706e-06 lambda = [-6.000616   1.0002654]\n",
            "It 17600: loss = 2.96526559e-06 lambda = [-6.0006166  1.000271 ]\n",
            "It 17650: loss = 2.71853560e-06 lambda = [-6.000602   1.0002793]\n",
            "It 17700: loss = 1.56896385e-06 lambda = [-6.0006213  1.0002328]\n",
            "It 17750: loss = 1.53179531e-06 lambda = [-6.0006075  1.0002593]\n",
            "It 17800: loss = 3.92960828e-06 lambda = [-6.0005546  1.0002882]\n",
            "It 17850: loss = 1.53560802e-06 lambda = [-6.000604   1.0002463]\n",
            "It 17900: loss = 5.36171410e-06 lambda = [-6.0005875  1.0002669]\n",
            "It 17950: loss = 3.62630499e-06 lambda = [-6.0006146  1.0002321]\n",
            "It 18000: loss = 2.33165838e-06 lambda = [-6.000613   1.0002288]\n",
            "It 18050: loss = 4.37843300e-05 lambda = [-6.000699   1.0001199]\n",
            "It 18100: loss = 1.75622881e-06 lambda = [-6.000577   1.0002475]\n",
            "It 18150: loss = 1.67135727e-06 lambda = [-6.000574   1.0002527]\n",
            "It 18200: loss = 2.19926278e-06 lambda = [-6.000561   1.0002568]\n",
            "It 18250: loss = 2.99683256e-06 lambda = [-6.000555   1.0002279]\n",
            "It 18300: loss = 1.51514234e-06 lambda = [-6.0005603  1.000239 ]\n",
            "It 18350: loss = 1.58945943e-06 lambda = [-6.0005584  1.0002469]\n",
            "It 18400: loss = 2.75033153e-06 lambda = [-6.0005574  1.0002329]\n",
            "It 18450: loss = 4.60167803e-06 lambda = [-6.0005527  1.0002211]\n",
            "It 18500: loss = 2.03394848e-06 lambda = [-6.0005465  1.0002235]\n",
            "It 18550: loss = 1.41343378e-06 lambda = [-6.0005445  1.0002286]\n",
            "It 18600: loss = 1.87597507e-05 lambda = [-6.0005546  1.000163 ]\n",
            "It 18650: loss = 1.63101197e-06 lambda = [-6.0005174  1.0002077]\n",
            "It 18700: loss = 1.39632937e-06 lambda = [-6.000519   1.0002059]\n",
            "It 18750: loss = 6.62599314e-06 lambda = [-6.00051    1.0002058]\n",
            "It 18800: loss = 1.40382383e-06 lambda = [-6.0005083  1.0002139]\n",
            "It 18850: loss = 1.36930225e-06 lambda = [-6.000515   1.0002141]\n",
            "It 18900: loss = 2.24739824e-06 lambda = [-6.0004945  1.0002385]\n",
            "It 18950: loss = 1.57716681e-06 lambda = [-6.0005217  1.0001839]\n",
            "It 19000: loss = 1.35909079e-06 lambda = [-6.000498   1.0001895]\n",
            "It 19050: loss = 4.12965119e-06 lambda = [-6.000477   1.0002065]\n",
            "It 19100: loss = 1.36531798e-06 lambda = [-6.0004845  1.0002004]\n",
            "It 19150: loss = 1.33017409e-06 lambda = [-6.000489   1.0001993]\n",
            "It 19200: loss = 1.46976512e-04 lambda = [-6.000238   1.0004318]\n",
            "It 19250: loss = 1.40977579e-06 lambda = [-6.000491   1.0001534]\n",
            "It 19300: loss = 1.52493499e-06 lambda = [-6.0004635  1.0001767]\n",
            "It 19350: loss = 2.59029275e-06 lambda = [-6.000456  1.000185]\n",
            "It 19400: loss = 1.31013314e-06 lambda = [-6.0004544  1.0001823]\n",
            "It 19450: loss = 1.29297098e-06 lambda = [-6.0004582  1.000183 ]\n",
            "It 19500: loss = 3.85275325e-06 lambda = [-6.0005054  1.0001402]\n",
            "It 19550: loss = 3.72104046e-06 lambda = [-6.0004783  1.0001245]\n",
            "It 19600: loss = 1.28074623e-06 lambda = [-6.000431  1.000151]\n",
            "It 19650: loss = 6.87279908e-06 lambda = [-6.0004115  1.0001513]\n",
            "It 19700: loss = 1.32696493e-06 lambda = [-6.000411   1.0001643]\n",
            "It 19750: loss = 1.25916222e-06 lambda = [-6.0004153  1.0001624]\n",
            "It 19800: loss = 1.25225233e-06 lambda = [-6.0004153  1.0001625]\n",
            "It 19850: loss = 1.32687865e-05 lambda = [-6.0003657  1.0001874]\n",
            "It 19900: loss = 1.95759935e-06 lambda = [-6.0003853  1.0001762]\n",
            "It 19950: loss = 1.99850479e-06 lambda = [-6.0004134  1.000137 ]\n",
            "It 20000: loss = 1.23971370e-06 lambda = [-6.0003977  1.0001426]\n",
            "It 20050: loss = 6.95331892e-06 lambda = [-6.0003624  1.0001397]\n",
            "It 20100: loss = 1.30922058e-06 lambda = [-6.000374   1.0001389]\n",
            "It 20150: loss = 1.39767144e-05 lambda = [-6.000384   1.0001271]\n",
            "It 20200: loss = 3.62596052e-06 lambda = [-6.00033    1.0001701]\n",
            "It 20250: loss = 1.26752877e-06 lambda = [-6.000362   1.0001293]\n",
            "It 20300: loss = 1.06672005e-05 lambda = [-6.0004325  1.0000519]\n",
            "It 20350: loss = 1.99399142e-06 lambda = [-6.000332   1.0001314]\n",
            "It 20400: loss = 1.31624529e-06 lambda = [-6.000337   1.0001181]\n",
            "It 20450: loss = 1.32560433e-06 lambda = [-6.000323   1.0001302]\n",
            "It 20500: loss = 1.84159562e-05 lambda = [-6.0004067  1.0000031]\n",
            "It 20550: loss = 1.30166757e-06 lambda = [-6.0003133  1.0001081]\n",
            "It 20600: loss = 1.16722072e-06 lambda = [-6.0003114  1.0001088]\n",
            "It 20650: loss = 5.73740817e-06 lambda = [-6.0003586  1.000029 ]\n",
            "It 20700: loss = 1.15025603e-06 lambda = [-6.000293   1.0000907]\n",
            "It 20750: loss = 4.72355350e-06 lambda = [-6.000268  1.000101]\n",
            "It 20800: loss = 1.13714736e-06 lambda = [-6.000277   1.0000952]\n",
            "It 20850: loss = 1.21235507e-06 lambda = [-6.0002875  1.0000875]\n",
            "It 20900: loss = 4.93578773e-06 lambda = [-6.0002375  1.000115 ]\n",
            "It 20950: loss = 1.12326904e-06 lambda = [-6.000257  1.000074]\n",
            "It 21000: loss = 1.11597865e-06 lambda = [-6.0002527  1.0000774]\n",
            "It 21050: loss = 2.18847272e-05 lambda = [-6.00022  1.00009]\n",
            "It 21100: loss = 1.14274587e-06 lambda = [-6.000236  1.000083]\n",
            "It 21150: loss = 8.82282620e-06 lambda = [-6.0002007  1.0000894]\n",
            "It 21200: loss = 1.12836733e-06 lambda = [-6.0002284  1.0000628]\n",
            "It 21250: loss = 1.09010227e-06 lambda = [-6.0002255  1.0000658]\n",
            "It 21300: loss = 7.62004129e-06 lambda = [-6.0003037  0.9999432]\n",
            "It 21350: loss = 1.08954760e-06 lambda = [-6.000211   1.0000484]\n",
            "It 21400: loss = 1.09864750e-05 lambda = [-6.0001907  1.0000485]\n",
            "It 21450: loss = 1.17743878e-06 lambda = [-6.0001945  1.0000544]\n",
            "It 21500: loss = 1.46199136e-06 lambda = [-6.000182  1.000071]\n",
            "It 21550: loss = 2.33073024e-06 lambda = [-6.0002017  1.0000293]\n",
            "It 21600: loss = 1.06183882e-06 lambda = [-6.0001764  1.0000373]\n",
            "It 21650: loss = 1.07697713e-06 lambda = [-6.0001755  1.000041 ]\n",
            "It 21700: loss = 1.51748202e-06 lambda = [-6.0001583  1.0000588]\n",
            "It 21750: loss = 8.32456135e-06 lambda = [-6.0002365  0.9999749]\n",
            "It 21800: loss = 1.75111245e-06 lambda = [-6.000153   1.0000365]\n",
            "It 21850: loss = 1.03418949e-06 lambda = [-6.0001574  1.0000277]\n",
            "It 21900: loss = 1.02482579e-06 lambda = [-6.0001554  1.0000347]\n",
            "It 21950: loss = 5.37788901e-06 lambda = [-6.000093   1.0000674]\n",
            "It 22000: loss = 1.05744925e-06 lambda = [-6.0001297  1.0000174]\n",
            "It 22050: loss = 3.00124884e-06 lambda = [-6.000108   1.0000404]\n",
            "It 22100: loss = 1.01254614e-06 lambda = [-6.0001245  1.0000225]\n",
            "It 22150: loss = 9.95252890e-07 lambda = [-6.0001307  1.0000224]\n",
            "It 22200: loss = 7.16578006e-06 lambda = [-6.000087   1.0000198]\n",
            "It 22250: loss = 1.00842544e-06 lambda = [-6.0001116  1.0000056]\n",
            "It 22300: loss = 1.84667497e-05 lambda = [-6.0001245  0.9999928]\n",
            "It 22350: loss = 1.02857132e-06 lambda = [-6.0001025  1.0000113]\n",
            "It 22400: loss = 9.71684130e-07 lambda = [-6.0001073  1.0000116]\n",
            "It 22450: loss = 3.95429015e-06 lambda = [-6.000155   0.9999708]\n",
            "Timeout is reached. Time elapsed: 100.00111031532288 seconds\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration: 5 Initial lambda: [10.0, 10.0]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "L-BFGS\n",
            "\n",
            "It 00000: loss = 2.35863969e-01 lambda = [9.998043 9.999989]\n",
            "It 00050: loss = 2.03785107e-01 lambda = [9.55115  9.942124]\n",
            "It 00100: loss = 1.97451338e-01 lambda = [5.9358687 9.560391 ]\n",
            "It 00150: loss = 1.73931435e-01 lambda = [-3.8405795  8.420766 ]\n",
            "It 00200: loss = 7.27463961e-02 lambda = [-12.240788   7.290753]\n",
            "It 00250: loss = 5.45417629e-02 lambda = [-13.094741   7.057437]\n",
            "It 00300: loss = 4.71058562e-02 lambda = [-13.524285    6.7718534]\n",
            "It 00350: loss = 4.22980599e-02 lambda = [-13.756922    6.4277945]\n",
            "It 00400: loss = 3.85353044e-02 lambda = [-14.040145    5.8253875]\n",
            "It 00450: loss = 3.73045206e-02 lambda = [-14.12126     5.5829816]\n",
            "It 00500: loss = 3.63528989e-02 lambda = [-14.159027   5.2738  ]\n",
            "It 00550: loss = 3.54713015e-02 lambda = [-14.080647    5.0793753]\n",
            "It 00600: loss = 3.44419405e-02 lambda = [-13.921319   4.788852]\n",
            "It 00650: loss = 3.35511342e-02 lambda = [-13.6981535   4.4432325]\n",
            "It 00700: loss = 3.16606499e-02 lambda = [-13.171948    3.8971062]\n",
            "It 00750: loss = 2.84616537e-02 lambda = [-12.020928    2.9484076]\n",
            "It 00800: loss = 2.45492682e-02 lambda = [-10.949915    2.3716333]\n",
            "It 00850: loss = 1.95149016e-02 lambda = [-8.91707    1.6249901]\n",
            "It 00900: loss = 8.93568061e-03 lambda = [-7.093176   1.3540369]\n",
            "It 00950: loss = 3.19802179e-03 lambda = [-6.5325665  1.2714273]\n",
            "It 01000: loss = 1.40505470e-03 lambda = [-6.415603   1.1863087]\n",
            "It 01050: loss = 8.73848097e-04 lambda = [-6.200738   1.0956247]\n",
            "It 01100: loss = 5.58900705e-04 lambda = [-6.0389137  1.0266966]\n",
            "It 01150: loss = 4.53688932e-04 lambda = [-5.988115    0.99337256]\n",
            "It 01200: loss = 3.62498802e-04 lambda = [-6.0473266  1.0162199]\n",
            "It 01250: loss = 3.13078490e-04 lambda = [-6.037898   1.0183679]\n",
            "It 01300: loss = 2.05297853e-04 lambda = [-5.9652414   0.99458754]\n",
            "It 01350: loss = 1.44760998e-04 lambda = [-5.9230285   0.97713286]\n",
            "It 01400: loss = 1.27644365e-04 lambda = [-5.9290957   0.97618294]\n",
            "It 01450: loss = 1.13620066e-04 lambda = [-5.9338045   0.97057337]\n",
            "It 01500: loss = 9.79992474e-05 lambda = [-5.942156   0.9743037]\n",
            "It 01550: loss = 6.89169683e-05 lambda = [-5.965513   0.9872513]\n",
            "It 01600: loss = 5.77214960e-05 lambda = [-5.976218   0.9939625]\n",
            "It 01650: loss = 4.83998374e-05 lambda = [-5.9889274  0.9950652]\n",
            "It 01700: loss = 4.39208452e-05 lambda = [-5.9896674   0.99258494]\n",
            "It 01750: loss = 3.88617336e-05 lambda = [-5.9958677  0.9935994]\n",
            "It 01800: loss = 3.55325465e-05 lambda = [-5.9987593   0.99745333]\n",
            "Timeout is reached. Time elapsed: 100.04257845878601\n",
            "\n",
            "\n",
            "SGD\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: loss = 5.12106061e-01 lambda = [9.998886 9.999993]\n",
            "It 00050: loss = 2.31820047e-01 lambda = [9.998696 9.999992]\n",
            "It 00100: loss = 2.28336796e-01 lambda = [9.99845  9.999971]\n",
            "It 00150: loss = 2.23806009e-01 lambda = [9.997845 9.999899]\n",
            "It 00200: loss = 2.18518466e-01 lambda = [9.996602 9.999703]\n",
            "It 00250: loss = 2.13261336e-01 lambda = [9.994491 9.999296]\n",
            "It 00300: loss = 2.09266677e-01 lambda = [9.991447 9.9986  ]\n",
            "It 00350: loss = 2.07219645e-01 lambda = [9.987555 9.997622]\n",
            "It 00400: loss = 2.06460848e-01 lambda = [9.983054 9.996456]\n",
            "It 00450: loss = 2.06180185e-01 lambda = [9.978263 9.995216]\n",
            "It 00500: loss = 2.06040949e-01 lambda = [9.97341  9.993977]\n",
            "It 00550: loss = 2.05949664e-01 lambda = [9.968631 9.992753]\n",
            "It 00600: loss = 2.05880284e-01 lambda = [9.963971 9.991574]\n",
            "It 00650: loss = 2.05823392e-01 lambda = [9.959454 9.990443]\n",
            "It 00700: loss = 2.05774575e-01 lambda = [9.955082 9.98936 ]\n",
            "It 00750: loss = 2.05731362e-01 lambda = [9.950858 9.988322]\n",
            "It 00800: loss = 2.05692261e-01 lambda = [9.946778 9.987329]\n",
            "It 00850: loss = 2.05656260e-01 lambda = [9.942839 9.986375]\n",
            "It 00900: loss = 2.05622852e-01 lambda = [9.939035 9.985469]\n",
            "It 00950: loss = 2.05591485e-01 lambda = [9.935365 9.984601]\n",
            "It 01000: loss = 2.05561936e-01 lambda = [9.931824 9.983767]\n",
            "It 01050: loss = 2.05533907e-01 lambda = [9.928402 9.982961]\n",
            "It 01100: loss = 2.05507293e-01 lambda = [9.925103 9.982198]\n",
            "It 01150: loss = 2.05481946e-01 lambda = [9.921917 9.981464]\n",
            "It 01200: loss = 2.05457717e-01 lambda = [9.918842 9.98075 ]\n",
            "It 01250: loss = 2.05434546e-01 lambda = [9.915875  9.9800825]\n",
            "It 01300: loss = 2.05412373e-01 lambda = [9.913012 9.979428]\n",
            "It 01350: loss = 2.05391094e-01 lambda = [9.910247 9.978808]\n",
            "It 01400: loss = 2.05370694e-01 lambda = [9.907578 9.978207]\n",
            "It 01450: loss = 2.05351129e-01 lambda = [9.905004 9.977634]\n",
            "It 01500: loss = 2.05332264e-01 lambda = [9.902517 9.977077]\n",
            "It 01550: loss = 2.05314159e-01 lambda = [9.900116 9.976552]\n",
            "It 01600: loss = 2.05296770e-01 lambda = [9.897801 9.976028]\n",
            "It 01650: loss = 2.05280036e-01 lambda = [9.895567 9.975552]\n",
            "It 01700: loss = 2.05263928e-01 lambda = [9.893406 9.975075]\n",
            "It 01750: loss = 2.05248445e-01 lambda = [9.891326 9.97462 ]\n",
            "It 01800: loss = 2.05233499e-01 lambda = [9.889313 9.974191]\n",
            "It 01850: loss = 2.05219135e-01 lambda = [9.887375 9.973762]\n",
            "It 01900: loss = 2.05205321e-01 lambda = [9.885499 9.973361]\n",
            "It 01950: loss = 2.05192015e-01 lambda = [9.883692 9.97298 ]\n",
            "It 02000: loss = 2.05179200e-01 lambda = [9.8819475 9.972598 ]\n",
            "It 02050: loss = 2.05166832e-01 lambda = [9.88026  9.972233]\n",
            "It 02100: loss = 2.05154955e-01 lambda = [9.878631 9.971899]\n",
            "It 02150: loss = 2.05143496e-01 lambda = [9.877062 9.971565]\n",
            "It 02200: loss = 2.05132470e-01 lambda = [9.875547 9.971231]\n",
            "It 02250: loss = 2.05121830e-01 lambda = [9.874084 9.970925]\n",
            "It 02300: loss = 2.05111608e-01 lambda = [9.872672 9.970639]\n",
            "It 02350: loss = 2.05101758e-01 lambda = [9.871308 9.970353]\n",
            "It 02400: loss = 2.05092251e-01 lambda = [9.869992 9.970067]\n",
            "It 02450: loss = 2.05083102e-01 lambda = [9.868721 9.969788]\n",
            "It 02500: loss = 2.05074295e-01 lambda = [9.867493 9.969549]\n",
            "It 02550: loss = 2.05065787e-01 lambda = [9.866306 9.969311]\n",
            "It 02600: loss = 2.05057621e-01 lambda = [9.865162 9.969072]\n",
            "It 02650: loss = 2.05049753e-01 lambda = [9.864062 9.968834]\n",
            "It 02700: loss = 2.05042154e-01 lambda = [9.862999  9.9685955]\n",
            "It 02750: loss = 2.05034822e-01 lambda = [9.861969 9.968392]\n",
            "It 02800: loss = 2.05027804e-01 lambda = [9.8609705 9.968202 ]\n",
            "It 02850: loss = 2.05021009e-01 lambda = [9.860017 9.968011]\n",
            "It 02900: loss = 2.05014497e-01 lambda = [9.859094 9.96782 ]\n",
            "It 02950: loss = 2.05008149e-01 lambda = [9.858194 9.967629]\n",
            "It 03000: loss = 2.05002099e-01 lambda = [9.857336 9.967439]\n",
            "It 03050: loss = 2.04999059e-01 lambda = [9.856907 9.967343]\n",
            "It 03100: loss = 2.04996064e-01 lambda = [9.856478 9.967248]\n",
            "It 03150: loss = 2.04993099e-01 lambda = [9.856049 9.967153]\n",
            "It 03200: loss = 2.04990119e-01 lambda = [9.855619 9.967057]\n",
            "It 03250: loss = 2.04987124e-01 lambda = [9.85519  9.966962]\n",
            "It 03300: loss = 2.04984158e-01 lambda = [9.854761  9.9668665]\n",
            "It 03350: loss = 2.04981178e-01 lambda = [9.854332 9.966771]\n",
            "It 03400: loss = 2.04978228e-01 lambda = [9.853903 9.966676]\n",
            "It 03450: loss = 2.04975262e-01 lambda = [9.853474 9.96658 ]\n",
            "It 03500: loss = 2.04972297e-01 lambda = [9.8530445 9.966485 ]\n",
            "It 03550: loss = 2.04969347e-01 lambda = [9.852615 9.96639 ]\n",
            "It 03600: loss = 2.04966381e-01 lambda = [9.852186 9.966294]\n",
            "It 03650: loss = 2.04963416e-01 lambda = [9.851757 9.966199]\n",
            "It 03700: loss = 2.04960465e-01 lambda = [9.851328 9.966104]\n",
            "It 03750: loss = 2.04957545e-01 lambda = [9.850899 9.966008]\n",
            "It 03800: loss = 2.04954594e-01 lambda = [9.85047  9.965913]\n",
            "It 03850: loss = 2.04951644e-01 lambda = [9.85004  9.965817]\n",
            "It 03900: loss = 2.04948738e-01 lambda = [9.849611 9.965722]\n",
            "It 03950: loss = 2.04945803e-01 lambda = [9.849182 9.965627]\n",
            "It 04000: loss = 2.04942867e-01 lambda = [9.848753 9.965531]\n",
            "It 04050: loss = 2.04939932e-01 lambda = [9.848324 9.965436]\n",
            "It 04100: loss = 2.04937011e-01 lambda = [9.847895 9.965341]\n",
            "It 04150: loss = 2.04934105e-01 lambda = [9.8474655 9.965245 ]\n",
            "It 04200: loss = 2.04931140e-01 lambda = [9.847036 9.96515 ]\n",
            "It 04250: loss = 2.04928264e-01 lambda = [9.846607  9.9650545]\n",
            "It 04300: loss = 2.04925373e-01 lambda = [9.846178 9.964959]\n",
            "It 04350: loss = 2.04922438e-01 lambda = [9.845749 9.964864]\n",
            "It 04400: loss = 2.04919547e-01 lambda = [9.84532  9.964768]\n",
            "It 04450: loss = 2.04916641e-01 lambda = [9.844891 9.964673]\n",
            "It 04500: loss = 2.04913750e-01 lambda = [9.844461 9.964578]\n",
            "It 04550: loss = 2.04910874e-01 lambda = [9.844032 9.964482]\n",
            "It 04600: loss = 2.04907969e-01 lambda = [9.843603 9.964387]\n",
            "It 04650: loss = 2.04905078e-01 lambda = [9.843174 9.964292]\n",
            "It 04700: loss = 2.04902202e-01 lambda = [9.842745 9.964196]\n",
            "It 04750: loss = 2.04899326e-01 lambda = [9.842316 9.964101]\n",
            "It 04800: loss = 2.04896435e-01 lambda = [9.8418865 9.964005 ]\n",
            "It 04850: loss = 2.04893604e-01 lambda = [9.841457 9.96391 ]\n",
            "It 04900: loss = 2.04890713e-01 lambda = [9.841028 9.963815]\n",
            "It 04950: loss = 2.04887837e-01 lambda = [9.840599 9.963719]\n",
            "It 05000: loss = 2.04884991e-01 lambda = [9.84017  9.963624]\n",
            "It 05050: loss = 2.04882130e-01 lambda = [9.839741 9.963529]\n",
            "It 05100: loss = 2.04879284e-01 lambda = [9.839312 9.963433]\n",
            "It 05150: loss = 2.04876453e-01 lambda = [9.838882 9.963338]\n",
            "It 05200: loss = 2.04873592e-01 lambda = [9.838453 9.963243]\n",
            "It 05250: loss = 2.04870731e-01 lambda = [9.838024 9.963147]\n",
            "It 05300: loss = 2.04867914e-01 lambda = [9.837595 9.963052]\n",
            "It 05350: loss = 2.04865083e-01 lambda = [9.837166 9.962956]\n",
            "It 05400: loss = 2.04862252e-01 lambda = [9.836737 9.962861]\n",
            "It 05450: loss = 2.04859421e-01 lambda = [9.836308 9.962766]\n",
            "It 05500: loss = 2.04856604e-01 lambda = [9.835878 9.96267 ]\n",
            "It 05550: loss = 2.04853788e-01 lambda = [9.835449 9.962575]\n",
            "It 05600: loss = 2.04850972e-01 lambda = [9.83502 9.96248]\n",
            "It 05650: loss = 2.04848170e-01 lambda = [9.834591 9.962384]\n",
            "It 05700: loss = 2.04845354e-01 lambda = [9.834162 9.962289]\n",
            "It 05750: loss = 2.04842567e-01 lambda = [9.833733  9.9621935]\n",
            "It 05800: loss = 2.04839766e-01 lambda = [9.833303 9.962098]\n",
            "It 05850: loss = 2.04836980e-01 lambda = [9.832874 9.962003]\n",
            "It 05900: loss = 2.04834193e-01 lambda = [9.832445 9.961907]\n",
            "It 05950: loss = 2.04831406e-01 lambda = [9.832016 9.961812]\n",
            "It 06000: loss = 2.04828620e-01 lambda = [9.831587 9.961717]\n",
            "It 06050: loss = 2.04825848e-01 lambda = [9.831158 9.961621]\n",
            "It 06100: loss = 2.04823062e-01 lambda = [9.830729 9.961526]\n",
            "It 06150: loss = 2.04820320e-01 lambda = [9.830299 9.961431]\n",
            "It 06200: loss = 2.04817533e-01 lambda = [9.82987  9.961335]\n",
            "It 06250: loss = 2.04814777e-01 lambda = [9.829441 9.96124 ]\n",
            "It 06300: loss = 2.04812050e-01 lambda = [9.829012 9.961144]\n",
            "It 06350: loss = 2.04809263e-01 lambda = [9.828583 9.961049]\n",
            "It 06400: loss = 2.04806536e-01 lambda = [9.828154 9.960954]\n",
            "It 06450: loss = 2.04803780e-01 lambda = [9.827724 9.960858]\n",
            "It 06500: loss = 2.04801038e-01 lambda = [9.827295 9.960763]\n",
            "It 06550: loss = 2.04798311e-01 lambda = [9.826866 9.960668]\n",
            "It 06600: loss = 2.04795599e-01 lambda = [9.826437 9.960572]\n",
            "It 06650: loss = 2.04792842e-01 lambda = [9.826008 9.960477]\n",
            "It 06700: loss = 2.04790130e-01 lambda = [9.825579  9.9603815]\n",
            "It 06750: loss = 2.04787433e-01 lambda = [9.82515  9.960286]\n",
            "It 06800: loss = 2.04784721e-01 lambda = [9.82472  9.960191]\n",
            "It 06850: loss = 2.04782009e-01 lambda = [9.824291 9.960095]\n",
            "It 06900: loss = 2.04779312e-01 lambda = [9.823862 9.96    ]\n",
            "It 06950: loss = 2.04776600e-01 lambda = [9.823433 9.959905]\n",
            "It 07000: loss = 2.04773888e-01 lambda = [9.823004 9.959809]\n",
            "It 07050: loss = 2.04772577e-01 lambda = [9.822813 9.959762]\n",
            "It 07100: loss = 2.04771236e-01 lambda = [9.822622 9.959714]\n",
            "It 07150: loss = 2.04769939e-01 lambda = [9.822432 9.959666]\n",
            "It 07200: loss = 2.04768628e-01 lambda = [9.822241 9.959619]\n",
            "It 07250: loss = 2.04767317e-01 lambda = [9.82205  9.959571]\n",
            "It 07300: loss = 2.04766005e-01 lambda = [9.821859 9.959523]\n",
            "It 07350: loss = 2.04764694e-01 lambda = [9.821669  9.9594755]\n",
            "It 07400: loss = 2.04763412e-01 lambda = [9.821478 9.959428]\n",
            "It 07450: loss = 2.04762101e-01 lambda = [9.821287 9.95938 ]\n",
            "It 07500: loss = 2.04760805e-01 lambda = [9.821096 9.959332]\n",
            "It 07550: loss = 2.04759493e-01 lambda = [9.820906 9.959285]\n",
            "It 07600: loss = 2.04758197e-01 lambda = [9.820715 9.959237]\n",
            "It 07650: loss = 2.04756901e-01 lambda = [9.820524 9.959189]\n",
            "It 07700: loss = 2.04755589e-01 lambda = [9.8203335 9.959142 ]\n",
            "It 07750: loss = 2.04754293e-01 lambda = [9.820143 9.959094]\n",
            "It 07800: loss = 2.04753011e-01 lambda = [9.819952 9.959046]\n",
            "It 07850: loss = 2.04751730e-01 lambda = [9.819761 9.958999]\n",
            "It 07900: loss = 2.04750434e-01 lambda = [9.819571 9.958951]\n",
            "It 07950: loss = 2.04749107e-01 lambda = [9.81938  9.958903]\n",
            "It 08000: loss = 2.04747856e-01 lambda = [9.819189 9.958856]\n",
            "It 08050: loss = 2.04746544e-01 lambda = [9.818998 9.958808]\n",
            "It 08100: loss = 2.04745263e-01 lambda = [9.818808 9.95876 ]\n",
            "It 08150: loss = 2.04743981e-01 lambda = [9.818617 9.958713]\n",
            "It 08200: loss = 2.04742670e-01 lambda = [9.818426 9.958665]\n",
            "It 08250: loss = 2.04741403e-01 lambda = [9.818235 9.958617]\n",
            "It 08300: loss = 2.04740122e-01 lambda = [9.818045 9.95857 ]\n",
            "It 08350: loss = 2.04738840e-01 lambda = [9.817854 9.958522]\n",
            "It 08400: loss = 2.04737544e-01 lambda = [9.817663 9.958474]\n",
            "It 08450: loss = 2.04736277e-01 lambda = [9.817472 9.958426]\n",
            "It 08500: loss = 2.04734981e-01 lambda = [9.817282 9.958379]\n",
            "It 08550: loss = 2.04733714e-01 lambda = [9.817091 9.958331]\n",
            "It 08600: loss = 2.04732433e-01 lambda = [9.8169   9.958283]\n",
            "It 08650: loss = 2.04731166e-01 lambda = [9.8167095 9.958236 ]\n",
            "It 08700: loss = 2.04729885e-01 lambda = [9.816519 9.958188]\n",
            "It 08750: loss = 2.04728618e-01 lambda = [9.816328 9.95814 ]\n",
            "It 08800: loss = 2.04727352e-01 lambda = [9.816137 9.958093]\n",
            "It 08850: loss = 2.04726040e-01 lambda = [9.815947 9.958045]\n",
            "It 08900: loss = 2.04724804e-01 lambda = [9.815756 9.957997]\n",
            "It 08950: loss = 2.04723537e-01 lambda = [9.815565 9.95795 ]\n",
            "It 09000: loss = 2.04722255e-01 lambda = [9.815374 9.957902]\n",
            "It 09050: loss = 2.04721004e-01 lambda = [9.815184 9.957854]\n",
            "It 09100: loss = 2.04719722e-01 lambda = [9.814993 9.957807]\n",
            "It 09150: loss = 2.04718456e-01 lambda = [9.814802 9.957759]\n",
            "It 09200: loss = 2.04717219e-01 lambda = [9.814611 9.957711]\n",
            "It 09250: loss = 2.04715952e-01 lambda = [9.814421 9.957664]\n",
            "It 09300: loss = 2.04714686e-01 lambda = [9.81423  9.957616]\n",
            "It 09350: loss = 2.04713434e-01 lambda = [9.814039 9.957568]\n",
            "It 09400: loss = 2.04712167e-01 lambda = [9.8138485 9.9575205]\n",
            "It 09450: loss = 2.04710916e-01 lambda = [9.813658 9.957473]\n",
            "It 09500: loss = 2.04709664e-01 lambda = [9.813467 9.957425]\n",
            "It 09550: loss = 2.04708412e-01 lambda = [9.813276 9.957377]\n",
            "It 09600: loss = 2.04707146e-01 lambda = [9.813086 9.95733 ]\n",
            "It 09650: loss = 2.04705894e-01 lambda = [9.812895 9.957282]\n",
            "It 09700: loss = 2.04704672e-01 lambda = [9.812704 9.957234]\n",
            "It 09750: loss = 2.04703391e-01 lambda = [9.812513 9.957187]\n",
            "It 09800: loss = 2.04702154e-01 lambda = [9.812323 9.957139]\n",
            "It 09850: loss = 2.04700917e-01 lambda = [9.812132 9.957091]\n",
            "It 09900: loss = 2.04699650e-01 lambda = [9.811941 9.957044]\n",
            "It 09950: loss = 2.04698399e-01 lambda = [9.81175  9.956996]\n",
            "It 10000: loss = 2.04697162e-01 lambda = [9.81156  9.956948]\n",
            "It 10050: loss = 2.04695910e-01 lambda = [9.811369 9.956901]\n",
            "It 10100: loss = 2.04694688e-01 lambda = [9.811178 9.956853]\n",
            "It 10150: loss = 2.04693437e-01 lambda = [9.810987 9.956805]\n",
            "It 10200: loss = 2.04692215e-01 lambda = [9.810797 9.956758]\n",
            "It 10250: loss = 2.04690978e-01 lambda = [9.810606 9.95671 ]\n",
            "It 10300: loss = 2.04689726e-01 lambda = [9.810415 9.956662]\n",
            "It 10350: loss = 2.04688489e-01 lambda = [9.810225  9.9566145]\n",
            "It 10400: loss = 2.04687238e-01 lambda = [9.810034 9.956567]\n",
            "It 10450: loss = 2.04686001e-01 lambda = [9.809843 9.956519]\n",
            "It 10500: loss = 2.04684794e-01 lambda = [9.809652 9.956471]\n",
            "It 10550: loss = 2.04683557e-01 lambda = [9.809462 9.956424]\n",
            "It 10600: loss = 2.04682305e-01 lambda = [9.809271 9.956376]\n",
            "It 10650: loss = 2.04681098e-01 lambda = [9.80908  9.956328]\n",
            "It 10700: loss = 2.04679862e-01 lambda = [9.808889 9.956281]\n",
            "It 10750: loss = 2.04678655e-01 lambda = [9.808699 9.956233]\n",
            "It 10800: loss = 2.04677403e-01 lambda = [9.808508 9.956185]\n",
            "It 10850: loss = 2.04676166e-01 lambda = [9.808317 9.956138]\n",
            "It 10900: loss = 2.04674959e-01 lambda = [9.808126 9.95609 ]\n",
            "It 10950: loss = 2.04673737e-01 lambda = [9.807936 9.956042]\n",
            "It 11000: loss = 2.04672515e-01 lambda = [9.807745 9.955995]\n",
            "It 11050: loss = 2.04671308e-01 lambda = [9.807554 9.955947]\n",
            "It 11100: loss = 2.04670072e-01 lambda = [9.8073635 9.955899 ]\n",
            "It 11150: loss = 2.04668850e-01 lambda = [9.807173 9.955852]\n",
            "It 11200: loss = 2.04667658e-01 lambda = [9.806982 9.955804]\n",
            "It 11250: loss = 2.04666421e-01 lambda = [9.806791 9.955756]\n",
            "It 11300: loss = 2.04665229e-01 lambda = [9.806601  9.9557085]\n",
            "It 11350: loss = 2.04664037e-01 lambda = [9.80641  9.955661]\n",
            "It 11400: loss = 2.04662800e-01 lambda = [9.806219 9.955613]\n",
            "It 11450: loss = 2.04661608e-01 lambda = [9.806028 9.955565]\n",
            "It 11500: loss = 2.04660386e-01 lambda = [9.805838 9.955518]\n",
            "It 11550: loss = 2.04659164e-01 lambda = [9.805647 9.95547 ]\n",
            "It 11600: loss = 2.04657972e-01 lambda = [9.805456 9.955422]\n",
            "It 11650: loss = 2.04656780e-01 lambda = [9.805265 9.955375]\n",
            "It 11700: loss = 2.04655558e-01 lambda = [9.805075 9.955327]\n",
            "It 11750: loss = 2.04654366e-01 lambda = [9.804884 9.955279]\n",
            "It 11800: loss = 2.04653174e-01 lambda = [9.804693 9.955232]\n",
            "It 11850: loss = 2.04651952e-01 lambda = [9.8045025 9.955184 ]\n",
            "It 11900: loss = 2.04650760e-01 lambda = [9.804312 9.955136]\n",
            "It 11950: loss = 2.04649568e-01 lambda = [9.804121 9.955089]\n",
            "It 12000: loss = 2.04648361e-01 lambda = [9.80393  9.955041]\n",
            "It 12050: loss = 2.04647198e-01 lambda = [9.80374  9.954993]\n",
            "It 12100: loss = 2.04645976e-01 lambda = [9.803549 9.954946]\n",
            "It 12150: loss = 2.04644755e-01 lambda = [9.803358 9.954898]\n",
            "It 12200: loss = 2.04643592e-01 lambda = [9.803167 9.95485 ]\n",
            "It 12250: loss = 2.04642385e-01 lambda = [9.802977  9.9548025]\n",
            "It 12300: loss = 2.04641193e-01 lambda = [9.802786 9.954755]\n",
            "It 12350: loss = 2.04640016e-01 lambda = [9.802595 9.954707]\n",
            "It 12400: loss = 2.04638839e-01 lambda = [9.802404 9.954659]\n",
            "It 12450: loss = 2.04637647e-01 lambda = [9.802214 9.954612]\n",
            "It 12500: loss = 2.04636455e-01 lambda = [9.802023 9.954564]\n",
            "It 12550: loss = 2.04635277e-01 lambda = [9.801832 9.954516]\n",
            "It 12600: loss = 2.04634100e-01 lambda = [9.801641 9.954469]\n",
            "It 12650: loss = 2.04632923e-01 lambda = [9.801451 9.954421]\n",
            "It 12700: loss = 2.04631716e-01 lambda = [9.80126  9.954373]\n",
            "It 12750: loss = 2.04630554e-01 lambda = [9.801069 9.954326]\n",
            "It 12800: loss = 2.04629377e-01 lambda = [9.800879 9.954278]\n",
            "It 12850: loss = 2.04628199e-01 lambda = [9.800688 9.95423 ]\n",
            "It 12900: loss = 2.04627037e-01 lambda = [9.800497 9.954183]\n",
            "It 12950: loss = 2.04625845e-01 lambda = [9.800306 9.954135]\n",
            "It 13000: loss = 2.04624668e-01 lambda = [9.800116 9.954087]\n",
            "It 13050: loss = 2.04623491e-01 lambda = [9.799925 9.95404 ]\n",
            "It 13100: loss = 2.04622343e-01 lambda = [9.799734 9.953992]\n",
            "It 13150: loss = 2.04621181e-01 lambda = [9.799543 9.953944]\n",
            "It 13200: loss = 2.04620004e-01 lambda = [9.799353  9.9538965]\n",
            "It 13250: loss = 2.04618841e-01 lambda = [9.799162 9.953849]\n",
            "It 13300: loss = 2.04617694e-01 lambda = [9.798971 9.953801]\n",
            "It 13350: loss = 2.04616517e-01 lambda = [9.79878  9.953753]\n",
            "It 13400: loss = 2.04615325e-01 lambda = [9.79859  9.953706]\n",
            "It 13450: loss = 2.04614192e-01 lambda = [9.798399 9.953658]\n",
            "It 13500: loss = 2.04613015e-01 lambda = [9.798208 9.95361 ]\n",
            "It 13550: loss = 2.04611883e-01 lambda = [9.7980175 9.953563 ]\n",
            "It 13600: loss = 2.04610720e-01 lambda = [9.797827 9.953515]\n",
            "It 13650: loss = 2.04609558e-01 lambda = [9.797636 9.953467]\n",
            "It 13700: loss = 2.04608396e-01 lambda = [9.797445 9.95342 ]\n",
            "It 13750: loss = 2.04607233e-01 lambda = [9.797255 9.953372]\n",
            "It 13800: loss = 2.04606071e-01 lambda = [9.797064 9.953324]\n",
            "It 13850: loss = 2.04604924e-01 lambda = [9.796873 9.953277]\n",
            "It 13900: loss = 2.04603776e-01 lambda = [9.796682 9.953229]\n",
            "It 13950: loss = 2.04602629e-01 lambda = [9.796492 9.953181]\n",
            "It 14000: loss = 2.04601482e-01 lambda = [9.796301 9.953134]\n",
            "It 14050: loss = 2.04600900e-01 lambda = [9.7962055 9.953134 ]\n",
            "It 14100: loss = 2.04600319e-01 lambda = [9.79611  9.953134]\n",
            "It 14150: loss = 2.04599738e-01 lambda = [9.796015 9.953134]\n",
            "It 14200: loss = 2.04599172e-01 lambda = [9.795919 9.953134]\n",
            "It 14250: loss = 2.04598635e-01 lambda = [9.795824 9.953134]\n",
            "It 14300: loss = 2.04598069e-01 lambda = [9.795729 9.953134]\n",
            "It 14350: loss = 2.04597488e-01 lambda = [9.795633 9.953134]\n",
            "It 14400: loss = 2.04596937e-01 lambda = [9.795538 9.953134]\n",
            "It 14450: loss = 2.04596370e-01 lambda = [9.795443 9.953134]\n",
            "It 14500: loss = 2.04595819e-01 lambda = [9.795347 9.953134]\n",
            "It 14550: loss = 2.04595238e-01 lambda = [9.795252 9.953134]\n",
            "It 14600: loss = 2.04594672e-01 lambda = [9.7951565 9.953134 ]\n",
            "It 14650: loss = 2.04594120e-01 lambda = [9.795061 9.953134]\n",
            "It 14700: loss = 2.04593539e-01 lambda = [9.794966 9.953134]\n",
            "It 14750: loss = 2.04592958e-01 lambda = [9.79487  9.953134]\n",
            "It 14800: loss = 2.04592407e-01 lambda = [9.794775 9.953134]\n",
            "It 14850: loss = 2.04591841e-01 lambda = [9.79468  9.953134]\n",
            "It 14900: loss = 2.04591274e-01 lambda = [9.794584 9.953134]\n",
            "It 14950: loss = 2.04590723e-01 lambda = [9.794489 9.953134]\n",
            "It 15000: loss = 2.04590142e-01 lambda = [9.794394 9.953134]\n",
            "It 15050: loss = 2.04589605e-01 lambda = [9.794298 9.953134]\n",
            "It 15100: loss = 2.04589039e-01 lambda = [9.794203 9.953134]\n",
            "It 15150: loss = 2.04588488e-01 lambda = [9.794107 9.953134]\n",
            "It 15200: loss = 2.04587922e-01 lambda = [9.794012 9.953134]\n",
            "It 15250: loss = 2.04587340e-01 lambda = [9.793917 9.953134]\n",
            "It 15300: loss = 2.04586804e-01 lambda = [9.793821 9.953134]\n",
            "It 15350: loss = 2.04586253e-01 lambda = [9.793726 9.953134]\n",
            "It 15400: loss = 2.04585686e-01 lambda = [9.793631 9.953134]\n",
            "It 15450: loss = 2.04585120e-01 lambda = [9.793535 9.953134]\n",
            "It 15500: loss = 2.04584584e-01 lambda = [9.79344  9.953134]\n",
            "It 15550: loss = 2.04584002e-01 lambda = [9.7933445 9.953134 ]\n",
            "It 15600: loss = 2.04583436e-01 lambda = [9.793249 9.953134]\n",
            "It 15650: loss = 2.04582885e-01 lambda = [9.793154 9.953134]\n",
            "It 15700: loss = 2.04582348e-01 lambda = [9.793058 9.953134]\n",
            "It 15750: loss = 2.04581782e-01 lambda = [9.792963 9.953134]\n",
            "It 15800: loss = 2.04581216e-01 lambda = [9.792868 9.953134]\n",
            "It 15850: loss = 2.04580694e-01 lambda = [9.792772 9.953134]\n",
            "It 15900: loss = 2.04580113e-01 lambda = [9.792677 9.953134]\n",
            "It 15950: loss = 2.04579562e-01 lambda = [9.792582 9.953134]\n",
            "It 16000: loss = 2.04578996e-01 lambda = [9.792486 9.953134]\n",
            "It 16050: loss = 2.04578444e-01 lambda = [9.792391 9.953134]\n",
            "It 16100: loss = 2.04577908e-01 lambda = [9.792295 9.953134]\n",
            "It 16150: loss = 2.04577357e-01 lambda = [9.7922   9.953134]\n",
            "It 16200: loss = 2.04576790e-01 lambda = [9.792105 9.953134]\n",
            "It 16250: loss = 2.04576224e-01 lambda = [9.792009 9.953134]\n",
            "It 16300: loss = 2.04575673e-01 lambda = [9.791914 9.953134]\n",
            "It 16350: loss = 2.04575121e-01 lambda = [9.791819 9.953134]\n",
            "It 16400: loss = 2.04574585e-01 lambda = [9.791723 9.953134]\n",
            "It 16450: loss = 2.04574004e-01 lambda = [9.791628 9.953134]\n",
            "It 16500: loss = 2.04573467e-01 lambda = [9.7915325 9.953134 ]\n",
            "It 16550: loss = 2.04572901e-01 lambda = [9.791437 9.953134]\n",
            "It 16600: loss = 2.04572380e-01 lambda = [9.791342 9.953134]\n",
            "It 16650: loss = 2.04571813e-01 lambda = [9.791246 9.953134]\n",
            "It 16700: loss = 2.04571247e-01 lambda = [9.791151 9.953134]\n",
            "It 16750: loss = 2.04570711e-01 lambda = [9.791056 9.953134]\n",
            "It 16800: loss = 2.04570159e-01 lambda = [9.79096  9.953134]\n",
            "It 16850: loss = 2.04569593e-01 lambda = [9.790865 9.953134]\n",
            "It 16900: loss = 2.04569072e-01 lambda = [9.79077  9.953134]\n",
            "It 16950: loss = 2.04568505e-01 lambda = [9.790674 9.953134]\n",
            "It 17000: loss = 2.04567954e-01 lambda = [9.790579 9.953134]\n",
            "It 17050: loss = 2.04567418e-01 lambda = [9.790483 9.953134]\n",
            "It 17100: loss = 2.04566851e-01 lambda = [9.790388 9.953134]\n",
            "It 17150: loss = 2.04566300e-01 lambda = [9.790293 9.953134]\n",
            "It 17200: loss = 2.04565749e-01 lambda = [9.790197 9.953134]\n",
            "It 17250: loss = 2.04565212e-01 lambda = [9.790102 9.953134]\n",
            "It 17300: loss = 2.04564661e-01 lambda = [9.790007 9.953134]\n",
            "It 17350: loss = 2.04564109e-01 lambda = [9.789911 9.953134]\n",
            "It 17400: loss = 2.04563543e-01 lambda = [9.789816 9.953134]\n",
            "It 17450: loss = 2.04563022e-01 lambda = [9.789721 9.953134]\n",
            "It 17500: loss = 2.04562470e-01 lambda = [9.789625 9.953134]\n",
            "It 17550: loss = 2.04561919e-01 lambda = [9.78953  9.953134]\n",
            "It 17600: loss = 2.04561383e-01 lambda = [9.789434 9.953134]\n",
            "It 17650: loss = 2.04560816e-01 lambda = [9.789339 9.953134]\n",
            "It 17700: loss = 2.04560280e-01 lambda = [9.789244 9.953134]\n",
            "It 17750: loss = 2.04559743e-01 lambda = [9.789148 9.953134]\n",
            "It 17800: loss = 2.04559192e-01 lambda = [9.789053 9.953134]\n",
            "It 17850: loss = 2.04558641e-01 lambda = [9.788958 9.953134]\n",
            "It 17900: loss = 2.04558104e-01 lambda = [9.788862 9.953134]\n",
            "It 17950: loss = 2.04557553e-01 lambda = [9.788767 9.953134]\n",
            "It 18000: loss = 2.04557002e-01 lambda = [9.7886715 9.953134 ]\n",
            "It 18050: loss = 2.04556465e-01 lambda = [9.788576 9.953134]\n",
            "It 18100: loss = 2.04555914e-01 lambda = [9.788481 9.953134]\n",
            "It 18150: loss = 2.04555362e-01 lambda = [9.788385 9.953134]\n",
            "It 18200: loss = 2.04554841e-01 lambda = [9.78829  9.953134]\n",
            "It 18250: loss = 2.04554260e-01 lambda = [9.788195 9.953134]\n",
            "It 18300: loss = 2.04553738e-01 lambda = [9.788099 9.953134]\n",
            "It 18350: loss = 2.04553187e-01 lambda = [9.788004 9.953134]\n",
            "It 18400: loss = 2.04552650e-01 lambda = [9.787909 9.953134]\n",
            "It 18450: loss = 2.04552099e-01 lambda = [9.787813 9.953134]\n",
            "It 18500: loss = 2.04551563e-01 lambda = [9.787718 9.953134]\n",
            "It 18550: loss = 2.04551026e-01 lambda = [9.787622 9.953134]\n",
            "It 18600: loss = 2.04550490e-01 lambda = [9.787527 9.953134]\n",
            "It 18650: loss = 2.04549938e-01 lambda = [9.787432 9.953134]\n",
            "It 18700: loss = 2.04549387e-01 lambda = [9.787336 9.953134]\n",
            "It 18750: loss = 2.04548836e-01 lambda = [9.787241 9.953134]\n",
            "It 18800: loss = 2.04548299e-01 lambda = [9.787146 9.953134]\n",
            "It 18850: loss = 2.04547778e-01 lambda = [9.78705  9.953134]\n",
            "It 18900: loss = 2.04547241e-01 lambda = [9.786955 9.953134]\n",
            "It 18950: loss = 2.04546690e-01 lambda = [9.7868595 9.953134 ]\n",
            "It 19000: loss = 2.04546154e-01 lambda = [9.786764 9.953134]\n",
            "It 19050: loss = 2.04545602e-01 lambda = [9.786669 9.953134]\n",
            "It 19100: loss = 2.04545096e-01 lambda = [9.786573 9.953134]\n",
            "It 19150: loss = 2.04544574e-01 lambda = [9.786478 9.953134]\n",
            "It 19200: loss = 2.04544008e-01 lambda = [9.786383 9.953134]\n",
            "It 19250: loss = 2.04543471e-01 lambda = [9.786287 9.953134]\n",
            "It 19300: loss = 2.04542935e-01 lambda = [9.786192 9.953134]\n",
            "It 19350: loss = 2.04542384e-01 lambda = [9.786097 9.953134]\n",
            "It 19400: loss = 2.04541862e-01 lambda = [9.786001 9.953134]\n",
            "It 19450: loss = 2.04541326e-01 lambda = [9.785906 9.953134]\n",
            "It 19500: loss = 2.04540789e-01 lambda = [9.78581  9.953134]\n",
            "It 19550: loss = 2.04540268e-01 lambda = [9.785715 9.953134]\n",
            "It 19600: loss = 2.04539716e-01 lambda = [9.78562  9.953134]\n",
            "It 19650: loss = 2.04539180e-01 lambda = [9.785524 9.953134]\n",
            "It 19700: loss = 2.04538658e-01 lambda = [9.785429 9.953134]\n",
            "It 19750: loss = 2.04538122e-01 lambda = [9.785334 9.953134]\n",
            "It 19800: loss = 2.04537600e-01 lambda = [9.785238 9.953134]\n",
            "It 19850: loss = 2.04537049e-01 lambda = [9.785143 9.953134]\n",
            "It 19900: loss = 2.04536512e-01 lambda = [9.785048 9.953134]\n",
            "It 19950: loss = 2.04535991e-01 lambda = [9.784952 9.953134]\n",
            "It 20000: loss = 2.04535455e-01 lambda = [9.784857 9.953134]\n",
            "It 20050: loss = 2.04534918e-01 lambda = [9.784761 9.953134]\n",
            "It 20100: loss = 2.04534397e-01 lambda = [9.784666 9.953134]\n",
            "It 20150: loss = 2.04533875e-01 lambda = [9.784571 9.953134]\n",
            "It 20200: loss = 2.04533339e-01 lambda = [9.784475 9.953134]\n",
            "It 20250: loss = 2.04532787e-01 lambda = [9.78438  9.953134]\n",
            "It 20300: loss = 2.04532266e-01 lambda = [9.784285 9.953134]\n",
            "It 20350: loss = 2.04531729e-01 lambda = [9.784189 9.953134]\n",
            "It 20400: loss = 2.04531223e-01 lambda = [9.784094 9.953134]\n",
            "It 20450: loss = 2.04530686e-01 lambda = [9.7839985 9.953134 ]\n",
            "It 20500: loss = 2.04530135e-01 lambda = [9.783903 9.953134]\n",
            "It 20550: loss = 2.04529613e-01 lambda = [9.783808 9.953134]\n",
            "It 20600: loss = 2.04529107e-01 lambda = [9.783712 9.953134]\n",
            "It 20650: loss = 2.04528555e-01 lambda = [9.783617 9.953134]\n",
            "It 20700: loss = 2.04528019e-01 lambda = [9.783522 9.953134]\n",
            "It 20750: loss = 2.04527482e-01 lambda = [9.783426 9.953134]\n",
            "It 20800: loss = 2.04526991e-01 lambda = [9.783331 9.953134]\n",
            "It 20850: loss = 2.04526439e-01 lambda = [9.783236 9.953134]\n",
            "It 20900: loss = 2.04525903e-01 lambda = [9.78314  9.953134]\n",
            "It 20950: loss = 2.04525366e-01 lambda = [9.783045 9.953134]\n",
            "It 21000: loss = 2.04524875e-01 lambda = [9.782949 9.953134]\n",
            "It 21050: loss = 2.04524338e-01 lambda = [9.782854 9.953134]\n",
            "It 21100: loss = 2.04523802e-01 lambda = [9.782759 9.953134]\n",
            "It 21150: loss = 2.04523265e-01 lambda = [9.782663 9.953134]\n",
            "It 21200: loss = 2.04522759e-01 lambda = [9.782568 9.953134]\n",
            "It 21250: loss = 2.04522237e-01 lambda = [9.782473 9.953134]\n",
            "It 21300: loss = 2.04521701e-01 lambda = [9.782377 9.953134]\n",
            "It 21350: loss = 2.04521164e-01 lambda = [9.782282 9.953134]\n",
            "It 21400: loss = 2.04520658e-01 lambda = [9.7821865 9.953134 ]\n",
            "It 21450: loss = 2.04520151e-01 lambda = [9.782091 9.953134]\n",
            "It 21500: loss = 2.04519600e-01 lambda = [9.781996 9.953134]\n",
            "It 21550: loss = 2.04519063e-01 lambda = [9.7819   9.953134]\n",
            "It 21600: loss = 2.04518557e-01 lambda = [9.781805 9.953134]\n",
            "It 21650: loss = 2.04518035e-01 lambda = [9.78171  9.953134]\n",
            "It 21700: loss = 2.04517499e-01 lambda = [9.781614 9.953134]\n",
            "It 21750: loss = 2.04516992e-01 lambda = [9.781519 9.953134]\n",
            "It 21800: loss = 2.04516470e-01 lambda = [9.781424 9.953134]\n",
            "It 21850: loss = 2.04515934e-01 lambda = [9.781328 9.953134]\n",
            "It 21900: loss = 2.04515412e-01 lambda = [9.781233 9.953134]\n",
            "It 21950: loss = 2.04514906e-01 lambda = [9.781137 9.953134]\n",
            "It 22000: loss = 2.04514354e-01 lambda = [9.781042 9.953134]\n",
            "It 22050: loss = 2.04513863e-01 lambda = [9.780947 9.953134]\n",
            "It 22100: loss = 2.04513326e-01 lambda = [9.780851 9.953134]\n",
            "It 22150: loss = 2.04512805e-01 lambda = [9.780756 9.953134]\n",
            "It 22200: loss = 2.04512283e-01 lambda = [9.780661 9.953134]\n",
            "It 22250: loss = 2.04511762e-01 lambda = [9.780565 9.953134]\n",
            "It 22300: loss = 2.04511255e-01 lambda = [9.78047  9.953134]\n",
            "It 22350: loss = 2.04510704e-01 lambda = [9.780375 9.953134]\n",
            "It 22400: loss = 2.04510182e-01 lambda = [9.780279 9.953134]\n",
            "It 22450: loss = 2.04509676e-01 lambda = [9.780184 9.953134]\n",
            "It 22500: loss = 2.04509184e-01 lambda = [9.780088 9.953134]\n",
            "It 22550: loss = 2.04508647e-01 lambda = [9.779993 9.953134]\n",
            "It 22600: loss = 2.04508126e-01 lambda = [9.779898 9.953134]\n",
            "It 22650: loss = 2.04507619e-01 lambda = [9.779802 9.953134]\n",
            "It 22700: loss = 2.04507113e-01 lambda = [9.779707 9.953134]\n",
            "It 22750: loss = 2.04506591e-01 lambda = [9.779612 9.953134]\n",
            "It 22800: loss = 2.04506055e-01 lambda = [9.779516 9.953134]\n",
            "It 22850: loss = 2.04505533e-01 lambda = [9.779421 9.953134]\n",
            "It 22900: loss = 2.04505026e-01 lambda = [9.7793255 9.953134 ]\n",
            "It 22950: loss = 2.04504505e-01 lambda = [9.77923  9.953134]\n",
            "It 23000: loss = 2.04503998e-01 lambda = [9.779135 9.953134]\n",
            "It 23050: loss = 2.04503477e-01 lambda = [9.779039 9.953134]\n",
            "It 23100: loss = 2.04502970e-01 lambda = [9.778944 9.953134]\n",
            "It 23150: loss = 2.04502434e-01 lambda = [9.778849 9.953134]\n",
            "It 23200: loss = 2.04501927e-01 lambda = [9.778753 9.953134]\n",
            "It 23250: loss = 2.04501420e-01 lambda = [9.778658 9.953134]\n",
            "It 23300: loss = 2.04500929e-01 lambda = [9.778563 9.953134]\n",
            "It 23350: loss = 2.04500377e-01 lambda = [9.778467 9.953134]\n",
            "It 23400: loss = 2.04499885e-01 lambda = [9.778372 9.953134]\n",
            "It 23450: loss = 2.04499379e-01 lambda = [9.778276 9.953134]\n",
            "Timeout is reached. Time elapsed: 100.00289964675903 seconds\n",
            "\n",
            "\n",
            "Adam\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: loss = 5.12106061e-01 lambda = [9.900025 9.904515]\n",
            "It 00050: loss = 2.18880460e-01 lambda = [9.273044 9.714351]\n",
            "It 00100: loss = 2.01865658e-01 lambda = [9.120582  3.6683886]\n",
            "It 00150: loss = 1.89907089e-01 lambda = [ 8.756675 -4.134025]\n",
            "It 00200: loss = 1.54978037e-01 lambda = [  8.069231 -11.832001]\n",
            "It 00250: loss = 1.68886542e-01 lambda = [  7.255049 -15.711786]\n",
            "It 00300: loss = 1.29516378e-01 lambda = [  6.5600405 -16.396397 ]\n",
            "It 00350: loss = 1.25575840e-01 lambda = [  6.087735 -16.58662 ]\n",
            "It 00400: loss = 1.13611966e-01 lambda = [  5.5199933 -16.505013 ]\n",
            "It 00450: loss = 1.12422340e-01 lambda = [  5.125391 -16.185938]\n",
            "It 00500: loss = 1.09910019e-01 lambda = [  4.850765 -15.724521]\n",
            "It 00550: loss = 1.06962845e-01 lambda = [  4.5447974 -15.25381  ]\n",
            "It 00600: loss = 1.49395019e-01 lambda = [  4.31928  -14.771311]\n",
            "It 00650: loss = 1.05776832e-01 lambda = [  3.7687132 -14.371838 ]\n",
            "It 00700: loss = 1.04328915e-01 lambda = [  3.6057875 -13.850196 ]\n",
            "It 00750: loss = 1.03244200e-01 lambda = [  3.4370527 -13.377976 ]\n",
            "It 00800: loss = 1.02244638e-01 lambda = [  3.2568018 -12.909625 ]\n",
            "It 00850: loss = 1.21776462e-01 lambda = [  3.062681 -12.443446]\n",
            "It 00900: loss = 1.01142623e-01 lambda = [  2.7107775 -12.015827 ]\n",
            "It 00950: loss = 9.97341424e-02 lambda = [  2.5234993 -11.563877 ]\n",
            "It 01000: loss = 9.86844003e-02 lambda = [  2.330308 -11.147819]\n",
            "It 01050: loss = 9.79092717e-02 lambda = [  2.1253104 -10.766179 ]\n",
            "It 01100: loss = 9.72751528e-02 lambda = [  1.918562 -10.39001 ]\n",
            "It 01150: loss = 9.78904366e-02 lambda = [ 1.6859888 -9.994267 ]\n",
            "It 01200: loss = 9.62947980e-02 lambda = [ 1.471818 -9.591782]\n",
            "It 01250: loss = 9.57447886e-02 lambda = [ 1.2606308 -9.173957 ]\n",
            "It 01300: loss = 9.51889157e-02 lambda = [ 1.0385737 -8.737451 ]\n",
            "It 01350: loss = 9.45624337e-02 lambda = [ 0.7996229 -8.259186 ]\n",
            "It 01400: loss = 9.37875435e-02 lambda = [ 0.53385  -7.709259]\n",
            "It 01450: loss = 9.27697867e-02 lambda = [ 0.2252029 -7.070149 ]\n",
            "It 01500: loss = 9.14088488e-02 lambda = [-0.1403957 -6.350142 ]\n",
            "It 01550: loss = 9.13783014e-02 lambda = [-0.55261695 -5.54809   ]\n",
            "It 01600: loss = 8.76789019e-02 lambda = [-1.00238   -4.8545218]\n",
            "It 01650: loss = 8.48208442e-02 lambda = [-1.4747552 -4.0517173]\n",
            "It 01700: loss = 8.16730186e-02 lambda = [-1.9463723 -3.3437767]\n",
            "It 01750: loss = 7.97338858e-02 lambda = [-2.2794237 -2.9021807]\n",
            "It 01800: loss = 7.67600015e-02 lambda = [-2.5895152 -2.2691257]\n",
            "It 01850: loss = 7.70824105e-02 lambda = [-2.798324  -2.1176147]\n",
            "It 01900: loss = 7.47387409e-02 lambda = [-2.9259295 -2.0726192]\n",
            "It 01950: loss = 7.42415488e-02 lambda = [-2.9718332 -2.0366263]\n",
            "It 02000: loss = 7.49867857e-02 lambda = [-2.9514031 -2.0031254]\n",
            "It 02050: loss = 7.36136883e-02 lambda = [-2.9817193 -2.003971 ]\n",
            "It 02100: loss = 7.33200088e-02 lambda = [-3.0059528 -1.9809307]\n",
            "It 02150: loss = 7.30667785e-02 lambda = [-3.019198  -1.9639148]\n",
            "It 02200: loss = 7.77107701e-02 lambda = [-3.0277197 -1.9516299]\n",
            "It 02250: loss = 7.26541579e-02 lambda = [-3.0233617 -1.942321 ]\n",
            "It 02300: loss = 7.24313334e-02 lambda = [-3.0431006 -1.9310616]\n",
            "It 02350: loss = 7.22239316e-02 lambda = [-3.0537198 -1.9203348]\n",
            "It 02400: loss = 7.20168427e-02 lambda = [-3.0624804 -1.9109796]\n",
            "It 02450: loss = 7.23359138e-02 lambda = [-3.043345  -1.8988458]\n",
            "It 02500: loss = 7.16650188e-02 lambda = [-3.062616 -1.904809]\n",
            "It 02550: loss = 7.14812055e-02 lambda = [-3.0775626 -1.8979475]\n",
            "It 02600: loss = 7.13206083e-02 lambda = [-3.0856068 -1.8927798]\n",
            "It 02650: loss = 7.11729452e-02 lambda = [-3.092317 -1.887418]\n",
            "It 02700: loss = 7.10713863e-02 lambda = [-3.0742872 -1.8757747]\n",
            "It 02750: loss = 7.09460974e-02 lambda = [-3.0942788 -1.8799584]\n",
            "It 02800: loss = 7.08229914e-02 lambda = [-3.1066175 -1.8706541]\n",
            "It 02850: loss = 7.07083046e-02 lambda = [-3.1148646 -1.8618169]\n",
            "It 02900: loss = 7.05971196e-02 lambda = [-3.1222012 -1.8524594]\n",
            "It 02950: loss = 7.04885125e-02 lambda = [-3.1294105 -1.8423737]\n",
            "It 03000: loss = 7.05415010e-02 lambda = [-3.119159  -1.8285649]\n",
            "It 03050: loss = 7.03470632e-02 lambda = [-3.1298857 -1.828346 ]\n",
            "It 03100: loss = 7.02943206e-02 lambda = [-3.138011  -1.8235761]\n",
            "It 03150: loss = 7.02404305e-02 lambda = [-3.1436307 -1.8173554]\n",
            "It 03200: loss = 7.01850951e-02 lambda = [-3.1484973 -1.8107414]\n",
            "It 03250: loss = 7.01280832e-02 lambda = [-3.1531084 -1.8037376]\n",
            "It 03300: loss = 7.00691417e-02 lambda = [-3.157696 -1.79629 ]\n",
            "It 03350: loss = 7.00081363e-02 lambda = [-3.1623864 -1.7883364]\n",
            "It 03400: loss = 6.99447691e-02 lambda = [-3.1672575 -1.7798097]\n",
            "It 03450: loss = 6.98787048e-02 lambda = [-3.172367  -1.7706336]\n",
            "It 03500: loss = 6.98096603e-02 lambda = [-3.1777663 -1.7607181]\n",
            "It 03550: loss = 6.97372034e-02 lambda = [-3.18351 -1.74995]\n",
            "It 03600: loss = 6.96607530e-02 lambda = [-3.1896617 -1.7381862]\n",
            "It 03650: loss = 6.95797056e-02 lambda = [-3.196304  -1.7252392]\n",
            "It 03700: loss = 6.94930926e-02 lambda = [-3.2035453 -1.7108632]\n",
            "It 03750: loss = 6.93997443e-02 lambda = [-3.2115254 -1.6947316]\n",
            "It 03800: loss = 6.92978352e-02 lambda = [-3.2204282 -1.6764121]\n",
            "It 03850: loss = 6.91848472e-02 lambda = [-3.2304883 -1.6553344]\n",
            "It 03900: loss = 6.90586343e-02 lambda = [-3.2420177 -1.6308024]\n",
            "It 03950: loss = 6.89419955e-02 lambda = [-3.2442312 -1.6059682]\n",
            "It 04000: loss = 6.87734410e-02 lambda = [-3.2639472 -1.5791305]\n",
            "It 04050: loss = 6.85756356e-02 lambda = [-3.2798102 -1.5449873]\n",
            "It 04100: loss = 6.83266148e-02 lambda = [-3.2953901 -1.504258 ]\n",
            "It 04150: loss = 6.81770965e-02 lambda = [-3.2924306 -1.4606208]\n",
            "It 04200: loss = 6.77594766e-02 lambda = [-3.3188956 -1.4152514]\n",
            "It 04250: loss = 6.74435124e-02 lambda = [-3.3404152 -1.3617721]\n",
            "It 04300: loss = 6.71390295e-02 lambda = [-3.3672762 -1.3119047]\n",
            "It 04350: loss = 6.71810582e-02 lambda = [-3.3975666 -1.2716566]\n",
            "It 04400: loss = 6.66470751e-02 lambda = [-3.4133344 -1.2408608]\n",
            "It 04450: loss = 6.63872808e-02 lambda = [-3.442045  -1.2157692]\n",
            "It 04500: loss = 6.61565140e-02 lambda = [-3.4598582 -1.1942358]\n",
            "It 04550: loss = 6.59209564e-02 lambda = [-3.4728682 -1.1755435]\n",
            "It 04600: loss = 6.63553774e-02 lambda = [-3.4717643 -1.15642  ]\n",
            "It 04650: loss = 6.54557645e-02 lambda = [-3.4831944 -1.1435266]\n",
            "It 04700: loss = 6.51998073e-02 lambda = [-3.4966207 -1.1280205]\n",
            "It 04750: loss = 6.49268478e-02 lambda = [-3.5051076 -1.1106046]\n",
            "It 04800: loss = 6.46214187e-02 lambda = [-3.514835  -1.0899744]\n",
            "It 04850: loss = 6.47730753e-02 lambda = [-3.5274708 -1.063408 ]\n",
            "It 04900: loss = 6.38576299e-02 lambda = [-3.5442832 -1.0244652]\n",
            "It 04950: loss = 6.31986186e-02 lambda = [-3.5779603 -0.9677368]\n",
            "It 05000: loss = 6.25653565e-02 lambda = [-3.6225436 -0.9229929]\n",
            "It 05050: loss = 6.17547482e-02 lambda = [-3.6721406 -0.8951317]\n",
            "It 05100: loss = 6.12250566e-02 lambda = [-3.6916249  -0.87107736]\n",
            "It 05150: loss = 6.21399879e-02 lambda = [-3.6990771 -0.8528815]\n",
            "It 05200: loss = 6.03557602e-02 lambda = [-3.6981277  -0.84107924]\n",
            "It 05250: loss = 6.07601665e-02 lambda = [-3.692699   -0.83053607]\n",
            "It 05300: loss = 5.97819984e-02 lambda = [-3.6935558  -0.82691795]\n",
            "It 05350: loss = 5.95933311e-02 lambda = [-3.692083  -0.8213368]\n",
            "It 05400: loss = 5.93964234e-02 lambda = [-3.6836627  -0.81851876]\n",
            "It 05450: loss = 5.91979921e-02 lambda = [-3.6838698 -0.8136034]\n",
            "It 05500: loss = 5.92673756e-02 lambda = [-3.6830952 -0.8099872]\n",
            "It 05550: loss = 5.88424541e-02 lambda = [-3.678156   -0.80654144]\n",
            "It 05600: loss = 5.88419139e-02 lambda = [-3.676631  -0.8023562]\n",
            "It 05650: loss = 5.89637458e-02 lambda = [-3.6769557 -0.7979857]\n",
            "It 05700: loss = 5.84351346e-02 lambda = [-3.6778686 -0.7959987]\n",
            "It 05750: loss = 5.82700148e-02 lambda = [-3.6760325  -0.79274714]\n",
            "It 05800: loss = 5.81745729e-02 lambda = [-3.67389   -0.7890255]\n",
            "It 05850: loss = 5.80924004e-02 lambda = [-3.6769145  -0.78603625]\n",
            "It 05900: loss = 5.78588285e-02 lambda = [-3.6740184  -0.78283995]\n",
            "It 05950: loss = 5.78341261e-02 lambda = [-3.6770527 -0.7809666]\n",
            "It 06000: loss = 5.79792522e-02 lambda = [-3.6796246 -0.7788241]\n",
            "It 06050: loss = 5.74843362e-02 lambda = [-3.676829   -0.77675426]\n",
            "It 06100: loss = 5.73275313e-02 lambda = [-3.6771643  -0.77470124]\n",
            "It 06150: loss = 5.71776442e-02 lambda = [-3.6745574  -0.77326983]\n",
            "It 06200: loss = 5.73689789e-02 lambda = [-3.6724863  -0.77146655]\n",
            "It 06250: loss = 5.68579733e-02 lambda = [-3.6692479 -0.769891 ]\n",
            "It 06300: loss = 5.68256043e-02 lambda = [-3.6659355 -0.7689428]\n",
            "It 06350: loss = 5.65137304e-02 lambda = [-3.6653554  -0.76869094]\n",
            "It 06400: loss = 5.63517362e-02 lambda = [-3.6494493  -0.76874405]\n",
            "It 06450: loss = 5.61729521e-02 lambda = [-3.6506174 -0.7683894]\n",
            "It 06500: loss = 5.59846982e-02 lambda = [-3.6454573  -0.76834756]\n",
            "It 06550: loss = 5.57707846e-02 lambda = [-3.6394649  -0.76755047]\n",
            "It 06600: loss = 5.59169799e-02 lambda = [-3.6297417 -0.766848 ]\n",
            "It 06650: loss = 5.53934090e-02 lambda = [-3.6245005 -0.7666139]\n",
            "It 06700: loss = 5.53449132e-02 lambda = [-3.6113594  -0.76608795]\n",
            "It 06750: loss = 5.58452085e-02 lambda = [-3.6105835 -0.7637032]\n",
            "It 06800: loss = 5.48837371e-02 lambda = [-3.609869  -0.7631751]\n",
            "It 06850: loss = 5.49594238e-02 lambda = [-3.6052635 -0.7621477]\n",
            "It 06900: loss = 5.46097681e-02 lambda = [-3.6069129  -0.75981796]\n",
            "It 06950: loss = 5.44966385e-02 lambda = [-3.6022332 -0.7586754]\n",
            "It 07000: loss = 5.43787107e-02 lambda = [-3.604864  -0.7568397]\n",
            "It 07050: loss = 5.42697348e-02 lambda = [-3.6058025 -0.7557205]\n",
            "It 07100: loss = 5.42051606e-02 lambda = [-3.6063066  -0.75467825]\n",
            "It 07150: loss = 5.41401058e-02 lambda = [-3.606651  -0.7537305]\n",
            "It 07200: loss = 5.40744513e-02 lambda = [-3.606852  -0.7528263]\n",
            "It 07250: loss = 5.40081561e-02 lambda = [-3.6069283 -0.7519478]\n",
            "It 07300: loss = 5.39410487e-02 lambda = [-3.6068926 -0.7510893]\n",
            "It 07350: loss = 5.38730882e-02 lambda = [-3.6067476 -0.7502498]\n",
            "It 07400: loss = 5.38041368e-02 lambda = [-3.6064878  -0.74943113]\n",
            "It 07450: loss = 5.37340157e-02 lambda = [-3.6061056  -0.74863625]\n",
            "It 07500: loss = 5.36626056e-02 lambda = [-3.60559    -0.74786985]\n",
            "It 07550: loss = 5.35897948e-02 lambda = [-3.6049306  -0.74713707]\n",
            "It 07600: loss = 5.35153262e-02 lambda = [-3.6041157  -0.74644446]\n",
            "It 07650: loss = 5.34390993e-02 lambda = [-3.6031342 -0.7457993]\n",
            "It 07700: loss = 5.33609279e-02 lambda = [-3.6019733 -0.7452094]\n",
            "It 07750: loss = 5.32805510e-02 lambda = [-3.600627  -0.7446822]\n",
            "It 07800: loss = 5.31978160e-02 lambda = [-3.5990894  -0.74422705]\n",
            "It 07850: loss = 5.31124435e-02 lambda = [-3.5973608 -0.7438523]\n",
            "It 07900: loss = 5.30241281e-02 lambda = [-3.595447   -0.74356866]\n",
            "It 07950: loss = 5.29324040e-02 lambda = [-3.5933561 -0.7433892]\n",
            "It 08000: loss = 5.29823005e-02 lambda = [-3.5905383 -0.742583 ]\n",
            "It 08050: loss = 5.27484715e-02 lambda = [-3.588947   -0.74355763]\n",
            "It 08100: loss = 5.26502430e-02 lambda = [-3.586765  -0.7436669]\n",
            "It 08150: loss = 5.25462478e-02 lambda = [-3.5844882 -0.7440931]\n",
            "It 08200: loss = 5.27747013e-02 lambda = [-3.5807428 -0.7437347]\n",
            "It 08250: loss = 5.23277372e-02 lambda = [-3.5795596  -0.74572027]\n",
            "It 08300: loss = 5.22063375e-02 lambda = [-3.5776765 -0.7466851]\n",
            "It 08350: loss = 5.20736836e-02 lambda = [-3.5756783 -0.7479316]\n",
            "It 08400: loss = 5.22967204e-02 lambda = [-3.5726104 -0.7486116]\n",
            "It 08450: loss = 5.17969690e-02 lambda = [-3.5720315 -0.7507905]\n",
            "It 08500: loss = 5.16512468e-02 lambda = [-3.570934   -0.75216424]\n",
            "It 08550: loss = 5.18419445e-02 lambda = [-3.568564   -0.75330806]\n",
            "It 08600: loss = 5.15950173e-02 lambda = [-3.5679407 -0.755349 ]\n",
            "It 08650: loss = 5.12257740e-02 lambda = [-3.5673506 -0.7566075]\n",
            "It 08700: loss = 5.10949939e-02 lambda = [-3.5666068 -0.7578115]\n",
            "It 08750: loss = 5.09832427e-02 lambda = [-3.5652952 -0.7590569]\n",
            "It 08800: loss = 5.08523174e-02 lambda = [-3.5640335  -0.76003206]\n",
            "It 08850: loss = 5.07738926e-02 lambda = [-3.560918  -0.7612304]\n",
            "It 08900: loss = 5.06643057e-02 lambda = [-3.5593624 -0.7618292]\n",
            "It 08950: loss = 5.05331643e-02 lambda = [-3.5576828 -0.7626187]\n",
            "It 09000: loss = 5.04739024e-02 lambda = [-3.5549753 -0.7627815]\n",
            "It 09050: loss = 5.03650680e-02 lambda = [-3.5529642  -0.76365674]\n",
            "It 09100: loss = 5.02525382e-02 lambda = [-3.5495377  -0.76415455]\n",
            "It 09150: loss = 5.01729287e-02 lambda = [-3.5468338  -0.76427525]\n",
            "It 09200: loss = 5.00719137e-02 lambda = [-3.544086   -0.76450825]\n",
            "It 09250: loss = 4.99843508e-02 lambda = [-3.539611  -0.7648072]\n",
            "It 09300: loss = 4.99267057e-02 lambda = [-3.5364702  -0.76463354]\n",
            "It 09350: loss = 4.98080403e-02 lambda = [-3.5332801  -0.76475203]\n",
            "It 09400: loss = 4.97230478e-02 lambda = [-3.529648   -0.76473385]\n",
            "It 09450: loss = 4.96580303e-02 lambda = [-3.52475   -0.7647773]\n",
            "It 09500: loss = 4.95718308e-02 lambda = [-3.5201006  -0.76448584]\n",
            "It 09550: loss = 4.94509079e-02 lambda = [-3.5160627  -0.76434153]\n",
            "It 09600: loss = 4.94416617e-02 lambda = [-3.5103688 -0.7640358]\n",
            "It 09650: loss = 4.96133752e-02 lambda = [-3.5052607  -0.76417667]\n",
            "It 09700: loss = 4.91702631e-02 lambda = [-3.4991353 -0.7637587]\n",
            "It 09750: loss = 4.90741171e-02 lambda = [-3.493735  -0.7634161]\n",
            "It 09800: loss = 4.89854105e-02 lambda = [-3.4875488 -0.7631126]\n",
            "It 09850: loss = 4.88763452e-02 lambda = [-3.4794643 -0.7631014]\n",
            "It 09900: loss = 4.88821045e-02 lambda = [-3.472759   -0.76235425]\n",
            "It 09950: loss = 4.86651547e-02 lambda = [-3.4668663  -0.76213634]\n",
            "It 10000: loss = 4.86965291e-02 lambda = [-3.460483  -0.7610975]\n",
            "It 10050: loss = 4.84473631e-02 lambda = [-3.4551876 -0.7599261]\n",
            "It 10100: loss = 4.83456962e-02 lambda = [-3.4500933  -0.75808775]\n",
            "It 10150: loss = 4.82498333e-02 lambda = [-3.4446237 -0.7562552]\n",
            "It 10200: loss = 4.81479019e-02 lambda = [-3.4400322 -0.7543025]\n",
            "It 10250: loss = 4.80088070e-02 lambda = [-3.4349082 -0.7520073]\n",
            "It 10300: loss = 4.79328148e-02 lambda = [-3.429872   -0.74955434]\n",
            "It 10350: loss = 4.77926880e-02 lambda = [-3.4259236  -0.74705434]\n",
            "It 10400: loss = 4.76787239e-02 lambda = [-3.4212978 -0.7444273]\n",
            "It 10450: loss = 4.75642756e-02 lambda = [-3.4180794  -0.74127907]\n",
            "It 10500: loss = 4.74811345e-02 lambda = [-3.4146068  -0.73771816]\n",
            "It 10550: loss = 4.73194234e-02 lambda = [-3.4103103  -0.73416334]\n",
            "It 10600: loss = 4.71985638e-02 lambda = [-3.406938 -0.730024]\n",
            "It 10650: loss = 4.70606163e-02 lambda = [-3.4047003 -0.7254427]\n",
            "It 10700: loss = 4.70035598e-02 lambda = [-3.4022942 -0.7203075]\n",
            "It 10750: loss = 4.67998534e-02 lambda = [-3.3993628  -0.71551925]\n",
            "It 10800: loss = 4.67082188e-02 lambda = [-3.397284  -0.7104345]\n",
            "It 10850: loss = 4.65328507e-02 lambda = [-3.395805  -0.7060261]\n",
            "It 10900: loss = 4.78046387e-02 lambda = [-3.3937955  -0.70178026]\n",
            "It 10950: loss = 4.62883636e-02 lambda = [-3.390742  -0.6977179]\n",
            "It 11000: loss = 4.62443829e-02 lambda = [-3.3886492 -0.6936627]\n",
            "It 11050: loss = 4.60382849e-02 lambda = [-3.3867354  -0.69024444]\n",
            "It 11100: loss = 4.59141769e-02 lambda = [-3.384396   -0.68667835]\n",
            "It 11150: loss = 4.58979867e-02 lambda = [-3.3794475 -0.6835152]\n",
            "It 11200: loss = 4.56758998e-02 lambda = [-3.378525 -0.680248]\n",
            "It 11250: loss = 4.55745384e-02 lambda = [-3.3763006  -0.67679954]\n",
            "It 11300: loss = 4.54342403e-02 lambda = [-3.3740673 -0.6737514]\n",
            "It 11350: loss = 4.53074425e-02 lambda = [-3.3716786 -0.6705016]\n",
            "It 11400: loss = 4.52797040e-02 lambda = [-3.3689387 -0.6669094]\n",
            "It 11450: loss = 4.50543612e-02 lambda = [-3.3668067 -0.6639659]\n",
            "It 11500: loss = 4.51570228e-02 lambda = [-3.3634617  -0.66046125]\n",
            "It 11550: loss = 4.47877012e-02 lambda = [-3.3611457  -0.65761685]\n",
            "It 11600: loss = 4.46408987e-02 lambda = [-3.3599088 -0.6541253]\n",
            "It 11650: loss = 4.47231606e-02 lambda = [-3.3583107  -0.65062445]\n",
            "It 11700: loss = 4.43296544e-02 lambda = [-3.3551042 -0.6468158]\n",
            "It 11750: loss = 4.41565886e-02 lambda = [-3.3543866  -0.64292914]\n",
            "It 11800: loss = 4.43477854e-02 lambda = [-3.352086   -0.63846165]\n",
            "It 11850: loss = 4.37783785e-02 lambda = [-3.3511722  -0.63485664]\n",
            "It 11900: loss = 4.36405316e-02 lambda = [-3.3489766 -0.6304256]\n",
            "It 11950: loss = 4.33603786e-02 lambda = [-3.3490565 -0.6266917]\n",
            "It 12000: loss = 4.31332141e-02 lambda = [-3.3486223  -0.62259907]\n",
            "It 12050: loss = 4.30943742e-02 lambda = [-3.34647    -0.61840934]\n",
            "It 12100: loss = 4.26627249e-02 lambda = [-3.3454607  -0.61525077]\n",
            "It 12150: loss = 4.25019599e-02 lambda = [-3.3456788 -0.6117094]\n",
            "It 12200: loss = 4.21701670e-02 lambda = [-3.344808  -0.6086252]\n",
            "It 12250: loss = 4.19008285e-02 lambda = [-3.344473 -0.605832]\n",
            "It 12300: loss = 4.19064462e-02 lambda = [-3.3426518 -0.6030423]\n",
            "It 12350: loss = 4.13828157e-02 lambda = [-3.3430731  -0.60111237]\n",
            "It 12400: loss = 4.11208346e-02 lambda = [-3.343284  -0.5990833]\n",
            "It 12450: loss = 4.09104601e-02 lambda = [-3.3424194 -0.5974284]\n",
            "It 12500: loss = 4.06839587e-02 lambda = [-3.341711  -0.5956913]\n",
            "It 12550: loss = 4.03893031e-02 lambda = [-3.3425264  -0.59469503]\n",
            "It 12600: loss = 4.02731523e-02 lambda = [-3.343056  -0.5935977]\n",
            "It 12650: loss = 3.99643444e-02 lambda = [-3.3419673  -0.59252024]\n",
            "It 12700: loss = 3.97424027e-02 lambda = [-3.342645  -0.5915149]\n",
            "It 12750: loss = 3.95550355e-02 lambda = [-3.3419151 -0.5903287]\n",
            "It 12800: loss = 3.94878685e-02 lambda = [-3.3411562 -0.5898408]\n",
            "It 12850: loss = 3.91801968e-02 lambda = [-3.3411126  -0.58966565]\n",
            "It 12900: loss = 3.90154123e-02 lambda = [-3.3410592  -0.58921695]\n",
            "It 12950: loss = 3.88321914e-02 lambda = [-3.3395696  -0.58889574]\n",
            "It 13000: loss = 3.86598855e-02 lambda = [-3.339335   -0.58862543]\n",
            "It 13050: loss = 3.85392681e-02 lambda = [-3.3382225 -0.5882933]\n",
            "It 13100: loss = 3.84649038e-02 lambda = [-3.3365874 -0.5883859]\n",
            "It 13150: loss = 3.81664820e-02 lambda = [-3.3356938 -0.5885063]\n",
            "It 13200: loss = 3.80121730e-02 lambda = [-3.3343701 -0.5885689]\n",
            "It 13250: loss = 3.83533537e-02 lambda = [-3.3327582  -0.58828783]\n",
            "It 13300: loss = 3.76844928e-02 lambda = [-3.3308637 -0.588893 ]\n",
            "It 13350: loss = 3.75896543e-02 lambda = [-3.3297942  -0.58862865]\n",
            "It 13400: loss = 3.73860486e-02 lambda = [-3.328439   -0.58925444]\n",
            "It 13450: loss = 3.71802747e-02 lambda = [-3.3263814 -0.5895131]\n",
            "It 13500: loss = 3.70258912e-02 lambda = [-3.3249683 -0.5897749]\n",
            "It 13550: loss = 3.68152708e-02 lambda = [-3.3228319 -0.5899832]\n",
            "It 13600: loss = 3.70964967e-02 lambda = [-3.3208349  -0.58998364]\n",
            "It 13650: loss = 3.64196040e-02 lambda = [-3.3194895 -0.5900158]\n",
            "It 13700: loss = 3.63093019e-02 lambda = [-3.318566  -0.5892446]\n",
            "It 13750: loss = 3.60172391e-02 lambda = [-3.3178911  -0.58957434]\n",
            "It 13800: loss = 3.58202979e-02 lambda = [-3.316035   -0.58932924]\n",
            "It 13850: loss = 3.55911329e-02 lambda = [-3.3159745 -0.5891648]\n",
            "It 13900: loss = 3.53673771e-02 lambda = [-3.3154888  -0.58882415]\n",
            "It 13950: loss = 3.51377502e-02 lambda = [-3.3147433 -0.5884934]\n",
            "It 14000: loss = 3.56026627e-02 lambda = [-3.313747   -0.58760834]\n",
            "It 14050: loss = 3.47356349e-02 lambda = [-3.3136113  -0.58788854]\n",
            "It 14100: loss = 3.45994346e-02 lambda = [-3.3134403  -0.58763504]\n",
            "It 14150: loss = 3.44565511e-02 lambda = [-3.313185  -0.5873936]\n",
            "It 14200: loss = 3.43053266e-02 lambda = [-3.3129153  -0.58713156]\n",
            "It 14250: loss = 3.41448784e-02 lambda = [-3.312679   -0.58683413]\n",
            "It 14300: loss = 3.39742675e-02 lambda = [-3.3125188 -0.5864873]\n",
            "It 14350: loss = 3.37932780e-02 lambda = [-3.3124666  -0.58608437]\n",
            "It 14400: loss = 3.36023308e-02 lambda = [-3.3124857 -0.5856488]\n",
            "It 14450: loss = 3.34014148e-02 lambda = [-3.3124595  -0.58523285]\n",
            "It 14500: loss = 3.31900753e-02 lambda = [-3.3122792 -0.5848649]\n",
            "It 14550: loss = 3.29676233e-02 lambda = [-3.3118942  -0.58454585]\n",
            "It 14600: loss = 3.27337310e-02 lambda = [-3.3112977  -0.58427656]\n",
            "It 14650: loss = 3.24879512e-02 lambda = [-3.3104877 -0.5840657]\n",
            "It 14700: loss = 3.22300494e-02 lambda = [-3.309451   -0.58392775]\n",
            "It 14750: loss = 3.19597125e-02 lambda = [-3.3081546 -0.5838837]\n",
            "It 14800: loss = 3.16769965e-02 lambda = [-3.306546  -0.5839619]\n",
            "It 14850: loss = 3.13822627e-02 lambda = [-3.3045502  -0.58419794]\n",
            "It 14900: loss = 3.10760364e-02 lambda = [-3.3020802  -0.58463496]\n",
            "It 14950: loss = 3.07593234e-02 lambda = [-3.2990484 -0.5853213]\n",
            "It 15000: loss = 3.04405615e-02 lambda = [-3.2954104  -0.58616376]\n",
            "It 15050: loss = 3.01085413e-02 lambda = [-3.2911923  -0.58759576]\n",
            "It 15100: loss = 2.97749750e-02 lambda = [-3.2863991  -0.58928376]\n",
            "It 15150: loss = 2.94518061e-02 lambda = [-3.2810624 -0.5910178]\n",
            "It 15200: loss = 2.91105732e-02 lambda = [-3.2754483 -0.5936736]\n",
            "It 15250: loss = 2.87850127e-02 lambda = [-3.2694185 -0.5963918]\n",
            "It 15300: loss = 2.84751803e-02 lambda = [-3.263457  -0.5992724]\n",
            "It 15350: loss = 2.81723216e-02 lambda = [-3.2573001  -0.60233593]\n",
            "It 15400: loss = 2.79068723e-02 lambda = [-3.2512388  -0.60525614]\n",
            "It 15450: loss = 2.76323743e-02 lambda = [-3.2455442 -0.6085036]\n",
            "It 15500: loss = 2.73876414e-02 lambda = [-3.239735  -0.6116144]\n",
            "It 15550: loss = 2.71757767e-02 lambda = [-3.2344358 -0.6144542]\n",
            "It 15600: loss = 2.69618090e-02 lambda = [-3.2290967  -0.61733663]\n",
            "It 15650: loss = 2.67684907e-02 lambda = [-3.2237737 -0.6201533]\n",
            "It 15700: loss = 2.65943799e-02 lambda = [-3.2188237 -0.6226997]\n",
            "It 15750: loss = 2.64264438e-02 lambda = [-3.2140603  -0.62523836]\n",
            "It 15800: loss = 2.62742806e-02 lambda = [-3.209381  -0.6276647]\n",
            "It 15850: loss = 2.61218064e-02 lambda = [-3.2044728 -0.6300655]\n",
            "It 15900: loss = 2.59994082e-02 lambda = [-3.1999907 -0.6321253]\n",
            "It 15950: loss = 2.58525107e-02 lambda = [-3.1955345 -0.6344081]\n",
            "It 16000: loss = 2.57240124e-02 lambda = [-3.1909823  -0.63656414]\n",
            "It 16050: loss = 2.60651037e-02 lambda = [-3.186363 -0.637826]\n",
            "It 16100: loss = 2.54889615e-02 lambda = [-3.1826985  -0.64044505]\n",
            "It 16150: loss = 2.53735930e-02 lambda = [-3.1782665  -0.64238983]\n",
            "It 16200: loss = 2.54043639e-02 lambda = [-3.1738698  -0.64414155]\n",
            "It 16250: loss = 2.51570791e-02 lambda = [-3.1702638 -0.6460174]\n",
            "It 16300: loss = 2.50507519e-02 lambda = [-3.1664004 -0.6477853]\n",
            "It 16350: loss = 2.49549095e-02 lambda = [-3.162827 -0.649192]\n",
            "It 16400: loss = 2.48457771e-02 lambda = [-3.1591146 -0.6510711]\n",
            "It 16450: loss = 2.49164756e-02 lambda = [-3.1554782 -0.652838 ]\n",
            "It 16500: loss = 2.46505924e-02 lambda = [-3.1520596 -0.6542423]\n",
            "It 16550: loss = 2.45678537e-02 lambda = [-3.1487641  -0.65533394]\n",
            "It 16600: loss = 2.44544055e-02 lambda = [-3.145563 -0.657238]\n",
            "It 16650: loss = 2.43942775e-02 lambda = [-3.1421926 -0.6580733]\n",
            "It 16700: loss = 2.42653042e-02 lambda = [-3.1392686 -0.6600313]\n",
            "It 16750: loss = 2.42195725e-02 lambda = [-3.1357322 -0.661156 ]\n",
            "It 16800: loss = 2.42170133e-02 lambda = [-3.1331694  -0.66256815]\n",
            "It 16850: loss = 2.39929706e-02 lambda = [-3.130527  -0.6638964]\n",
            "It 16900: loss = 2.39219237e-02 lambda = [-3.1277983  -0.66483796]\n",
            "It 16950: loss = 2.38222107e-02 lambda = [-3.1250892 -0.6662003]\n",
            "It 17000: loss = 2.37411633e-02 lambda = [-3.1225321 -0.6672616]\n",
            "It 17050: loss = 2.36591455e-02 lambda = [-3.120324  -0.6681643]\n",
            "It 17100: loss = 2.35998742e-02 lambda = [-3.1177537 -0.6692527]\n",
            "It 17150: loss = 2.34976877e-02 lambda = [-3.1158566 -0.6701417]\n",
            "It 17200: loss = 2.34120898e-02 lambda = [-3.1136408 -0.6709875]\n",
            "It 17250: loss = 2.33431719e-02 lambda = [-3.1118796 -0.6715428]\n",
            "It 17300: loss = 2.32605767e-02 lambda = [-3.1097589 -0.6725022]\n",
            "It 17350: loss = 2.32300218e-02 lambda = [-3.1076257 -0.6728405]\n",
            "It 17400: loss = 2.31151972e-02 lambda = [-3.1062224 -0.6738763]\n",
            "It 17450: loss = 2.31927447e-02 lambda = [-3.1046073 -0.6736598]\n",
            "It 17500: loss = 2.29736716e-02 lambda = [-3.1032426 -0.674994 ]\n",
            "It 17550: loss = 2.29326729e-02 lambda = [-3.1014445 -0.6754193]\n",
            "It 17600: loss = 2.28362046e-02 lambda = [-3.1001844  -0.67605716]\n",
            "It 17650: loss = 2.27968283e-02 lambda = [-3.0990777 -0.6761498]\n",
            "It 17700: loss = 2.27016378e-02 lambda = [-3.097852   -0.67685467]\n",
            "It 17750: loss = 2.26358920e-02 lambda = [-3.096598  -0.6771574]\n",
            "It 17800: loss = 2.25986261e-02 lambda = [-3.0957623 -0.6770207]\n",
            "It 17850: loss = 2.25100443e-02 lambda = [-3.0948312  -0.67773575]\n",
            "It 17900: loss = 2.24515703e-02 lambda = [-3.0940413 -0.6779069]\n",
            "It 17950: loss = 2.23774239e-02 lambda = [-3.0931435 -0.6781857]\n",
            "It 18000: loss = 2.23160721e-02 lambda = [-3.0928302  -0.67817426]\n",
            "It 18050: loss = 2.23108493e-02 lambda = [-3.0914965 -0.6780126]\n",
            "It 18100: loss = 2.21857913e-02 lambda = [-3.0911977  -0.67852074]\n",
            "It 18150: loss = 2.21220367e-02 lambda = [-3.0904477 -0.6786478]\n",
            "It 18200: loss = 2.20856797e-02 lambda = [-3.0901997 -0.6782923]\n",
            "It 18250: loss = 2.19954848e-02 lambda = [-3.0894856  -0.67859864]\n",
            "It 18300: loss = 2.20189728e-02 lambda = [-3.0884614  -0.67812526]\n",
            "It 18350: loss = 2.18703654e-02 lambda = [-3.0884178 -0.6785761]\n",
            "It 18400: loss = 2.18451284e-02 lambda = [-3.0877914  -0.67853296]\n",
            "It 18450: loss = 2.17442345e-02 lambda = [-3.0876667 -0.6783376]\n",
            "It 18500: loss = 2.16764659e-02 lambda = [-3.0868497  -0.67831314]\n",
            "It 18550: loss = 2.16243491e-02 lambda = [-3.0862837 -0.6779236]\n",
            "It 18600: loss = 2.15490460e-02 lambda = [-3.0856616  -0.67805403]\n",
            "It 18650: loss = 2.14880332e-02 lambda = [-3.0852447 -0.6777693]\n",
            "It 18700: loss = 2.14588400e-02 lambda = [-3.084169  -0.6774421]\n",
            "It 18750: loss = 2.13525631e-02 lambda = [-3.0836608 -0.677573 ]\n",
            "It 18800: loss = 2.12990027e-02 lambda = [-3.083068  -0.6771173]\n",
            "It 18850: loss = 2.13498510e-02 lambda = [-3.0820246 -0.6769702]\n",
            "It 18900: loss = 2.11832691e-02 lambda = [-3.0814154 -0.6769818]\n",
            "It 18950: loss = 2.10995171e-02 lambda = [-3.0807757  -0.67680186]\n",
            "It 19000: loss = 2.10320950e-02 lambda = [-3.0797107 -0.6766806]\n",
            "It 19050: loss = 2.09527779e-02 lambda = [-3.0790417 -0.6764815]\n",
            "It 19100: loss = 2.10637171e-02 lambda = [-3.0776715 -0.6758435]\n",
            "It 19150: loss = 2.08249371e-02 lambda = [-3.0769613 -0.6763532]\n",
            "It 19200: loss = 2.08231043e-02 lambda = [-3.0757778 -0.6754585]\n",
            "It 19250: loss = 2.07042694e-02 lambda = [-3.0748296 -0.6762407]\n",
            "It 19300: loss = 2.06456054e-02 lambda = [-3.0732625 -0.6762778]\n",
            "It 19350: loss = 2.05826126e-02 lambda = [-3.0719187  -0.67645025]\n",
            "It 19400: loss = 2.05249581e-02 lambda = [-3.0710444 -0.6762307]\n",
            "It 19450: loss = 2.04645768e-02 lambda = [-3.069353   -0.67655414]\n",
            "It 19500: loss = 2.04379465e-02 lambda = [-3.067547  -0.6766034]\n",
            "It 19550: loss = 2.07608920e-02 lambda = [-3.0662897 -0.6767028]\n",
            "It 19600: loss = 2.03052722e-02 lambda = [-3.0653543 -0.6768231]\n",
            "It 19650: loss = 2.02463530e-02 lambda = [-3.063338  -0.6772074]\n",
            "It 19700: loss = 2.02318691e-02 lambda = [-3.0614958 -0.6775601]\n",
            "It 19750: loss = 2.01428086e-02 lambda = [-3.059962   -0.67752266]\n",
            "It 19800: loss = 2.00879015e-02 lambda = [-3.0580647 -0.6779221]\n",
            "It 19850: loss = 2.00434830e-02 lambda = [-3.0565648  -0.67793816]\n",
            "It 19900: loss = 2.00071335e-02 lambda = [-3.054329  -0.6783803]\n",
            "It 19950: loss = 1.99383944e-02 lambda = [-3.0526323 -0.6786305]\n",
            "It 20000: loss = 1.98847111e-02 lambda = [-3.050647   -0.67903495]\n",
            "It 20050: loss = 1.98482592e-02 lambda = [-3.0493515 -0.6787208]\n",
            "It 20100: loss = 1.97881050e-02 lambda = [-3.047194  -0.6794486]\n",
            "It 20150: loss = 1.97394826e-02 lambda = [-3.0448291 -0.6799166]\n",
            "It 20200: loss = 1.97046790e-02 lambda = [-3.0428843 -0.6800343]\n",
            "It 20250: loss = 1.96442772e-02 lambda = [-3.0409734  -0.68054986]\n",
            "It 20300: loss = 1.96183752e-02 lambda = [-3.0390644  -0.68024063]\n",
            "It 20350: loss = 1.95508171e-02 lambda = [-3.0371149  -0.68112475]\n",
            "It 20400: loss = 1.95638705e-02 lambda = [-3.0345654 -0.6808174]\n",
            "It 20450: loss = 1.94594543e-02 lambda = [-3.0328753 -0.6817932]\n",
            "It 20500: loss = 1.94744039e-02 lambda = [-3.0308762  -0.68116057]\n",
            "It 20550: loss = 1.93727799e-02 lambda = [-3.0288913 -0.682354 ]\n",
            "It 20600: loss = 1.93282105e-02 lambda = [-3.026626  -0.6827248]\n",
            "It 20650: loss = 1.93289220e-02 lambda = [-3.0244224  -0.68243504]\n",
            "It 20700: loss = 1.92422085e-02 lambda = [-3.022673   -0.68337405]\n",
            "It 20750: loss = 1.92211717e-02 lambda = [-3.0205169  -0.68320405]\n",
            "It 20800: loss = 1.96055919e-02 lambda = [-3.018404 -0.683688]\n",
            "It 20850: loss = 1.91182010e-02 lambda = [-3.016926  -0.6841853]\n",
            "It 20900: loss = 1.90774910e-02 lambda = [-3.0147033 -0.6846463]\n",
            "It 20950: loss = 1.90420803e-02 lambda = [-3.013109  -0.6846936]\n",
            "It 21000: loss = 1.90430656e-02 lambda = [-3.0108054 -0.6849591]\n",
            "It 21050: loss = 1.90058872e-02 lambda = [-3.0089278 -0.6854388]\n",
            "It 21100: loss = 1.89299248e-02 lambda = [-3.0073025  -0.68567157]\n",
            "It 21150: loss = 1.89532265e-02 lambda = [-3.0051541  -0.68580663]\n",
            "It 21200: loss = 1.88515931e-02 lambda = [-3.003887  -0.6860931]\n",
            "It 21250: loss = 1.88246276e-02 lambda = [-3.001886   -0.68653756]\n",
            "It 21300: loss = 1.87797826e-02 lambda = [-3.0005524  -0.68657136]\n",
            "It 21350: loss = 1.87689569e-02 lambda = [-2.9984732 -0.687079 ]\n",
            "It 21400: loss = 1.87124368e-02 lambda = [-2.9967945  -0.68723565]\n",
            "It 21450: loss = 1.86930969e-02 lambda = [-2.9951806  -0.68712777]\n",
            "It 21500: loss = 1.86364613e-02 lambda = [-2.993468  -0.6877511]\n",
            "It 21550: loss = 1.86372176e-02 lambda = [-2.9919693 -0.687689 ]\n",
            "It 21600: loss = 1.85688585e-02 lambda = [-2.9902756 -0.6882126]\n",
            "It 21650: loss = 1.85429063e-02 lambda = [-2.9886532  -0.68847793]\n",
            "It 21700: loss = 1.85577925e-02 lambda = [-2.986936  -0.6878467]\n",
            "It 21750: loss = 1.84651222e-02 lambda = [-2.9855933 -0.688829 ]\n",
            "It 21800: loss = 1.91307329e-02 lambda = [-2.9833846 -0.6886655]\n",
            "It 21850: loss = 1.84002817e-02 lambda = [-2.9825337  -0.68925107]\n",
            "It 21900: loss = 1.84158273e-02 lambda = [-2.9806657  -0.68960667]\n",
            "It 21950: loss = 1.83362495e-02 lambda = [-2.9795046 -0.6896604]\n",
            "It 22000: loss = 1.83047876e-02 lambda = [-2.9774709 -0.6900466]\n",
            "It 22050: loss = 1.82760637e-02 lambda = [-2.9764628  -0.69005567]\n",
            "It 22100: loss = 1.82381570e-02 lambda = [-2.974754  -0.6904129]\n",
            "It 22150: loss = 1.83242373e-02 lambda = [-2.9730575  -0.69064254]\n",
            "It 22200: loss = 1.81794204e-02 lambda = [-2.9724145 -0.6905612]\n",
            "It 22250: loss = 1.81439929e-02 lambda = [-2.970314  -0.6910296]\n",
            "It 22300: loss = 1.81122255e-02 lambda = [-2.9684858 -0.6914051]\n",
            "It 22350: loss = 1.80996545e-02 lambda = [-2.9674215 -0.6912606]\n",
            "It 22400: loss = 1.80509798e-02 lambda = [-2.9658728 -0.6916985]\n",
            "It 22450: loss = 1.80218909e-02 lambda = [-2.964125  -0.6920336]\n",
            "It 22500: loss = 1.80048700e-02 lambda = [-2.9632957  -0.69183123]\n",
            "It 22550: loss = 1.79586858e-02 lambda = [-2.961342  -0.6923635]\n",
            "It 22600: loss = 1.81217175e-02 lambda = [-2.959344  -0.6918015]\n",
            "It 22650: loss = 1.78993996e-02 lambda = [-2.9585009 -0.6927632]\n",
            "Timeout is reached. Time elapsed: 100.0008635520935 seconds\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_models = 5\n",
        "timeout = 100\n",
        "initial_lambdas = [[0.0, 0.0], [1.0, -6.0], [10.0, 10.0]]\n",
        "path = dir + \"/model weights/kdv_eqn_inv\"\n",
        "\n",
        "old_timeout = timeout\n",
        "models_LBFGS = [None] * n_models\n",
        "models_SGD = [None] * n_models\n",
        "models_Adam = [None] * n_models\n",
        "hists_LBFGS = [None] * n_models\n",
        "hists_SGD = [None] * n_models\n",
        "hists_Adam = [None] * n_models\n",
        "\n",
        "\n",
        "for i in range(n_models):\n",
        "  timeout = old_timeout\n",
        "  models_LBFGS[i] = []\n",
        "  models_SGD[i] = []\n",
        "  models_Adam[i] = []\n",
        "  hists_LBFGS[i] = []\n",
        "  hists_SGD[i] = []\n",
        "  hists_Adam[i] = []\n",
        "\n",
        "  for j in range(len(initial_lambdas)):\n",
        "    print('{:s}\\nIteration: {:d} Initial lambda: {}\\n{:s}'.format(50*'-',i+1,initial_lambdas[j],50*'-'))\n",
        "    # Prepare models' architecture\n",
        "    models_LBFGS[i].append(pinn.PINN_IdentificationNet(initial_lambda=initial_lambdas[j], lb=lb, ub=ub, **arch))\n",
        "    models_SGD[i].append(pinn.PINN_IdentificationNet(initial_lambda=initial_lambdas[j], lb=lb, ub=ub, **arch))\n",
        "    models_Adam[i].append(pinn.PINN_IdentificationNet(initial_lambda=initial_lambdas[j], lb=lb, ub=ub, **arch))\n",
        "\n",
        "    models_LBFGS[i][j].build((None, 2))\n",
        "    models_SGD[i][j].build((None, 2))\n",
        "    models_Adam[i][j].build((None, 2))\n",
        "\n",
        "    # Copy weights from the previous model instance to make every iteration comparable\n",
        "    models_LBFGS[i][j].set_weights(models[i].get_weights())\n",
        "    models_SGD[i][j].set_weights(models[i].get_weights())\n",
        "    models_Adam[i][j].set_weights(models[i].get_weights())\n",
        "\n",
        "    # Assigning initial lambda\n",
        "    models_LBFGS[i][j].trainable_variables[-1].assign(initial_lambdas[j])\n",
        "    models_SGD[i][j].trainable_variables[-1].assign(initial_lambdas[j])\n",
        "    models_Adam[i][j].trainable_variables[-1].assign(initial_lambdas[j])\n",
        "\n",
        "    # Prepare optimizer\n",
        "    optim_SGD = tf.keras.optimizers.SGD(learning_rate=lr_comb)\n",
        "    optim_Adam = tf.keras.optimizers.Adam(learning_rate=lr_comb)\n",
        "\n",
        "    # Initialize solver\n",
        "    solver_LBFGS = pinn.PINN_IdentificationSolver(models_LBFGS[i][j], X_d, fun_r, get_r)\n",
        "    solver_SGD = pinn.PINN_IdentificationSolver(models_SGD[i][j], X_d, fun_r, get_r)\n",
        "    solver_Adam = pinn.PINN_IdentificationSolver(models_Adam[i][j], X_d, fun_r, get_r)\n",
        "\n",
        "    # Train models\n",
        "    print('\\n\\nL-BFGS\\n')\n",
        "    solver_LBFGS.solve_with_ScipyOptimizer(X_param, u_param,\n",
        "                                          timeout=timeout,\n",
        "                                          method='L-BFGS-B')\n",
        "    print('\\n\\nSGD\\n')\n",
        "    solver_SGD.solve_with_TFoptimizer(optim_SGD, X_param, u_param, timeout=timeout)\n",
        "    print('\\n\\nAdam\\n')\n",
        "    solver_Adam.solve_with_TFoptimizer(optim_Adam, X_param, u_param, timeout=timeout)\n",
        "\n",
        "    # Store evolution of lambdas and hists\n",
        "    hists_LBFGS[i].append(np.array([models_LBFGS[i][j].lambd_list, solver_LBFGS.hist]))\n",
        "    hists_SGD[i].append(np.array([models_SGD[i][j].lambd_list, solver_SGD.hist]))\n",
        "    hists_Adam[i].append(np.array([models_Adam[i][j].lambd_list, solver_Adam.hist]))\n",
        "\n",
        "    hists_LBFGS[i][j] = np.column_stack((np.stack(hists_LBFGS[i][j][0], axis=0), hists_LBFGS[i][j][1]))\n",
        "    hists_SGD[i][j] = np.column_stack((np.stack(hists_SGD[i][j][0], axis=0), hists_SGD[i][j][1]))\n",
        "    hists_Adam[i][j] = np.column_stack((np.stack(hists_Adam[i][j][0], axis=0), hists_Adam[i][j][1]))\n",
        "\n",
        "    print('\\n\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sKE475lI4_4"
      },
      "source": [
        "### Exporting the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKlLNRj-I4_4"
      },
      "source": [
        "Export the weights and biases obtained during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvKnvzNlI4_4"
      },
      "outputs": [],
      "source": [
        "path = dir + \"/model weights/kdv_eqn_inv\"\n",
        "\n",
        "for i in range(n_models):\n",
        "  for j in range(len(initial_lambdas)):\n",
        "    models_LBFGS[i][j].save_weights(path+\"_\"+str(i)+\"/model_LBFGS_\"+str(j)+\".h5\", 'h5')\n",
        "    models_SGD[i][j].save_weights(path+\"_\"+str(i)+\"/model_SGD_\"+str(j)+\".h5\", 'h5')\n",
        "    models_Adam[i][j].save_weights(path+\"_\"+str(i)+\"/model_Adam_\"+str(j)+\".h5\", 'h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr2PgTitI4_5"
      },
      "source": [
        "Export the training loss progression as `hist`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLn7j4e7I4_5"
      },
      "outputs": [],
      "source": [
        "for i in range(n_models):\n",
        "  for j in range(len(initial_lambdas)):\n",
        "    np.savetxt(path+\"_\"+str(i)+\"/loss and param/hist_LBFGS_\"+str(j)+\".txt\", hists_LBFGS[i][j])\n",
        "    np.savetxt(path+\"_\"+str(i)+\"/loss and param/hist_SGD_\"+str(j)+\".txt\", hists_SGD[i][j])\n",
        "    np.savetxt(path+\"_\"+str(i)+\"/loss and param/hist_Adam_\"+str(j)+\".txt\", hists_Adam[i][j])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPKeFwzBO0lG"
      },
      "source": [
        "### Importing the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7HWsyOHO0lH"
      },
      "outputs": [],
      "source": [
        "n_models = 5\n",
        "timeout = 100\n",
        "initial_lambdas = [[0.0, 0.0], [1.0, -6.0], [10.0, 10.0]]\n",
        "path = dir + \"/model weights/kdv_eqn_inv\"\n",
        "\n",
        "models_LBFGS = [None] * n_models\n",
        "models_SGD = [None] * n_models\n",
        "models_Adam = [None] * n_models\n",
        "hists_LBFGS = [None] * n_models\n",
        "hists_SGD = [None] * n_models\n",
        "hists_Adam = [None] * n_models\n",
        "\n",
        "for i in range(n_models):\n",
        "  models_LBFGS[i] = []\n",
        "  models_SGD[i] = []\n",
        "  models_Adam[i] = []\n",
        "  hists_LBFGS[i] = []\n",
        "  hists_SGD[i] = []\n",
        "  hists_Adam[i] = []\n",
        "\n",
        "  for j in range(len(initial_lambdas)):\n",
        "    models_LBFGS[i].append(pinn.PINN_IdentificationNet(initial_lambda=initial_lambdas[j], lb=lb, ub=ub, **arch))\n",
        "    models_SGD[i].append(pinn.PINN_IdentificationNet(initial_lambda=initial_lambdas[j], lb=lb, ub=ub, **arch))\n",
        "    models_Adam[i].append(pinn.PINN_IdentificationNet(initial_lambda=initial_lambdas[j], lb=lb, ub=ub, **arch))\n",
        "\n",
        "    models_LBFGS[i][j].build((None, 2))\n",
        "    models_SGD[i][j].build((None, 2))\n",
        "    models_Adam[i][j].build((None, 2))\n",
        "\n",
        "    models_LBFGS[i][j].load_weights(path+\"_\"+str(i)+\"/model_LBFGS_\"+str(j)+\".h5\", 'h5')\n",
        "    models_SGD[i][j].load_weights(path+\"_\"+str(i)+\"/model_SGD_\"+str(j)+\".h5\", 'h5')\n",
        "    models_Adam[i][j].load_weights(path+\"_\"+str(i)+\"/model_Adam_\"+str(j)+\".h5\", 'h5')\n",
        "\n",
        "    hists_LBFGS[i].append(np.loadtxt(path+\"_\"+str(i)+\"/loss and param/hist_LBFGS_\"+str(j)+\".txt\"))\n",
        "    hists_SGD[i].append(np.loadtxt(path+\"_\"+str(i)+\"/loss and param/hist_SGD_\"+str(j)+\".txt\"))\n",
        "    hists_Adam[i].append(np.loadtxt(path+\"_\"+str(i)+\"/loss and param/hist_Adam_\"+str(j)+\".txt\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Iy7rGlcQkUe"
      },
      "source": [
        "## Prediction Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEi9ITO6RhJW"
      },
      "outputs": [],
      "source": [
        "def lambdas(hists, iter_model, iter_init, lambd_init, N=500):\n",
        "  return sum(hists[iter_model][iter_init][-N:,lambd_init]) / N\n",
        "\n",
        "cols = ['L-BFGS_0', 'L-BFGS_1',\n",
        "        'SGD_0', 'SGD_1',\n",
        "        'Adam_0', 'Adam_1']\n",
        "df1 = pd.DataFrame(columns = cols)\n",
        "df2 = pd.DataFrame(columns = cols)\n",
        "df3 = pd.DataFrame(columns = cols)\n",
        "\n",
        "for i in range(n_models):\n",
        "  x = []\n",
        "  x.append(lambdas(hists_LBFGS, i, 0, 0)); x.append(lambdas(hists_LBFGS, i, 0, 1))\n",
        "  x.append(lambdas(hists_SGD, i, 0, 0)); x.append(lambdas(hists_SGD, i, 0, 1))\n",
        "  x.append(lambdas(hists_Adam, i, 0, 0)); x.append(lambdas(hists_Adam, i, 0, 1))\n",
        "  df1.loc['Attempt '+str(i+1)] = x\n",
        "\n",
        "df1.loc['Average'] = df1.mean(axis=0)\n",
        "\n",
        "for i in range(n_models):\n",
        "  x = []\n",
        "  x.append(lambdas(hists_LBFGS, i, 1, 0)); x.append(lambdas(hists_LBFGS, i, 1, 1))\n",
        "  x.append(lambdas(hists_SGD, i, 1, 0)); x.append(lambdas(hists_SGD, i, 1, 1))\n",
        "  x.append(lambdas(hists_Adam, i, 1, 0)); x.append(lambdas(hists_Adam, i, 1, 1))\n",
        "  df2.loc['Attempt '+str(i+1)] = x\n",
        "\n",
        "df2.loc['Average'] = df2.mean(axis=0)\n",
        "\n",
        "for i in range(n_models):\n",
        "  x = []\n",
        "  x.append(lambdas(hists_LBFGS, i, 2, 0)); x.append(lambdas(hists_LBFGS, i, 2, 1))\n",
        "  x.append(lambdas(hists_SGD, i, 2, 0)); x.append(lambdas(hists_SGD, i, 2, 1))\n",
        "  x.append(lambdas(hists_Adam, i, 2, 0)); x.append(lambdas(hists_Adam, i, 2, 1))\n",
        "  df3.loc['Attempt '+str(i+1)] = x\n",
        "\n",
        "df3.loc['Average'] = df3.mean(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Qov71A-cxfI",
        "outputId": "deae2cd9-5a21-4000-8713-1c9585b73ec3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{lrrrrrr}\n",
            "\\hline\n",
            "           &   L-BFGS\\_0 &   L-BFGS\\_1 &   SGD\\_0 &   SGD\\_1 &   Adam\\_0 &   Adam\\_1 \\\\\n",
            "\\hline\n",
            " Attempt 1 &    -5.9888 &     0.9962 & -0.8925 & -0.5300 &  -6.0000 &   1.0000 \\\\\n",
            " Attempt 2 &    -5.9940 &     0.9976 & -0.8844 & -0.5951 &  -5.9998 &   1.0000 \\\\\n",
            " Attempt 3 &    -6.0031 &     1.0013 & -1.2734 & -0.8983 &  -6.0006 &   1.0002 \\\\\n",
            " Attempt 4 &    -6.0053 &     1.0022 & -1.4010 & -0.9241 &  -6.0000 &   1.0000 \\\\\n",
            " Attempt 5 &    -6.0674 &     1.0259 & -1.3908 & -0.9049 &  -6.0001 &   1.0000 \\\\\n",
            " Average   &    -6.0117 &     1.0046 & -1.1684 & -0.7705 &  -6.0001 &   1.0000 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "\\begin{tabular}{lrrrrrr}\n",
            "\\hline\n",
            "           &   L-BFGS\\_0 &   L-BFGS\\_1 &   SGD\\_0 &   SGD\\_1 &   Adam\\_0 &   Adam\\_1 \\\\\n",
            "\\hline\n",
            " Attempt 1 &    -3.8661 &    -0.7705 &  0.5554 & -6.0954 &  -5.9995 &   0.9998 \\\\\n",
            " Attempt 2 &    -3.8347 &    -0.8067 &  0.5511 & -6.0340 &  -5.9997 &   0.9999 \\\\\n",
            " Attempt 3 &    -3.7654 &    -0.8907 &  0.4996 & -6.0623 &  -5.9965 &   0.9988 \\\\\n",
            " Attempt 4 &    -3.7676 &    -0.9413 &  0.5148 & -6.0193 &  -5.9999 &   0.9999 \\\\\n",
            " Attempt 5 &    -3.7323 &    -1.0190 &  0.5056 & -6.0367 &  -6.0001 &   1.0000 \\\\\n",
            " Average   &    -3.7932 &    -0.8857 &  0.5253 & -6.0496 &  -5.9991 &   0.9997 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n",
            "\\begin{tabular}{lrrrrrr}\n",
            "\\hline\n",
            "           &   L-BFGS\\_0 &   L-BFGS\\_1 &   SGD\\_0 &   SGD\\_1 &   Adam\\_0 &   Adam\\_1 \\\\\n",
            "\\hline\n",
            " Attempt 1 &    -6.0088 &     1.0031 &  9.7769 &  9.9576 &  -2.5796 &  -0.5208 \\\\\n",
            " Attempt 2 &    -6.1571 &     1.0566 &  9.7814 &  9.9578 &  -3.6897 &  -0.6933 \\\\\n",
            " Attempt 3 &    -6.0129 &     1.0044 &  9.7891 &  9.9515 &  -3.3325 &  -0.4593 \\\\\n",
            " Attempt 4 &    -6.0064 &     1.0031 &  9.7838 &  9.9520 &  -2.9117 &  -1.1151 \\\\\n",
            " Attempt 5 &    -5.9624 &     0.9855 &  9.7787 &  9.9531 &  -2.9657 &  -0.6915 \\\\\n",
            " Average   &    -6.0295 &     1.0106 &  9.7820 &  9.9544 &  -3.0958 &  -0.6960 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n"
          ]
        }
      ],
      "source": [
        "print(tabulate(df1.round(4), headers='keys', tablefmt='latex', floatfmt=\"#.4f\"))\n",
        "print(tabulate(df2.round(4), headers='keys', tablefmt='latex', floatfmt=\"#.4f\"))\n",
        "print(tabulate(df3.round(4), headers='keys', tablefmt='latex', floatfmt=\"#.4f\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_shXnZex9ePp"
      },
      "source": [
        "## H-PINN Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeXoxfJtqiHw",
        "outputId": "4a21c258-e857-44d7-8541-f27f2763c386"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "Iteration: 1 Initial lambda: [0.0, 0.0]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Adam\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: l_u = 3.31840247e-01 loss = 3.31840247e-01\n",
            "It 00050: l_u = 3.36617045e-03 loss = 3.36617045e-03\n",
            "It 00100: l_u = 2.42268899e-03 loss = 2.42268899e-03\n",
            "It 00150: l_u = 1.05786276e-04 loss = 1.05786276e-04\n",
            "It 00200: l_u = 5.87090726e-05 loss = 5.87090726e-05\n",
            "It 00250: l_u = 3.57485333e-05 loss = 3.57485333e-05\n",
            "It 00300: l_u = 2.17353669e-03 loss = 2.17353669e-03\n",
            "It 00350: l_u = 2.79217784e-05 loss = 2.79217784e-05\n",
            "It 00400: l_u = 1.44473170e-05 loss = 1.44473170e-05\n",
            "It 00450: l_u = 1.09469902e-05 loss = 1.09469902e-05\n",
            "It 00500: l_u = 8.84935980e-06 loss = 8.84935980e-06\n",
            "It 00550: l_u = 7.50259142e-06 loss = 7.50259142e-06\n",
            "It 00600: l_u = 6.59669104e-06 loss = 6.59669104e-06\n",
            "It 00650: l_u = 5.95301708e-06 loss = 5.95301708e-06\n",
            "It 00700: l_u = 5.46838237e-06 loss = 5.46838237e-06\n",
            "It 00750: l_u = 5.08349149e-06 loss = 5.08349149e-06\n",
            "It 00800: l_u = 4.76473997e-06 loss = 4.76473997e-06\n",
            "It 00850: l_u = 4.49266781e-06 loss = 4.49266781e-06\n",
            "It 00900: l_u = 2.99481704e-04 loss = 2.99481704e-04\n",
            "It 00950: l_u = 1.50764126e-05 loss = 1.50764126e-05\n",
            "It 01000: l_u = 4.07072002e-06 loss = 4.07072002e-06\n",
            "It 01050: l_u = 3.81632753e-06 loss = 3.81632753e-06\n",
            "It 01100: l_u = 3.64062066e-06 loss = 3.64062066e-06\n",
            "It 01150: l_u = 3.48077469e-06 loss = 3.48077469e-06\n",
            "It 01200: l_u = 3.33360208e-06 loss = 3.33360208e-06\n",
            "It 01250: l_u = 3.19734909e-06 loss = 3.19734909e-06\n",
            "It 01300: l_u = 3.07047162e-06 loss = 3.07047162e-06\n",
            "It 01350: l_u = 2.95199902e-06 loss = 2.95199902e-06\n",
            "It 01400: l_u = 2.84106295e-06 loss = 2.84106295e-06\n",
            "It 01450: l_u = 2.73691558e-06 loss = 2.73691558e-06\n",
            "It 01500: l_u = 2.63897596e-06 loss = 2.63897596e-06\n",
            "It 01550: l_u = 2.54669635e-06 loss = 2.54669635e-06\n",
            "It 01600: l_u = 2.45966498e-06 loss = 2.45966498e-06\n",
            "It 01650: l_u = 2.37739641e-06 loss = 2.37739641e-06\n",
            "It 01700: l_u = 2.29960983e-06 loss = 2.29960983e-06\n",
            "It 01750: l_u = 2.22597646e-06 loss = 2.22597646e-06\n",
            "It 01800: l_u = 2.15621890e-06 loss = 2.15621890e-06\n",
            "It 01850: l_u = 2.09011660e-06 loss = 2.09011660e-06\n",
            "It 01900: l_u = 2.02740262e-06 loss = 2.02740262e-06\n",
            "It 01950: l_u = 1.96787937e-06 loss = 1.96787937e-06\n",
            "It 02000: l_u = 1.91130812e-06 loss = 1.91130812e-06\n",
            "It 02050: l_u = 1.85761337e-06 loss = 1.85761337e-06\n",
            "It 02100: l_u = 1.80656525e-06 loss = 1.80656525e-06\n",
            "It 02150: l_u = 1.75800426e-06 loss = 1.75800426e-06\n",
            "It 02200: l_u = 1.71181682e-06 loss = 1.71181682e-06\n",
            "It 02250: l_u = 1.66788311e-06 loss = 1.66788311e-06\n",
            "It 02300: l_u = 1.62599235e-06 loss = 1.62599235e-06\n",
            "It 02350: l_u = 1.58612409e-06 loss = 1.58612409e-06\n",
            "It 02400: l_u = 1.54811050e-06 loss = 1.54811050e-06\n",
            "It 02450: l_u = 1.51187135e-06 loss = 1.51187135e-06\n",
            "It 02500: l_u = 1.47727121e-06 loss = 1.47727121e-06\n",
            "It 02550: l_u = 1.44425621e-06 loss = 1.44425621e-06\n",
            "It 02600: l_u = 1.41277076e-06 loss = 1.41277076e-06\n",
            "It 02650: l_u = 1.38264602e-06 loss = 1.38264602e-06\n",
            "It 02700: l_u = 1.35384630e-06 loss = 1.35384630e-06\n",
            "It 02750: l_u = 1.32633988e-06 loss = 1.32633988e-06\n",
            "It 02800: l_u = 1.29998602e-06 loss = 1.29998602e-06\n",
            "It 02850: l_u = 1.27477540e-06 loss = 1.27477540e-06\n",
            "It 02900: l_u = 1.25060933e-06 loss = 1.25060933e-06\n",
            "It 02950: l_u = 1.22744791e-06 loss = 1.22744791e-06\n",
            "It 03000: l_u = 1.20522827e-06 loss = 1.20522827e-06\n",
            "It 03050: l_u = 1.19410470e-06 loss = 1.19410470e-06\n",
            "It 03100: l_u = 1.18309958e-06 loss = 1.18309958e-06\n",
            "It 03150: l_u = 1.17196191e-06 loss = 1.17196191e-06\n",
            "It 03200: l_u = 1.16073636e-06 loss = 1.16073636e-06\n",
            "It 03250: l_u = 1.14944817e-06 loss = 1.14944817e-06\n",
            "It 03300: l_u = 1.13806152e-06 loss = 1.13806152e-06\n",
            "It 03350: l_u = 1.12657096e-06 loss = 1.12657096e-06\n",
            "It 03400: l_u = 1.11500424e-06 loss = 1.11500424e-06\n",
            "It 03450: l_u = 1.10338988e-06 loss = 1.10338988e-06\n",
            "It 03500: l_u = 1.09162772e-06 loss = 1.09162772e-06\n",
            "It 03550: l_u = 1.07985750e-06 loss = 1.07985750e-06\n",
            "It 03600: l_u = 1.06798109e-06 loss = 1.06798109e-06\n",
            "It 03650: l_u = 1.05609433e-06 loss = 1.05609433e-06\n",
            "It 03700: l_u = 1.04409344e-06 loss = 1.04409344e-06\n",
            "It 03750: l_u = 1.03210823e-06 loss = 1.03210823e-06\n",
            "It 03800: l_u = 1.02002980e-06 loss = 1.02002980e-06\n",
            "It 03850: l_u = 1.00791794e-06 loss = 1.00791794e-06\n",
            "It 03900: l_u = 9.95783353e-07 loss = 9.95783353e-07\n",
            "It 03950: l_u = 9.83627501e-07 loss = 9.83627501e-07\n",
            "It 04000: l_u = 9.71405484e-07 loss = 9.71405484e-07\n",
            "It 04050: l_u = 9.59220074e-07 loss = 9.59220074e-07\n",
            "It 04100: l_u = 9.46962871e-07 loss = 9.46962871e-07\n",
            "It 04150: l_u = 9.34724028e-07 loss = 9.34724028e-07\n",
            "It 04200: l_u = 9.22467109e-07 loss = 9.22467109e-07\n",
            "It 04250: l_u = 9.10203198e-07 loss = 9.10203198e-07\n",
            "It 04300: l_u = 8.97983114e-07 loss = 8.97983114e-07\n",
            "It 04350: l_u = 8.85743248e-07 loss = 8.85743248e-07\n",
            "It 04400: l_u = 8.73553120e-07 loss = 8.73553120e-07\n",
            "It 04450: l_u = 8.61346393e-07 loss = 8.61346393e-07\n",
            "It 04500: l_u = 8.49161722e-07 loss = 8.49161722e-07\n",
            "It 04550: l_u = 8.37040318e-07 loss = 8.37040318e-07\n",
            "It 04600: l_u = 8.24931192e-07 loss = 8.24931192e-07\n",
            "It 04650: l_u = 8.12831786e-07 loss = 8.12831786e-07\n",
            "It 04700: l_u = 8.00829014e-07 loss = 8.00829014e-07\n",
            "It 04750: l_u = 7.88845796e-07 loss = 7.88845796e-07\n",
            "It 04800: l_u = 7.76956369e-07 loss = 7.76956369e-07\n",
            "It 04850: l_u = 7.65070638e-07 loss = 7.65070638e-07\n",
            "It 04900: l_u = 7.22755658e-06 loss = 7.22755658e-06\n",
            "It 04950: l_u = 1.89072546e-06 loss = 1.89072546e-06\n",
            "It 05000: l_u = 7.45628711e-07 loss = 7.45628711e-07\n",
            "It 05050: l_u = 7.17380431e-07 loss = 7.17380431e-07\n",
            "It 05100: l_u = 7.05917273e-07 loss = 7.05917273e-07\n",
            "It 05150: l_u = 6.94578603e-07 loss = 6.94578603e-07\n",
            "It 05200: l_u = 6.93505115e-07 loss = 6.93505115e-07\n",
            "It 05250: l_u = 6.78512333e-06 loss = 6.78512333e-06\n",
            "It 05300: l_u = 6.72659098e-07 loss = 6.72659098e-07\n",
            "It 05350: l_u = 6.49637400e-07 loss = 6.49637400e-07\n",
            "It 05400: l_u = 6.38403662e-07 loss = 6.38403662e-07\n",
            "It 05450: l_u = 6.27711415e-07 loss = 6.27711415e-07\n",
            "It 05500: l_u = 2.76420207e-04 loss = 2.76420207e-04\n",
            "It 05550: l_u = 1.93007645e-06 loss = 1.93007645e-06\n",
            "It 05600: l_u = 5.96054463e-07 loss = 5.96054463e-07\n",
            "It 05650: l_u = 5.85018313e-07 loss = 5.85018313e-07\n",
            "It 05700: l_u = 5.74775015e-07 loss = 5.74775015e-07\n",
            "It 05750: l_u = 5.64790412e-07 loss = 5.64790412e-07\n",
            "It 05800: l_u = 5.55362874e-07 loss = 5.55362874e-07\n",
            "It 05850: l_u = 1.69277591e-05 loss = 1.69277591e-05\n",
            "It 05900: l_u = 5.93803975e-07 loss = 5.93803975e-07\n",
            "It 05950: l_u = 5.26319695e-07 loss = 5.26319695e-07\n",
            "It 06000: l_u = 5.16057469e-07 loss = 5.16057469e-07\n",
            "It 06050: l_u = 5.06793299e-07 loss = 5.06793299e-07\n",
            "It 06100: l_u = 4.97719782e-07 loss = 4.97719782e-07\n",
            "It 06150: l_u = 4.92705913e-05 loss = 4.92705913e-05\n",
            "It 06200: l_u = 7.03583851e-07 loss = 7.03583851e-07\n",
            "It 06250: l_u = 4.74017526e-07 loss = 4.74017526e-07\n",
            "It 06300: l_u = 4.62641822e-07 loss = 4.62641822e-07\n",
            "It 06350: l_u = 4.54086518e-07 loss = 4.54086518e-07\n",
            "It 06400: l_u = 4.48131232e-07 loss = 4.48131232e-07\n",
            "It 06450: l_u = 7.88352281e-06 loss = 7.88352281e-06\n",
            "It 06500: l_u = 4.32791097e-07 loss = 4.32791097e-07\n",
            "It 06550: l_u = 4.22580257e-07 loss = 4.22580257e-07\n",
            "It 06600: l_u = 4.14380423e-07 loss = 4.14380423e-07\n",
            "It 06650: l_u = 4.06605068e-07 loss = 4.06605068e-07\n",
            "It 06700: l_u = 3.61919083e-05 loss = 3.61919083e-05\n",
            "It 06750: l_u = 1.96898554e-06 loss = 1.96898554e-06\n",
            "It 06800: l_u = 3.93343953e-07 loss = 3.93343953e-07\n",
            "It 06850: l_u = 3.78565460e-07 loss = 3.78565460e-07\n",
            "It 06900: l_u = 3.71140459e-07 loss = 3.71140459e-07\n",
            "It 06950: l_u = 3.64147752e-07 loss = 3.64147752e-07\n",
            "It 07000: l_u = 4.78217808e-05 loss = 4.78217808e-05\n",
            "It 07050: l_u = 4.05225109e-07 loss = 4.05225109e-07\n",
            "It 07100: l_u = 3.55406996e-07 loss = 3.55406996e-07\n",
            "It 07150: l_u = 3.50653920e-07 loss = 3.50653920e-07\n",
            "It 07200: l_u = 3.46507647e-07 loss = 3.46507647e-07\n",
            "It 07250: l_u = 3.42640703e-07 loss = 3.42640703e-07\n",
            "It 07300: l_u = 3.38937298e-07 loss = 3.38937298e-07\n",
            "It 07350: l_u = 3.35342378e-07 loss = 3.35342378e-07\n",
            "It 07400: l_u = 3.31821695e-07 loss = 3.31821695e-07\n",
            "It 07450: l_u = 3.28354105e-07 loss = 3.28354105e-07\n",
            "It 07500: l_u = 3.24929260e-07 loss = 3.24929260e-07\n",
            "It 07550: l_u = 3.21510754e-07 loss = 3.21510754e-07\n",
            "It 07600: l_u = 3.18112654e-07 loss = 3.18112654e-07\n",
            "It 07650: l_u = 3.14725241e-07 loss = 3.14725241e-07\n",
            "It 07700: l_u = 3.11349424e-07 loss = 3.11349424e-07\n",
            "It 07750: l_u = 3.07963774e-07 loss = 3.07963774e-07\n",
            "It 07800: l_u = 3.04590259e-07 loss = 3.04590259e-07\n",
            "It 07850: l_u = 3.01222883e-07 loss = 3.01222883e-07\n",
            "It 07900: l_u = 2.97851329e-07 loss = 2.97851329e-07\n",
            "It 07950: l_u = 2.94487222e-07 loss = 2.94487222e-07\n",
            "It 08000: l_u = 2.91124309e-07 loss = 2.91124309e-07\n",
            "It 08050: l_u = 2.87743092e-07 loss = 2.87743092e-07\n",
            "It 08100: l_u = 2.84377563e-07 loss = 2.84377563e-07\n",
            "It 08150: l_u = 2.81019254e-07 loss = 2.81019254e-07\n",
            "It 08200: l_u = 2.77638321e-07 loss = 2.77638321e-07\n",
            "It 08250: l_u = 2.74267450e-07 loss = 2.74267450e-07\n",
            "It 08300: l_u = 2.70891945e-07 loss = 2.70891945e-07\n",
            "It 08350: l_u = 2.67512576e-07 loss = 2.67512576e-07\n",
            "It 08400: l_u = 2.64145115e-07 loss = 2.64145115e-07\n",
            "It 08450: l_u = 2.60767905e-07 loss = 2.60767905e-07\n",
            "It 08500: l_u = 2.57390013e-07 loss = 2.57390013e-07\n",
            "It 08550: l_u = 2.54008626e-07 loss = 2.54008626e-07\n",
            "It 08600: l_u = 2.50649151e-07 loss = 2.50649151e-07\n",
            "It 08650: l_u = 2.74174681e-07 loss = 2.74174681e-07\n",
            "It 08700: l_u = 4.82947314e-07 loss = 4.82947314e-07\n",
            "It 08750: l_u = 2.45961559e-07 loss = 2.45961559e-07\n",
            "It 08800: l_u = 2.37749305e-07 loss = 2.37749305e-07\n",
            "It 08850: l_u = 2.91426488e-07 loss = 2.91426488e-07\n",
            "It 08900: l_u = 3.46449895e-07 loss = 3.46449895e-07\n",
            "It 08950: l_u = 2.28837195e-07 loss = 2.28837195e-07\n",
            "It 09000: l_u = 3.76212733e-06 loss = 3.76212733e-06\n",
            "It 09050: l_u = 1.60260549e-06 loss = 1.60260549e-06\n",
            "It 09100: l_u = 2.38068822e-07 loss = 2.38068822e-07\n",
            "It 09150: l_u = 2.58810906e-06 loss = 2.58810906e-06\n",
            "It 09200: l_u = 2.20052428e-07 loss = 2.20052428e-07\n",
            "It 09250: l_u = 4.44014859e-06 loss = 4.44014859e-06\n",
            "It 09300: l_u = 4.01040523e-07 loss = 4.01040523e-07\n",
            "It 09350: l_u = 2.06084394e-07 loss = 2.06084394e-07\n",
            "It 09400: l_u = 2.63904985e-05 loss = 2.63904985e-05\n",
            "It 09450: l_u = 3.05029744e-07 loss = 3.05029744e-07\n",
            "It 09500: l_u = 1.99434012e-07 loss = 1.99434012e-07\n",
            "It 09550: l_u = 3.49469786e-07 loss = 3.49469786e-07\n",
            "It 09600: l_u = 1.42465933e-06 loss = 1.42465933e-06\n",
            "It 09650: l_u = 1.95655559e-07 loss = 1.95655559e-07\n",
            "It 09700: l_u = 1.90379197e-07 loss = 1.90379197e-07\n",
            "It 09750: l_u = 4.05215928e-07 loss = 4.05215928e-07\n",
            "It 09800: l_u = 1.89676769e-07 loss = 1.89676769e-07\n",
            "It 09850: l_u = 1.81766310e-07 loss = 1.81766310e-07\n",
            "It 09900: l_u = 1.38504549e-06 loss = 1.38504549e-06\n",
            "It 09950: l_u = 4.91016863e-07 loss = 4.91016863e-07\n",
            "It 10000: l_u = 2.04537969e-07 loss = 2.04537969e-07\n",
            "Timeout is reached. Time elapsed: 20.00037169456482 seconds\n",
            "\n",
            "\n",
            "Finding PDE parameters.\n",
            "It 10050: loss = 2.95317960e-07 lambda = [-2.2607455  -0.18173459]\n",
            "It 10100: loss = 2.95317960e-07 lambda = [-4.3632574   0.49998456]\n",
            "It 10150: loss = 2.95317960e-07 lambda = [-5.448794   0.8283764]\n",
            "It 10200: loss = 2.95317960e-07 lambda = [-5.825376   0.9416594]\n",
            "It 10250: loss = 2.95317960e-07 lambda = [-5.91891     0.96967566]\n",
            "It 10300: loss = 2.95317960e-07 lambda = [-5.935699    0.97471166]\n",
            "It 10350: loss = 2.95317960e-07 lambda = [-5.9378223  0.9753484]\n",
            "It 10400: loss = 2.95317960e-07 lambda = [-5.9379935   0.97539985]\n",
            "It 10450: loss = 2.95317960e-07 lambda = [-5.9379973   0.97540104]\n",
            "It 10500: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 10550: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 10600: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 10650: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 10700: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 10750: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 10800: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 10850: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 10900: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 10950: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 11000: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 11050: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 11100: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 11150: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 11200: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 11250: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 11300: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 11350: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 11400: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 11450: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 11500: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 11550: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 11600: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 11650: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 11700: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 11750: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 11800: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 11850: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 11900: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 11950: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 12000: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 12050: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 12100: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 12150: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "It 12200: loss = 2.95317960e-07 lambda = [-5.9379973  0.975401 ]\n",
            "Timeout is reached. Time elapsed: 80.00701403617859 seconds\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration: 1 Initial lambda: [1.0, -6.0]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Adam\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It 00000: l_u = 3.31840247e-01 loss = 3.31840247e-01\n",
            "It 00050: l_u = 3.36616556e-03 loss = 3.36616556e-03\n",
            "It 00100: l_u = 2.42840126e-03 loss = 2.42840126e-03\n",
            "It 00150: l_u = 1.05467603e-04 loss = 1.05467603e-04\n",
            "It 00200: l_u = 5.87070172e-05 loss = 5.87070172e-05\n",
            "It 00250: l_u = 3.57601675e-05 loss = 3.57601675e-05\n",
            "It 00300: l_u = 1.41117442e-03 loss = 1.41117442e-03\n",
            "It 00350: l_u = 2.18808473e-05 loss = 2.18808473e-05\n",
            "It 00400: l_u = 1.43015322e-05 loss = 1.43015322e-05\n",
            "It 00450: l_u = 1.08932591e-05 loss = 1.08932591e-05\n",
            "It 00500: l_u = 8.80792322e-06 loss = 8.80792322e-06\n",
            "It 00550: l_u = 7.47248987e-06 loss = 7.47248987e-06\n",
            "It 00600: l_u = 6.57605597e-06 loss = 6.57605597e-06\n",
            "It 00650: l_u = 5.93977757e-06 loss = 5.93977757e-06\n",
            "It 00700: l_u = 5.46068031e-06 loss = 5.46068031e-06\n",
            "It 00750: l_u = 5.08015046e-06 loss = 5.08015046e-06\n",
            "It 00800: l_u = 4.76487276e-06 loss = 4.76487276e-06\n",
            "It 00850: l_u = 1.39109607e-05 loss = 1.39109607e-05\n",
            "It 00900: l_u = 8.97274294e-05 loss = 8.97274294e-05\n",
            "It 00950: l_u = 4.29744523e-06 loss = 4.29744523e-06\n",
            "It 01000: l_u = 4.05039100e-06 loss = 4.05039100e-06\n",
            "It 01050: l_u = 3.84834266e-06 loss = 3.84834266e-06\n",
            "It 01100: l_u = 3.66956647e-06 loss = 3.66956647e-06\n",
            "It 01150: l_u = 3.50654182e-06 loss = 3.50654182e-06\n",
            "It 01200: l_u = 3.35648656e-06 loss = 3.35648656e-06\n",
            "It 01250: l_u = 3.21748894e-06 loss = 3.21748894e-06\n",
            "It 01300: l_u = 3.08818699e-06 loss = 3.08818699e-06\n",
            "It 01350: l_u = 2.96752114e-06 loss = 2.96752114e-06\n",
            "It 01400: l_u = 2.85454689e-06 loss = 2.85454689e-06\n",
            "It 01450: l_u = 2.74854028e-06 loss = 2.74854028e-06\n",
            "It 01500: l_u = 2.64886899e-06 loss = 2.64886899e-06\n",
            "It 01550: l_u = 2.55501641e-06 loss = 2.55501641e-06\n",
            "It 01600: l_u = 2.46644618e-06 loss = 2.46644618e-06\n",
            "It 01650: l_u = 2.38283405e-06 loss = 2.38283405e-06\n",
            "It 01700: l_u = 2.30376781e-06 loss = 2.30376781e-06\n",
            "It 01750: l_u = 2.22897552e-06 loss = 2.22897552e-06\n",
            "It 01800: l_u = 2.15818295e-06 loss = 2.15818295e-06\n",
            "It 01850: l_u = 2.09105428e-06 loss = 2.09105428e-06\n",
            "It 01900: l_u = 2.02740216e-06 loss = 2.02740216e-06\n",
            "It 01950: l_u = 1.96703036e-06 loss = 1.96703036e-06\n",
            "It 02000: l_u = 1.90973356e-06 loss = 1.90973356e-06\n",
            "It 02050: l_u = 1.85535418e-06 loss = 1.85535418e-06\n",
            "It 02100: l_u = 1.80365282e-06 loss = 1.80365282e-06\n",
            "It 02150: l_u = 1.75451760e-06 loss = 1.75451760e-06\n",
            "It 02200: l_u = 1.70779504e-06 loss = 1.70779504e-06\n",
            "It 02250: l_u = 1.66336474e-06 loss = 1.66336474e-06\n",
            "It 02300: l_u = 1.62109700e-06 loss = 1.62109700e-06\n",
            "It 02350: l_u = 1.58082184e-06 loss = 1.58082184e-06\n",
            "It 02400: l_u = 1.54250029e-06 loss = 1.54250029e-06\n",
            "It 02450: l_u = 1.50593189e-06 loss = 1.50593189e-06\n",
            "It 02500: l_u = 1.47111177e-06 loss = 1.47111177e-06\n",
            "It 02550: l_u = 1.43784530e-06 loss = 1.43784530e-06\n",
            "It 02600: l_u = 1.40614316e-06 loss = 1.40614316e-06\n",
            "It 02650: l_u = 1.37588188e-06 loss = 1.37588188e-06\n",
            "It 02700: l_u = 1.34692493e-06 loss = 1.34692493e-06\n",
            "It 02750: l_u = 1.31929073e-06 loss = 1.31929073e-06\n",
            "It 02800: l_u = 1.29283490e-06 loss = 1.29283490e-06\n",
            "It 02850: l_u = 1.26751115e-06 loss = 1.26751115e-06\n",
            "It 02900: l_u = 1.24327300e-06 loss = 1.24327300e-06\n",
            "It 02950: l_u = 1.22004758e-06 loss = 1.22004758e-06\n",
            "It 03000: l_u = 1.19783567e-06 loss = 1.19783567e-06\n",
            "It 03050: l_u = 1.18667242e-06 loss = 1.18667242e-06\n",
            "It 03100: l_u = 1.17565946e-06 loss = 1.17565946e-06\n",
            "It 03150: l_u = 1.16451201e-06 loss = 1.16451201e-06\n",
            "It 03200: l_u = 1.15331693e-06 loss = 1.15331693e-06\n",
            "It 03250: l_u = 1.14198554e-06 loss = 1.14198554e-06\n",
            "It 03300: l_u = 1.13058604e-06 loss = 1.13058604e-06\n",
            "It 03350: l_u = 1.11908025e-06 loss = 1.11908025e-06\n",
            "It 03400: l_u = 1.10750932e-06 loss = 1.10750932e-06\n",
            "It 03450: l_u = 1.09590849e-06 loss = 1.09590849e-06\n",
            "It 03500: l_u = 1.08418055e-06 loss = 1.08418055e-06\n",
            "It 03550: l_u = 1.07240419e-06 loss = 1.07240419e-06\n",
            "It 03600: l_u = 1.06055938e-06 loss = 1.06055938e-06\n",
            "It 03650: l_u = 1.04864387e-06 loss = 1.04864387e-06\n",
            "It 03700: l_u = 1.03673392e-06 loss = 1.03673392e-06\n",
            "It 03750: l_u = 1.02472211e-06 loss = 1.02472211e-06\n",
            "It 03800: l_u = 1.01267119e-06 loss = 1.01267119e-06\n",
            "It 03850: l_u = 1.00061789e-06 loss = 1.00061789e-06\n",
            "It 03900: l_u = 9.88498414e-07 loss = 9.88498414e-07\n",
            "It 03950: l_u = 9.76379624e-07 loss = 9.76379624e-07\n",
            "It 04000: l_u = 9.64210926e-07 loss = 9.64210926e-07\n",
            "It 04050: l_u = 9.52064966e-07 loss = 9.52064966e-07\n",
            "It 04100: l_u = 9.39853749e-07 loss = 9.39853749e-07\n",
            "It 04150: l_u = 9.27683800e-07 loss = 9.27683800e-07\n",
            "It 04200: l_u = 9.15481678e-07 loss = 9.15481678e-07\n",
            "It 04250: l_u = 9.03313151e-07 loss = 9.03313151e-07\n",
            "It 04300: l_u = 8.91119953e-07 loss = 8.91119953e-07\n",
            "It 04350: l_u = 8.78940000e-07 loss = 8.78940000e-07\n",
            "It 04400: l_u = 8.66803248e-07 loss = 8.66803248e-07\n",
            "It 04450: l_u = 8.54694406e-07 loss = 8.54694406e-07\n",
            "It 04500: l_u = 8.42598922e-07 loss = 8.42598922e-07\n",
            "It 04550: l_u = 8.30516569e-07 loss = 8.30516569e-07\n",
            "It 04600: l_u = 8.18492083e-07 loss = 8.18492083e-07\n",
            "It 04650: l_u = 8.06492721e-07 loss = 8.06492721e-07\n",
            "It 04700: l_u = 7.94552989e-07 loss = 7.94552989e-07\n",
            "It 04750: l_u = 7.82681695e-07 loss = 7.82681695e-07\n",
            "It 04800: l_u = 7.70864006e-07 loss = 7.70864006e-07\n",
            "It 04850: l_u = 7.59073259e-07 loss = 7.59073259e-07\n",
            "It 04900: l_u = 7.47459126e-07 loss = 7.47459126e-07\n",
            "It 04950: l_u = 1.30743401e-05 loss = 1.30743401e-05\n",
            "It 05000: l_u = 8.79197160e-07 loss = 8.79197160e-07\n",
            "It 05050: l_u = 7.12902931e-07 loss = 7.12902931e-07\n",
            "It 05100: l_u = 7.00621683e-07 loss = 7.00621683e-07\n",
            "It 05150: l_u = 6.89354465e-07 loss = 6.89354465e-07\n",
            "It 05200: l_u = 6.78217873e-07 loss = 6.78217873e-07\n",
            "It 05250: l_u = 1.53200144e-05 loss = 1.53200144e-05\n",
            "It 05300: l_u = 7.70292502e-07 loss = 7.70292502e-07\n",
            "It 05350: l_u = 6.45354930e-07 loss = 6.45354930e-07\n",
            "It 05400: l_u = 6.33990453e-07 loss = 6.33990453e-07\n",
            "It 05450: l_u = 6.23325434e-07 loss = 6.23325434e-07\n",
            "It 05500: l_u = 6.14399937e-07 loss = 6.14399937e-07\n",
            "It 05550: l_u = 2.20127936e-06 loss = 2.20127936e-06\n",
            "It 05600: l_u = 6.80925609e-07 loss = 6.80925609e-07\n",
            "It 05650: l_u = 5.81500046e-07 loss = 5.81500046e-07\n",
            "It 05700: l_u = 5.71293299e-07 loss = 5.71293299e-07\n",
            "It 05750: l_u = 5.61351328e-07 loss = 5.61351328e-07\n",
            "It 05800: l_u = 5.51551182e-07 loss = 5.51551182e-07\n",
            "It 05850: l_u = 1.98528733e-06 loss = 1.98528733e-06\n",
            "It 05900: l_u = 3.03642582e-06 loss = 3.03642582e-06\n",
            "It 05950: l_u = 5.23251174e-07 loss = 5.23251174e-07\n",
            "It 06000: l_u = 5.13590919e-07 loss = 5.13590919e-07\n",
            "It 06050: l_u = 5.04327090e-07 loss = 5.04327090e-07\n",
            "It 06100: l_u = 4.95288191e-07 loss = 4.95288191e-07\n",
            "It 06150: l_u = 1.44920428e-04 loss = 1.44920428e-04\n",
            "It 06200: l_u = 4.86296926e-07 loss = 4.86296926e-07\n",
            "It 06250: l_u = 4.72167272e-07 loss = 4.72167272e-07\n",
            "It 06300: l_u = 4.61066406e-07 loss = 4.61066406e-07\n",
            "It 06350: l_u = 4.52455993e-07 loss = 4.52455993e-07\n",
            "It 06400: l_u = 4.44119394e-07 loss = 4.44119394e-07\n",
            "It 06450: l_u = 4.42276445e-07 loss = 4.42276445e-07\n",
            "It 06500: l_u = 3.02640046e-06 loss = 3.02640046e-06\n",
            "It 06550: l_u = 4.66083918e-07 loss = 4.66083918e-07\n",
            "It 06600: l_u = 4.13695261e-07 loss = 4.13695261e-07\n",
            "It 06650: l_u = 4.05678293e-07 loss = 4.05678293e-07\n",
            "It 06700: l_u = 3.98053174e-07 loss = 3.98053174e-07\n",
            "It 06750: l_u = 7.31271757e-06 loss = 7.31271757e-06\n",
            "It 06800: l_u = 1.92218704e-06 loss = 1.92218704e-06\n",
            "It 06850: l_u = 3.98588355e-07 loss = 3.98588355e-07\n",
            "It 06900: l_u = 3.71679960e-07 loss = 3.71679960e-07\n",
            "It 06950: l_u = 3.64194648e-07 loss = 3.64194648e-07\n",
            "It 07000: l_u = 3.57179744e-07 loss = 3.57179744e-07\n",
            "It 07050: l_u = 3.53709112e-07 loss = 3.53709112e-07\n",
            "It 07100: l_u = 3.50319567e-07 loss = 3.50319567e-07\n",
            "It 07150: l_u = 3.46942983e-07 loss = 3.46942983e-07\n",
            "It 07200: l_u = 3.43572054e-07 loss = 3.43572054e-07\n",
            "It 07250: l_u = 3.40187427e-07 loss = 3.40187427e-07\n",
            "It 07300: l_u = 3.36817550e-07 loss = 3.36817550e-07\n",
            "It 07350: l_u = 3.33421696e-07 loss = 3.33421696e-07\n",
            "It 07400: l_u = 3.30043719e-07 loss = 3.30043719e-07\n",
            "It 07450: l_u = 3.26658039e-07 loss = 3.26658039e-07\n",
            "It 07500: l_u = 3.23272445e-07 loss = 3.23272445e-07\n",
            "It 07550: l_u = 3.19865421e-07 loss = 3.19865421e-07\n",
            "It 07600: l_u = 3.16469851e-07 loss = 3.16469851e-07\n",
            "It 07650: l_u = 3.13063850e-07 loss = 3.13063850e-07\n",
            "It 07700: l_u = 3.09646822e-07 loss = 3.09646822e-07\n",
            "It 07750: l_u = 3.06222603e-07 loss = 3.06222603e-07\n",
            "It 07800: l_u = 3.02800572e-07 loss = 3.02800572e-07\n",
            "It 07850: l_u = 2.99352365e-07 loss = 2.99352365e-07\n",
            "It 07900: l_u = 2.95914873e-07 loss = 2.95914873e-07\n",
            "It 07950: l_u = 2.92474880e-07 loss = 2.92474880e-07\n",
            "It 08000: l_u = 2.89020051e-07 loss = 2.89020051e-07\n",
            "It 08050: l_u = 2.85583781e-07 loss = 2.85583781e-07\n",
            "It 08100: l_u = 2.82111813e-07 loss = 2.82111813e-07\n",
            "It 08150: l_u = 2.78664459e-07 loss = 2.78664459e-07\n",
            "It 08200: l_u = 2.75191610e-07 loss = 2.75191610e-07\n",
            "It 08250: l_u = 2.71737747e-07 loss = 2.71737747e-07\n",
            "It 08300: l_u = 2.68263136e-07 loss = 2.68263136e-07\n",
            "It 08350: l_u = 2.64793215e-07 loss = 2.64793215e-07\n",
            "It 08400: l_u = 2.61324374e-07 loss = 2.61324374e-07\n",
            "It 08450: l_u = 9.51046422e-06 loss = 9.51046422e-06\n",
            "It 08500: l_u = 3.07188287e-07 loss = 3.07188287e-07\n",
            "It 08550: l_u = 2.54014680e-07 loss = 2.54014680e-07\n",
            "It 08600: l_u = 2.47894803e-07 loss = 2.47894803e-07\n",
            "It 08650: l_u = 2.60463054e-07 loss = 2.60463054e-07\n",
            "It 08700: l_u = 2.45325418e-06 loss = 2.45325418e-06\n",
            "It 08750: l_u = 2.59596703e-07 loss = 2.59596703e-07\n",
            "It 08800: l_u = 2.35041698e-05 loss = 2.35041698e-05\n",
            "It 08850: l_u = 3.87523670e-07 loss = 3.87523670e-07\n",
            "It 08900: l_u = 2.29878751e-07 loss = 2.29878751e-07\n",
            "It 08950: l_u = 1.93253732e-06 loss = 1.93253732e-06\n",
            "It 09000: l_u = 6.47968363e-07 loss = 6.47968363e-07\n",
            "It 09050: l_u = 2.22502209e-07 loss = 2.22502209e-07\n",
            "It 09100: l_u = 2.23257075e-07 loss = 2.23257075e-07\n",
            "It 09150: l_u = 4.59298775e-07 loss = 4.59298775e-07\n",
            "It 09200: l_u = 2.18961731e-07 loss = 2.18961731e-07\n",
            "It 09250: l_u = 2.09311779e-07 loss = 2.09311779e-07\n",
            "It 09300: l_u = 2.06688725e-07 loss = 2.06688725e-07\n",
            "Timeout is reached. Time elapsed: 20.001071214675903 seconds\n",
            "\n",
            "\n",
            "Finding PDE parameters.\n",
            "It 09350: loss = 2.06904517e-07 lambda = [ 4.34284  -2.419382]\n",
            "It 09400: loss = 2.06904517e-07 lambda = [ 3.6339107 -1.9130235]\n",
            "It 09450: loss = 2.06904517e-07 lambda = [ 2.5167134 -1.5960683]\n",
            "It 09500: loss = 2.06904517e-07 lambda = [ 1.4042044 -1.2570999]\n",
            "It 09550: loss = 2.06904517e-07 lambda = [ 0.34210432 -0.9337246 ]\n",
            "It 09600: loss = 2.06904517e-07 lambda = [-0.6332773  -0.63712466]\n",
            "It 09650: loss = 2.06904517e-07 lambda = [-1.504208   -0.37239236]\n",
            "It 09700: loss = 2.06904517e-07 lambda = [-2.2654576  -0.14107214]\n",
            "It 09750: loss = 2.06904517e-07 lambda = [-2.9195893   0.05765414]\n",
            "It 09800: loss = 2.06904517e-07 lambda = [-3.4738493   0.22601326]\n",
            "It 09850: loss = 2.06904517e-07 lambda = [-3.9379933   0.36698443]\n",
            "It 09900: loss = 2.06904517e-07 lambda = [-4.3228073   0.48385274]\n",
            "It 09950: loss = 2.06904517e-07 lambda = [-4.6391277  0.5799153]\n",
            "It 10000: loss = 2.06904517e-07 lambda = [-4.8972335   0.65829575]\n",
            "It 10050: loss = 2.06904517e-07 lambda = [-5.1064973   0.72184277]\n",
            "It 10100: loss = 2.06904517e-07 lambda = [-5.27523     0.77308065]\n",
            "It 10150: loss = 2.06904517e-07 lambda = [-5.410632   0.8141975]\n",
            "It 10200: loss = 2.06904517e-07 lambda = [-5.5188437  0.8470571]\n",
            "It 10250: loss = 2.06904517e-07 lambda = [-5.605019   0.8732252]\n",
            "It 10300: loss = 2.06904517e-07 lambda = [-5.673442    0.89400214]\n",
            "It 10350: loss = 2.06904517e-07 lambda = [-5.7276278  0.9104557]\n",
            "It 10400: loss = 2.06904517e-07 lambda = [-5.7704477   0.92345846]\n",
            "It 10450: loss = 2.06904517e-07 lambda = [-5.8042264  0.9337156]\n",
            "It 10500: loss = 2.06904517e-07 lambda = [-5.830835   0.9417955]\n",
            "It 10550: loss = 2.06904517e-07 lambda = [-5.851771    0.94815296]\n",
            "It 10600: loss = 2.06904517e-07 lambda = [-5.868229    0.95315045]\n",
            "It 10650: loss = 2.06904517e-07 lambda = [-5.881159   0.9570768]\n",
            "It 10700: loss = 2.06904517e-07 lambda = [-5.891314   0.9601605]\n",
            "It 10750: loss = 2.06904517e-07 lambda = [-5.8992887   0.96258193]\n",
            "It 10800: loss = 2.06904517e-07 lambda = [-5.9055495   0.96448314]\n",
            "It 10850: loss = 2.06904517e-07 lambda = [-5.910465   0.9659755]\n",
            "It 10900: loss = 2.06904517e-07 lambda = [-5.914327   0.9671486]\n",
            "It 10950: loss = 2.06904517e-07 lambda = [-5.917362    0.96807015]\n",
            "It 11000: loss = 2.06904517e-07 lambda = [-5.9197493  0.9687952]\n",
            "It 11050: loss = 2.06904517e-07 lambda = [-5.9216275  0.9693653]\n",
            "It 11100: loss = 2.06904517e-07 lambda = [-5.923106    0.96981454]\n",
            "It 11150: loss = 2.06904517e-07 lambda = [-5.9242725  0.9701686]\n",
            "It 11200: loss = 2.06904517e-07 lambda = [-5.9251914   0.97044766]\n",
            "It 11250: loss = 2.06904517e-07 lambda = [-5.9259176  0.9706682]\n",
            "It 11300: loss = 2.06904517e-07 lambda = [-5.926492    0.97084254]\n",
            "It 11350: loss = 2.06904517e-07 lambda = [-5.9269466   0.97098064]\n",
            "It 11400: loss = 2.06904517e-07 lambda = [-5.927308   0.9710902]\n",
            "It 11450: loss = 2.06904517e-07 lambda = [-5.927594   0.9711771]\n",
            "It 11500: loss = 2.06904517e-07 lambda = [-5.9278216   0.97124606]\n",
            "Timeout is reached. Time elapsed: 80.02132892608643 seconds\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration: 1 Initial lambda: [10.0, 10.0]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Adam\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: l_u = 3.31840247e-01 loss = 3.31840247e-01\n",
            "It 00050: l_u = 3.36616905e-03 loss = 3.36616905e-03\n",
            "It 00100: l_u = 2.42417213e-03 loss = 2.42417213e-03\n",
            "It 00150: l_u = 1.05697065e-04 loss = 1.05697065e-04\n",
            "It 00200: l_u = 5.87089380e-05 loss = 5.87089380e-05\n",
            "It 00250: l_u = 3.57516001e-05 loss = 3.57516001e-05\n",
            "It 00300: l_u = 1.97145389e-03 loss = 1.97145389e-03\n",
            "It 00350: l_u = 2.61395453e-05 loss = 2.61395453e-05\n",
            "It 00400: l_u = 1.44222695e-05 loss = 1.44222695e-05\n",
            "It 00450: l_u = 1.09330986e-05 loss = 1.09330986e-05\n",
            "It 00500: l_u = 8.83877146e-06 loss = 8.83877146e-06\n",
            "It 00550: l_u = 7.49495030e-06 loss = 7.49495030e-06\n",
            "It 00600: l_u = 6.59137004e-06 loss = 6.59137004e-06\n",
            "It 00650: l_u = 5.94963558e-06 loss = 5.94963558e-06\n",
            "It 00700: l_u = 5.46642650e-06 loss = 5.46642650e-06\n",
            "It 00750: l_u = 5.08264293e-06 loss = 5.08264293e-06\n",
            "It 00800: l_u = 4.76474133e-06 loss = 4.76474133e-06\n",
            "It 00850: l_u = 4.49361323e-06 loss = 4.49361323e-06\n",
            "It 00900: l_u = 3.00065521e-03 loss = 3.00065521e-03\n",
            "It 00950: l_u = 7.00811370e-06 loss = 7.00811370e-06\n",
            "It 01000: l_u = 4.04401817e-06 loss = 4.04401817e-06\n",
            "It 01050: l_u = 3.83598854e-06 loss = 3.83598854e-06\n",
            "It 01100: l_u = 3.65731512e-06 loss = 3.65731512e-06\n",
            "It 01150: l_u = 3.49526340e-06 loss = 3.49526340e-06\n",
            "It 01200: l_u = 3.34621336e-06 loss = 3.34621336e-06\n",
            "It 01250: l_u = 3.20819481e-06 loss = 3.20819481e-06\n",
            "It 01300: l_u = 3.07978371e-06 loss = 3.07978371e-06\n",
            "It 01350: l_u = 2.95994118e-06 loss = 2.95994118e-06\n",
            "It 01400: l_u = 2.84769840e-06 loss = 2.84769840e-06\n",
            "It 01450: l_u = 2.74239324e-06 loss = 2.74239324e-06\n",
            "It 01500: l_u = 2.64339451e-06 loss = 2.64339451e-06\n",
            "It 01550: l_u = 2.55015402e-06 loss = 2.55015402e-06\n",
            "It 01600: l_u = 2.46216018e-06 loss = 2.46216018e-06\n",
            "It 01650: l_u = 2.37905715e-06 loss = 2.37905715e-06\n",
            "It 01700: l_u = 2.30051387e-06 loss = 2.30051387e-06\n",
            "It 01750: l_u = 2.22614835e-06 loss = 2.22614835e-06\n",
            "It 01800: l_u = 2.15577711e-06 loss = 2.15577711e-06\n",
            "It 01850: l_u = 2.08907886e-06 loss = 2.08907886e-06\n",
            "It 01900: l_u = 2.02577985e-06 loss = 2.02577985e-06\n",
            "It 01950: l_u = 1.96581072e-06 loss = 1.96581072e-06\n",
            "It 02000: l_u = 1.90880223e-06 loss = 1.90880223e-06\n",
            "It 02050: l_u = 1.85469764e-06 loss = 1.85469764e-06\n",
            "It 02100: l_u = 1.80327140e-06 loss = 1.80327140e-06\n",
            "It 02150: l_u = 1.75440766e-06 loss = 1.75440766e-06\n",
            "It 02200: l_u = 1.70791293e-06 loss = 1.70791293e-06\n",
            "It 02250: l_u = 1.66369750e-06 loss = 1.66369750e-06\n",
            "It 02300: l_u = 1.62160836e-06 loss = 1.62160836e-06\n",
            "It 02350: l_u = 1.58152352e-06 loss = 1.58152352e-06\n",
            "It 02400: l_u = 1.54335464e-06 loss = 1.54335464e-06\n",
            "It 02450: l_u = 1.50695814e-06 loss = 1.50695814e-06\n",
            "It 02500: l_u = 1.47224978e-06 loss = 1.47224978e-06\n",
            "It 02550: l_u = 1.43912109e-06 loss = 1.43912109e-06\n",
            "It 02600: l_u = 1.40749364e-06 loss = 1.40749364e-06\n",
            "It 02650: l_u = 1.37730649e-06 loss = 1.37730649e-06\n",
            "It 02700: l_u = 1.34846061e-06 loss = 1.34846061e-06\n",
            "It 02750: l_u = 1.32087132e-06 loss = 1.32087132e-06\n",
            "It 02800: l_u = 1.29450984e-06 loss = 1.29450984e-06\n",
            "It 02850: l_u = 1.26922555e-06 loss = 1.26922555e-06\n",
            "It 02900: l_u = 1.24506778e-06 loss = 1.24506778e-06\n",
            "It 02950: l_u = 1.22189999e-06 loss = 1.22189999e-06\n",
            "It 03000: l_u = 1.19969684e-06 loss = 1.19969684e-06\n",
            "It 03050: l_u = 1.18855041e-06 loss = 1.18855041e-06\n",
            "It 03100: l_u = 1.17756531e-06 loss = 1.17756531e-06\n",
            "It 03150: l_u = 1.16643912e-06 loss = 1.16643912e-06\n",
            "It 03200: l_u = 1.15522482e-06 loss = 1.15522482e-06\n",
            "It 03250: l_u = 1.14391128e-06 loss = 1.14391128e-06\n",
            "It 03300: l_u = 1.13254384e-06 loss = 1.13254384e-06\n",
            "It 03350: l_u = 1.12108160e-06 loss = 1.12108160e-06\n",
            "It 03400: l_u = 1.10950930e-06 loss = 1.10950930e-06\n",
            "It 03450: l_u = 1.09788289e-06 loss = 1.09788289e-06\n",
            "It 03500: l_u = 1.08619270e-06 loss = 1.08619270e-06\n",
            "It 03550: l_u = 1.07441565e-06 loss = 1.07441565e-06\n",
            "It 03600: l_u = 1.06257426e-06 loss = 1.06257426e-06\n",
            "It 03650: l_u = 1.05069455e-06 loss = 1.05069455e-06\n",
            "It 03700: l_u = 1.03875993e-06 loss = 1.03875993e-06\n",
            "It 03750: l_u = 1.02674448e-06 loss = 1.02674448e-06\n",
            "It 03800: l_u = 1.01472028e-06 loss = 1.01472028e-06\n",
            "It 03850: l_u = 1.00265197e-06 loss = 1.00265197e-06\n",
            "It 03900: l_u = 9.90527838e-07 loss = 9.90527838e-07\n",
            "It 03950: l_u = 9.78400521e-07 loss = 9.78400521e-07\n",
            "It 04000: l_u = 9.66229663e-07 loss = 9.66229663e-07\n",
            "It 04050: l_u = 9.54053462e-07 loss = 9.54053462e-07\n",
            "It 04100: l_u = 9.41880558e-07 loss = 9.41880558e-07\n",
            "It 04150: l_u = 9.29684006e-07 loss = 9.29684006e-07\n",
            "It 04200: l_u = 9.17454088e-07 loss = 9.17454088e-07\n",
            "It 04250: l_u = 9.05265381e-07 loss = 9.05265381e-07\n",
            "It 04300: l_u = 8.93093215e-07 loss = 8.93093215e-07\n",
            "It 04350: l_u = 8.80907862e-07 loss = 8.80907862e-07\n",
            "It 04400: l_u = 8.68740074e-07 loss = 8.68740074e-07\n",
            "It 04450: l_u = 8.56600309e-07 loss = 8.56600309e-07\n",
            "It 04500: l_u = 8.44477086e-07 loss = 8.44477086e-07\n",
            "It 04550: l_u = 8.32403543e-07 loss = 8.32403543e-07\n",
            "It 04600: l_u = 8.20364278e-07 loss = 8.20364278e-07\n",
            "It 04650: l_u = 8.08347522e-07 loss = 8.08347522e-07\n",
            "It 04700: l_u = 7.96381130e-07 loss = 7.96381130e-07\n",
            "It 04750: l_u = 7.84473684e-07 loss = 7.84473684e-07\n",
            "It 04800: l_u = 7.72601823e-07 loss = 7.72601823e-07\n",
            "It 04850: l_u = 7.60797548e-07 loss = 7.60797548e-07\n",
            "It 04900: l_u = 8.67942390e-07 loss = 8.67942390e-07\n",
            "It 04950: l_u = 5.63073172e-06 loss = 5.63073172e-06\n",
            "It 05000: l_u = 7.50388608e-07 loss = 7.50388608e-07\n",
            "It 05050: l_u = 7.13711984e-07 loss = 7.13711984e-07\n",
            "It 05100: l_u = 7.02240186e-07 loss = 7.02240186e-07\n",
            "It 05150: l_u = 6.90985587e-07 loss = 6.90985587e-07\n",
            "It 05200: l_u = 2.40786194e-05 loss = 2.40786194e-05\n",
            "It 05250: l_u = 6.71394844e-07 loss = 6.71394844e-07\n",
            "It 05300: l_u = 6.59431464e-07 loss = 6.59431464e-07\n",
            "It 05350: l_u = 6.46130218e-07 loss = 6.46130218e-07\n",
            "It 05400: l_u = 6.35348272e-07 loss = 6.35348272e-07\n",
            "It 05450: l_u = 1.12325026e-04 loss = 1.12325026e-04\n",
            "It 05500: l_u = 9.45917805e-07 loss = 9.45917805e-07\n",
            "It 05550: l_u = 6.04872980e-07 loss = 6.04872980e-07\n",
            "It 05600: l_u = 5.92787387e-07 loss = 5.92787387e-07\n",
            "It 05650: l_u = 5.82597011e-07 loss = 5.82597011e-07\n",
            "It 05700: l_u = 5.53852151e-05 loss = 5.53852151e-05\n",
            "It 05750: l_u = 5.70096120e-07 loss = 5.70096120e-07\n",
            "It 05800: l_u = 5.55797328e-07 loss = 5.55797328e-07\n",
            "It 05850: l_u = 5.42565374e-07 loss = 5.42565374e-07\n",
            "It 05900: l_u = 5.32999195e-07 loss = 5.32999195e-07\n",
            "It 05950: l_u = 9.29818634e-06 loss = 9.29818634e-06\n",
            "It 06000: l_u = 6.50308152e-07 loss = 6.50308152e-07\n",
            "It 06050: l_u = 5.09892232e-07 loss = 5.09892232e-07\n",
            "It 06100: l_u = 4.95869131e-07 loss = 4.95869131e-07\n",
            "It 06150: l_u = 4.86878889e-07 loss = 4.86878889e-07\n",
            "It 06200: l_u = 4.80571487e-07 loss = 4.80571487e-07\n",
            "It 06250: l_u = 2.60379443e-06 loss = 2.60379443e-06\n",
            "It 06300: l_u = 5.17301999e-07 loss = 5.17301999e-07\n",
            "It 06350: l_u = 4.53182196e-07 loss = 4.53182196e-07\n",
            "It 06400: l_u = 4.44600630e-07 loss = 4.44600630e-07\n",
            "It 06450: l_u = 4.36331959e-07 loss = 4.36331959e-07\n",
            "It 06500: l_u = 4.31068713e-07 loss = 4.31068713e-07\n",
            "It 06550: l_u = 1.02504537e-05 loss = 1.02504537e-05\n",
            "It 06600: l_u = 4.19515459e-07 loss = 4.19515459e-07\n",
            "It 06650: l_u = 4.07185922e-07 loss = 4.07185922e-07\n",
            "It 06700: l_u = 3.98643095e-07 loss = 3.98643095e-07\n",
            "It 06750: l_u = 3.91047337e-07 loss = 3.91047337e-07\n",
            "It 06800: l_u = 3.83753331e-07 loss = 3.83753331e-07\n",
            "It 06850: l_u = 7.45602083e-05 loss = 7.45602083e-05\n",
            "It 06900: l_u = 8.16076920e-07 loss = 8.16076920e-07\n",
            "It 06950: l_u = 3.69146903e-07 loss = 3.69146903e-07\n",
            "It 07000: l_u = 3.58524829e-07 loss = 3.58524829e-07\n",
            "It 07050: l_u = 3.54779871e-07 loss = 3.54779871e-07\n",
            "It 07100: l_u = 3.51185093e-07 loss = 3.51185093e-07\n",
            "It 07150: l_u = 3.47670806e-07 loss = 3.47670806e-07\n",
            "It 07200: l_u = 3.44199435e-07 loss = 3.44199435e-07\n",
            "It 07250: l_u = 3.40750660e-07 loss = 3.40750660e-07\n",
            "It 07300: l_u = 3.37329169e-07 loss = 3.37329169e-07\n",
            "It 07350: l_u = 3.33911771e-07 loss = 3.33911771e-07\n",
            "It 07400: l_u = 3.30513501e-07 loss = 3.30513501e-07\n",
            "It 07450: l_u = 3.27124269e-07 loss = 3.27124269e-07\n",
            "It 07500: l_u = 3.23744018e-07 loss = 3.23744018e-07\n",
            "It 07550: l_u = 3.20354673e-07 loss = 3.20354673e-07\n",
            "It 07600: l_u = 3.16959529e-07 loss = 3.16959529e-07\n",
            "It 07650: l_u = 3.13574560e-07 loss = 3.13574560e-07\n",
            "It 07700: l_u = 3.10174300e-07 loss = 3.10174300e-07\n",
            "It 07750: l_u = 3.06798142e-07 loss = 3.06798142e-07\n",
            "It 07800: l_u = 3.03394359e-07 loss = 3.03394359e-07\n",
            "It 07850: l_u = 2.99985118e-07 loss = 2.99985118e-07\n",
            "It 07900: l_u = 2.96588553e-07 loss = 2.96588553e-07\n",
            "It 07950: l_u = 2.93183945e-07 loss = 2.93183945e-07\n",
            "It 08000: l_u = 2.89773851e-07 loss = 2.89773851e-07\n",
            "It 08050: l_u = 2.86362990e-07 loss = 2.86362990e-07\n",
            "It 08100: l_u = 2.82938174e-07 loss = 2.82938174e-07\n",
            "It 08150: l_u = 2.79517053e-07 loss = 2.79517053e-07\n",
            "It 08200: l_u = 2.76109688e-07 loss = 2.76109688e-07\n",
            "It 08250: l_u = 2.72680182e-07 loss = 2.72680182e-07\n",
            "It 08300: l_u = 2.69263808e-07 loss = 2.69263808e-07\n",
            "It 08350: l_u = 2.65833989e-07 loss = 2.65833989e-07\n",
            "It 08400: l_u = 2.62412328e-07 loss = 2.62412328e-07\n",
            "It 08450: l_u = 2.58994504e-07 loss = 2.58994504e-07\n",
            "It 08500: l_u = 2.55567357e-07 loss = 2.55567357e-07\n",
            "It 08550: l_u = 2.52194411e-07 loss = 2.52194411e-07\n",
            "It 08600: l_u = 8.01828992e-06 loss = 8.01828992e-06\n",
            "It 08650: l_u = 2.46352243e-07 loss = 2.46352243e-07\n",
            "It 08700: l_u = 2.42704260e-07 loss = 2.42704260e-07\n",
            "It 08750: l_u = 2.39242013e-07 loss = 2.39242013e-07\n",
            "It 08800: l_u = 3.14246950e-06 loss = 3.14246950e-06\n",
            "It 08850: l_u = 2.59558902e-07 loss = 2.59558902e-07\n",
            "It 08900: l_u = 2.98747864e-06 loss = 2.98747864e-06\n",
            "It 08950: l_u = 2.92566568e-07 loss = 2.92566568e-07\n",
            "It 09000: l_u = 2.25346952e-07 loss = 2.25346952e-07\n",
            "It 09050: l_u = 5.83653673e-06 loss = 5.83653673e-06\n",
            "It 09100: l_u = 2.56724661e-07 loss = 2.56724661e-07\n",
            "It 09150: l_u = 3.74912446e-07 loss = 3.74912446e-07\n",
            "It 09200: l_u = 4.37594935e-07 loss = 4.37594935e-07\n",
            "It 09250: l_u = 8.78063986e-07 loss = 8.78063986e-07\n",
            "It 09300: l_u = 2.08326583e-07 loss = 2.08326583e-07\n",
            "It 09350: l_u = 4.42871141e-07 loss = 4.42871141e-07\n",
            "It 09400: l_u = 7.82908955e-07 loss = 7.82908955e-07\n",
            "It 09450: l_u = 1.21222320e-06 loss = 1.21222320e-06\n",
            "It 09500: l_u = 2.06179450e-07 loss = 2.06179450e-07\n",
            "It 09550: l_u = 2.10269081e-06 loss = 2.10269081e-06\n",
            "It 09600: l_u = 2.68267343e-07 loss = 2.68267343e-07\n",
            "It 09650: l_u = 1.90212106e-07 loss = 1.90212106e-07\n",
            "It 09700: l_u = 1.90091257e-07 loss = 1.90091257e-07\n",
            "It 09750: l_u = 9.47099807e-07 loss = 9.47099807e-07\n",
            "It 09800: l_u = 1.88338021e-07 loss = 1.88338021e-07\n",
            "It 09850: l_u = 1.19066215e-06 loss = 1.19066215e-06\n",
            "It 09900: l_u = 1.80848616e-07 loss = 1.80848616e-07\n",
            "It 09950: l_u = 1.39819554e-06 loss = 1.39819554e-06\n",
            "Timeout is reached. Time elapsed: 20.00048303604126 seconds\n",
            "\n",
            "\n",
            "Finding PDE parameters.\n",
            "It 10000: loss = 9.79302058e-06 lambda = [5.6475897 5.654152 ]\n",
            "It 10050: loss = 9.79302058e-06 lambda = [2.3685172 2.4186215]\n",
            "It 10100: loss = 9.79302058e-06 lambda = [0.48805198 0.63466555]\n",
            "It 10150: loss = 9.79302058e-06 lambda = [-0.43500084 -0.14495438]\n",
            "It 10200: loss = 9.79302058e-06 lambda = [-0.8663741 -0.4024229]\n",
            "It 10250: loss = 9.79302058e-06 lambda = [-1.1030918 -0.4486558]\n",
            "It 10300: loss = 9.79302058e-06 lambda = [-1.27899   -0.4256049]\n",
            "It 10350: loss = 9.79302058e-06 lambda = [-1.4399146  -0.38348705]\n",
            "It 10400: loss = 9.79302058e-06 lambda = [-1.5978612  -0.33691177]\n",
            "It 10450: loss = 9.79302058e-06 lambda = [-1.7547514  -0.28961918]\n",
            "It 10500: loss = 9.79302058e-06 lambda = [-1.9101815  -0.24259675]\n",
            "It 10550: loss = 9.79302058e-06 lambda = [-2.0634222  -0.19621295]\n",
            "It 10600: loss = 9.79302058e-06 lambda = [-2.2138238  -0.15068607]\n",
            "It 10650: loss = 9.79302058e-06 lambda = [-2.3608642  -0.10617659]\n",
            "It 10700: loss = 9.79302058e-06 lambda = [-2.5041397  -0.06280703]\n",
            "It 10750: loss = 9.79302058e-06 lambda = [-2.6433473 -0.0206692]\n",
            "It 10800: loss = 9.79302058e-06 lambda = [-2.778265    0.02017013]\n",
            "It 10850: loss = 9.79302058e-06 lambda = [-2.908744    0.05966549]\n",
            "It 10900: loss = 9.79302058e-06 lambda = [-3.034692    0.09778909]\n",
            "It 10950: loss = 9.79302058e-06 lambda = [-3.1560657   0.13452792]\n",
            "It 11000: loss = 9.79302058e-06 lambda = [-3.2728617   0.16988103]\n",
            "It 11050: loss = 9.79302058e-06 lambda = [-3.3851094   0.20385717]\n",
            "It 11100: loss = 9.79302058e-06 lambda = [-3.4928658   0.23647359]\n",
            "It 11150: loss = 9.79302058e-06 lambda = [-3.596208    0.26775396]\n",
            "It 11200: loss = 9.79302058e-06 lambda = [-3.6952322   0.29772708]\n",
            "It 11250: loss = 9.79302058e-06 lambda = [-3.7900484   0.32642603]\n",
            "It 11300: loss = 9.79302058e-06 lambda = [-3.8807714   0.35388666]\n",
            "It 11350: loss = 9.79302058e-06 lambda = [-3.96753     0.38014704]\n",
            "It 11400: loss = 9.79302058e-06 lambda = [-4.0504565  0.4052472]\n",
            "It 11450: loss = 9.79302058e-06 lambda = [-4.129685    0.42922816]\n",
            "It 11500: loss = 9.79302058e-06 lambda = [-4.205353   0.4521312]\n",
            "It 11550: loss = 9.79302058e-06 lambda = [-4.277599    0.47399837]\n",
            "It 11600: loss = 9.79302058e-06 lambda = [-4.346559    0.49487096]\n",
            "It 11650: loss = 9.79302058e-06 lambda = [-4.4123683  0.51479  ]\n",
            "It 11700: loss = 9.79302058e-06 lambda = [-4.475161   0.5337959]\n",
            "It 11750: loss = 9.79302058e-06 lambda = [-4.5350666  0.5519278]\n",
            "It 11800: loss = 9.79302058e-06 lambda = [-4.592212   0.5692243]\n",
            "It 11850: loss = 9.79302058e-06 lambda = [-4.6467223   0.58572286]\n",
            "It 11900: loss = 9.79302058e-06 lambda = [-4.6987166   0.60146016]\n",
            "It 11950: loss = 9.79302058e-06 lambda = [-4.748313    0.61647123]\n",
            "It 12000: loss = 9.79302058e-06 lambda = [-4.795617   0.6307892]\n",
            "It 12050: loss = 9.79302058e-06 lambda = [-4.84074     0.64444685]\n",
            "It 12100: loss = 9.79302058e-06 lambda = [-4.8837857   0.65747553]\n",
            "Timeout is reached. Time elapsed: 80.01133751869202 seconds\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration: 2 Initial lambda: [0.0, 0.0]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Adam\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: l_u = 4.56506044e-01 loss = 4.56506044e-01\n",
            "It 00050: l_u = 4.93783280e-02 loss = 4.93783280e-02\n",
            "It 00100: l_u = 1.98343696e-04 loss = 1.98343696e-04\n",
            "It 00150: l_u = 4.52453314e-05 loss = 4.52453314e-05\n",
            "It 00200: l_u = 2.60484030e-05 loss = 2.60484030e-05\n",
            "It 00250: l_u = 4.71300678e-03 loss = 4.71300678e-03\n",
            "It 00300: l_u = 2.71707668e-05 loss = 2.71707668e-05\n",
            "It 00350: l_u = 1.30444769e-05 loss = 1.30444769e-05\n",
            "It 00400: l_u = 1.05864774e-05 loss = 1.05864774e-05\n",
            "It 00450: l_u = 8.95074845e-06 loss = 8.95074845e-06\n",
            "It 00500: l_u = 7.77195692e-06 loss = 7.77195692e-06\n",
            "It 00550: l_u = 6.87363354e-06 loss = 6.87363354e-06\n",
            "It 00600: l_u = 6.15975387e-06 loss = 6.15975387e-06\n",
            "It 00650: l_u = 5.57485509e-06 loss = 5.57485509e-06\n",
            "It 00700: l_u = 5.08521180e-06 loss = 5.08521180e-06\n",
            "It 00750: l_u = 4.66887332e-06 loss = 4.66887332e-06\n",
            "It 00800: l_u = 4.31064882e-06 loss = 4.31064882e-06\n",
            "It 00850: l_u = 5.00366968e-06 loss = 5.00366968e-06\n",
            "It 00900: l_u = 7.56020381e-05 loss = 7.56020381e-05\n",
            "It 00950: l_u = 3.88073977e-06 loss = 3.88073977e-06\n",
            "It 01000: l_u = 3.58631951e-06 loss = 3.58631951e-06\n",
            "It 01050: l_u = 3.35918139e-06 loss = 3.35918139e-06\n",
            "It 01100: l_u = 3.16300589e-06 loss = 3.16300589e-06\n",
            "It 01150: l_u = 2.98885197e-06 loss = 2.98885197e-06\n",
            "It 01200: l_u = 2.83276154e-06 loss = 2.83276154e-06\n",
            "It 01250: l_u = 2.69187535e-06 loss = 2.69187535e-06\n",
            "It 01300: l_u = 2.56407520e-06 loss = 2.56407520e-06\n",
            "It 01350: l_u = 2.44758826e-06 loss = 2.44758826e-06\n",
            "It 01400: l_u = 2.34100685e-06 loss = 2.34100685e-06\n",
            "It 01450: l_u = 2.24311748e-06 loss = 2.24311748e-06\n",
            "It 01500: l_u = 2.15296654e-06 loss = 2.15296654e-06\n",
            "It 01550: l_u = 2.06970481e-06 loss = 2.06970481e-06\n",
            "It 01600: l_u = 1.99256056e-06 loss = 1.99256056e-06\n",
            "It 01650: l_u = 1.92092148e-06 loss = 1.92092148e-06\n",
            "It 01700: l_u = 1.85428121e-06 loss = 1.85428121e-06\n",
            "It 01750: l_u = 1.79204017e-06 loss = 1.79204017e-06\n",
            "It 01800: l_u = 1.73394267e-06 loss = 1.73394267e-06\n",
            "It 01850: l_u = 1.67946223e-06 loss = 1.67946223e-06\n",
            "It 01900: l_u = 1.62832669e-06 loss = 1.62832669e-06\n",
            "It 01950: l_u = 1.58025398e-06 loss = 1.58025398e-06\n",
            "It 02000: l_u = 1.53500298e-06 loss = 1.53500298e-06\n",
            "It 02050: l_u = 1.49229561e-06 loss = 1.49229561e-06\n",
            "It 02100: l_u = 1.45194156e-06 loss = 1.45194156e-06\n",
            "It 02150: l_u = 1.41373414e-06 loss = 1.41373414e-06\n",
            "It 02200: l_u = 1.37761174e-06 loss = 1.37761174e-06\n",
            "It 02250: l_u = 1.34326456e-06 loss = 1.34326456e-06\n",
            "It 02300: l_u = 1.31066338e-06 loss = 1.31066338e-06\n",
            "It 02350: l_u = 1.27970122e-06 loss = 1.27970122e-06\n",
            "It 02400: l_u = 1.25018448e-06 loss = 1.25018448e-06\n",
            "It 02450: l_u = 1.22204699e-06 loss = 1.22204699e-06\n",
            "It 02500: l_u = 1.19520405e-06 loss = 1.19520405e-06\n",
            "It 02550: l_u = 1.16958790e-06 loss = 1.16958790e-06\n",
            "It 02600: l_u = 1.14507759e-06 loss = 1.14507759e-06\n",
            "It 02650: l_u = 1.12165083e-06 loss = 1.12165083e-06\n",
            "It 02700: l_u = 1.09921075e-06 loss = 1.09921075e-06\n",
            "It 02750: l_u = 1.07770211e-06 loss = 1.07770211e-06\n",
            "It 02800: l_u = 1.05707488e-06 loss = 1.05707488e-06\n",
            "It 02850: l_u = 1.03729326e-06 loss = 1.03729326e-06\n",
            "It 02900: l_u = 1.01829789e-06 loss = 1.01829789e-06\n",
            "It 02950: l_u = 1.00002580e-06 loss = 1.00002580e-06\n",
            "It 03000: l_u = 9.82465508e-07 loss = 9.82465508e-07\n",
            "It 03050: l_u = 9.73650344e-07 loss = 9.73650344e-07\n",
            "It 03100: l_u = 9.64908395e-07 loss = 9.64908395e-07\n",
            "It 03150: l_u = 9.56066174e-07 loss = 9.56066174e-07\n",
            "It 03200: l_u = 9.47150170e-07 loss = 9.47150170e-07\n",
            "It 03250: l_u = 9.38098538e-07 loss = 9.38098538e-07\n",
            "It 03300: l_u = 9.29000805e-07 loss = 9.29000805e-07\n",
            "It 03350: l_u = 9.19814113e-07 loss = 9.19814113e-07\n",
            "It 03400: l_u = 9.10513108e-07 loss = 9.10513108e-07\n",
            "It 03450: l_u = 9.01148496e-07 loss = 9.01148496e-07\n",
            "It 03500: l_u = 8.91721470e-07 loss = 8.91721470e-07\n",
            "It 03550: l_u = 8.82213953e-07 loss = 8.82213953e-07\n",
            "It 03600: l_u = 8.72603039e-07 loss = 8.72603039e-07\n",
            "It 03650: l_u = 8.62944091e-07 loss = 8.62944091e-07\n",
            "It 03700: l_u = 8.53221309e-07 loss = 8.53221309e-07\n",
            "It 03750: l_u = 8.43429575e-07 loss = 8.43429575e-07\n",
            "It 03800: l_u = 8.33577815e-07 loss = 8.33577815e-07\n",
            "It 03850: l_u = 8.23661026e-07 loss = 8.23661026e-07\n",
            "It 03900: l_u = 8.13706038e-07 loss = 8.13706038e-07\n",
            "It 03950: l_u = 8.03684543e-07 loss = 8.03684543e-07\n",
            "It 04000: l_u = 7.93607569e-07 loss = 7.93607569e-07\n",
            "It 04050: l_u = 7.83497683e-07 loss = 7.83497683e-07\n",
            "It 04100: l_u = 7.73337774e-07 loss = 7.73337774e-07\n",
            "It 04150: l_u = 7.63140804e-07 loss = 7.63140804e-07\n",
            "It 04200: l_u = 7.52924336e-07 loss = 7.52924336e-07\n",
            "It 04250: l_u = 7.42684449e-07 loss = 7.42684449e-07\n",
            "It 04300: l_u = 7.32363446e-07 loss = 7.32363446e-07\n",
            "It 04350: l_u = 7.22070070e-07 loss = 7.22070070e-07\n",
            "It 04400: l_u = 7.11762425e-07 loss = 7.11762425e-07\n",
            "It 04450: l_u = 7.01387251e-07 loss = 7.01387251e-07\n",
            "It 04500: l_u = 6.91053458e-07 loss = 6.91053458e-07\n",
            "It 04550: l_u = 6.80713924e-07 loss = 6.80713924e-07\n",
            "It 04600: l_u = 6.70356542e-07 loss = 6.70356542e-07\n",
            "It 04650: l_u = 6.59995294e-07 loss = 6.59995294e-07\n",
            "It 04700: l_u = 6.49635126e-07 loss = 6.49635126e-07\n",
            "It 04750: l_u = 6.39280643e-07 loss = 6.39280643e-07\n",
            "It 04800: l_u = 6.29016085e-07 loss = 6.29016085e-07\n",
            "It 04850: l_u = 4.14256647e-05 loss = 4.14256647e-05\n",
            "It 04900: l_u = 6.61510512e-07 loss = 6.61510512e-07\n",
            "It 04950: l_u = 6.03431658e-07 loss = 6.03431658e-07\n",
            "It 05000: l_u = 5.92069739e-07 loss = 5.92069739e-07\n",
            "It 05050: l_u = 5.82660221e-07 loss = 5.82660221e-07\n",
            "It 05100: l_u = 4.31567832e-06 loss = 4.31567832e-06\n",
            "It 05150: l_u = 6.28836972e-07 loss = 6.28836972e-07\n",
            "It 05200: l_u = 5.60292335e-07 loss = 5.60292335e-07\n",
            "It 05250: l_u = 5.50682500e-07 loss = 5.50682500e-07\n",
            "It 05300: l_u = 3.17285230e-06 loss = 3.17285230e-06\n",
            "It 05350: l_u = 6.59988075e-07 loss = 6.59988075e-07\n",
            "It 05400: l_u = 5.26919450e-07 loss = 5.26919450e-07\n",
            "It 05450: l_u = 5.17920000e-07 loss = 5.17920000e-07\n",
            "It 05500: l_u = 6.41072234e-07 loss = 6.41072234e-07\n",
            "It 05550: l_u = 7.45309194e-07 loss = 7.45309194e-07\n",
            "It 05600: l_u = 2.69104021e-06 loss = 2.69104021e-06\n",
            "It 05650: l_u = 5.29037322e-07 loss = 5.29037322e-07\n",
            "It 05700: l_u = 6.55060057e-06 loss = 6.55060057e-06\n",
            "It 05750: l_u = 1.33198989e-06 loss = 1.33198989e-06\n",
            "It 05800: l_u = 5.82952396e-07 loss = 5.82952396e-07\n",
            "It 05850: l_u = 5.83301869e-07 loss = 5.83301869e-07\n",
            "It 05900: l_u = 4.59451002e-07 loss = 4.59451002e-07\n",
            "It 05950: l_u = 4.54907167e-05 loss = 4.54907167e-05\n",
            "It 06000: l_u = 4.46990612e-07 loss = 4.46990612e-07\n",
            "It 06050: l_u = 1.48442996e-06 loss = 1.48442996e-06\n",
            "It 06100: l_u = 1.30889748e-06 loss = 1.30889748e-06\n",
            "It 06150: l_u = 6.30272382e-07 loss = 6.30272382e-07\n",
            "It 06200: l_u = 3.71006604e-06 loss = 3.71006604e-06\n",
            "It 06250: l_u = 4.32273197e-07 loss = 4.32273197e-07\n",
            "It 06300: l_u = 1.30408134e-05 loss = 1.30408134e-05\n",
            "It 06350: l_u = 4.55859163e-06 loss = 4.55859163e-06\n",
            "It 06400: l_u = 1.14330965e-06 loss = 1.14330965e-06\n",
            "It 06450: l_u = 3.74945957e-05 loss = 3.74945957e-05\n",
            "It 06500: l_u = 7.38866447e-07 loss = 7.38866447e-07\n",
            "It 06550: l_u = 6.34630078e-06 loss = 6.34630078e-06\n",
            "It 06600: l_u = 9.21096557e-07 loss = 9.21096557e-07\n",
            "It 06650: l_u = 2.52024984e-06 loss = 2.52024984e-06\n",
            "It 06700: l_u = 2.37842460e-06 loss = 2.37842460e-06\n",
            "It 06750: l_u = 3.38882887e-06 loss = 3.38882887e-06\n",
            "It 06800: l_u = 1.08661936e-06 loss = 1.08661936e-06\n",
            "It 06850: l_u = 5.50626737e-06 loss = 5.50626737e-06\n",
            "It 06900: l_u = 1.19700496e-06 loss = 1.19700496e-06\n",
            "It 06950: l_u = 4.13318558e-05 loss = 4.13318558e-05\n",
            "It 07000: l_u = 8.61739750e-07 loss = 8.61739750e-07\n",
            "It 07050: l_u = 3.22036698e-07 loss = 3.22036698e-07\n",
            "It 07100: l_u = 3.17526968e-07 loss = 3.17526968e-07\n",
            "It 07150: l_u = 3.14039511e-07 loss = 3.14039511e-07\n",
            "It 07200: l_u = 3.10587069e-07 loss = 3.10587069e-07\n",
            "It 07250: l_u = 3.07148611e-07 loss = 3.07148611e-07\n",
            "It 07300: l_u = 3.03710749e-07 loss = 3.03710749e-07\n",
            "It 07350: l_u = 3.00289457e-07 loss = 3.00289457e-07\n",
            "It 07400: l_u = 2.96845172e-07 loss = 2.96845172e-07\n",
            "It 07450: l_u = 2.93393668e-07 loss = 2.93393668e-07\n",
            "It 07500: l_u = 2.89943728e-07 loss = 2.89943728e-07\n",
            "It 07550: l_u = 2.86484806e-07 loss = 2.86484806e-07\n",
            "It 07600: l_u = 2.83010479e-07 loss = 2.83010479e-07\n",
            "It 07650: l_u = 2.79519668e-07 loss = 2.79519668e-07\n",
            "It 07700: l_u = 2.76024480e-07 loss = 2.76024480e-07\n",
            "It 07750: l_u = 2.72532048e-07 loss = 2.72532048e-07\n",
            "It 07800: l_u = 2.69035297e-07 loss = 2.69035297e-07\n",
            "It 07850: l_u = 2.65515553e-07 loss = 2.65515553e-07\n",
            "It 07900: l_u = 2.61991943e-07 loss = 2.61991943e-07\n",
            "It 07950: l_u = 2.58460318e-07 loss = 2.58460318e-07\n",
            "It 08000: l_u = 2.54919541e-07 loss = 2.54919541e-07\n",
            "It 08050: l_u = 2.51378623e-07 loss = 2.51378623e-07\n",
            "It 08100: l_u = 2.47844639e-07 loss = 2.47844639e-07\n",
            "It 08150: l_u = 2.44288628e-07 loss = 2.44288628e-07\n",
            "It 08200: l_u = 2.40746147e-07 loss = 2.40746147e-07\n",
            "It 08250: l_u = 2.37190960e-07 loss = 2.37190960e-07\n",
            "It 08300: l_u = 2.33646290e-07 loss = 2.33646290e-07\n",
            "It 08350: l_u = 2.30097513e-07 loss = 2.30097513e-07\n",
            "It 08400: l_u = 2.26559379e-07 loss = 2.26559379e-07\n",
            "It 08450: l_u = 2.94433557e-05 loss = 2.94433557e-05\n",
            "It 08500: l_u = 3.71397107e-07 loss = 3.71397107e-07\n",
            "It 08550: l_u = 9.41125620e-07 loss = 9.41125620e-07\n",
            "It 08600: l_u = 4.74142468e-07 loss = 4.74142468e-07\n",
            "It 08650: l_u = 7.08679522e-07 loss = 7.08679522e-07\n",
            "It 08700: l_u = 2.25503371e-07 loss = 2.25503371e-07\n",
            "It 08750: l_u = 1.09440020e-06 loss = 1.09440020e-06\n",
            "It 08800: l_u = 2.83344235e-07 loss = 2.83344235e-07\n",
            "It 08850: l_u = 5.71991166e-07 loss = 5.71991166e-07\n",
            "It 08900: l_u = 4.36077335e-06 loss = 4.36077335e-06\n",
            "It 08950: l_u = 2.84683836e-07 loss = 2.84683836e-07\n",
            "It 09000: l_u = 1.20358072e-06 loss = 1.20358072e-06\n",
            "It 09050: l_u = 4.45123788e-07 loss = 4.45123788e-07\n",
            "It 09100: l_u = 8.09836820e-07 loss = 8.09836820e-07\n",
            "It 09150: l_u = 1.87870185e-07 loss = 1.87870185e-07\n",
            "It 09200: l_u = 2.32509660e-06 loss = 2.32509660e-06\n",
            "It 09250: l_u = 1.79947932e-07 loss = 1.79947932e-07\n",
            "It 09300: l_u = 9.73862188e-06 loss = 9.73862188e-06\n",
            "It 09350: l_u = 1.77065786e-07 loss = 1.77065786e-07\n",
            "It 09400: l_u = 1.71902798e-07 loss = 1.71902798e-07\n",
            "It 09450: l_u = 6.17896239e-06 loss = 6.17896239e-06\n",
            "It 09500: l_u = 2.71599220e-07 loss = 2.71599220e-07\n",
            "It 09550: l_u = 1.14225884e-06 loss = 1.14225884e-06\n",
            "It 09600: l_u = 2.15401116e-07 loss = 2.15401116e-07\n",
            "It 09650: l_u = 1.62999669e-07 loss = 1.62999669e-07\n",
            "It 09700: l_u = 1.58147401e-07 loss = 1.58147401e-07\n",
            "It 09750: l_u = 1.02237727e-05 loss = 1.02237727e-05\n",
            "Timeout is reached. Time elapsed: 20.000874519348145 seconds\n",
            "\n",
            "\n",
            "Finding PDE parameters.\n",
            "It 09800: loss = 3.43815555e-06 lambda = [-1.1410098 -0.7116643]\n",
            "It 09850: loss = 3.43815555e-06 lambda = [-3.4100919   0.20839977]\n",
            "It 09900: loss = 3.43815555e-06 lambda = [-5.0316734  0.7040308]\n",
            "It 09950: loss = 3.43815555e-06 lambda = [-5.7229176  0.9136696]\n",
            "It 10000: loss = 3.43815555e-06 lambda = [-5.9324756  0.9767995]\n",
            "It 10050: loss = 3.43815555e-06 lambda = [-5.9789734  0.9908115]\n",
            "It 10100: loss = 3.43815555e-06 lambda = [-5.9865375  0.9930906]\n",
            "It 10150: loss = 3.43815555e-06 lambda = [-5.9874063  0.9933524]\n",
            "It 10200: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337137]\n",
            "It 10250: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 10300: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 10350: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 10400: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 10450: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 10500: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 10550: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 10600: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 10650: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 10700: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 10750: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 10800: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 10850: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 10900: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 10950: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 11000: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 11050: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 11100: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 11150: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 11200: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 11250: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 11300: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 11350: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 11400: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 11450: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 11500: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 11550: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 11600: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 11650: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 11700: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 11750: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 11800: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 11850: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "It 11900: loss = 3.43815555e-06 lambda = [-5.9874687   0.99337107]\n",
            "Timeout is reached. Time elapsed: 80.01020622253418 seconds\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration: 2 Initial lambda: [1.0, -6.0]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Adam\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: l_u = 4.56506044e-01 loss = 4.56506044e-01\n",
            "It 00050: l_u = 4.93783094e-02 loss = 4.93783094e-02\n",
            "It 00100: l_u = 1.98343012e-04 loss = 1.98343012e-04\n",
            "It 00150: l_u = 4.52452005e-05 loss = 4.52452005e-05\n",
            "It 00200: l_u = 2.60484430e-05 loss = 2.60484430e-05\n",
            "It 00250: l_u = 1.15467543e-02 loss = 1.15467543e-02\n",
            "It 00300: l_u = 2.07761186e-05 loss = 2.07761186e-05\n",
            "It 00350: l_u = 1.37242569e-05 loss = 1.37242569e-05\n",
            "It 00400: l_u = 1.08410750e-05 loss = 1.08410750e-05\n",
            "It 00450: l_u = 9.15417149e-06 loss = 9.15417149e-06\n",
            "It 00500: l_u = 7.94634889e-06 loss = 7.94634889e-06\n",
            "It 00550: l_u = 7.02979378e-06 loss = 7.02979378e-06\n",
            "It 00600: l_u = 6.30355908e-06 loss = 6.30355908e-06\n",
            "It 00650: l_u = 5.70990505e-06 loss = 5.70990505e-06\n",
            "It 00700: l_u = 5.21341644e-06 loss = 5.21341644e-06\n",
            "It 00750: l_u = 4.79145274e-06 loss = 4.79145274e-06\n",
            "It 00800: l_u = 4.42823784e-06 loss = 4.42823784e-06\n",
            "It 00850: l_u = 4.11254041e-06 loss = 4.11254041e-06\n",
            "It 00900: l_u = 3.83595716e-06 loss = 3.83595716e-06\n",
            "It 00950: l_u = 3.59189880e-06 loss = 3.59189880e-06\n",
            "It 01000: l_u = 3.37598635e-06 loss = 3.37598635e-06\n",
            "It 01050: l_u = 3.49815848e-04 loss = 3.49815848e-04\n",
            "It 01100: l_u = 3.19768674e-06 loss = 3.19768674e-06\n",
            "It 01150: l_u = 3.05958247e-06 loss = 3.05958247e-06\n",
            "It 01200: l_u = 2.85060378e-06 loss = 2.85060378e-06\n",
            "It 01250: l_u = 2.70898909e-06 loss = 2.70898909e-06\n",
            "It 01300: l_u = 2.58093269e-06 loss = 2.58093269e-06\n",
            "It 01350: l_u = 2.46428613e-06 loss = 2.46428613e-06\n",
            "It 01400: l_u = 2.35755351e-06 loss = 2.35755351e-06\n",
            "It 01450: l_u = 2.25945746e-06 loss = 2.25945746e-06\n",
            "It 01500: l_u = 2.16905414e-06 loss = 2.16905414e-06\n",
            "It 01550: l_u = 2.08541087e-06 loss = 2.08541087e-06\n",
            "It 01600: l_u = 2.00788099e-06 loss = 2.00788099e-06\n",
            "It 01650: l_u = 1.93581423e-06 loss = 1.93581423e-06\n",
            "It 01700: l_u = 1.86866396e-06 loss = 1.86866396e-06\n",
            "It 01750: l_u = 1.80595907e-06 loss = 1.80595907e-06\n",
            "It 01800: l_u = 1.74728291e-06 loss = 1.74728291e-06\n",
            "It 01850: l_u = 1.69231794e-06 loss = 1.69231794e-06\n",
            "It 01900: l_u = 1.64063044e-06 loss = 1.64063044e-06\n",
            "It 01950: l_u = 1.59206968e-06 loss = 1.59206968e-06\n",
            "It 02000: l_u = 1.54634063e-06 loss = 1.54634063e-06\n",
            "It 02050: l_u = 1.50310530e-06 loss = 1.50310530e-06\n",
            "It 02100: l_u = 1.46228047e-06 loss = 1.46228047e-06\n",
            "It 02150: l_u = 1.42367810e-06 loss = 1.42367810e-06\n",
            "It 02200: l_u = 1.38705661e-06 loss = 1.38705661e-06\n",
            "It 02250: l_u = 1.35230528e-06 loss = 1.35230528e-06\n",
            "It 02300: l_u = 1.31929107e-06 loss = 1.31929107e-06\n",
            "It 02350: l_u = 1.28790828e-06 loss = 1.28790828e-06\n",
            "It 02400: l_u = 1.25800739e-06 loss = 1.25800739e-06\n",
            "It 02450: l_u = 1.22952588e-06 loss = 1.22952588e-06\n",
            "It 02500: l_u = 1.20234131e-06 loss = 1.20234131e-06\n",
            "It 02550: l_u = 1.17636193e-06 loss = 1.17636193e-06\n",
            "It 02600: l_u = 1.15158093e-06 loss = 1.15158093e-06\n",
            "It 02650: l_u = 1.12784721e-06 loss = 1.12784721e-06\n",
            "It 02700: l_u = 1.10511940e-06 loss = 1.10511940e-06\n",
            "It 02750: l_u = 1.08336269e-06 loss = 1.08336269e-06\n",
            "It 02800: l_u = 1.06247194e-06 loss = 1.06247194e-06\n",
            "It 02850: l_u = 1.04243929e-06 loss = 1.04243929e-06\n",
            "It 02900: l_u = 1.02320587e-06 loss = 1.02320587e-06\n",
            "It 02950: l_u = 1.00469549e-06 loss = 1.00469549e-06\n",
            "It 03000: l_u = 9.86909868e-07 loss = 9.86909868e-07\n",
            "It 03050: l_u = 9.77986588e-07 loss = 9.77986588e-07\n",
            "It 03100: l_u = 9.69164716e-07 loss = 9.69164716e-07\n",
            "It 03150: l_u = 9.60212674e-07 loss = 9.60212674e-07\n",
            "It 03200: l_u = 9.51160416e-07 loss = 9.51160416e-07\n",
            "It 03250: l_u = 9.42041879e-07 loss = 9.42041879e-07\n",
            "It 03300: l_u = 9.32810224e-07 loss = 9.32810224e-07\n",
            "It 03350: l_u = 9.23511777e-07 loss = 9.23511777e-07\n",
            "It 03400: l_u = 9.14116015e-07 loss = 9.14116015e-07\n",
            "It 03450: l_u = 9.04643571e-07 loss = 9.04643571e-07\n",
            "It 03500: l_u = 8.95114113e-07 loss = 8.95114113e-07\n",
            "It 03550: l_u = 8.85481768e-07 loss = 8.85481768e-07\n",
            "It 03600: l_u = 8.75769558e-07 loss = 8.75769558e-07\n",
            "It 03650: l_u = 8.65988966e-07 loss = 8.65988966e-07\n",
            "It 03700: l_u = 8.56167162e-07 loss = 8.56167162e-07\n",
            "It 03750: l_u = 8.46267028e-07 loss = 8.46267028e-07\n",
            "It 03800: l_u = 8.36309994e-07 loss = 8.36309994e-07\n",
            "It 03850: l_u = 8.26287476e-07 loss = 8.26287476e-07\n",
            "It 03900: l_u = 8.16200895e-07 loss = 8.16200895e-07\n",
            "It 03950: l_u = 8.06065202e-07 loss = 8.06065202e-07\n",
            "It 04000: l_u = 7.95894607e-07 loss = 7.95894607e-07\n",
            "It 04050: l_u = 7.85663588e-07 loss = 7.85663588e-07\n",
            "It 04100: l_u = 7.75424212e-07 loss = 7.75424212e-07\n",
            "It 04150: l_u = 7.65123218e-07 loss = 7.65123218e-07\n",
            "It 04200: l_u = 7.54786356e-07 loss = 7.54786356e-07\n",
            "It 04250: l_u = 7.44440229e-07 loss = 7.44440229e-07\n",
            "It 04300: l_u = 7.34076252e-07 loss = 7.34076252e-07\n",
            "It 04350: l_u = 7.23656342e-07 loss = 7.23656342e-07\n",
            "It 04400: l_u = 7.13252859e-07 loss = 7.13252859e-07\n",
            "It 04450: l_u = 7.02817829e-07 loss = 7.02817829e-07\n",
            "It 04500: l_u = 6.92359038e-07 loss = 6.92359038e-07\n",
            "It 04550: l_u = 6.81920540e-07 loss = 6.81920540e-07\n",
            "It 04600: l_u = 6.71462715e-07 loss = 6.71462715e-07\n",
            "It 04650: l_u = 6.61035358e-07 loss = 6.61035358e-07\n",
            "It 04700: l_u = 6.50603283e-07 loss = 6.50603283e-07\n",
            "It 04750: l_u = 6.40136193e-07 loss = 6.40136193e-07\n",
            "It 04800: l_u = 6.29817862e-07 loss = 6.29817862e-07\n",
            "It 04850: l_u = 1.43618206e-06 loss = 1.43618206e-06\n",
            "It 04900: l_u = 8.18113051e-07 loss = 8.18113051e-07\n",
            "It 04950: l_u = 6.03344574e-07 loss = 6.03344574e-07\n",
            "It 05000: l_u = 5.92717242e-07 loss = 5.92717242e-07\n",
            "It 05050: l_u = 5.83744225e-07 loss = 5.83744225e-07\n",
            "It 05100: l_u = 9.75867351e-06 loss = 9.75867351e-06\n",
            "It 05150: l_u = 5.86967872e-07 loss = 5.86967872e-07\n",
            "It 05200: l_u = 5.59873286e-07 loss = 5.59873286e-07\n",
            "It 05250: l_u = 6.58514864e-07 loss = 6.58514864e-07\n",
            "It 05300: l_u = 4.70200484e-06 loss = 4.70200484e-06\n",
            "It 05350: l_u = 5.39371456e-07 loss = 5.39371456e-07\n",
            "It 05400: l_u = 5.25837550e-07 loss = 5.25837550e-07\n",
            "It 05450: l_u = 3.41629020e-05 loss = 3.41629020e-05\n",
            "It 05500: l_u = 1.01443345e-06 loss = 1.01443345e-06\n",
            "It 05550: l_u = 5.48515118e-06 loss = 5.48515118e-06\n",
            "It 05600: l_u = 5.17184390e-07 loss = 5.17184390e-07\n",
            "It 05650: l_u = 1.13678761e-04 loss = 1.13678761e-04\n",
            "It 05700: l_u = 8.12482199e-07 loss = 8.12482199e-07\n",
            "It 05750: l_u = 4.28301028e-05 loss = 4.28301028e-05\n",
            "It 05800: l_u = 7.05755326e-07 loss = 7.05755326e-07\n",
            "It 05850: l_u = 4.60239676e-07 loss = 4.60239676e-07\n",
            "It 05900: l_u = 1.24791677e-06 loss = 1.24791677e-06\n",
            "It 05950: l_u = 6.33590844e-07 loss = 6.33590844e-07\n",
            "It 06000: l_u = 1.48468564e-06 loss = 1.48468564e-06\n",
            "It 06050: l_u = 4.38044964e-07 loss = 4.38044964e-07\n",
            "It 06100: l_u = 6.30309387e-07 loss = 6.30309387e-07\n",
            "It 06150: l_u = 1.54015856e-06 loss = 1.54015856e-06\n",
            "It 06200: l_u = 3.05988897e-06 loss = 3.05988897e-06\n",
            "It 06250: l_u = 4.41127838e-07 loss = 4.41127838e-07\n",
            "It 06300: l_u = 1.35067567e-05 loss = 1.35067567e-05\n",
            "It 06350: l_u = 6.74432897e-07 loss = 6.74432897e-07\n",
            "It 06400: l_u = 2.68329877e-05 loss = 2.68329877e-05\n",
            "It 06450: l_u = 5.59881755e-07 loss = 5.59881755e-07\n",
            "It 06500: l_u = 3.79502268e-07 loss = 3.79502268e-07\n",
            "It 06550: l_u = 2.49240693e-05 loss = 2.49240693e-05\n",
            "It 06600: l_u = 3.81322025e-07 loss = 3.81322025e-07\n",
            "It 06650: l_u = 4.51564438e-06 loss = 4.51564438e-06\n",
            "It 06700: l_u = 4.05417268e-07 loss = 4.05417268e-07\n",
            "It 06750: l_u = 3.48160910e-07 loss = 3.48160910e-07\n",
            "It 06800: l_u = 1.24871822e-05 loss = 1.24871822e-05\n",
            "It 06850: l_u = 7.61689307e-06 loss = 7.61689307e-06\n",
            "It 06900: l_u = 8.08327570e-07 loss = 8.08327570e-07\n",
            "It 06950: l_u = 3.34008462e-07 loss = 3.34008462e-07\n",
            "It 07000: l_u = 9.92705191e-06 loss = 9.92705191e-06\n",
            "It 07050: l_u = 3.75470051e-07 loss = 3.75470051e-07\n",
            "It 07100: l_u = 3.14701680e-07 loss = 3.14701680e-07\n",
            "It 07150: l_u = 3.11328648e-07 loss = 3.11328648e-07\n",
            "It 07200: l_u = 3.07966701e-07 loss = 3.07966701e-07\n",
            "It 07250: l_u = 3.04590856e-07 loss = 3.04590856e-07\n",
            "It 07300: l_u = 3.01213703e-07 loss = 3.01213703e-07\n",
            "It 07350: l_u = 2.97813159e-07 loss = 2.97813159e-07\n",
            "It 07400: l_u = 2.94400053e-07 loss = 2.94400053e-07\n",
            "It 07450: l_u = 2.90977852e-07 loss = 2.90977852e-07\n",
            "It 07500: l_u = 2.87545191e-07 loss = 2.87545191e-07\n",
            "It 07550: l_u = 2.84105965e-07 loss = 2.84105965e-07\n",
            "It 07600: l_u = 2.80651790e-07 loss = 2.80651790e-07\n",
            "It 07650: l_u = 2.77181101e-07 loss = 2.77181101e-07\n",
            "It 07700: l_u = 2.73690290e-07 loss = 2.73690290e-07\n",
            "It 07750: l_u = 2.70221250e-07 loss = 2.70221250e-07\n",
            "It 07800: l_u = 2.66721116e-07 loss = 2.66721116e-07\n",
            "It 07850: l_u = 2.63213877e-07 loss = 2.63213877e-07\n",
            "It 07900: l_u = 2.59702176e-07 loss = 2.59702176e-07\n",
            "It 07950: l_u = 2.56163759e-07 loss = 2.56163759e-07\n",
            "It 08000: l_u = 2.52647965e-07 loss = 2.52647965e-07\n",
            "It 08050: l_u = 2.49109746e-07 loss = 2.49109746e-07\n",
            "It 08100: l_u = 2.45563854e-07 loss = 2.45563854e-07\n",
            "It 08150: l_u = 2.42017052e-07 loss = 2.42017052e-07\n",
            "It 08200: l_u = 2.38475906e-07 loss = 2.38475906e-07\n",
            "It 08250: l_u = 2.34936863e-07 loss = 2.34936863e-07\n",
            "It 08300: l_u = 2.31383552e-07 loss = 2.31383552e-07\n",
            "It 08350: l_u = 2.27852880e-07 loss = 2.27852880e-07\n",
            "It 08400: l_u = 2.24405269e-07 loss = 2.24405269e-07\n",
            "It 08450: l_u = 3.54099711e-06 loss = 3.54099711e-06\n",
            "It 08500: l_u = 2.20303463e-07 loss = 2.20303463e-07\n",
            "It 08550: l_u = 2.17633840e-07 loss = 2.17633840e-07\n",
            "It 08600: l_u = 6.98549457e-07 loss = 6.98549457e-07\n",
            "It 08650: l_u = 2.09950556e-07 loss = 2.09950556e-07\n",
            "It 08700: l_u = 2.06769471e-07 loss = 2.06769471e-07\n",
            "It 08750: l_u = 2.28462852e-07 loss = 2.28462852e-07\n",
            "It 08800: l_u = 1.26596819e-06 loss = 1.26596819e-06\n",
            "It 08850: l_u = 2.02571727e-07 loss = 2.02571727e-07\n",
            "It 08900: l_u = 1.10366204e-06 loss = 1.10366204e-06\n",
            "It 08950: l_u = 2.07536132e-07 loss = 2.07536132e-07\n",
            "It 09000: l_u = 8.50294555e-07 loss = 8.50294555e-07\n",
            "It 09050: l_u = 6.46699959e-07 loss = 6.46699959e-07\n",
            "It 09100: l_u = 9.47295939e-06 loss = 9.47295939e-06\n",
            "It 09150: l_u = 1.91092653e-07 loss = 1.91092653e-07\n",
            "It 09200: l_u = 7.10167171e-07 loss = 7.10167171e-07\n",
            "It 09250: l_u = 1.86661097e-07 loss = 1.86661097e-07\n",
            "It 09300: l_u = 1.67483256e-06 loss = 1.67483256e-06\n",
            "It 09350: l_u = 1.83521806e-07 loss = 1.83521806e-07\n",
            "It 09400: l_u = 2.45820672e-07 loss = 2.45820672e-07\n",
            "It 09450: l_u = 3.08101136e-07 loss = 3.08101136e-07\n",
            "It 09500: l_u = 1.65916362e-07 loss = 1.65916362e-07\n",
            "It 09550: l_u = 1.63319513e-07 loss = 1.63319513e-07\n",
            "It 09600: l_u = 1.14315003e-06 loss = 1.14315003e-06\n",
            "It 09650: l_u = 4.01333324e-07 loss = 4.01333324e-07\n",
            "It 09700: l_u = 6.76457660e-07 loss = 6.76457660e-07\n",
            "It 09750: l_u = 1.59122266e-07 loss = 1.59122266e-07\n",
            "It 09800: l_u = 4.08176277e-07 loss = 4.08176277e-07\n",
            "It 09850: l_u = 4.73988308e-07 loss = 4.73988308e-07\n",
            "It 09900: l_u = 1.58831412e-07 loss = 1.58831412e-07\n",
            "Timeout is reached. Time elapsed: 20.000014305114746 seconds\n",
            "\n",
            "\n",
            "Finding PDE parameters.\n",
            "It 09950: loss = 6.84903671e-06 lambda = [ 3.9168258 -2.9919155]\n",
            "It 10000: loss = 6.84903671e-06 lambda = [ 3.934052  -1.9566797]\n",
            "It 10050: loss = 6.84903671e-06 lambda = [ 2.792584  -1.6926237]\n",
            "It 10100: loss = 6.84903671e-06 lambda = [ 1.6882187 -1.3504839]\n",
            "It 10150: loss = 6.84903671e-06 lambda = [ 0.613875  -1.0229688]\n",
            "It 10200: loss = 6.84903671e-06 lambda = [-0.38365057 -0.71905357]\n",
            "It 10250: loss = 6.84903671e-06 lambda = [-1.282642   -0.44526422]\n",
            "It 10300: loss = 6.84903671e-06 lambda = [-2.0748575  -0.20407708]\n",
            "It 10350: loss = 6.84903671e-06 lambda = [-2.7606914  0.0046724]\n",
            "It 10400: loss = 6.84903671e-06 lambda = [-3.3458822   0.18275903]\n",
            "It 10450: loss = 6.84903671e-06 lambda = [-3.8391933   0.33286706]\n",
            "It 10500: loss = 6.84903671e-06 lambda = [-4.250811    0.45810655]\n",
            "It 10550: loss = 6.84903671e-06 lambda = [-4.5912642  0.5616879]\n",
            "It 10600: loss = 6.84903671e-06 lambda = [-4.8707385  0.6467139]\n",
            "It 10650: loss = 6.84903671e-06 lambda = [-5.0986686   0.71605617]\n",
            "It 10700: loss = 6.84903671e-06 lambda = [-5.2835164   0.77229065]\n",
            "It 10750: loss = 6.84903671e-06 lambda = [-5.4326944   0.81767327]\n",
            "It 10800: loss = 6.84903671e-06 lambda = [-5.552582  0.854145]\n",
            "It 10850: loss = 6.84903671e-06 lambda = [-5.648582   0.8833496]\n",
            "It 10900: loss = 6.84903671e-06 lambda = [-5.7252173  0.906663 ]\n",
            "It 10950: loss = 6.84903671e-06 lambda = [-5.7862334   0.92522484]\n",
            "It 11000: loss = 6.84903671e-06 lambda = [-5.834706   0.9399706]\n",
            "It 11050: loss = 6.84903671e-06 lambda = [-5.873143    0.95166355]\n",
            "It 11100: loss = 6.84903671e-06 lambda = [-5.903576  0.960922]\n",
            "It 11150: loss = 6.84903671e-06 lambda = [-5.927643   0.9682432]\n",
            "It 11200: loss = 6.84903671e-06 lambda = [-5.946658   0.9740277]\n",
            "It 11250: loss = 6.84903671e-06 lambda = [-5.9616714   0.97859526]\n",
            "It 11300: loss = 6.84903671e-06 lambda = [-5.9735208  0.9821997]\n",
            "It 11350: loss = 6.84903671e-06 lambda = [-5.982868    0.98504347]\n",
            "It 11400: loss = 6.84903671e-06 lambda = [-5.990244   0.9872872]\n",
            "It 11450: loss = 6.84903671e-06 lambda = [-5.996064   0.9890578]\n",
            "It 11500: loss = 6.84903671e-06 lambda = [-6.000658    0.99045527]\n",
            "It 11550: loss = 6.84903671e-06 lambda = [-6.004284   0.9915584]\n",
            "It 11600: loss = 6.84903671e-06 lambda = [-6.0071487   0.99242985]\n",
            "It 11650: loss = 6.84903671e-06 lambda = [-6.009413    0.99311864]\n",
            "It 11700: loss = 6.84903671e-06 lambda = [-6.0112047  0.9936637]\n",
            "It 11750: loss = 6.84903671e-06 lambda = [-6.012623   0.9940952]\n",
            "It 11800: loss = 6.84903671e-06 lambda = [-6.013747   0.9944373]\n",
            "It 11850: loss = 6.84903671e-06 lambda = [-6.014639   0.9947085]\n",
            "It 11900: loss = 6.84903671e-06 lambda = [-6.0153475   0.99492395]\n",
            "It 11950: loss = 6.84903671e-06 lambda = [-6.0159106  0.9950954]\n",
            "It 12000: loss = 6.84903671e-06 lambda = [-6.016359   0.9952317]\n",
            "It 12050: loss = 6.84903671e-06 lambda = [-6.0167165  0.9953403]\n",
            "Timeout is reached. Time elapsed: 80.00422406196594 seconds\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration: 2 Initial lambda: [10.0, 10.0]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Adam\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: l_u = 4.56506044e-01 loss = 4.56506044e-01\n",
            "It 00050: l_u = 4.93783504e-02 loss = 4.93783504e-02\n",
            "It 00100: l_u = 1.98344918e-04 loss = 1.98344918e-04\n",
            "It 00150: l_u = 4.52450622e-05 loss = 4.52450622e-05\n",
            "It 00200: l_u = 2.60484267e-05 loss = 2.60484267e-05\n",
            "It 00250: l_u = 7.03893276e-03 loss = 7.03893276e-03\n",
            "It 00300: l_u = 2.97447623e-05 loss = 2.97447623e-05\n",
            "It 00350: l_u = 1.30372146e-05 loss = 1.30372146e-05\n",
            "It 00400: l_u = 1.05662975e-05 loss = 1.05662975e-05\n",
            "It 00450: l_u = 8.93476226e-06 loss = 8.93476226e-06\n",
            "It 00500: l_u = 7.75799072e-06 loss = 7.75799072e-06\n",
            "It 00550: l_u = 6.86081466e-06 loss = 6.86081466e-06\n",
            "It 00600: l_u = 6.14764758e-06 loss = 6.14764758e-06\n",
            "It 00650: l_u = 5.56323675e-06 loss = 5.56323675e-06\n",
            "It 00700: l_u = 5.07396908e-06 loss = 5.07396908e-06\n",
            "It 00750: l_u = 4.65791391e-06 loss = 4.65791391e-06\n",
            "It 00800: l_u = 4.30005821e-06 loss = 4.30005821e-06\n",
            "It 00850: l_u = 1.87742353e-05 loss = 1.87742353e-05\n",
            "It 00900: l_u = 3.04211735e-05 loss = 3.04211735e-05\n",
            "It 00950: l_u = 3.96493169e-06 loss = 3.96493169e-06\n",
            "It 01000: l_u = 3.60936247e-06 loss = 3.60936247e-06\n",
            "It 01050: l_u = 3.38150994e-06 loss = 3.38150994e-06\n",
            "It 01100: l_u = 3.18283014e-06 loss = 3.18283014e-06\n",
            "It 01150: l_u = 3.00673901e-06 loss = 3.00673901e-06\n",
            "It 01200: l_u = 2.84899579e-06 loss = 2.84899579e-06\n",
            "It 01250: l_u = 2.70676833e-06 loss = 2.70676833e-06\n",
            "It 01300: l_u = 2.57774059e-06 loss = 2.57774059e-06\n",
            "It 01350: l_u = 2.46018089e-06 loss = 2.46018089e-06\n",
            "It 01400: l_u = 2.35264724e-06 loss = 2.35264724e-06\n",
            "It 01450: l_u = 2.25396298e-06 loss = 2.25396298e-06\n",
            "It 01500: l_u = 2.16309513e-06 loss = 2.16309513e-06\n",
            "It 01550: l_u = 2.07913763e-06 loss = 2.07913763e-06\n",
            "It 01600: l_u = 2.00144632e-06 loss = 2.00144632e-06\n",
            "It 01650: l_u = 1.92930929e-06 loss = 1.92930929e-06\n",
            "It 01700: l_u = 1.86215652e-06 loss = 1.86215652e-06\n",
            "It 01750: l_u = 1.79949893e-06 loss = 1.79949893e-06\n",
            "It 01800: l_u = 1.74099523e-06 loss = 1.74099523e-06\n",
            "It 01850: l_u = 1.68612780e-06 loss = 1.68612780e-06\n",
            "It 01900: l_u = 1.63470179e-06 loss = 1.63470179e-06\n",
            "It 01950: l_u = 1.58631019e-06 loss = 1.58631019e-06\n",
            "It 02000: l_u = 1.54078452e-06 loss = 1.54078452e-06\n",
            "It 02050: l_u = 1.49783227e-06 loss = 1.49783227e-06\n",
            "It 02100: l_u = 1.45722811e-06 loss = 1.45722811e-06\n",
            "It 02150: l_u = 1.41884902e-06 loss = 1.41884902e-06\n",
            "It 02200: l_u = 1.38251460e-06 loss = 1.38251460e-06\n",
            "It 02250: l_u = 1.34801576e-06 loss = 1.34801576e-06\n",
            "It 02300: l_u = 1.31521847e-06 loss = 1.31521847e-06\n",
            "It 02350: l_u = 1.28410466e-06 loss = 1.28410466e-06\n",
            "It 02400: l_u = 1.25443376e-06 loss = 1.25443376e-06\n",
            "It 02450: l_u = 1.22616086e-06 loss = 1.22616086e-06\n",
            "It 02500: l_u = 1.19921003e-06 loss = 1.19921003e-06\n",
            "It 02550: l_u = 1.17344473e-06 loss = 1.17344473e-06\n",
            "It 02600: l_u = 1.14886916e-06 loss = 1.14886916e-06\n",
            "It 02650: l_u = 1.12533473e-06 loss = 1.12533473e-06\n",
            "It 02700: l_u = 1.10277631e-06 loss = 1.10277631e-06\n",
            "It 02750: l_u = 1.08120128e-06 loss = 1.08120128e-06\n",
            "It 02800: l_u = 1.06047105e-06 loss = 1.06047105e-06\n",
            "It 02850: l_u = 1.04065259e-06 loss = 1.04065259e-06\n",
            "It 02900: l_u = 1.02154843e-06 loss = 1.02154843e-06\n",
            "It 02950: l_u = 1.00318357e-06 loss = 1.00318357e-06\n",
            "It 03000: l_u = 9.85572910e-07 loss = 9.85572910e-07\n",
            "It 03050: l_u = 9.76691013e-07 loss = 9.76691013e-07\n",
            "It 03100: l_u = 9.67935989e-07 loss = 9.67935989e-07\n",
            "It 03150: l_u = 9.59072509e-07 loss = 9.59072509e-07\n",
            "It 03200: l_u = 9.50113247e-07 loss = 9.50113247e-07\n",
            "It 03250: l_u = 9.41070937e-07 loss = 9.41070937e-07\n",
            "It 03300: l_u = 9.31907266e-07 loss = 9.31907266e-07\n",
            "It 03350: l_u = 9.22687718e-07 loss = 9.22687718e-07\n",
            "It 03400: l_u = 9.13372730e-07 loss = 9.13372730e-07\n",
            "It 03450: l_u = 9.03965713e-07 loss = 9.03965713e-07\n",
            "It 03500: l_u = 8.94488210e-07 loss = 8.94488210e-07\n",
            "It 03550: l_u = 8.84939880e-07 loss = 8.84939880e-07\n",
            "It 03600: l_u = 8.75290198e-07 loss = 8.75290198e-07\n",
            "It 03650: l_u = 8.65635457e-07 loss = 8.65635457e-07\n",
            "It 03700: l_u = 8.55855831e-07 loss = 8.55855831e-07\n",
            "It 03750: l_u = 8.46005776e-07 loss = 8.46005776e-07\n",
            "It 03800: l_u = 8.36139975e-07 loss = 8.36139975e-07\n",
            "It 03850: l_u = 8.26168389e-07 loss = 8.26168389e-07\n",
            "It 03900: l_u = 8.16168608e-07 loss = 8.16168608e-07\n",
            "It 03950: l_u = 8.06118180e-07 loss = 8.06118180e-07\n",
            "It 04000: l_u = 7.96013808e-07 loss = 7.96013808e-07\n",
            "It 04050: l_u = 7.85859925e-07 loss = 7.85859925e-07\n",
            "It 04100: l_u = 7.75674721e-07 loss = 7.75674721e-07\n",
            "It 04150: l_u = 7.65449158e-07 loss = 7.65449158e-07\n",
            "It 04200: l_u = 7.55186193e-07 loss = 7.55186193e-07\n",
            "It 04250: l_u = 7.44884744e-07 loss = 7.44884744e-07\n",
            "It 04300: l_u = 7.34566299e-07 loss = 7.34566299e-07\n",
            "It 04350: l_u = 7.24251493e-07 loss = 7.24251493e-07\n",
            "It 04400: l_u = 7.13882343e-07 loss = 7.13882343e-07\n",
            "It 04450: l_u = 7.03523710e-07 loss = 7.03523710e-07\n",
            "It 04500: l_u = 6.93122217e-07 loss = 6.93122217e-07\n",
            "It 04550: l_u = 6.82735561e-07 loss = 6.82735561e-07\n",
            "It 04600: l_u = 6.72336853e-07 loss = 6.72336853e-07\n",
            "It 04650: l_u = 6.61951162e-07 loss = 6.61951162e-07\n",
            "It 04700: l_u = 6.51573487e-07 loss = 6.51573487e-07\n",
            "It 04750: l_u = 6.41170118e-07 loss = 6.41170118e-07\n",
            "It 04800: l_u = 6.30841612e-07 loss = 6.30841612e-07\n",
            "It 04850: l_u = 6.21159706e-05 loss = 6.21159706e-05\n",
            "It 04900: l_u = 1.32563230e-06 loss = 1.32563230e-06\n",
            "It 04950: l_u = 6.04672948e-07 loss = 6.04672948e-07\n",
            "It 05000: l_u = 5.94045446e-07 loss = 5.94045446e-07\n",
            "It 05050: l_u = 5.84279292e-07 loss = 5.84279292e-07\n",
            "It 05100: l_u = 1.16465399e-05 loss = 1.16465399e-05\n",
            "It 05150: l_u = 6.07839297e-07 loss = 6.07839297e-07\n",
            "It 05200: l_u = 5.59784951e-07 loss = 5.59784951e-07\n",
            "It 05250: l_u = 4.69182669e-05 loss = 4.69182669e-05\n",
            "It 05300: l_u = 5.83928511e-07 loss = 5.83928511e-07\n",
            "It 05350: l_u = 5.35534582e-07 loss = 5.35534582e-07\n",
            "It 05400: l_u = 8.11388077e-07 loss = 8.11388077e-07\n",
            "It 05450: l_u = 1.98896169e-06 loss = 1.98896169e-06\n",
            "It 05500: l_u = 8.16867941e-06 loss = 8.16867941e-06\n",
            "It 05550: l_u = 6.71979194e-07 loss = 6.71979194e-07\n",
            "It 05600: l_u = 4.61853915e-06 loss = 4.61853915e-06\n",
            "It 05650: l_u = 5.11288874e-07 loss = 5.11288874e-07\n",
            "It 05700: l_u = 2.47656408e-05 loss = 2.47656408e-05\n",
            "It 05750: l_u = 1.13726571e-06 loss = 1.13726571e-06\n",
            "It 05800: l_u = 6.53670941e-05 loss = 6.53670941e-05\n",
            "It 05850: l_u = 4.61435718e-07 loss = 4.61435718e-07\n",
            "It 05900: l_u = 4.60210856e-07 loss = 4.60210856e-07\n",
            "It 05950: l_u = 2.47042099e-05 loss = 2.47042099e-05\n",
            "It 06000: l_u = 1.09696396e-06 loss = 1.09696396e-06\n",
            "It 06050: l_u = 2.19545086e-06 loss = 2.19545086e-06\n",
            "It 06100: l_u = 5.38826214e-07 loss = 5.38826214e-07\n",
            "It 06150: l_u = 4.24674710e-07 loss = 4.24674710e-07\n",
            "It 06200: l_u = 4.09650420e-06 loss = 4.09650420e-06\n",
            "It 06250: l_u = 5.92630897e-07 loss = 5.92630897e-07\n",
            "It 06300: l_u = 2.09290783e-06 loss = 2.09290783e-06\n",
            "It 06350: l_u = 3.97096926e-07 loss = 3.97096926e-07\n",
            "It 06400: l_u = 3.89014019e-07 loss = 3.89014019e-07\n",
            "It 06450: l_u = 5.59744240e-06 loss = 5.59744240e-06\n",
            "It 06500: l_u = 1.14540608e-05 loss = 1.14540608e-05\n",
            "It 06550: l_u = 4.40186022e-06 loss = 4.40186022e-06\n",
            "It 06600: l_u = 1.38424161e-06 loss = 1.38424161e-06\n",
            "It 06650: l_u = 9.80036930e-05 loss = 9.80036930e-05\n",
            "It 06700: l_u = 1.70470648e-05 loss = 1.70470648e-05\n",
            "It 06750: l_u = 4.41507666e-07 loss = 4.41507666e-07\n",
            "It 06800: l_u = 3.68405813e-06 loss = 3.68405813e-06\n",
            "It 06850: l_u = 1.04635628e-05 loss = 1.04635628e-05\n",
            "It 06900: l_u = 3.47953090e-07 loss = 3.47953090e-07\n",
            "It 06950: l_u = 2.15638356e-05 loss = 2.15638356e-05\n",
            "It 07000: l_u = 9.89854357e-07 loss = 9.89854357e-07\n",
            "It 07050: l_u = 3.22564574e-07 loss = 3.22564574e-07\n",
            "It 07100: l_u = 3.17385712e-07 loss = 3.17385712e-07\n",
            "It 07150: l_u = 3.13983321e-07 loss = 3.13983321e-07\n",
            "It 07200: l_u = 3.10608982e-07 loss = 3.10608982e-07\n",
            "It 07250: l_u = 3.07210826e-07 loss = 3.07210826e-07\n",
            "It 07300: l_u = 3.03825658e-07 loss = 3.03825658e-07\n",
            "It 07350: l_u = 3.00426620e-07 loss = 3.00426620e-07\n",
            "It 07400: l_u = 2.97016555e-07 loss = 2.97016555e-07\n",
            "It 07450: l_u = 2.93612089e-07 loss = 2.93612089e-07\n",
            "It 07500: l_u = 2.90184346e-07 loss = 2.90184346e-07\n",
            "It 07550: l_u = 2.86735599e-07 loss = 2.86735599e-07\n",
            "It 07600: l_u = 2.83310555e-07 loss = 2.83310555e-07\n",
            "It 07650: l_u = 2.79834154e-07 loss = 2.79834154e-07\n",
            "It 07700: l_u = 2.76383133e-07 loss = 2.76383133e-07\n",
            "It 07750: l_u = 2.72894994e-07 loss = 2.72894994e-07\n",
            "It 07800: l_u = 2.69429506e-07 loss = 2.69429506e-07\n",
            "It 07850: l_u = 2.65940685e-07 loss = 2.65940685e-07\n",
            "It 07900: l_u = 2.62426028e-07 loss = 2.62426028e-07\n",
            "It 07950: l_u = 2.58927827e-07 loss = 2.58927827e-07\n",
            "It 08000: l_u = 2.55416722e-07 loss = 2.55416722e-07\n",
            "It 08050: l_u = 2.51909256e-07 loss = 2.51909256e-07\n",
            "It 08100: l_u = 2.48381838e-07 loss = 2.48381838e-07\n",
            "It 08150: l_u = 2.44857574e-07 loss = 2.44857574e-07\n",
            "It 08200: l_u = 2.41342008e-07 loss = 2.41342008e-07\n",
            "It 08250: l_u = 2.37811037e-07 loss = 2.37811037e-07\n",
            "It 08300: l_u = 2.34278971e-07 loss = 2.34278971e-07\n",
            "It 08350: l_u = 2.30745869e-07 loss = 2.30745869e-07\n",
            "It 08400: l_u = 2.29698813e-07 loss = 2.29698813e-07\n",
            "It 08450: l_u = 2.56392491e-06 loss = 2.56392491e-06\n",
            "It 08500: l_u = 2.33183769e-07 loss = 2.33183769e-07\n",
            "It 08550: l_u = 2.18170200e-07 loss = 2.18170200e-07\n",
            "It 08600: l_u = 3.63187087e-06 loss = 3.63187087e-06\n",
            "It 08650: l_u = 2.26135128e-07 loss = 2.26135128e-07\n",
            "It 08700: l_u = 2.88142729e-07 loss = 2.88142729e-07\n",
            "It 08750: l_u = 2.09769581e-07 loss = 2.09769581e-07\n",
            "It 08800: l_u = 2.03440152e-07 loss = 2.03440152e-07\n",
            "It 08850: l_u = 1.93834367e-05 loss = 1.93834367e-05\n",
            "It 08900: l_u = 1.04969149e-06 loss = 1.04969149e-06\n",
            "It 08950: l_u = 2.00703326e-07 loss = 2.00703326e-07\n",
            "It 09000: l_u = 8.81687174e-06 loss = 8.81687174e-06\n",
            "It 09050: l_u = 2.96997968e-07 loss = 2.96997968e-07\n",
            "It 09100: l_u = 8.54580094e-07 loss = 8.54580094e-07\n",
            "It 09150: l_u = 1.38361547e-05 loss = 1.38361547e-05\n",
            "It 09200: l_u = 2.45780200e-07 loss = 2.45780200e-07\n",
            "It 09250: l_u = 1.75998650e-06 loss = 1.75998650e-06\n",
            "It 09300: l_u = 1.84919898e-07 loss = 1.84919898e-07\n",
            "It 09350: l_u = 2.20834224e-07 loss = 2.20834224e-07\n",
            "It 09400: l_u = 1.00685952e-06 loss = 1.00685952e-06\n",
            "It 09450: l_u = 2.32294806e-05 loss = 2.32294806e-05\n",
            "It 09500: l_u = 2.55690850e-07 loss = 2.55690850e-07\n",
            "It 09550: l_u = 1.66594461e-07 loss = 1.66594461e-07\n",
            "It 09600: l_u = 1.63166519e-07 loss = 1.63166519e-07\n",
            "It 09650: l_u = 2.11028379e-07 loss = 2.11028379e-07\n",
            "It 09700: l_u = 2.36176675e-06 loss = 2.36176675e-06\n",
            "It 09750: l_u = 1.67377465e-07 loss = 1.67377465e-07\n",
            "It 09800: l_u = 1.40990005e-06 loss = 1.40990005e-06\n",
            "It 09850: l_u = 2.99198263e-07 loss = 2.99198263e-07\n",
            "It 09900: l_u = 6.60066871e-06 loss = 6.60066871e-06\n",
            "It 09950: l_u = 4.09356176e-07 loss = 4.09356176e-07\n",
            "Timeout is reached. Time elapsed: 20.00087547302246 seconds\n",
            "\n",
            "\n",
            "Finding PDE parameters.\n",
            "It 10000: loss = 1.48880659e-07 lambda = [8.810056 8.810172]\n",
            "It 10050: loss = 1.48880659e-07 lambda = [4.5016723 4.516119 ]\n",
            "It 10100: loss = 1.48880659e-07 lambda = [1.6729432 1.7459178]\n",
            "It 10150: loss = 1.48880659e-07 lambda = [0.13255168 0.31690744]\n",
            "It 10200: loss = 1.48880659e-07 lambda = [-0.60031724 -0.26240322]\n",
            "It 10250: loss = 1.48880659e-07 lambda = [-0.95055515 -0.43342757]\n",
            "It 10300: loss = 1.48880659e-07 lambda = [-1.1598045 -0.4498299]\n",
            "It 10350: loss = 1.48880659e-07 lambda = [-1.3279667  -0.41819766]\n",
            "It 10400: loss = 1.48880659e-07 lambda = [-1.4867768  -0.37392968]\n",
            "It 10450: loss = 1.48880659e-07 lambda = [-1.643772   -0.32685977]\n",
            "It 10500: loss = 1.48880659e-07 lambda = [-1.7997766  -0.27947092]\n",
            "It 10550: loss = 1.48880659e-07 lambda = [-1.9542023  -0.23246442]\n",
            "It 10600: loss = 1.48880659e-07 lambda = [-2.1063313  -0.18614426]\n",
            "It 10650: loss = 1.48880659e-07 lambda = [-2.2555516  -0.14070858]\n",
            "It 10700: loss = 1.48880659e-07 lambda = [-2.4013767  -0.09630676]\n",
            "It 10750: loss = 1.48880659e-07 lambda = [-2.5434325  -0.05305294]\n",
            "It 10800: loss = 1.48880659e-07 lambda = [-2.6814384  -0.01103265]\n",
            "It 10850: loss = 1.48880659e-07 lambda = [-2.8151908   0.02969244]\n",
            "It 10900: loss = 1.48880659e-07 lambda = [-2.9445531   0.06908062]\n",
            "It 10950: loss = 1.48880659e-07 lambda = [-3.0694437   0.10710705]\n",
            "It 11000: loss = 1.48880659e-07 lambda = [-3.189826    0.14376065]\n",
            "It 11050: loss = 1.48880659e-07 lambda = [-3.3057017   0.17904185]\n",
            "It 11100: loss = 1.48880659e-07 lambda = [-3.4171028   0.21296051]\n",
            "It 11150: loss = 1.48880659e-07 lambda = [-3.524088    0.24553436]\n",
            "It 11200: loss = 1.48880659e-07 lambda = [-3.626734    0.27678716]\n",
            "It 11250: loss = 1.48880659e-07 lambda = [-3.725137   0.3067477]\n",
            "It 11300: loss = 1.48880659e-07 lambda = [-3.8194013   0.33544832]\n",
            "It 11350: loss = 1.48880659e-07 lambda = [-3.9096448   0.36292455]\n",
            "It 11400: loss = 1.48880659e-07 lambda = [-3.9959922   0.38921437]\n",
            "It 11450: loss = 1.48880659e-07 lambda = [-4.0785694   0.41435653]\n",
            "It 11500: loss = 1.48880659e-07 lambda = [-4.1575103   0.43839127]\n",
            "It 11550: loss = 1.48880659e-07 lambda = [-4.232949   0.4613595]\n",
            "It 11600: loss = 1.48880659e-07 lambda = [-4.3050184   0.48330206]\n",
            "It 11650: loss = 1.48880659e-07 lambda = [-4.373853   0.5042596]\n",
            "It 11700: loss = 1.48880659e-07 lambda = [-4.439584    0.52427197]\n",
            "It 11750: loss = 1.48880659e-07 lambda = [-4.5023413   0.54337895]\n",
            "It 11800: loss = 1.48880659e-07 lambda = [-4.562251   0.5616192]\n",
            "It 11850: loss = 1.48880659e-07 lambda = [-4.6194396   0.57903063]\n",
            "It 11900: loss = 1.48880659e-07 lambda = [-4.6740255  0.5956498]\n",
            "It 11950: loss = 1.48880659e-07 lambda = [-4.726128    0.61151224]\n",
            "It 12000: loss = 1.48880659e-07 lambda = [-4.775856    0.62665284]\n",
            "It 12050: loss = 1.48880659e-07 lambda = [-4.823321    0.64110386]\n",
            "It 12100: loss = 1.48880659e-07 lambda = [-4.8686275  0.6548978]\n",
            "It 12150: loss = 1.48880659e-07 lambda = [-4.9118776  0.6680655]\n",
            "Timeout is reached. Time elapsed: 80.00079917907715 seconds\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration: 3 Initial lambda: [0.0, 0.0]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Adam\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: l_u = 3.45607370e-01 loss = 3.45607370e-01\n",
            "It 00050: l_u = 3.97772435e-03 loss = 3.97772435e-03\n",
            "It 00100: l_u = 1.55872418e-04 loss = 1.55872418e-04\n",
            "It 00150: l_u = 4.84154625e-05 loss = 4.84154625e-05\n",
            "It 00200: l_u = 3.29409449e-05 loss = 3.29409449e-05\n",
            "It 00250: l_u = 6.42341445e-04 loss = 6.42341445e-04\n",
            "It 00300: l_u = 3.58131438e-05 loss = 3.58131438e-05\n",
            "It 00350: l_u = 1.72007112e-05 loss = 1.72007112e-05\n",
            "It 00400: l_u = 1.53143046e-05 loss = 1.53143046e-05\n",
            "It 00450: l_u = 1.41867085e-05 loss = 1.41867085e-05\n",
            "It 00500: l_u = 1.32918913e-05 loss = 1.32918913e-05\n",
            "It 00550: l_u = 1.25432316e-05 loss = 1.25432316e-05\n",
            "It 00600: l_u = 1.18987609e-05 loss = 1.18987609e-05\n",
            "It 00650: l_u = 1.13316964e-05 loss = 1.13316964e-05\n",
            "It 00700: l_u = 1.08242903e-05 loss = 1.08242903e-05\n",
            "It 00750: l_u = 1.03642678e-05 loss = 1.03642678e-05\n",
            "It 00800: l_u = 9.94295078e-06 loss = 9.94295078e-06\n",
            "It 00850: l_u = 9.55405812e-06 loss = 9.55405812e-06\n",
            "It 00900: l_u = 9.19283684e-06 loss = 9.19283684e-06\n",
            "It 00950: l_u = 8.85560530e-06 loss = 8.85560530e-06\n",
            "It 01000: l_u = 8.53943766e-06 loss = 8.53943766e-06\n",
            "It 01050: l_u = 8.24200015e-06 loss = 8.24200015e-06\n",
            "It 01100: l_u = 7.96136101e-06 loss = 7.96136101e-06\n",
            "It 01150: l_u = 7.69599774e-06 loss = 7.69599774e-06\n",
            "It 01200: l_u = 7.44448471e-06 loss = 7.44448471e-06\n",
            "It 01250: l_u = 7.20570233e-06 loss = 7.20570233e-06\n",
            "It 01300: l_u = 6.97859787e-06 loss = 6.97859787e-06\n",
            "It 01350: l_u = 6.76237096e-06 loss = 6.76237096e-06\n",
            "It 01400: l_u = 6.55621989e-06 loss = 6.55621989e-06\n",
            "It 01450: l_u = 6.35947617e-06 loss = 6.35947617e-06\n",
            "It 01500: l_u = 6.17160322e-06 loss = 6.17160322e-06\n",
            "It 01550: l_u = 5.99196892e-06 loss = 5.99196892e-06\n",
            "It 01600: l_u = 5.82008079e-06 loss = 5.82008079e-06\n",
            "It 01650: l_u = 5.65545088e-06 loss = 5.65545088e-06\n",
            "It 01700: l_u = 5.49778269e-06 loss = 5.49778269e-06\n",
            "It 01750: l_u = 5.34663513e-06 loss = 5.34663513e-06\n",
            "It 01800: l_u = 5.20167350e-06 loss = 5.20167350e-06\n",
            "It 01850: l_u = 5.06254946e-06 loss = 5.06254946e-06\n",
            "It 01900: l_u = 4.92896015e-06 loss = 4.92896015e-06\n",
            "It 01950: l_u = 4.80070639e-06 loss = 4.80070639e-06\n",
            "It 02000: l_u = 4.67737027e-06 loss = 4.67737027e-06\n",
            "It 02050: l_u = 4.55883674e-06 loss = 4.55883674e-06\n",
            "It 02100: l_u = 4.44486159e-06 loss = 4.44486159e-06\n",
            "It 02150: l_u = 4.33524519e-06 loss = 4.33524519e-06\n",
            "It 02200: l_u = 4.22969606e-06 loss = 4.22969606e-06\n",
            "It 02250: l_u = 4.12812415e-06 loss = 4.12812415e-06\n",
            "It 02300: l_u = 4.03029526e-06 loss = 4.03029526e-06\n",
            "It 02350: l_u = 3.93605433e-06 loss = 3.93605433e-06\n",
            "It 02400: l_u = 3.84524810e-06 loss = 3.84524810e-06\n",
            "It 02450: l_u = 3.75769650e-06 loss = 3.75769650e-06\n",
            "It 02500: l_u = 3.67331222e-06 loss = 3.67331222e-06\n",
            "It 02550: l_u = 3.59184401e-06 loss = 3.59184401e-06\n",
            "It 02600: l_u = 3.51332596e-06 loss = 3.51332596e-06\n",
            "It 02650: l_u = 3.43751958e-06 loss = 3.43751958e-06\n",
            "It 02700: l_u = 3.36433504e-06 loss = 3.36433504e-06\n",
            "It 02750: l_u = 3.29367776e-06 loss = 3.29367776e-06\n",
            "It 02800: l_u = 3.22550068e-06 loss = 3.22550068e-06\n",
            "It 02850: l_u = 3.15955685e-06 loss = 3.15955685e-06\n",
            "It 02900: l_u = 3.09582242e-06 loss = 3.09582242e-06\n",
            "It 02950: l_u = 3.03424463e-06 loss = 3.03424463e-06\n",
            "It 03000: l_u = 2.97469069e-06 loss = 2.97469069e-06\n",
            "It 03050: l_u = 2.94468919e-06 loss = 2.94468919e-06\n",
            "It 03100: l_u = 2.91485844e-06 loss = 2.91485844e-06\n",
            "It 03150: l_u = 2.88460478e-06 loss = 2.88460478e-06\n",
            "It 03200: l_u = 2.85401393e-06 loss = 2.85401393e-06\n",
            "It 03250: l_u = 2.82294604e-06 loss = 2.82294604e-06\n",
            "It 03300: l_u = 2.79156620e-06 loss = 2.79156620e-06\n",
            "It 03350: l_u = 2.75978641e-06 loss = 2.75978641e-06\n",
            "It 03400: l_u = 2.72768466e-06 loss = 2.72768466e-06\n",
            "It 03450: l_u = 2.69521092e-06 loss = 2.69521092e-06\n",
            "It 03500: l_u = 2.66236862e-06 loss = 2.66236862e-06\n",
            "It 03550: l_u = 2.62920571e-06 loss = 2.62920571e-06\n",
            "It 03600: l_u = 2.59565513e-06 loss = 2.59565513e-06\n",
            "It 03650: l_u = 2.56184535e-06 loss = 2.56184535e-06\n",
            "It 03700: l_u = 2.52774157e-06 loss = 2.52774157e-06\n",
            "It 03750: l_u = 2.49333152e-06 loss = 2.49333152e-06\n",
            "It 03800: l_u = 2.45864680e-06 loss = 2.45864680e-06\n",
            "It 03850: l_u = 2.42367810e-06 loss = 2.42367810e-06\n",
            "It 03900: l_u = 2.38843654e-06 loss = 2.38843654e-06\n",
            "It 03950: l_u = 2.35301695e-06 loss = 2.35301695e-06\n",
            "It 04000: l_u = 2.31732452e-06 loss = 2.31732452e-06\n",
            "It 04050: l_u = 2.28146860e-06 loss = 2.28146860e-06\n",
            "It 04100: l_u = 2.24533983e-06 loss = 2.24533983e-06\n",
            "It 04150: l_u = 2.20910579e-06 loss = 2.20910579e-06\n",
            "It 04200: l_u = 2.17268121e-06 loss = 2.17268121e-06\n",
            "It 04250: l_u = 2.13615658e-06 loss = 2.13615658e-06\n",
            "It 04300: l_u = 2.09949485e-06 loss = 2.09949485e-06\n",
            "It 04350: l_u = 2.06267714e-06 loss = 2.06267714e-06\n",
            "It 04400: l_u = 2.02583124e-06 loss = 2.02583124e-06\n",
            "It 04450: l_u = 1.98890302e-06 loss = 1.98890302e-06\n",
            "It 04500: l_u = 1.95194616e-06 loss = 1.95194616e-06\n",
            "It 04550: l_u = 1.91492427e-06 loss = 1.91492427e-06\n",
            "It 04600: l_u = 1.87793955e-06 loss = 1.87793955e-06\n",
            "It 04650: l_u = 1.84098542e-06 loss = 1.84098542e-06\n",
            "It 04700: l_u = 1.80402799e-06 loss = 1.80402799e-06\n",
            "It 04750: l_u = 1.76718106e-06 loss = 1.76718106e-06\n",
            "It 04800: l_u = 1.73035437e-06 loss = 1.73035437e-06\n",
            "It 04850: l_u = 1.69369878e-06 loss = 1.69369878e-06\n",
            "It 04900: l_u = 1.65718450e-06 loss = 1.65718450e-06\n",
            "It 04950: l_u = 1.62081517e-06 loss = 1.62081517e-06\n",
            "It 05000: l_u = 2.22049475e-05 loss = 2.22049475e-05\n",
            "It 05050: l_u = 2.11863971e-06 loss = 2.11863971e-06\n",
            "It 05100: l_u = 1.52427401e-06 loss = 1.52427401e-06\n",
            "It 05150: l_u = 1.48305071e-06 loss = 1.48305071e-06\n",
            "It 05200: l_u = 1.44802948e-06 loss = 1.44802948e-06\n",
            "It 05250: l_u = 1.41332873e-06 loss = 1.41332873e-06\n",
            "It 05300: l_u = 6.65044399e-06 loss = 6.65044399e-06\n",
            "It 05350: l_u = 3.10264818e-06 loss = 3.10264818e-06\n",
            "It 05400: l_u = 1.32069692e-06 loss = 1.32069692e-06\n",
            "It 05450: l_u = 1.28748331e-06 loss = 1.28748331e-06\n",
            "It 05500: l_u = 1.25459530e-06 loss = 1.25459530e-06\n",
            "It 05550: l_u = 1.22218682e-06 loss = 1.22218682e-06\n",
            "It 05600: l_u = 1.19022388e-06 loss = 1.19022388e-06\n",
            "It 05650: l_u = 1.15865259e-06 loss = 1.15865259e-06\n",
            "It 05700: l_u = 2.07147605e-05 loss = 2.07147605e-05\n",
            "It 05750: l_u = 1.30307569e-06 loss = 1.30307569e-06\n",
            "It 05800: l_u = 1.07377502e-06 loss = 1.07377502e-06\n",
            "It 05850: l_u = 1.04387402e-06 loss = 1.04387402e-06\n",
            "It 05900: l_u = 1.01470675e-06 loss = 1.01470675e-06\n",
            "It 05950: l_u = 9.86108830e-07 loss = 9.86108830e-07\n",
            "It 06000: l_u = 9.92722335e-07 loss = 9.92722335e-07\n",
            "It 06050: l_u = 1.27432747e-06 loss = 1.27432747e-06\n",
            "It 06100: l_u = 9.11091149e-07 loss = 9.11091149e-07\n",
            "It 06150: l_u = 8.83622874e-07 loss = 8.83622874e-07\n",
            "It 06200: l_u = 8.57737405e-07 loss = 8.57737405e-07\n",
            "It 06250: l_u = 8.32485739e-07 loss = 8.32485739e-07\n",
            "It 06300: l_u = 8.23708376e-07 loss = 8.23708376e-07\n",
            "It 06350: l_u = 8.14496104e-07 loss = 8.14496104e-07\n",
            "It 06400: l_u = 7.69734527e-07 loss = 7.69734527e-07\n",
            "It 06450: l_u = 7.45940440e-07 loss = 7.45940440e-07\n",
            "It 06500: l_u = 7.23537255e-07 loss = 7.23537255e-07\n",
            "It 06550: l_u = 7.01799763e-07 loss = 7.01799763e-07\n",
            "It 06600: l_u = 6.80741209e-07 loss = 6.80741209e-07\n",
            "It 06650: l_u = 1.14225131e-05 loss = 1.14225131e-05\n",
            "It 06700: l_u = 6.48853472e-07 loss = 6.48853472e-07\n",
            "It 06750: l_u = 6.27091879e-07 loss = 6.27091879e-07\n",
            "It 06800: l_u = 6.08149548e-07 loss = 6.08149548e-07\n",
            "It 06850: l_u = 5.89889510e-07 loss = 5.89889510e-07\n",
            "It 06900: l_u = 7.94488369e-06 loss = 7.94488369e-06\n",
            "It 06950: l_u = 8.58268493e-07 loss = 8.58268493e-07\n",
            "It 07000: l_u = 5.45831142e-07 loss = 5.45831142e-07\n",
            "It 07050: l_u = 5.36897062e-07 loss = 5.36897062e-07\n",
            "It 07100: l_u = 5.28751627e-07 loss = 5.28751627e-07\n",
            "It 07150: l_u = 5.20669687e-07 loss = 5.20669687e-07\n",
            "It 07200: l_u = 5.12678753e-07 loss = 5.12678753e-07\n",
            "It 07250: l_u = 5.04789625e-07 loss = 5.04789625e-07\n",
            "It 07300: l_u = 4.96934945e-07 loss = 4.96934945e-07\n",
            "It 07350: l_u = 4.89184174e-07 loss = 4.89184174e-07\n",
            "It 07400: l_u = 4.81494226e-07 loss = 4.81494226e-07\n",
            "It 07450: l_u = 4.73896165e-07 loss = 4.73896165e-07\n",
            "It 07500: l_u = 4.66391754e-07 loss = 4.66391754e-07\n",
            "It 07550: l_u = 4.58956066e-07 loss = 4.58956066e-07\n",
            "It 07600: l_u = 4.51631450e-07 loss = 4.51631450e-07\n",
            "It 07650: l_u = 4.44381214e-07 loss = 4.44381214e-07\n",
            "It 07700: l_u = 4.37241766e-07 loss = 4.37241766e-07\n",
            "It 07750: l_u = 4.30210974e-07 loss = 4.30210974e-07\n",
            "It 07800: l_u = 4.23273974e-07 loss = 4.23273974e-07\n",
            "It 07850: l_u = 4.16455663e-07 loss = 4.16455663e-07\n",
            "It 07900: l_u = 4.09724208e-07 loss = 4.09724208e-07\n",
            "It 07950: l_u = 4.03127700e-07 loss = 4.03127700e-07\n",
            "It 08000: l_u = 3.96644225e-07 loss = 3.96644225e-07\n",
            "It 08050: l_u = 3.90253177e-07 loss = 3.90253177e-07\n",
            "It 08100: l_u = 3.83997445e-07 loss = 3.83997445e-07\n",
            "It 08150: l_u = 3.77845907e-07 loss = 3.77845907e-07\n",
            "It 08200: l_u = 3.71829458e-07 loss = 3.71829458e-07\n",
            "It 08250: l_u = 3.65922091e-07 loss = 3.65922091e-07\n",
            "It 08300: l_u = 3.60149187e-07 loss = 3.60149187e-07\n",
            "It 08350: l_u = 3.54487440e-07 loss = 3.54487440e-07\n",
            "It 08400: l_u = 3.48932645e-07 loss = 3.48932645e-07\n",
            "It 08450: l_u = 3.43529990e-07 loss = 3.43529990e-07\n",
            "It 08500: l_u = 3.38221298e-07 loss = 3.38221298e-07\n",
            "It 08550: l_u = 3.48028891e-07 loss = 3.48028891e-07\n",
            "It 08600: l_u = 1.45270951e-06 loss = 1.45270951e-06\n",
            "It 08650: l_u = 3.30037153e-07 loss = 3.30037153e-07\n",
            "It 08700: l_u = 3.19170653e-07 loss = 3.19170653e-07\n",
            "It 08750: l_u = 3.14495992e-07 loss = 3.14495992e-07\n",
            "It 08800: l_u = 3.09973672e-07 loss = 3.09973672e-07\n",
            "It 08850: l_u = 3.37319725e-05 loss = 3.37319725e-05\n",
            "It 08900: l_u = 4.57958379e-07 loss = 4.57958379e-07\n",
            "It 08950: l_u = 2.98889802e-07 loss = 2.98889802e-07\n",
            "It 09000: l_u = 2.93807091e-07 loss = 2.93807091e-07\n",
            "It 09050: l_u = 2.89839505e-07 loss = 2.89839505e-07\n",
            "It 09100: l_u = 2.86023408e-07 loss = 2.86023408e-07\n",
            "It 09150: l_u = 3.92960510e-06 loss = 3.92960510e-06\n",
            "Timeout is reached. Time elapsed: 20.00232458114624 seconds\n",
            "\n",
            "\n",
            "Finding PDE parameters.\n",
            "It 09200: loss = 3.92960510e-06 lambda = [-2.6782541  -0.01680786]\n",
            "It 09250: loss = 3.92960510e-06 lambda = [-4.6258163  0.5842069]\n",
            "It 09300: loss = 3.92960510e-06 lambda = [-5.5536275  0.8656285]\n",
            "It 09350: loss = 3.92960510e-06 lambda = [-5.859194    0.95772755]\n",
            "It 09400: loss = 3.92960510e-06 lambda = [-5.9317393   0.97967625]\n",
            "It 09450: loss = 3.92960510e-06 lambda = [-5.9442625  0.9834603]\n",
            "It 09500: loss = 3.92960510e-06 lambda = [-5.945786    0.98392105]\n",
            "It 09550: loss = 3.92960510e-06 lambda = [-5.9459023  0.983956 ]\n",
            "It 09600: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 09650: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 09700: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 09750: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 09800: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 09850: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 09900: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 09950: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 10000: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 10050: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 10100: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 10150: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 10200: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 10250: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 10300: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 10350: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 10400: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 10450: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 10500: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 10550: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 10600: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 10650: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 10700: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 10750: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 10800: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 10850: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 10900: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 10950: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 11000: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 11050: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 11100: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 11150: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 11200: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 11250: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 11300: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "It 11350: loss = 3.92960510e-06 lambda = [-5.9459033  0.9839565]\n",
            "Timeout is reached. Time elapsed: 80.03304815292358 seconds\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration: 3 Initial lambda: [1.0, -6.0]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Adam\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: l_u = 3.45607370e-01 loss = 3.45607370e-01\n",
            "It 00050: l_u = 3.97773040e-03 loss = 3.97773040e-03\n",
            "It 00100: l_u = 1.55873146e-04 loss = 1.55873146e-04\n",
            "It 00150: l_u = 4.84154007e-05 loss = 4.84154007e-05\n",
            "It 00200: l_u = 3.29409595e-05 loss = 3.29409595e-05\n",
            "It 00250: l_u = 9.43616219e-03 loss = 9.43616219e-03\n",
            "It 00300: l_u = 2.43521372e-05 loss = 2.43521372e-05\n",
            "It 00350: l_u = 1.70711919e-05 loss = 1.70711919e-05\n",
            "It 00400: l_u = 1.52534221e-05 loss = 1.52534221e-05\n",
            "It 00450: l_u = 1.41359087e-05 loss = 1.41359087e-05\n",
            "It 00500: l_u = 1.32448877e-05 loss = 1.32448877e-05\n",
            "It 00550: l_u = 1.24980988e-05 loss = 1.24980988e-05\n",
            "It 00600: l_u = 1.18540638e-05 loss = 1.18540638e-05\n",
            "It 00650: l_u = 1.12867874e-05 loss = 1.12867874e-05\n",
            "It 00700: l_u = 1.07786746e-05 loss = 1.07786746e-05\n",
            "It 00750: l_u = 1.03178463e-05 loss = 1.03178463e-05\n",
            "It 00800: l_u = 9.89566070e-06 loss = 9.89566070e-06\n",
            "It 00850: l_u = 9.50580488e-06 loss = 9.50580488e-06\n",
            "It 00900: l_u = 9.14349766e-06 loss = 9.14349766e-06\n",
            "It 00950: l_u = 8.80521657e-06 loss = 8.80521657e-06\n",
            "It 01000: l_u = 8.48797208e-06 loss = 8.48797208e-06\n",
            "It 01050: l_u = 8.18945318e-06 loss = 8.18945318e-06\n",
            "It 01100: l_u = 7.90783724e-06 loss = 7.90783724e-06\n",
            "It 01150: l_u = 7.64146716e-06 loss = 7.64146716e-06\n",
            "It 01200: l_u = 7.38908739e-06 loss = 7.38908739e-06\n",
            "It 01250: l_u = 7.14942780e-06 loss = 7.14942780e-06\n",
            "It 01300: l_u = 6.92160529e-06 loss = 6.92160529e-06\n",
            "It 01350: l_u = 6.70477402e-06 loss = 6.70477402e-06\n",
            "It 01400: l_u = 6.49806771e-06 loss = 6.49806771e-06\n",
            "It 01450: l_u = 6.30079830e-06 loss = 6.30079830e-06\n",
            "It 01500: l_u = 6.11255882e-06 loss = 6.11255882e-06\n",
            "It 01550: l_u = 5.93262439e-06 loss = 5.93262439e-06\n",
            "It 01600: l_u = 5.76051480e-06 loss = 5.76051480e-06\n",
            "It 01650: l_u = 5.59573937e-06 loss = 5.59573937e-06\n",
            "It 01700: l_u = 5.43801980e-06 loss = 5.43801980e-06\n",
            "It 01750: l_u = 5.28692499e-06 loss = 5.28692499e-06\n",
            "It 01800: l_u = 5.14206840e-06 loss = 5.14206840e-06\n",
            "It 01850: l_u = 5.00317583e-06 loss = 5.00317583e-06\n",
            "It 01900: l_u = 4.86978615e-06 loss = 4.86978615e-06\n",
            "It 01950: l_u = 4.74187573e-06 loss = 4.74187573e-06\n",
            "It 02000: l_u = 4.61894524e-06 loss = 4.61894524e-06\n",
            "It 02050: l_u = 4.50087191e-06 loss = 4.50087191e-06\n",
            "It 02100: l_u = 4.38745792e-06 loss = 4.38745792e-06\n",
            "It 02150: l_u = 4.27830628e-06 loss = 4.27830628e-06\n",
            "It 02200: l_u = 4.17339879e-06 loss = 4.17339879e-06\n",
            "It 02250: l_u = 4.07246307e-06 loss = 4.07246307e-06\n",
            "It 02300: l_u = 3.97529629e-06 loss = 3.97529629e-06\n",
            "It 02350: l_u = 3.88174294e-06 loss = 3.88174294e-06\n",
            "It 02400: l_u = 3.79163043e-06 loss = 3.79163043e-06\n",
            "It 02450: l_u = 3.70480780e-06 loss = 3.70480780e-06\n",
            "It 02500: l_u = 3.62121091e-06 loss = 3.62121091e-06\n",
            "It 02550: l_u = 3.54061149e-06 loss = 3.54061149e-06\n",
            "It 02600: l_u = 3.46285606e-06 loss = 3.46285606e-06\n",
            "It 02650: l_u = 3.38789528e-06 loss = 3.38789528e-06\n",
            "It 02700: l_u = 3.31556021e-06 loss = 3.31556021e-06\n",
            "It 02750: l_u = 3.24577286e-06 loss = 3.24577286e-06\n",
            "It 02800: l_u = 3.17837703e-06 loss = 3.17837703e-06\n",
            "It 02850: l_u = 3.11331542e-06 loss = 3.11331542e-06\n",
            "It 02900: l_u = 3.05051049e-06 loss = 3.05051049e-06\n",
            "It 02950: l_u = 2.98973032e-06 loss = 2.98973032e-06\n",
            "It 03000: l_u = 2.93108042e-06 loss = 2.93108042e-06\n",
            "It 03050: l_u = 2.90153571e-06 loss = 2.90153571e-06\n",
            "It 03100: l_u = 2.87213652e-06 loss = 2.87213652e-06\n",
            "It 03150: l_u = 2.84238536e-06 loss = 2.84238536e-06\n",
            "It 03200: l_u = 2.81223606e-06 loss = 2.81223606e-06\n",
            "It 03250: l_u = 2.78174048e-06 loss = 2.78174048e-06\n",
            "It 03300: l_u = 2.75078264e-06 loss = 2.75078264e-06\n",
            "It 03350: l_u = 2.71954059e-06 loss = 2.71954059e-06\n",
            "It 03400: l_u = 2.68798590e-06 loss = 2.68798590e-06\n",
            "It 03450: l_u = 2.65602284e-06 loss = 2.65602284e-06\n",
            "It 03500: l_u = 2.62379331e-06 loss = 2.62379331e-06\n",
            "It 03550: l_u = 2.59117905e-06 loss = 2.59117905e-06\n",
            "It 03600: l_u = 2.55826944e-06 loss = 2.55826944e-06\n",
            "It 03650: l_u = 2.52504174e-06 loss = 2.52504174e-06\n",
            "It 03700: l_u = 2.49153413e-06 loss = 2.49153413e-06\n",
            "It 03750: l_u = 2.45778233e-06 loss = 2.45778233e-06\n",
            "It 03800: l_u = 2.42377087e-06 loss = 2.42377087e-06\n",
            "It 03850: l_u = 2.38951156e-06 loss = 2.38951156e-06\n",
            "It 03900: l_u = 2.35494554e-06 loss = 2.35494554e-06\n",
            "It 03950: l_u = 2.32021762e-06 loss = 2.32021762e-06\n",
            "It 04000: l_u = 2.28521526e-06 loss = 2.28521526e-06\n",
            "It 04050: l_u = 2.25007648e-06 loss = 2.25007648e-06\n",
            "It 04100: l_u = 2.21474988e-06 loss = 2.21474988e-06\n",
            "It 04150: l_u = 2.17924321e-06 loss = 2.17924321e-06\n",
            "It 04200: l_u = 2.14358806e-06 loss = 2.14358806e-06\n",
            "It 04250: l_u = 2.10784219e-06 loss = 2.10784219e-06\n",
            "It 04300: l_u = 2.07196263e-06 loss = 2.07196263e-06\n",
            "It 04350: l_u = 2.03598643e-06 loss = 2.03598643e-06\n",
            "It 04400: l_u = 1.99994656e-06 loss = 1.99994656e-06\n",
            "It 04450: l_u = 1.96386668e-06 loss = 1.96386668e-06\n",
            "It 04500: l_u = 1.92773928e-06 loss = 1.92773928e-06\n",
            "It 04550: l_u = 1.89159368e-06 loss = 1.89159368e-06\n",
            "It 04600: l_u = 1.85548708e-06 loss = 1.85548708e-06\n",
            "It 04650: l_u = 1.81937639e-06 loss = 1.81937639e-06\n",
            "It 04700: l_u = 1.78333141e-06 loss = 1.78333141e-06\n",
            "It 04750: l_u = 1.74734259e-06 loss = 1.74734259e-06\n",
            "It 04800: l_u = 1.71147519e-06 loss = 1.71147519e-06\n",
            "It 04850: l_u = 1.67569362e-06 loss = 1.67569362e-06\n",
            "It 04900: l_u = 1.64006428e-06 loss = 1.64006428e-06\n",
            "It 04950: l_u = 1.12442085e-05 loss = 1.12442085e-05\n",
            "It 05000: l_u = 1.77792481e-06 loss = 1.77792481e-06\n",
            "It 05050: l_u = 1.54109671e-06 loss = 1.54109671e-06\n",
            "It 05100: l_u = 1.50542121e-06 loss = 1.50542121e-06\n",
            "It 05150: l_u = 1.47100377e-06 loss = 1.47100377e-06\n",
            "It 05200: l_u = 1.58131957e-06 loss = 1.58131957e-06\n",
            "It 05250: l_u = 1.90909964e-06 loss = 1.90909964e-06\n",
            "It 05300: l_u = 1.37767870e-06 loss = 1.37767870e-06\n",
            "It 05350: l_u = 1.34269499e-06 loss = 1.34269499e-06\n",
            "It 05400: l_u = 1.30970136e-06 loss = 1.30970136e-06\n",
            "It 05450: l_u = 1.27720011e-06 loss = 1.27720011e-06\n",
            "It 05500: l_u = 2.80756030e-05 loss = 2.80756030e-05\n",
            "It 05550: l_u = 1.60446336e-06 loss = 1.60446336e-06\n",
            "It 05600: l_u = 1.18953358e-06 loss = 1.18953358e-06\n",
            "It 05650: l_u = 1.15761463e-06 loss = 1.15761463e-06\n",
            "It 05700: l_u = 1.12716282e-06 loss = 1.12716282e-06\n",
            "It 05750: l_u = 1.09816915e-06 loss = 1.09816915e-06\n",
            "It 05800: l_u = 6.46546050e-06 loss = 6.46546050e-06\n",
            "It 05850: l_u = 1.08496545e-06 loss = 1.08496545e-06\n",
            "It 05900: l_u = 1.01783428e-06 loss = 1.01783428e-06\n",
            "It 05950: l_u = 9.89594810e-07 loss = 9.89594810e-07\n",
            "It 06000: l_u = 9.61941737e-07 loss = 9.61941737e-07\n",
            "It 06050: l_u = 9.34861077e-07 loss = 9.34861077e-07\n",
            "It 06100: l_u = 1.30689314e-05 loss = 1.30689314e-05\n",
            "It 06150: l_u = 1.06456446e-06 loss = 1.06456446e-06\n",
            "It 06200: l_u = 8.66174560e-07 loss = 8.66174560e-07\n",
            "It 06250: l_u = 8.39501979e-07 loss = 8.39501979e-07\n",
            "It 06300: l_u = 8.14999339e-07 loss = 8.14999339e-07\n",
            "It 06350: l_u = 7.91126070e-07 loss = 7.91126070e-07\n",
            "It 06400: l_u = 8.12618396e-07 loss = 8.12618396e-07\n",
            "It 06450: l_u = 2.23862958e-06 loss = 2.23862958e-06\n",
            "It 06500: l_u = 7.46805085e-07 loss = 7.46805085e-07\n",
            "It 06550: l_u = 7.11888333e-07 loss = 7.11888333e-07\n",
            "It 06600: l_u = 6.90372474e-07 loss = 6.90372474e-07\n",
            "It 06650: l_u = 6.69689598e-07 loss = 6.69689598e-07\n",
            "It 06700: l_u = 6.49677702e-07 loss = 6.49677702e-07\n",
            "It 06750: l_u = 6.30315753e-07 loss = 6.30315753e-07\n",
            "It 06800: l_u = 8.43222836e-07 loss = 8.43222836e-07\n",
            "It 06850: l_u = 1.65785491e-06 loss = 1.65785491e-06\n",
            "It 06900: l_u = 5.85972657e-07 loss = 5.85972657e-07\n",
            "It 06950: l_u = 5.67598704e-07 loss = 5.67598704e-07\n",
            "It 07000: l_u = 5.50504694e-07 loss = 5.50504694e-07\n",
            "It 07050: l_u = 5.42107045e-07 loss = 5.42107045e-07\n",
            "It 07100: l_u = 5.33933928e-07 loss = 5.33933928e-07\n",
            "It 07150: l_u = 5.25840790e-07 loss = 5.25840790e-07\n",
            "It 07200: l_u = 5.17816204e-07 loss = 5.17816204e-07\n",
            "It 07250: l_u = 5.09834933e-07 loss = 5.09834933e-07\n",
            "It 07300: l_u = 5.01937961e-07 loss = 5.01937961e-07\n",
            "It 07350: l_u = 4.94123128e-07 loss = 4.94123128e-07\n",
            "It 07400: l_u = 4.86400779e-07 loss = 4.86400779e-07\n",
            "It 07450: l_u = 4.78743686e-07 loss = 4.78743686e-07\n",
            "It 07500: l_u = 4.71156653e-07 loss = 4.71156653e-07\n",
            "It 07550: l_u = 4.63683989e-07 loss = 4.63683989e-07\n",
            "It 07600: l_u = 4.56270982e-07 loss = 4.56270982e-07\n",
            "It 07650: l_u = 4.48984878e-07 loss = 4.48984878e-07\n",
            "It 07700: l_u = 4.41777985e-07 loss = 4.41777985e-07\n",
            "It 07750: l_u = 4.34683415e-07 loss = 4.34683415e-07\n",
            "It 07800: l_u = 4.27687240e-07 loss = 4.27687240e-07\n",
            "It 07850: l_u = 4.20776786e-07 loss = 4.20776786e-07\n",
            "It 07900: l_u = 4.13992041e-07 loss = 4.13992041e-07\n",
            "It 07950: l_u = 4.07314019e-07 loss = 4.07314019e-07\n",
            "It 08000: l_u = 4.00758978e-07 loss = 4.00758978e-07\n",
            "It 08050: l_u = 3.94291391e-07 loss = 3.94291391e-07\n",
            "It 08100: l_u = 3.87956931e-07 loss = 3.87956931e-07\n",
            "It 08150: l_u = 3.81746617e-07 loss = 3.81746617e-07\n",
            "It 08200: l_u = 3.75641577e-07 loss = 3.75641577e-07\n",
            "It 08250: l_u = 3.69658295e-07 loss = 3.69658295e-07\n",
            "It 08300: l_u = 3.63793220e-07 loss = 3.63793220e-07\n",
            "It 08350: l_u = 3.58051494e-07 loss = 3.58051494e-07\n",
            "It 08400: l_u = 3.52426554e-07 loss = 3.52426554e-07\n",
            "It 08450: l_u = 3.46916636e-07 loss = 3.46916636e-07\n",
            "It 08500: l_u = 3.41529670e-07 loss = 3.41529670e-07\n",
            "It 08550: l_u = 1.65804377e-05 loss = 1.65804377e-05\n",
            "It 08600: l_u = 4.27947754e-07 loss = 4.27947754e-07\n",
            "It 08650: l_u = 3.27327598e-07 loss = 3.27327598e-07\n",
            "It 08700: l_u = 3.21860938e-07 loss = 3.21860938e-07\n",
            "It 08750: l_u = 3.17126251e-07 loss = 3.17126251e-07\n",
            "It 08800: l_u = 4.03911343e-07 loss = 4.03911343e-07\n",
            "It 08850: l_u = 5.33345997e-07 loss = 5.33345997e-07\n",
            "It 08900: l_u = 3.07124964e-07 loss = 3.07124964e-07\n",
            "It 08950: l_u = 2.99987704e-07 loss = 2.99987704e-07\n",
            "It 09000: l_u = 2.95813209e-07 loss = 2.95813209e-07\n",
            "It 09050: l_u = 2.91750240e-07 loss = 2.91750240e-07\n",
            "It 09100: l_u = 1.09688044e-05 loss = 1.09688044e-05\n",
            "It 09150: l_u = 5.44262889e-07 loss = 5.44262889e-07\n",
            "It 09200: l_u = 2.82192673e-07 loss = 2.82192673e-07\n",
            "It 09250: l_u = 2.77279867e-07 loss = 2.77279867e-07\n",
            "Timeout is reached. Time elapsed: 20.000583171844482 seconds\n",
            "\n",
            "\n",
            "Finding PDE parameters.\n",
            "It 09300: loss = 2.75681458e-07 lambda = [ 3.4967978 -3.458728 ]\n",
            "It 09350: loss = 2.75681458e-07 lambda = [ 4.0785527 -1.9802305]\n",
            "It 09400: loss = 2.75681458e-07 lambda = [ 2.9034555 -1.7414595]\n",
            "It 09450: loss = 2.75681458e-07 lambda = [ 1.7909904 -1.3899492]\n",
            "It 09500: loss = 2.75681458e-07 lambda = [ 0.7008016 -1.0550716]\n",
            "It 09550: loss = 2.75681458e-07 lambda = [-0.31236225 -0.743733  ]\n",
            "It 09600: loss = 2.75681458e-07 lambda = [-1.2250316 -0.463399 ]\n",
            "It 09650: loss = 2.75681458e-07 lambda = [-2.0280595  -0.21683405]\n",
            "It 09700: loss = 2.75681458e-07 lambda = [-2.7216344  -0.00392981]\n",
            "It 09750: loss = 2.75681458e-07 lambda = [-3.3116941  0.1771671]\n",
            "It 09800: loss = 2.75681458e-07 lambda = [-3.8074076   0.32928953]\n",
            "It 09850: loss = 2.75681458e-07 lambda = [-4.2194457   0.45572367]\n",
            "It 09900: loss = 2.75681458e-07 lambda = [-4.5588284  0.5598576]\n",
            "It 09950: loss = 2.75681458e-07 lambda = [-4.8361835   0.64495605]\n",
            "It 10000: loss = 2.75681458e-07 lambda = [-5.0613174   0.71403044]\n",
            "It 10050: loss = 2.75681458e-07 lambda = [-5.2429986   0.76977175]\n",
            "It 10100: loss = 2.75681458e-07 lambda = [-5.3888707  0.8145262]\n",
            "It 10150: loss = 2.75681458e-07 lambda = [-5.5054846  0.8503038]\n",
            "It 10200: loss = 2.75681458e-07 lambda = [-5.598357   0.8787972]\n",
            "It 10250: loss = 2.75681458e-07 lambda = [-5.672086   0.9014172]\n",
            "It 10300: loss = 2.75681458e-07 lambda = [-5.730456   0.9193253]\n",
            "It 10350: loss = 2.75681458e-07 lambda = [-5.7765627   0.93347067]\n",
            "It 10400: loss = 2.75681458e-07 lambda = [-5.812912   0.9446228]\n",
            "It 10450: loss = 2.75681458e-07 lambda = [-5.841523   0.9534006]\n",
            "It 10500: loss = 2.75681458e-07 lambda = [-5.864016   0.9603014]\n",
            "It 10550: loss = 2.75681458e-07 lambda = [-5.8816824  0.9657214]\n",
            "It 10600: loss = 2.75681458e-07 lambda = [-5.8955474  0.9699752]\n",
            "It 10650: loss = 2.75681458e-07 lambda = [-5.906424   0.9733122]\n",
            "It 10700: loss = 2.75681458e-07 lambda = [-5.9149537  0.9759292]\n",
            "It 10750: loss = 2.75681458e-07 lambda = [-5.921643   0.9779813]\n",
            "It 10800: loss = 2.75681458e-07 lambda = [-5.9268928   0.97959137]\n",
            "It 10850: loss = 2.75681458e-07 lambda = [-5.931007    0.98085415]\n",
            "It 10900: loss = 2.75681458e-07 lambda = [-5.934236   0.9818448]\n",
            "It 10950: loss = 2.75681458e-07 lambda = [-5.936771   0.9826225]\n",
            "It 11000: loss = 2.75681458e-07 lambda = [-5.938763    0.98323387]\n",
            "It 11050: loss = 2.75681458e-07 lambda = [-5.94033    0.9837145]\n",
            "It 11100: loss = 2.75681458e-07 lambda = [-5.941563   0.9840928]\n",
            "It 11150: loss = 2.75681458e-07 lambda = [-5.9425344   0.98439085]\n",
            "It 11200: loss = 2.75681458e-07 lambda = [-5.9433002  0.9846257]\n",
            "It 11250: loss = 2.75681458e-07 lambda = [-5.943905    0.98481107]\n",
            "It 11300: loss = 2.75681458e-07 lambda = [-5.944382   0.9849577]\n",
            "It 11350: loss = 2.75681458e-07 lambda = [-5.9447603   0.98507375]\n",
            "It 11400: loss = 2.75681458e-07 lambda = [-5.9450603  0.9851658]\n",
            "It 11450: loss = 2.75681458e-07 lambda = [-5.9452977   0.98523873]\n",
            "Timeout is reached. Time elapsed: 80.01226449012756 seconds\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration: 3 Initial lambda: [10.0, 10.0]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Adam\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: l_u = 3.45607370e-01 loss = 3.45607370e-01\n",
            "It 00050: l_u = 3.97772389e-03 loss = 3.97772389e-03\n",
            "It 00100: l_u = 1.55872855e-04 loss = 1.55872855e-04\n",
            "It 00150: l_u = 4.84154298e-05 loss = 4.84154298e-05\n",
            "It 00200: l_u = 3.29410832e-05 loss = 3.29410832e-05\n",
            "It 00250: l_u = 9.18544643e-03 loss = 9.18544643e-03\n",
            "It 00300: l_u = 2.44285256e-05 loss = 2.44285256e-05\n",
            "It 00350: l_u = 1.70629173e-05 loss = 1.70629173e-05\n",
            "It 00400: l_u = 1.52548646e-05 loss = 1.52548646e-05\n",
            "It 00450: l_u = 1.41368564e-05 loss = 1.41368564e-05\n",
            "It 00500: l_u = 1.32457581e-05 loss = 1.32457581e-05\n",
            "It 00550: l_u = 1.24987828e-05 loss = 1.24987828e-05\n",
            "It 00600: l_u = 1.18548096e-05 loss = 1.18548096e-05\n",
            "It 00650: l_u = 1.12875896e-05 loss = 1.12875896e-05\n",
            "It 00700: l_u = 1.07795231e-05 loss = 1.07795231e-05\n",
            "It 00750: l_u = 1.03186067e-05 loss = 1.03186067e-05\n",
            "It 00800: l_u = 9.89647833e-06 loss = 9.89647833e-06\n",
            "It 00850: l_u = 9.50657159e-06 loss = 9.50657159e-06\n",
            "It 00900: l_u = 9.14441898e-06 loss = 9.14441898e-06\n",
            "It 00950: l_u = 8.80617063e-06 loss = 8.80617063e-06\n",
            "It 01000: l_u = 8.48890340e-06 loss = 8.48890340e-06\n",
            "It 01050: l_u = 8.19045181e-06 loss = 8.19045181e-06\n",
            "It 01100: l_u = 7.90886861e-06 loss = 7.90886861e-06\n",
            "It 01150: l_u = 7.64252763e-06 loss = 7.64252763e-06\n",
            "It 01200: l_u = 7.39014649e-06 loss = 7.39014649e-06\n",
            "It 01250: l_u = 7.15054830e-06 loss = 7.15054830e-06\n",
            "It 01300: l_u = 6.92274216e-06 loss = 6.92274216e-06\n",
            "It 01350: l_u = 6.70587178e-06 loss = 6.70587178e-06\n",
            "It 01400: l_u = 6.49917047e-06 loss = 6.49917047e-06\n",
            "It 01450: l_u = 6.30197246e-06 loss = 6.30197246e-06\n",
            "It 01500: l_u = 6.11370797e-06 loss = 6.11370797e-06\n",
            "It 01550: l_u = 5.93375535e-06 loss = 5.93375535e-06\n",
            "It 01600: l_u = 5.76167258e-06 loss = 5.76167258e-06\n",
            "It 01650: l_u = 5.59692080e-06 loss = 5.59692080e-06\n",
            "It 01700: l_u = 5.43924807e-06 loss = 5.43924807e-06\n",
            "It 01750: l_u = 5.28819101e-06 loss = 5.28819101e-06\n",
            "It 01800: l_u = 5.14325711e-06 loss = 5.14325711e-06\n",
            "It 01850: l_u = 5.00435908e-06 loss = 5.00435908e-06\n",
            "It 01900: l_u = 4.87098532e-06 loss = 4.87098532e-06\n",
            "It 01950: l_u = 4.74303624e-06 loss = 4.74303624e-06\n",
            "It 02000: l_u = 4.62017533e-06 loss = 4.62017533e-06\n",
            "It 02050: l_u = 4.50206244e-06 loss = 4.50206244e-06\n",
            "It 02100: l_u = 4.38856432e-06 loss = 4.38856432e-06\n",
            "It 02150: l_u = 4.27945906e-06 loss = 4.27945906e-06\n",
            "It 02200: l_u = 4.17445108e-06 loss = 4.17445108e-06\n",
            "It 02250: l_u = 4.07356947e-06 loss = 4.07356947e-06\n",
            "It 02300: l_u = 3.97634130e-06 loss = 3.97634130e-06\n",
            "It 02350: l_u = 3.88274520e-06 loss = 3.88274520e-06\n",
            "It 02400: l_u = 3.79272933e-06 loss = 3.79272933e-06\n",
            "It 02450: l_u = 3.70593511e-06 loss = 3.70593511e-06\n",
            "It 02500: l_u = 3.62222909e-06 loss = 3.62222909e-06\n",
            "It 02550: l_u = 3.54160375e-06 loss = 3.54160375e-06\n",
            "It 02600: l_u = 3.46387765e-06 loss = 3.46387765e-06\n",
            "It 02650: l_u = 3.38890550e-06 loss = 3.38890550e-06\n",
            "It 02700: l_u = 3.31648016e-06 loss = 3.31648016e-06\n",
            "It 02750: l_u = 3.24671055e-06 loss = 3.24671055e-06\n",
            "It 02800: l_u = 3.17926424e-06 loss = 3.17926424e-06\n",
            "It 02850: l_u = 3.11422059e-06 loss = 3.11422059e-06\n",
            "It 02900: l_u = 3.05136837e-06 loss = 3.05136837e-06\n",
            "It 02950: l_u = 2.99062003e-06 loss = 2.99062003e-06\n",
            "It 03000: l_u = 2.93196604e-06 loss = 2.93196604e-06\n",
            "It 03050: l_u = 2.90236426e-06 loss = 2.90236426e-06\n",
            "It 03100: l_u = 2.87297871e-06 loss = 2.87297871e-06\n",
            "It 03150: l_u = 2.84321209e-06 loss = 2.84321209e-06\n",
            "It 03200: l_u = 2.81302982e-06 loss = 2.81302982e-06\n",
            "It 03250: l_u = 2.78251446e-06 loss = 2.78251446e-06\n",
            "It 03300: l_u = 2.75157504e-06 loss = 2.75157504e-06\n",
            "It 03350: l_u = 2.72034231e-06 loss = 2.72034231e-06\n",
            "It 03400: l_u = 2.68873077e-06 loss = 2.68873077e-06\n",
            "It 03450: l_u = 2.65679614e-06 loss = 2.65679614e-06\n",
            "It 03500: l_u = 2.62451567e-06 loss = 2.62451567e-06\n",
            "It 03550: l_u = 2.59189301e-06 loss = 2.59189301e-06\n",
            "It 03600: l_u = 2.55900909e-06 loss = 2.55900909e-06\n",
            "It 03650: l_u = 2.52575228e-06 loss = 2.52575228e-06\n",
            "It 03700: l_u = 2.49227310e-06 loss = 2.49227310e-06\n",
            "It 03750: l_u = 2.45847855e-06 loss = 2.45847855e-06\n",
            "It 03800: l_u = 2.42438500e-06 loss = 2.42438500e-06\n",
            "It 03850: l_u = 2.39010342e-06 loss = 2.39010342e-06\n",
            "It 03900: l_u = 2.35556763e-06 loss = 2.35556763e-06\n",
            "It 03950: l_u = 2.32080015e-06 loss = 2.32080015e-06\n",
            "It 04000: l_u = 2.28579461e-06 loss = 2.28579461e-06\n",
            "It 04050: l_u = 2.25063695e-06 loss = 2.25063695e-06\n",
            "It 04100: l_u = 2.21531855e-06 loss = 2.21531855e-06\n",
            "It 04150: l_u = 2.17983074e-06 loss = 2.17983074e-06\n",
            "It 04200: l_u = 2.14415263e-06 loss = 2.14415263e-06\n",
            "It 04250: l_u = 2.10836083e-06 loss = 2.10836083e-06\n",
            "It 04300: l_u = 2.07248240e-06 loss = 2.07248240e-06\n",
            "It 04350: l_u = 2.03650166e-06 loss = 2.03650166e-06\n",
            "It 04400: l_u = 2.00044315e-06 loss = 2.00044315e-06\n",
            "It 04450: l_u = 1.96433530e-06 loss = 1.96433530e-06\n",
            "It 04500: l_u = 1.92821039e-06 loss = 1.92821039e-06\n",
            "It 04550: l_u = 1.89202444e-06 loss = 1.89202444e-06\n",
            "It 04600: l_u = 1.85589795e-06 loss = 1.85589795e-06\n",
            "It 04650: l_u = 1.81979578e-06 loss = 1.81979578e-06\n",
            "It 04700: l_u = 1.78369021e-06 loss = 1.78369021e-06\n",
            "It 04750: l_u = 1.74771219e-06 loss = 1.74771219e-06\n",
            "It 04800: l_u = 1.71182614e-06 loss = 1.71182614e-06\n",
            "It 04850: l_u = 1.67600297e-06 loss = 1.67600297e-06\n",
            "It 04900: l_u = 1.64037317e-06 loss = 1.64037317e-06\n",
            "It 04950: l_u = 3.17626859e-06 loss = 3.17626859e-06\n",
            "It 05000: l_u = 1.69786836e-06 loss = 1.69786836e-06\n",
            "It 05050: l_u = 1.54090355e-06 loss = 1.54090355e-06\n",
            "It 05100: l_u = 1.50551296e-06 loss = 1.50551296e-06\n",
            "It 05150: l_u = 1.47104913e-06 loss = 1.47104913e-06\n",
            "It 05200: l_u = 1.67393373e-05 loss = 1.67393373e-05\n",
            "It 05250: l_u = 1.44565649e-06 loss = 1.44565649e-06\n",
            "It 05300: l_u = 1.37561801e-06 loss = 1.37561801e-06\n",
            "It 05350: l_u = 1.34183131e-06 loss = 1.34183131e-06\n",
            "It 05400: l_u = 1.30892022e-06 loss = 1.30892022e-06\n",
            "It 05450: l_u = 1.02145686e-05 loss = 1.02145686e-05\n",
            "It 05500: l_u = 1.59526940e-06 loss = 1.59526940e-06\n",
            "It 05550: l_u = 1.21959795e-06 loss = 1.21959795e-06\n",
            "It 05600: l_u = 1.18706089e-06 loss = 1.18706089e-06\n",
            "It 05650: l_u = 1.15613807e-06 loss = 1.15613807e-06\n",
            "It 05700: l_u = 1.29838645e-06 loss = 1.29838645e-06\n",
            "It 05750: l_u = 1.70915541e-06 loss = 1.70915541e-06\n",
            "It 05800: l_u = 1.09267421e-06 loss = 1.09267421e-06\n",
            "It 05850: l_u = 1.04443882e-06 loss = 1.04443882e-06\n",
            "It 05900: l_u = 1.01562648e-06 loss = 1.01562648e-06\n",
            "It 05950: l_u = 9.87469889e-07 loss = 9.87469889e-07\n",
            "It 06000: l_u = 9.59895374e-07 loss = 9.59895374e-07\n",
            "It 06050: l_u = 1.17974150e-05 loss = 1.17974150e-05\n",
            "It 06100: l_u = 9.21461606e-07 loss = 9.21461606e-07\n",
            "It 06150: l_u = 8.93683819e-07 loss = 8.93683819e-07\n",
            "It 06200: l_u = 8.67080587e-07 loss = 8.67080587e-07\n",
            "It 06250: l_u = 8.41856661e-07 loss = 8.41856661e-07\n",
            "It 06300: l_u = 8.17276771e-07 loss = 8.17276771e-07\n",
            "It 06350: l_u = 7.93348988e-07 loss = 7.93348988e-07\n",
            "It 06400: l_u = 7.69983160e-07 loss = 7.69983160e-07\n",
            "It 06450: l_u = 7.47521824e-07 loss = 7.47521824e-07\n",
            "It 06500: l_u = 8.73492127e-07 loss = 8.73492127e-07\n",
            "It 06550: l_u = 7.77262301e-07 loss = 7.77262301e-07\n",
            "It 06600: l_u = 6.89560864e-07 loss = 6.89560864e-07\n",
            "It 06650: l_u = 6.68879466e-07 loss = 6.68879466e-07\n",
            "It 06700: l_u = 6.48893831e-07 loss = 6.48893831e-07\n",
            "It 06750: l_u = 6.29533588e-07 loss = 6.29533588e-07\n",
            "It 06800: l_u = 8.73899080e-06 loss = 8.73899080e-06\n",
            "It 06850: l_u = 8.65156608e-07 loss = 8.65156608e-07\n",
            "It 06900: l_u = 5.86974068e-07 loss = 5.86974068e-07\n",
            "It 06950: l_u = 5.67510767e-07 loss = 5.67510767e-07\n",
            "It 07000: l_u = 5.50564948e-07 loss = 5.50564948e-07\n",
            "It 07050: l_u = 5.42175712e-07 loss = 5.42175712e-07\n",
            "It 07100: l_u = 5.33988839e-07 loss = 5.33988839e-07\n",
            "It 07150: l_u = 5.25898940e-07 loss = 5.25898940e-07\n",
            "It 07200: l_u = 5.17851220e-07 loss = 5.17851220e-07\n",
            "It 07250: l_u = 5.09906101e-07 loss = 5.09906101e-07\n",
            "It 07300: l_u = 5.02009470e-07 loss = 5.02009470e-07\n",
            "It 07350: l_u = 4.94175538e-07 loss = 4.94175538e-07\n",
            "It 07400: l_u = 4.86446822e-07 loss = 4.86446822e-07\n",
            "It 07450: l_u = 4.78769607e-07 loss = 4.78769607e-07\n",
            "It 07500: l_u = 4.71201929e-07 loss = 4.71201929e-07\n",
            "It 07550: l_u = 4.63725087e-07 loss = 4.63725087e-07\n",
            "It 07600: l_u = 4.56320009e-07 loss = 4.56320009e-07\n",
            "It 07650: l_u = 4.49010457e-07 loss = 4.49010457e-07\n",
            "It 07700: l_u = 4.41807089e-07 loss = 4.41807089e-07\n",
            "It 07750: l_u = 4.34699757e-07 loss = 4.34699757e-07\n",
            "It 07800: l_u = 4.27696733e-07 loss = 4.27696733e-07\n",
            "It 07850: l_u = 4.20796113e-07 loss = 4.20796113e-07\n",
            "It 07900: l_u = 4.14020974e-07 loss = 4.14020974e-07\n",
            "It 07950: l_u = 4.07324194e-07 loss = 4.07324194e-07\n",
            "It 08000: l_u = 4.00761621e-07 loss = 4.00761621e-07\n",
            "It 08050: l_u = 3.94298524e-07 loss = 3.94298524e-07\n",
            "It 08100: l_u = 3.87980009e-07 loss = 3.87980009e-07\n",
            "It 08150: l_u = 3.81753551e-07 loss = 3.81753551e-07\n",
            "It 08200: l_u = 3.75640440e-07 loss = 3.75640440e-07\n",
            "It 08250: l_u = 3.69655368e-07 loss = 3.69655368e-07\n",
            "It 08300: l_u = 3.63793760e-07 loss = 3.63793760e-07\n",
            "It 08350: l_u = 3.58044360e-07 loss = 3.58044360e-07\n",
            "It 08400: l_u = 3.52424820e-07 loss = 3.52424820e-07\n",
            "It 08450: l_u = 3.46909758e-07 loss = 3.46909758e-07\n",
            "It 08500: l_u = 3.41521968e-07 loss = 3.41521968e-07\n",
            "It 08550: l_u = 1.20419800e-05 loss = 1.20419800e-05\n",
            "It 08600: l_u = 4.29362530e-07 loss = 4.29362530e-07\n",
            "It 08650: l_u = 3.27365029e-07 loss = 3.27365029e-07\n",
            "It 08700: l_u = 3.21846869e-07 loss = 3.21846869e-07\n",
            "It 08750: l_u = 3.17103883e-07 loss = 3.17103883e-07\n",
            "It 08800: l_u = 4.07436943e-07 loss = 4.07436943e-07\n",
            "It 08850: l_u = 7.73475222e-07 loss = 7.73475222e-07\n",
            "It 08900: l_u = 3.09133327e-07 loss = 3.09133327e-07\n",
            "It 08950: l_u = 3.00003336e-07 loss = 3.00003336e-07\n",
            "It 09000: l_u = 2.95803346e-07 loss = 2.95803346e-07\n",
            "It 09050: l_u = 2.91739525e-07 loss = 2.91739525e-07\n",
            "It 09100: l_u = 3.34606000e-07 loss = 3.34606000e-07\n",
            "It 09150: l_u = 4.37270103e-07 loss = 4.37270103e-07\n",
            "It 09200: l_u = 2.85198126e-07 loss = 2.85198126e-07\n",
            "It 09250: l_u = 2.77431639e-07 loss = 2.77431639e-07\n",
            "It 09300: l_u = 2.73811224e-07 loss = 2.73811224e-07\n",
            "It 09350: l_u = 2.70324762e-07 loss = 2.70324762e-07\n",
            "It 09400: l_u = 1.18813830e-06 loss = 1.18813830e-06\n",
            "It 09450: l_u = 1.22185502e-05 loss = 1.22185502e-05\n",
            "It 09500: l_u = 3.32752080e-07 loss = 3.32752080e-07\n",
            "It 09550: l_u = 2.86938871e-07 loss = 2.86938871e-07\n",
            "It 09600: l_u = 9.96161589e-07 loss = 9.96161589e-07\n",
            "It 09650: l_u = 2.53619731e-07 loss = 2.53619731e-07\n",
            "It 09700: l_u = 2.55242128e-07 loss = 2.55242128e-07\n",
            "It 09750: l_u = 3.84877382e-07 loss = 3.84877382e-07\n",
            "It 09800: l_u = 2.49942872e-07 loss = 2.49942872e-07\n",
            "It 09850: l_u = 8.03353601e-07 loss = 8.03353601e-07\n",
            "It 09900: l_u = 3.33865302e-07 loss = 3.33865302e-07\n",
            "It 09950: l_u = 4.46536518e-07 loss = 4.46536518e-07\n",
            "Timeout is reached. Time elapsed: 20.001633167266846 seconds\n",
            "\n",
            "\n",
            "Finding PDE parameters.\n",
            "It 10000: loss = 2.85552630e-07 lambda = [7.2900763 7.2915072]\n",
            "It 10050: loss = 2.85552630e-07 lambda = [3.4332592 3.4609373]\n",
            "It 10100: loss = 2.85552630e-07 lambda = [1.0598841 1.1637005]\n",
            "It 10150: loss = 2.85552630e-07 lambda = [-0.16845812  0.06287742]\n",
            "It 10200: loss = 2.85552630e-07 lambda = [-0.7421282  -0.34624046]\n",
            "It 10250: loss = 2.85552630e-07 lambda = [-1.0303453  -0.44868255]\n",
            "It 10300: loss = 2.85552630e-07 lambda = [-1.2209678  -0.44251558]\n",
            "It 10350: loss = 2.85552630e-07 lambda = [-1.3851802 -0.4044455]\n",
            "It 10400: loss = 2.85552630e-07 lambda = [-1.5437845 -0.3584013]\n",
            "It 10450: loss = 2.85552630e-07 lambda = [-1.701093  -0.3107571]\n",
            "It 10500: loss = 2.85552630e-07 lambda = [-1.8571901  -0.26313126]\n",
            "It 10550: loss = 2.85552630e-07 lambda = [-2.0113847 -0.2160338]\n",
            "It 10600: loss = 2.85552630e-07 lambda = [-2.1629822  -0.16972311]\n",
            "It 10650: loss = 2.85552630e-07 lambda = [-2.3114114  -0.12437977]\n",
            "It 10700: loss = 2.85552630e-07 lambda = [-2.4562259  -0.08014094]\n",
            "It 10750: loss = 2.85552630e-07 lambda = [-2.597086   -0.03711057]\n",
            "It 10800: loss = 2.85552630e-07 lambda = [-2.7337403  0.0046348]\n",
            "It 10850: loss = 2.85552630e-07 lambda = [-2.8660133   0.04504147]\n",
            "It 10900: loss = 2.85552630e-07 lambda = [-2.9937909   0.08407477]\n",
            "It 10950: loss = 2.85552630e-07 lambda = [-3.1170113   0.12171582]\n",
            "It 11000: loss = 2.85552630e-07 lambda = [-3.2356577  0.1579592]\n",
            "It 11050: loss = 2.85552630e-07 lambda = [-3.3497458   0.19281018]\n",
            "It 11100: loss = 2.85552630e-07 lambda = [-3.4593217   0.22628273]\n",
            "It 11150: loss = 2.85552630e-07 lambda = [-3.5644562   0.25839823]\n",
            "It 11200: loss = 2.85552630e-07 lambda = [-3.6652377   0.28918383]\n",
            "It 11250: loss = 2.85552630e-07 lambda = [-3.761771    0.31867108]\n",
            "It 11300: loss = 2.85552630e-07 lambda = [-3.854167    0.34689555]\n",
            "It 11350: loss = 2.85552630e-07 lambda = [-3.9425511   0.37389418]\n",
            "It 11400: loss = 2.85552630e-07 lambda = [-4.0270534   0.39970657]\n",
            "It 11450: loss = 2.85552630e-07 lambda = [-4.1078067  0.4243739]\n",
            "It 11500: loss = 2.85552630e-07 lambda = [-4.1849513  0.4479382]\n",
            "It 11550: loss = 2.85552630e-07 lambda = [-4.258617   0.4704407]\n",
            "It 11600: loss = 2.85552630e-07 lambda = [-4.328944   0.4919231]\n",
            "It 11650: loss = 2.85552630e-07 lambda = [-4.39607     0.51242733]\n",
            "It 11700: loss = 2.85552630e-07 lambda = [-4.4601264  0.5319941]\n",
            "It 11750: loss = 2.85552630e-07 lambda = [-4.521246   0.5506636]\n",
            "It 11800: loss = 2.85552630e-07 lambda = [-4.5795565   0.56847495]\n",
            "It 11850: loss = 2.85552630e-07 lambda = [-4.6351824   0.58546644]\n",
            "It 11900: loss = 2.85552630e-07 lambda = [-4.688246   0.6016748]\n",
            "It 11950: loss = 2.85552630e-07 lambda = [-4.7388625  0.6171363]\n",
            "It 12000: loss = 2.85552630e-07 lambda = [-4.787148   0.6318851]\n",
            "It 12050: loss = 2.85552630e-07 lambda = [-4.8332095   0.64595497]\n",
            "It 12100: loss = 2.85552630e-07 lambda = [-4.877152   0.6593773]\n",
            "It 12150: loss = 2.85552630e-07 lambda = [-4.919075   0.6721829]\n",
            "Timeout is reached. Time elapsed: 80.03067207336426 seconds\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration: 4 Initial lambda: [0.0, 0.0]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Adam\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: l_u = 3.56525987e-01 loss = 3.56525987e-01\n",
            "It 00050: l_u = 1.98209975e-02 loss = 1.98209975e-02\n",
            "It 00100: l_u = 3.05251539e-04 loss = 3.05251539e-04\n",
            "It 00150: l_u = 1.28088956e-04 loss = 1.28088956e-04\n",
            "It 00200: l_u = 8.18262706e-05 loss = 8.18262706e-05\n",
            "It 00250: l_u = 5.65821247e-05 loss = 5.65821247e-05\n",
            "It 00300: l_u = 4.26175247e-05 loss = 4.26175247e-05\n",
            "It 00350: l_u = 3.48167232e-05 loss = 3.48167232e-05\n",
            "It 00400: l_u = 3.01989821e-05 loss = 3.01989821e-05\n",
            "It 00450: l_u = 2.71449226e-05 loss = 2.71449226e-05\n",
            "It 00500: l_u = 2.48731012e-05 loss = 2.48731012e-05\n",
            "It 00550: l_u = 2.30337228e-05 loss = 2.30337228e-05\n",
            "It 00600: l_u = 2.14686588e-05 loss = 2.14686588e-05\n",
            "It 00650: l_u = 2.01000057e-05 loss = 2.01000057e-05\n",
            "It 00700: l_u = 1.88840459e-05 loss = 1.88840459e-05\n",
            "It 00750: l_u = 1.77927213e-05 loss = 1.77927213e-05\n",
            "It 00800: l_u = 1.68061542e-05 loss = 1.68061542e-05\n",
            "It 00850: l_u = 1.59095343e-05 loss = 1.59095343e-05\n",
            "It 00900: l_u = 1.50909809e-05 loss = 1.50909809e-05\n",
            "It 00950: l_u = 1.43412699e-05 loss = 1.43412699e-05\n",
            "It 01000: l_u = 1.36523095e-05 loss = 1.36523095e-05\n",
            "It 01050: l_u = 1.30176268e-05 loss = 1.30176268e-05\n",
            "It 01100: l_u = 1.24316693e-05 loss = 1.24316693e-05\n",
            "It 01150: l_u = 1.18894359e-05 loss = 1.18894359e-05\n",
            "It 01200: l_u = 1.13866736e-05 loss = 1.13866736e-05\n",
            "It 01250: l_u = 1.09196953e-05 loss = 1.09196953e-05\n",
            "It 01300: l_u = 1.04851633e-05 loss = 1.04851633e-05\n",
            "It 01350: l_u = 1.00801526e-05 loss = 1.00801526e-05\n",
            "It 01400: l_u = 9.70204474e-06 loss = 9.70204474e-06\n",
            "It 01450: l_u = 9.34852051e-06 loss = 9.34852051e-06\n",
            "It 01500: l_u = 9.01738349e-06 loss = 9.01738349e-06\n",
            "It 01550: l_u = 8.70669191e-06 loss = 8.70669191e-06\n",
            "It 01600: l_u = 8.41492874e-06 loss = 8.41492874e-06\n",
            "It 01650: l_u = 8.14043233e-06 loss = 8.14043233e-06\n",
            "It 01700: l_u = 7.88180660e-06 loss = 7.88180660e-06\n",
            "It 01750: l_u = 7.63782464e-06 loss = 7.63782464e-06\n",
            "It 01800: l_u = 7.40750784e-06 loss = 7.40750784e-06\n",
            "It 01850: l_u = 7.18968568e-06 loss = 7.18968568e-06\n",
            "It 01900: l_u = 6.98350004e-06 loss = 6.98350004e-06\n",
            "It 01950: l_u = 6.78801553e-06 loss = 6.78801553e-06\n",
            "It 02000: l_u = 6.60257865e-06 loss = 6.60257865e-06\n",
            "It 02050: l_u = 6.42643317e-06 loss = 6.42643317e-06\n",
            "It 02100: l_u = 6.25893608e-06 loss = 6.25893608e-06\n",
            "It 02150: l_u = 6.09962854e-06 loss = 6.09962854e-06\n",
            "It 02200: l_u = 5.94782750e-06 loss = 5.94782750e-06\n",
            "It 02250: l_u = 5.80321466e-06 loss = 5.80321466e-06\n",
            "It 02300: l_u = 5.66524295e-06 loss = 5.66524295e-06\n",
            "It 02350: l_u = 5.53346717e-06 loss = 5.53346717e-06\n",
            "It 02400: l_u = 5.40764404e-06 loss = 5.40764404e-06\n",
            "It 02450: l_u = 5.28727924e-06 loss = 5.28727924e-06\n",
            "It 02500: l_u = 5.17210492e-06 loss = 5.17210492e-06\n",
            "It 02550: l_u = 5.06190509e-06 loss = 5.06190509e-06\n",
            "It 02600: l_u = 4.95628728e-06 loss = 4.95628728e-06\n",
            "It 02650: l_u = 4.85512692e-06 loss = 4.85512692e-06\n",
            "It 02700: l_u = 4.75796924e-06 loss = 4.75796924e-06\n",
            "It 02750: l_u = 4.66488200e-06 loss = 4.66488200e-06\n",
            "It 02800: l_u = 4.57541819e-06 loss = 4.57541819e-06\n",
            "It 02850: l_u = 4.48949049e-06 loss = 4.48949049e-06\n",
            "It 02900: l_u = 4.40690837e-06 loss = 4.40690837e-06\n",
            "It 02950: l_u = 4.32744946e-06 loss = 4.32744946e-06\n",
            "It 03000: l_u = 4.25104781e-06 loss = 4.25104781e-06\n",
            "It 03050: l_u = 4.21263894e-06 loss = 4.21263894e-06\n",
            "It 03100: l_u = 4.17459114e-06 loss = 4.17459114e-06\n",
            "It 03150: l_u = 4.13610269e-06 loss = 4.13610269e-06\n",
            "It 03200: l_u = 4.09716677e-06 loss = 4.09716677e-06\n",
            "It 03250: l_u = 4.05787659e-06 loss = 4.05787659e-06\n",
            "It 03300: l_u = 4.01821580e-06 loss = 4.01821580e-06\n",
            "It 03350: l_u = 3.97818212e-06 loss = 3.97818212e-06\n",
            "It 03400: l_u = 3.93770597e-06 loss = 3.93770597e-06\n",
            "It 03450: l_u = 3.89698471e-06 loss = 3.89698471e-06\n",
            "It 03500: l_u = 3.85587146e-06 loss = 3.85587146e-06\n",
            "It 03550: l_u = 3.81443374e-06 loss = 3.81443374e-06\n",
            "It 03600: l_u = 3.77268952e-06 loss = 3.77268952e-06\n",
            "It 03650: l_u = 3.73067428e-06 loss = 3.73067428e-06\n",
            "It 03700: l_u = 3.68837027e-06 loss = 3.68837027e-06\n",
            "It 03750: l_u = 3.64578386e-06 loss = 3.64578386e-06\n",
            "It 03800: l_u = 3.60294757e-06 loss = 3.60294757e-06\n",
            "It 03850: l_u = 3.55985549e-06 loss = 3.55985549e-06\n",
            "It 03900: l_u = 3.51662629e-06 loss = 3.51662629e-06\n",
            "It 03950: l_u = 3.47315290e-06 loss = 3.47315290e-06\n",
            "It 04000: l_u = 3.42945191e-06 loss = 3.42945191e-06\n",
            "It 04050: l_u = 3.38570953e-06 loss = 3.38570953e-06\n",
            "It 04100: l_u = 3.34174501e-06 loss = 3.34174501e-06\n",
            "It 04150: l_u = 3.29770432e-06 loss = 3.29770432e-06\n",
            "It 04200: l_u = 3.25350106e-06 loss = 3.25350106e-06\n",
            "It 04250: l_u = 3.20924846e-06 loss = 3.20924846e-06\n",
            "It 04300: l_u = 3.16498313e-06 loss = 3.16498313e-06\n",
            "It 04350: l_u = 3.12058864e-06 loss = 3.12058864e-06\n",
            "It 04400: l_u = 3.07619894e-06 loss = 3.07619894e-06\n",
            "It 04450: l_u = 3.03185743e-06 loss = 3.03185743e-06\n",
            "It 04500: l_u = 2.98746249e-06 loss = 2.98746249e-06\n",
            "It 04550: l_u = 2.94313622e-06 loss = 2.94313622e-06\n",
            "It 04600: l_u = 2.89887453e-06 loss = 2.89887453e-06\n",
            "It 04650: l_u = 2.85468809e-06 loss = 2.85468809e-06\n",
            "It 04700: l_u = 2.81063285e-06 loss = 2.81063285e-06\n",
            "It 04750: l_u = 2.76663764e-06 loss = 2.76663764e-06\n",
            "It 04800: l_u = 2.72283273e-06 loss = 2.72283273e-06\n",
            "It 04850: l_u = 3.41213558e-06 loss = 3.41213558e-06\n",
            "It 04900: l_u = 3.54389363e-06 loss = 3.54389363e-06\n",
            "It 04950: l_u = 2.60098363e-06 loss = 2.60098363e-06\n",
            "It 05000: l_u = 2.55552277e-06 loss = 2.55552277e-06\n",
            "It 05050: l_u = 2.51352594e-06 loss = 2.51352594e-06\n",
            "It 05100: l_u = 1.85006083e-05 loss = 1.85006083e-05\n",
            "It 05150: l_u = 2.53020721e-06 loss = 2.53020721e-06\n",
            "It 05200: l_u = 2.39674205e-06 loss = 2.39674205e-06\n",
            "It 05250: l_u = 2.35542916e-06 loss = 2.35542916e-06\n",
            "It 05300: l_u = 2.31553850e-06 loss = 2.31553850e-06\n",
            "It 05350: l_u = 1.78245245e-05 loss = 1.78245245e-05\n",
            "It 05400: l_u = 2.31600893e-06 loss = 2.31600893e-06\n",
            "It 05450: l_u = 2.20798461e-06 loss = 2.20798461e-06\n",
            "It 05500: l_u = 2.16927015e-06 loss = 2.16927015e-06\n",
            "It 05550: l_u = 2.13195312e-06 loss = 2.13195312e-06\n",
            "It 05600: l_u = 2.17174011e-06 loss = 2.17174011e-06\n",
            "It 05650: l_u = 4.34050980e-06 loss = 4.34050980e-06\n",
            "It 05700: l_u = 2.03111244e-06 loss = 2.03111244e-06\n",
            "It 05750: l_u = 1.99571355e-06 loss = 1.99571355e-06\n",
            "It 05800: l_u = 1.96095289e-06 loss = 1.96095289e-06\n",
            "It 05850: l_u = 1.92683683e-06 loss = 1.92683683e-06\n",
            "It 05900: l_u = 2.00122631e-05 loss = 2.00122631e-05\n",
            "It 05950: l_u = 1.90301080e-06 loss = 1.90301080e-06\n",
            "It 06000: l_u = 1.83648069e-06 loss = 1.83648069e-06\n",
            "It 06050: l_u = 1.80403310e-06 loss = 1.80403310e-06\n",
            "It 06100: l_u = 1.77237666e-06 loss = 1.77237666e-06\n",
            "It 06150: l_u = 1.95253574e-06 loss = 1.95253574e-06\n",
            "It 06200: l_u = 4.87862235e-06 loss = 4.87862235e-06\n",
            "It 06250: l_u = 1.71186889e-06 loss = 1.71186889e-06\n",
            "It 06300: l_u = 1.66202119e-06 loss = 1.66202119e-06\n",
            "It 06350: l_u = 1.63282300e-06 loss = 1.63282300e-06\n",
            "It 06400: l_u = 1.60421655e-06 loss = 1.60421655e-06\n",
            "It 06450: l_u = 1.58022294e-06 loss = 1.58022294e-06\n",
            "It 06500: l_u = 2.72672105e-06 loss = 2.72672105e-06\n",
            "It 06550: l_u = 1.54541715e-06 loss = 1.54541715e-06\n",
            "It 06600: l_u = 1.50323217e-06 loss = 1.50323217e-06\n",
            "It 06650: l_u = 1.47657352e-06 loss = 1.47657352e-06\n",
            "It 06700: l_u = 1.45070885e-06 loss = 1.45070885e-06\n",
            "It 06750: l_u = 2.17547731e-05 loss = 2.17547731e-05\n",
            "It 06800: l_u = 1.52160987e-06 loss = 1.52160987e-06\n",
            "It 06850: l_u = 1.38371411e-06 loss = 1.38371411e-06\n",
            "It 06900: l_u = 1.35912057e-06 loss = 1.35912057e-06\n",
            "It 06950: l_u = 1.33513868e-06 loss = 1.33513868e-06\n",
            "It 07000: l_u = 1.36770221e-04 loss = 1.36770221e-04\n",
            "It 07050: l_u = 1.55295299e-06 loss = 1.55295299e-06\n",
            "It 07100: l_u = 1.29609487e-06 loss = 1.29609487e-06\n",
            "It 07150: l_u = 1.28176123e-06 loss = 1.28176123e-06\n",
            "It 07200: l_u = 1.27007343e-06 loss = 1.27007343e-06\n",
            "It 07250: l_u = 1.25847157e-06 loss = 1.25847157e-06\n",
            "It 07300: l_u = 1.24688006e-06 loss = 1.24688006e-06\n",
            "It 07350: l_u = 1.23523853e-06 loss = 1.23523853e-06\n",
            "It 07400: l_u = 1.22358574e-06 loss = 1.22358574e-06\n",
            "It 07450: l_u = 1.21186258e-06 loss = 1.21186258e-06\n",
            "It 07500: l_u = 1.20011259e-06 loss = 1.20011259e-06\n",
            "It 07550: l_u = 1.18829439e-06 loss = 1.18829439e-06\n",
            "It 07600: l_u = 1.17639877e-06 loss = 1.17639877e-06\n",
            "It 07650: l_u = 1.16448268e-06 loss = 1.16448268e-06\n",
            "It 07700: l_u = 1.15251078e-06 loss = 1.15251078e-06\n",
            "It 07750: l_u = 1.14044292e-06 loss = 1.14044292e-06\n",
            "It 07800: l_u = 1.12832788e-06 loss = 1.12832788e-06\n",
            "It 07850: l_u = 1.11611109e-06 loss = 1.11611109e-06\n",
            "It 07900: l_u = 1.10389760e-06 loss = 1.10389760e-06\n",
            "It 07950: l_u = 1.09161124e-06 loss = 1.09161124e-06\n",
            "It 08000: l_u = 1.07926030e-06 loss = 1.07926030e-06\n",
            "It 08050: l_u = 1.06684035e-06 loss = 1.06684035e-06\n",
            "It 08100: l_u = 1.05436425e-06 loss = 1.05436425e-06\n",
            "It 08150: l_u = 1.04187188e-06 loss = 1.04187188e-06\n",
            "It 08200: l_u = 1.02928243e-06 loss = 1.02928243e-06\n",
            "It 08250: l_u = 1.01665137e-06 loss = 1.01665137e-06\n",
            "It 08300: l_u = 1.00395653e-06 loss = 1.00395653e-06\n",
            "It 08350: l_u = 9.91285447e-07 loss = 9.91285447e-07\n",
            "It 08400: l_u = 9.78488742e-07 loss = 9.78488742e-07\n",
            "It 08450: l_u = 9.65711706e-07 loss = 9.65711706e-07\n",
            "It 08500: l_u = 9.52844459e-07 loss = 9.52844459e-07\n",
            "It 08550: l_u = 9.39943220e-07 loss = 9.39943220e-07\n",
            "It 08600: l_u = 9.27046528e-07 loss = 9.27046528e-07\n",
            "It 08650: l_u = 4.03403028e-05 loss = 4.03403028e-05\n",
            "It 08700: l_u = 1.06701395e-06 loss = 1.06701395e-06\n",
            "It 08750: l_u = 8.91114269e-07 loss = 8.91114269e-07\n",
            "It 08800: l_u = 8.77783236e-07 loss = 8.77783236e-07\n",
            "It 08850: l_u = 8.65515062e-07 loss = 8.65515062e-07\n",
            "It 08900: l_u = 8.86012856e-07 loss = 8.86012856e-07\n",
            "It 08950: l_u = 1.40541465e-06 loss = 1.40541465e-06\n",
            "It 09000: l_u = 8.30531860e-07 loss = 8.30531860e-07\n",
            "It 09050: l_u = 8.18957062e-07 loss = 8.18957062e-07\n",
            "Timeout is reached. Time elapsed: 20.000338315963745 seconds\n",
            "\n",
            "\n",
            "Finding PDE parameters.\n",
            "It 09100: loss = 8.11567645e-07 lambda = [-1.1908771 -0.6340402]\n",
            "It 09150: loss = 8.11567645e-07 lambda = [-3.486774    0.22602446]\n",
            "It 09200: loss = 8.11567645e-07 lambda = [-5.032745    0.70683336]\n",
            "It 09250: loss = 8.11567645e-07 lambda = [-5.668189   0.9007817]\n",
            "It 09300: loss = 8.11567645e-07 lambda = [-5.8519025  0.9563908]\n",
            "It 09350: loss = 8.11567645e-07 lambda = [-5.8902392  0.9680115]\n",
            "It 09400: loss = 8.11567645e-07 lambda = [-5.89598     0.96975076]\n",
            "It 09450: loss = 8.11567645e-07 lambda = [-5.8965626   0.96992725]\n",
            "It 09500: loss = 8.11567645e-07 lambda = [-5.8965926   0.96993625]\n",
            "It 09550: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 09600: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 09650: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 09700: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 09750: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 09800: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 09850: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 09900: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 09950: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 10000: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 10050: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 10100: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699363]\n",
            "It 10150: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699363]\n",
            "It 10200: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699363]\n",
            "It 10250: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699363]\n",
            "It 10300: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699363]\n",
            "It 10350: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699363]\n",
            "It 10400: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699363]\n",
            "It 10450: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 10500: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 10550: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 10600: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 10650: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 10700: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 10750: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 10800: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 10850: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699363]\n",
            "It 10900: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 10950: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 11000: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 11050: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 11100: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 11150: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "It 11200: loss = 8.11567645e-07 lambda = [-5.8965926  0.9699364]\n",
            "Timeout is reached. Time elapsed: 80.03301048278809 seconds\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration: 4 Initial lambda: [1.0, -6.0]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Adam\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: l_u = 3.56525987e-01 loss = 3.56525987e-01\n",
            "It 00050: l_u = 1.98209845e-02 loss = 1.98209845e-02\n",
            "It 00100: l_u = 3.05251509e-04 loss = 3.05251509e-04\n",
            "It 00150: l_u = 1.28089130e-04 loss = 1.28089130e-04\n",
            "It 00200: l_u = 8.18261615e-05 loss = 8.18261615e-05\n",
            "It 00250: l_u = 5.65820919e-05 loss = 5.65820919e-05\n",
            "It 00300: l_u = 4.26175720e-05 loss = 4.26175720e-05\n",
            "It 00350: l_u = 3.48166614e-05 loss = 3.48166614e-05\n",
            "It 00400: l_u = 3.01990258e-05 loss = 3.01990258e-05\n",
            "It 00450: l_u = 2.71450335e-05 loss = 2.71450335e-05\n",
            "It 00500: l_u = 2.48732285e-05 loss = 2.48732285e-05\n",
            "It 00550: l_u = 2.30337610e-05 loss = 2.30337610e-05\n",
            "It 00600: l_u = 2.14686370e-05 loss = 2.14686370e-05\n",
            "It 00650: l_u = 2.01000548e-05 loss = 2.01000548e-05\n",
            "It 00700: l_u = 1.88840149e-05 loss = 1.88840149e-05\n",
            "It 00750: l_u = 1.77926449e-05 loss = 1.77926449e-05\n",
            "It 00800: l_u = 1.68061470e-05 loss = 1.68061470e-05\n",
            "It 00850: l_u = 1.59093834e-05 loss = 1.59093834e-05\n",
            "It 00900: l_u = 1.50909682e-05 loss = 1.50909682e-05\n",
            "It 00950: l_u = 1.43411871e-05 loss = 1.43411871e-05\n",
            "It 01000: l_u = 1.36523131e-05 loss = 1.36523131e-05\n",
            "It 01050: l_u = 1.30177141e-05 loss = 1.30177141e-05\n",
            "It 01100: l_u = 1.24316939e-05 loss = 1.24316939e-05\n",
            "It 01150: l_u = 1.18894613e-05 loss = 1.18894613e-05\n",
            "It 01200: l_u = 1.13866763e-05 loss = 1.13866763e-05\n",
            "It 01250: l_u = 1.09196917e-05 loss = 1.09196917e-05\n",
            "It 01300: l_u = 1.04852106e-05 loss = 1.04852106e-05\n",
            "It 01350: l_u = 1.00801399e-05 loss = 1.00801399e-05\n",
            "It 01400: l_u = 9.70202109e-06 loss = 9.70202109e-06\n",
            "It 01450: l_u = 9.34851505e-06 loss = 9.34851505e-06\n",
            "It 01500: l_u = 9.01732710e-06 loss = 9.01732710e-06\n",
            "It 01550: l_u = 8.70673102e-06 loss = 8.70673102e-06\n",
            "It 01600: l_u = 8.41489236e-06 loss = 8.41489236e-06\n",
            "It 01650: l_u = 8.14040595e-06 loss = 8.14040595e-06\n",
            "It 01700: l_u = 7.88175203e-06 loss = 7.88175203e-06\n",
            "It 01750: l_u = 7.63787739e-06 loss = 7.63787739e-06\n",
            "It 01800: l_u = 7.40750602e-06 loss = 7.40750602e-06\n",
            "It 01850: l_u = 7.18975662e-06 loss = 7.18975662e-06\n",
            "It 01900: l_u = 6.98346730e-06 loss = 6.98346730e-06\n",
            "It 01950: l_u = 6.78797596e-06 loss = 6.78797596e-06\n",
            "It 02000: l_u = 6.60256546e-06 loss = 6.60256546e-06\n",
            "It 02050: l_u = 6.42641226e-06 loss = 6.42641226e-06\n",
            "It 02100: l_u = 6.25891880e-06 loss = 6.25891880e-06\n",
            "It 02150: l_u = 6.09962581e-06 loss = 6.09962581e-06\n",
            "It 02200: l_u = 5.94786570e-06 loss = 5.94786570e-06\n",
            "It 02250: l_u = 5.80316828e-06 loss = 5.80316828e-06\n",
            "It 02300: l_u = 5.66521521e-06 loss = 5.66521521e-06\n",
            "It 02350: l_u = 5.53348400e-06 loss = 5.53348400e-06\n",
            "It 02400: l_u = 5.40762039e-06 loss = 5.40762039e-06\n",
            "It 02450: l_u = 5.28728060e-06 loss = 5.28728060e-06\n",
            "It 02500: l_u = 5.17214676e-06 loss = 5.17214676e-06\n",
            "It 02550: l_u = 5.06190690e-06 loss = 5.06190690e-06\n",
            "It 02600: l_u = 4.95636323e-06 loss = 4.95636323e-06\n",
            "It 02650: l_u = 4.85508508e-06 loss = 4.85508508e-06\n",
            "It 02700: l_u = 4.75798834e-06 loss = 4.75798834e-06\n",
            "It 02750: l_u = 4.66488200e-06 loss = 4.66488200e-06\n",
            "It 02800: l_u = 4.57544866e-06 loss = 4.57544866e-06\n",
            "It 02850: l_u = 4.48946548e-06 loss = 4.48946548e-06\n",
            "It 02900: l_u = 4.40688746e-06 loss = 4.40688746e-06\n",
            "It 02950: l_u = 4.32742172e-06 loss = 4.32742172e-06\n",
            "It 03000: l_u = 4.25101734e-06 loss = 4.25101734e-06\n",
            "It 03050: l_u = 4.21263530e-06 loss = 4.21263530e-06\n",
            "It 03100: l_u = 4.17456840e-06 loss = 4.17456840e-06\n",
            "It 03150: l_u = 4.13609587e-06 loss = 4.13609587e-06\n",
            "It 03200: l_u = 4.09723043e-06 loss = 4.09723043e-06\n",
            "It 03250: l_u = 4.05794344e-06 loss = 4.05794344e-06\n",
            "It 03300: l_u = 4.01822808e-06 loss = 4.01822808e-06\n",
            "It 03350: l_u = 3.97820031e-06 loss = 3.97820031e-06\n",
            "It 03400: l_u = 3.93775144e-06 loss = 3.93775144e-06\n",
            "It 03450: l_u = 3.89699835e-06 loss = 3.89699835e-06\n",
            "It 03500: l_u = 3.85584553e-06 loss = 3.85584553e-06\n",
            "It 03550: l_u = 3.81439418e-06 loss = 3.81439418e-06\n",
            "It 03600: l_u = 3.77271863e-06 loss = 3.77271863e-06\n",
            "It 03650: l_u = 3.73069474e-06 loss = 3.73069474e-06\n",
            "It 03700: l_u = 3.68838118e-06 loss = 3.68838118e-06\n",
            "It 03750: l_u = 3.64578636e-06 loss = 3.64578636e-06\n",
            "It 03800: l_u = 3.60291210e-06 loss = 3.60291210e-06\n",
            "It 03850: l_u = 3.55986299e-06 loss = 3.55986299e-06\n",
            "It 03900: l_u = 3.51658855e-06 loss = 3.51658855e-06\n",
            "It 03950: l_u = 3.47311970e-06 loss = 3.47311970e-06\n",
            "It 04000: l_u = 3.42949511e-06 loss = 3.42949511e-06\n",
            "It 04050: l_u = 3.38567861e-06 loss = 3.38567861e-06\n",
            "It 04100: l_u = 3.34178026e-06 loss = 3.34178026e-06\n",
            "It 04150: l_u = 3.29766931e-06 loss = 3.29766931e-06\n",
            "It 04200: l_u = 3.25347287e-06 loss = 3.25347287e-06\n",
            "It 04250: l_u = 3.20925665e-06 loss = 3.20925665e-06\n",
            "It 04300: l_u = 3.16494334e-06 loss = 3.16494334e-06\n",
            "It 04350: l_u = 3.12054294e-06 loss = 3.12054294e-06\n",
            "It 04400: l_u = 3.07617461e-06 loss = 3.07617461e-06\n",
            "It 04450: l_u = 3.03178808e-06 loss = 3.03178808e-06\n",
            "It 04500: l_u = 2.98743907e-06 loss = 2.98743907e-06\n",
            "It 04550: l_u = 2.94313850e-06 loss = 2.94313850e-06\n",
            "It 04600: l_u = 2.89888953e-06 loss = 2.89888953e-06\n",
            "It 04650: l_u = 2.85466626e-06 loss = 2.85466626e-06\n",
            "It 04700: l_u = 2.81058396e-06 loss = 2.81058396e-06\n",
            "It 04750: l_u = 2.76664150e-06 loss = 2.76664150e-06\n",
            "It 04800: l_u = 2.72287298e-06 loss = 2.72287298e-06\n",
            "It 04850: l_u = 2.91267884e-06 loss = 2.91267884e-06\n",
            "It 04900: l_u = 4.28251451e-06 loss = 4.28251451e-06\n",
            "It 04950: l_u = 2.60865704e-06 loss = 2.60865704e-06\n",
            "It 05000: l_u = 2.55590226e-06 loss = 2.55590226e-06\n",
            "It 05050: l_u = 2.51386746e-06 loss = 2.51386746e-06\n",
            "It 05100: l_u = 6.75984847e-06 loss = 6.75984847e-06\n",
            "It 05150: l_u = 2.65875383e-06 loss = 2.65875383e-06\n",
            "It 05200: l_u = 2.39804649e-06 loss = 2.39804649e-06\n",
            "It 05250: l_u = 2.35653715e-06 loss = 2.35653715e-06\n",
            "It 05300: l_u = 2.31673039e-06 loss = 2.31673039e-06\n",
            "It 05350: l_u = 2.35358107e-06 loss = 2.35358107e-06\n",
            "It 05400: l_u = 3.33638104e-06 loss = 3.33638104e-06\n",
            "It 05450: l_u = 2.22106382e-06 loss = 2.22106382e-06\n",
            "It 05500: l_u = 2.16951094e-06 loss = 2.16951094e-06\n",
            "It 05550: l_u = 2.13203975e-06 loss = 2.13203975e-06\n",
            "It 05600: l_u = 2.10922849e-06 loss = 2.10922849e-06\n",
            "It 05650: l_u = 6.01035845e-06 loss = 6.01035845e-06\n",
            "It 05700: l_u = 2.03694935e-06 loss = 2.03694935e-06\n",
            "It 05750: l_u = 1.99551801e-06 loss = 1.99551801e-06\n",
            "It 05800: l_u = 1.96065548e-06 loss = 1.96065548e-06\n",
            "It 05850: l_u = 1.93102665e-06 loss = 1.93102665e-06\n",
            "It 05900: l_u = 2.04947651e-06 loss = 2.04947651e-06\n",
            "It 05950: l_u = 1.89366176e-06 loss = 1.89366176e-06\n",
            "It 06000: l_u = 1.83522491e-06 loss = 1.83522491e-06\n",
            "It 06050: l_u = 1.80305869e-06 loss = 1.80305869e-06\n",
            "It 06100: l_u = 1.77149366e-06 loss = 1.77149366e-06\n",
            "It 06150: l_u = 2.78119046e-06 loss = 2.78119046e-06\n",
            "It 06200: l_u = 1.76752337e-06 loss = 1.76752337e-06\n",
            "It 06250: l_u = 1.68857116e-06 loss = 1.68857116e-06\n",
            "It 06300: l_u = 1.65886047e-06 loss = 1.65886047e-06\n",
            "It 06350: l_u = 1.62967808e-06 loss = 1.62967808e-06\n",
            "It 06400: l_u = 1.34530521e-04 loss = 1.34530521e-04\n",
            "It 06450: l_u = 2.11462043e-06 loss = 2.11462043e-06\n",
            "It 06500: l_u = 1.55787541e-06 loss = 1.55787541e-06\n",
            "It 06550: l_u = 1.52655070e-06 loss = 1.52655070e-06\n",
            "It 06600: l_u = 1.49969412e-06 loss = 1.49969412e-06\n",
            "It 06650: l_u = 1.83300585e-06 loss = 1.83300585e-06\n",
            "It 06700: l_u = 2.64003666e-06 loss = 2.64003666e-06\n",
            "It 06750: l_u = 1.44919841e-06 loss = 1.44919841e-06\n",
            "It 06800: l_u = 1.40635382e-06 loss = 1.40635382e-06\n",
            "It 06850: l_u = 1.38145720e-06 loss = 1.38145720e-06\n",
            "It 06900: l_u = 1.35713708e-06 loss = 1.35713708e-06\n",
            "It 06950: l_u = 6.52497238e-06 loss = 6.52497238e-06\n",
            "It 07000: l_u = 1.34272136e-06 loss = 1.34272136e-06\n",
            "It 07050: l_u = 1.31528270e-06 loss = 1.31528270e-06\n",
            "It 07100: l_u = 1.29796410e-06 loss = 1.29796410e-06\n",
            "It 07150: l_u = 1.28536112e-06 loss = 1.28536112e-06\n",
            "It 07200: l_u = 1.27315070e-06 loss = 1.27315070e-06\n",
            "It 07250: l_u = 1.26109103e-06 loss = 1.26109103e-06\n",
            "It 07300: l_u = 1.24910457e-06 loss = 1.24910457e-06\n",
            "It 07350: l_u = 1.23713949e-06 loss = 1.23713949e-06\n",
            "It 07400: l_u = 1.22521487e-06 loss = 1.22521487e-06\n",
            "It 07450: l_u = 1.21324717e-06 loss = 1.21324717e-06\n",
            "It 07500: l_u = 1.20124116e-06 loss = 1.20124116e-06\n",
            "It 07550: l_u = 1.18924936e-06 loss = 1.18924936e-06\n",
            "It 07600: l_u = 1.17722175e-06 loss = 1.17722175e-06\n",
            "It 07650: l_u = 1.16509989e-06 loss = 1.16509989e-06\n",
            "It 07700: l_u = 1.15297723e-06 loss = 1.15297723e-06\n",
            "It 07750: l_u = 1.14080012e-06 loss = 1.14080012e-06\n",
            "It 07800: l_u = 1.12856378e-06 loss = 1.12856378e-06\n",
            "It 07850: l_u = 1.11630209e-06 loss = 1.11630209e-06\n",
            "It 07900: l_u = 1.10397161e-06 loss = 1.10397161e-06\n",
            "It 07950: l_u = 1.09159532e-06 loss = 1.09159532e-06\n",
            "It 08000: l_u = 1.07915639e-06 loss = 1.07915639e-06\n",
            "It 08050: l_u = 1.06667665e-06 loss = 1.06667665e-06\n",
            "It 08100: l_u = 1.05410686e-06 loss = 1.05410686e-06\n",
            "It 08150: l_u = 1.04154594e-06 loss = 1.04154594e-06\n",
            "It 08200: l_u = 1.02891931e-06 loss = 1.02891931e-06\n",
            "It 08250: l_u = 1.01622447e-06 loss = 1.01622447e-06\n",
            "It 08300: l_u = 1.00351485e-06 loss = 1.00351485e-06\n",
            "It 08350: l_u = 9.90739977e-07 loss = 9.90739977e-07\n",
            "It 08400: l_u = 9.77937930e-07 loss = 9.77937930e-07\n",
            "It 08450: l_u = 9.65088930e-07 loss = 9.65088930e-07\n",
            "It 08500: l_u = 9.52222194e-07 loss = 9.52222194e-07\n",
            "It 08550: l_u = 9.39300492e-07 loss = 9.39300492e-07\n",
            "It 08600: l_u = 9.26355426e-07 loss = 9.26355426e-07\n",
            "It 08650: l_u = 1.21456253e-06 loss = 1.21456253e-06\n",
            "It 08700: l_u = 9.09256755e-07 loss = 9.09256755e-07\n",
            "It 08750: l_u = 8.89142086e-07 loss = 8.89142086e-07\n",
            "It 08800: l_u = 8.76740046e-07 loss = 8.76740046e-07\n",
            "It 08850: l_u = 8.64421565e-07 loss = 8.64421565e-07\n",
            "It 08900: l_u = 8.79949368e-07 loss = 8.79949368e-07\n",
            "It 08950: l_u = 9.74620662e-07 loss = 9.74620662e-07\n",
            "It 09000: l_u = 8.31422142e-07 loss = 8.31422142e-07\n",
            "It 09050: l_u = 8.17885280e-07 loss = 8.17885280e-07\n",
            "It 09100: l_u = 8.06359708e-07 loss = 8.06359708e-07\n",
            "It 09150: l_u = 8.15386954e-07 loss = 8.15386954e-07\n",
            "It 09200: l_u = 1.15197395e-06 loss = 1.15197395e-06\n",
            "It 09250: l_u = 7.75038870e-07 loss = 7.75038870e-07\n",
            "It 09300: l_u = 7.61704598e-07 loss = 7.61704598e-07\n",
            "It 09350: l_u = 3.21831885e-06 loss = 3.21831885e-06\n",
            "It 09400: l_u = 7.75028241e-07 loss = 7.75028241e-07\n",
            "It 09450: l_u = 7.30690886e-07 loss = 7.30690886e-07\n",
            "It 09500: l_u = 7.19437878e-07 loss = 7.19437878e-07\n",
            "It 09550: l_u = 7.59599914e-07 loss = 7.59599914e-07\n",
            "It 09600: l_u = 1.38895757e-06 loss = 1.38895757e-06\n",
            "It 09650: l_u = 6.92676792e-07 loss = 6.92676792e-07\n",
            "It 09700: l_u = 6.78777553e-07 loss = 6.78777553e-07\n",
            "It 09750: l_u = 1.36541064e-06 loss = 1.36541064e-06\n",
            "It 09800: l_u = 1.00308455e-06 loss = 1.00308455e-06\n",
            "It 09850: l_u = 6.52763447e-07 loss = 6.52763447e-07\n",
            "Timeout is reached. Time elapsed: 20.001024961471558 seconds\n",
            "\n",
            "\n",
            "Finding PDE parameters.\n",
            "It 09900: loss = 6.49648712e-07 lambda = [ 4.2330756 -2.5839634]\n",
            "It 09950: loss = 6.49648712e-07 lambda = [ 3.698885 -1.944344]\n",
            "It 10000: loss = 6.49648712e-07 lambda = [ 2.5695024 -1.6349623]\n",
            "It 10050: loss = 6.49648712e-07 lambda = [ 1.4530725 -1.2897941]\n",
            "It 10100: loss = 6.49648712e-07 lambda = [ 0.38378823 -0.9604067 ]\n",
            "It 10150: loss = 6.49648712e-07 lambda = [-0.59927756 -0.6579533 ]\n",
            "It 10200: loss = 6.49648712e-07 lambda = [-1.47735   -0.3879084]\n",
            "It 10250: loss = 6.49648712e-07 lambda = [-2.2446864  -0.15199567]\n",
            "It 10300: loss = 6.49648712e-07 lambda = [-2.9036648   0.05055723]\n",
            "It 10350: loss = 6.49648712e-07 lambda = [-3.4615424   0.22200775]\n",
            "It 10400: loss = 6.49648712e-07 lambda = [-3.9281976  0.3654079]\n",
            "It 10450: loss = 6.49648712e-07 lambda = [-4.314588    0.48413458]\n",
            "It 10500: loss = 6.49648712e-07 lambda = [-4.63174     0.58158153]\n",
            "It 10550: loss = 6.49648712e-07 lambda = [-4.8901076  0.6609642]\n",
            "It 10600: loss = 6.49648712e-07 lambda = [-5.099223   0.7252128]\n",
            "It 10650: loss = 6.49648712e-07 lambda = [-5.2675276  0.7769216]\n",
            "It 10700: loss = 6.49648712e-07 lambda = [-5.4023266  0.8183363]\n",
            "It 10750: loss = 6.49648712e-07 lambda = [-5.5098424   0.85136855]\n",
            "It 10800: loss = 6.49648712e-07 lambda = [-5.595289  0.87762 ]\n",
            "It 10850: loss = 6.49648712e-07 lambda = [-5.662986    0.89841855]\n",
            "It 10900: loss = 6.49648712e-07 lambda = [-5.716482  0.914854]\n",
            "It 10950: loss = 6.49648712e-07 lambda = [-5.758665   0.9278137]\n",
            "It 11000: loss = 6.49648712e-07 lambda = [-5.791867  0.938014]\n",
            "It 11050: loss = 6.49648712e-07 lambda = [-5.8179607  0.9460308]\n",
            "It 11100: loss = 6.49648712e-07 lambda = [-5.8384433  0.9523237]\n",
            "It 11150: loss = 6.49648712e-07 lambda = [-5.8545074  0.9572592]\n",
            "It 11200: loss = 6.49648712e-07 lambda = [-5.8671      0.96112776]\n",
            "It 11250: loss = 6.49648712e-07 lambda = [-5.876966    0.96415895]\n",
            "It 11300: loss = 6.49648712e-07 lambda = [-5.884694   0.9665331]\n",
            "It 11350: loss = 6.49648712e-07 lambda = [-5.890748  0.968393]\n",
            "It 11400: loss = 6.49648712e-07 lambda = [-5.8954906  0.9698502]\n",
            "It 11450: loss = 6.49648712e-07 lambda = [-5.8992066   0.97099185]\n",
            "It 11500: loss = 6.49648712e-07 lambda = [-5.90212     0.97188693]\n",
            "It 11550: loss = 6.49648712e-07 lambda = [-5.9044065  0.9725895]\n",
            "It 11600: loss = 6.49648712e-07 lambda = [-5.9062014  0.9731407]\n",
            "It 11650: loss = 6.49648712e-07 lambda = [-5.9076104  0.9735737]\n",
            "It 11700: loss = 6.49648712e-07 lambda = [-5.9087186  0.9739141]\n",
            "It 11750: loss = 6.49648712e-07 lambda = [-5.909591    0.97418225]\n",
            "It 11800: loss = 6.49648712e-07 lambda = [-5.9102793   0.97439355]\n",
            "It 11850: loss = 6.49648712e-07 lambda = [-5.910821    0.97456014]\n",
            "It 11900: loss = 6.49648712e-07 lambda = [-5.911249    0.97469157]\n",
            "It 11950: loss = 6.49648712e-07 lambda = [-5.9115887   0.97479576]\n",
            "It 12000: loss = 6.49648712e-07 lambda = [-5.911856   0.9748783]\n",
            "It 12050: loss = 6.49648712e-07 lambda = [-5.912069   0.9749436]\n",
            "Timeout is reached. Time elapsed: 80.03291916847229 seconds\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration: 4 Initial lambda: [10.0, 10.0]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Adam\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: l_u = 3.56525987e-01 loss = 3.56525987e-01\n",
            "It 00050: l_u = 1.98210031e-02 loss = 1.98210031e-02\n",
            "It 00100: l_u = 3.05251451e-04 loss = 3.05251451e-04\n",
            "It 00150: l_u = 1.28088985e-04 loss = 1.28088985e-04\n",
            "It 00200: l_u = 8.18259286e-05 loss = 8.18259286e-05\n",
            "It 00250: l_u = 5.65820337e-05 loss = 5.65820337e-05\n",
            "It 00300: l_u = 4.26174702e-05 loss = 4.26174702e-05\n",
            "It 00350: l_u = 3.48166686e-05 loss = 3.48166686e-05\n",
            "It 00400: l_u = 3.01988930e-05 loss = 3.01988930e-05\n",
            "It 00450: l_u = 2.71447916e-05 loss = 2.71447916e-05\n",
            "It 00500: l_u = 2.48731121e-05 loss = 2.48731121e-05\n",
            "It 00550: l_u = 2.30337118e-05 loss = 2.30337118e-05\n",
            "It 00600: l_u = 2.14686552e-05 loss = 2.14686552e-05\n",
            "It 00650: l_u = 2.01000275e-05 loss = 2.01000275e-05\n",
            "It 00700: l_u = 1.88840095e-05 loss = 1.88840095e-05\n",
            "It 00750: l_u = 1.77926577e-05 loss = 1.77926577e-05\n",
            "It 00800: l_u = 1.68061270e-05 loss = 1.68061270e-05\n",
            "It 00850: l_u = 1.59094743e-05 loss = 1.59094743e-05\n",
            "It 00900: l_u = 1.50909564e-05 loss = 1.50909564e-05\n",
            "It 00950: l_u = 1.43411571e-05 loss = 1.43411571e-05\n",
            "It 01000: l_u = 1.36523568e-05 loss = 1.36523568e-05\n",
            "It 01050: l_u = 1.30176559e-05 loss = 1.30176559e-05\n",
            "It 01100: l_u = 1.24316839e-05 loss = 1.24316839e-05\n",
            "It 01150: l_u = 1.18893895e-05 loss = 1.18893895e-05\n",
            "It 01200: l_u = 1.13866745e-05 loss = 1.13866745e-05\n",
            "It 01250: l_u = 1.09197281e-05 loss = 1.09197281e-05\n",
            "It 01300: l_u = 1.04852352e-05 loss = 1.04852352e-05\n",
            "It 01350: l_u = 1.00801344e-05 loss = 1.00801344e-05\n",
            "It 01400: l_u = 9.70202382e-06 loss = 9.70202382e-06\n",
            "It 01450: l_u = 9.34848413e-06 loss = 9.34848413e-06\n",
            "It 01500: l_u = 9.01728708e-06 loss = 9.01728708e-06\n",
            "It 01550: l_u = 8.70669828e-06 loss = 8.70669828e-06\n",
            "It 01600: l_u = 8.41489145e-06 loss = 8.41489145e-06\n",
            "It 01650: l_u = 8.14044688e-06 loss = 8.14044688e-06\n",
            "It 01700: l_u = 7.88182570e-06 loss = 7.88182570e-06\n",
            "It 01750: l_u = 7.63791468e-06 loss = 7.63791468e-06\n",
            "It 01800: l_u = 7.40759197e-06 loss = 7.40759197e-06\n",
            "It 01850: l_u = 7.18973661e-06 loss = 7.18973661e-06\n",
            "It 01900: l_u = 6.98350959e-06 loss = 6.98350959e-06\n",
            "It 01950: l_u = 6.78803144e-06 loss = 6.78803144e-06\n",
            "It 02000: l_u = 6.60259775e-06 loss = 6.60259775e-06\n",
            "It 02050: l_u = 6.42642271e-06 loss = 6.42642271e-06\n",
            "It 02100: l_u = 6.25895154e-06 loss = 6.25895154e-06\n",
            "It 02150: l_u = 6.09962763e-06 loss = 6.09962763e-06\n",
            "It 02200: l_u = 5.94789253e-06 loss = 5.94789253e-06\n",
            "It 02250: l_u = 5.80318510e-06 loss = 5.80318510e-06\n",
            "It 02300: l_u = 5.66524841e-06 loss = 5.66524841e-06\n",
            "It 02350: l_u = 5.53346626e-06 loss = 5.53346626e-06\n",
            "It 02400: l_u = 5.40761357e-06 loss = 5.40761357e-06\n",
            "It 02450: l_u = 5.28724149e-06 loss = 5.28724149e-06\n",
            "It 02500: l_u = 5.17214903e-06 loss = 5.17214903e-06\n",
            "It 02550: l_u = 5.06194874e-06 loss = 5.06194874e-06\n",
            "It 02600: l_u = 4.95634822e-06 loss = 4.95634822e-06\n",
            "It 02650: l_u = 4.85516193e-06 loss = 4.85516193e-06\n",
            "It 02700: l_u = 4.75801562e-06 loss = 4.75801562e-06\n",
            "It 02750: l_u = 4.66486017e-06 loss = 4.66486017e-06\n",
            "It 02800: l_u = 4.57544638e-06 loss = 4.57544638e-06\n",
            "It 02850: l_u = 4.48945366e-06 loss = 4.48945366e-06\n",
            "It 02900: l_u = 4.40686517e-06 loss = 4.40686517e-06\n",
            "It 02950: l_u = 4.32744355e-06 loss = 4.32744355e-06\n",
            "It 03000: l_u = 4.25103008e-06 loss = 4.25103008e-06\n",
            "It 03050: l_u = 4.21262757e-06 loss = 4.21262757e-06\n",
            "It 03100: l_u = 4.17454748e-06 loss = 4.17454748e-06\n",
            "It 03150: l_u = 4.13608541e-06 loss = 4.13608541e-06\n",
            "It 03200: l_u = 4.09718132e-06 loss = 4.09718132e-06\n",
            "It 03250: l_u = 4.05791479e-06 loss = 4.05791479e-06\n",
            "It 03300: l_u = 4.01822763e-06 loss = 4.01822763e-06\n",
            "It 03350: l_u = 3.97816302e-06 loss = 3.97816302e-06\n",
            "It 03400: l_u = 3.93773689e-06 loss = 3.93773689e-06\n",
            "It 03450: l_u = 3.89699926e-06 loss = 3.89699926e-06\n",
            "It 03500: l_u = 3.85587646e-06 loss = 3.85587646e-06\n",
            "It 03550: l_u = 3.81443465e-06 loss = 3.81443465e-06\n",
            "It 03600: l_u = 3.77270635e-06 loss = 3.77270635e-06\n",
            "It 03650: l_u = 3.73067519e-06 loss = 3.73067519e-06\n",
            "It 03700: l_u = 3.68840983e-06 loss = 3.68840983e-06\n",
            "It 03750: l_u = 3.64578091e-06 loss = 3.64578091e-06\n",
            "It 03800: l_u = 3.60290960e-06 loss = 3.60290960e-06\n",
            "It 03850: l_u = 3.55989778e-06 loss = 3.55989778e-06\n",
            "It 03900: l_u = 3.51663061e-06 loss = 3.51663061e-06\n",
            "It 03950: l_u = 3.47313562e-06 loss = 3.47313562e-06\n",
            "It 04000: l_u = 3.42949897e-06 loss = 3.42949897e-06\n",
            "It 04050: l_u = 3.38567384e-06 loss = 3.38567384e-06\n",
            "It 04100: l_u = 3.34176320e-06 loss = 3.34176320e-06\n",
            "It 04150: l_u = 3.29767090e-06 loss = 3.29767090e-06\n",
            "It 04200: l_u = 3.25353039e-06 loss = 3.25353039e-06\n",
            "It 04250: l_u = 3.20923232e-06 loss = 3.20923232e-06\n",
            "It 04300: l_u = 3.16495107e-06 loss = 3.16495107e-06\n",
            "It 04350: l_u = 3.12057819e-06 loss = 3.12057819e-06\n",
            "It 04400: l_u = 3.07621872e-06 loss = 3.07621872e-06\n",
            "It 04450: l_u = 3.03183060e-06 loss = 3.03183060e-06\n",
            "It 04500: l_u = 2.98746113e-06 loss = 2.98746113e-06\n",
            "It 04550: l_u = 2.94307847e-06 loss = 2.94307847e-06\n",
            "It 04600: l_u = 2.89881791e-06 loss = 2.89881791e-06\n",
            "It 04650: l_u = 2.85467650e-06 loss = 2.85467650e-06\n",
            "It 04700: l_u = 2.81063262e-06 loss = 2.81063262e-06\n",
            "It 04750: l_u = 2.76665514e-06 loss = 2.76665514e-06\n",
            "It 04800: l_u = 2.72284456e-06 loss = 2.72284456e-06\n",
            "It 04850: l_u = 2.72815942e-06 loss = 2.72815942e-06\n",
            "It 04900: l_u = 3.71531473e-06 loss = 3.71531473e-06\n",
            "It 04950: l_u = 2.60649472e-06 loss = 2.60649472e-06\n",
            "It 05000: l_u = 2.55645591e-06 loss = 2.55645591e-06\n",
            "It 05050: l_u = 2.51439610e-06 loss = 2.51439610e-06\n",
            "It 05100: l_u = 2.47274488e-06 loss = 2.47274488e-06\n",
            "It 05150: l_u = 8.86670296e-06 loss = 8.86670296e-06\n",
            "It 05200: l_u = 2.49867298e-06 loss = 2.49867298e-06\n",
            "It 05250: l_u = 2.36017718e-06 loss = 2.36017718e-06\n",
            "It 05300: l_u = 2.31969580e-06 loss = 2.31969580e-06\n",
            "It 05350: l_u = 2.28048111e-06 loss = 2.28048111e-06\n",
            "It 05400: l_u = 2.24158430e-06 loss = 2.24158430e-06\n",
            "It 05450: l_u = 8.27890181e-05 loss = 8.27890181e-05\n",
            "It 05500: l_u = 2.54167685e-06 loss = 2.54167685e-06\n",
            "It 05550: l_u = 2.13890507e-06 loss = 2.13890507e-06\n",
            "It 05600: l_u = 2.09823270e-06 loss = 2.09823270e-06\n",
            "It 05650: l_u = 2.06184086e-06 loss = 2.06184086e-06\n",
            "It 05700: l_u = 9.66734588e-05 loss = 9.66734588e-05\n",
            "It 05750: l_u = 2.04153434e-06 loss = 2.04153434e-06\n",
            "It 05800: l_u = 1.96397582e-06 loss = 1.96397582e-06\n",
            "It 05850: l_u = 1.92970992e-06 loss = 1.92970992e-06\n",
            "It 05900: l_u = 1.89595232e-06 loss = 1.89595232e-06\n",
            "It 05950: l_u = 3.81646851e-06 loss = 3.81646851e-06\n",
            "It 06000: l_u = 3.44542264e-06 loss = 3.44542264e-06\n",
            "It 06050: l_u = 1.81288738e-06 loss = 1.81288738e-06\n",
            "It 06100: l_u = 1.77517256e-06 loss = 1.77517256e-06\n",
            "It 06150: l_u = 1.74400373e-06 loss = 1.74400373e-06\n",
            "It 06200: l_u = 1.71393287e-06 loss = 1.71393287e-06\n",
            "It 06250: l_u = 1.71867623e-06 loss = 1.71867623e-06\n",
            "It 06300: l_u = 1.67691212e-06 loss = 1.67691212e-06\n",
            "It 06350: l_u = 1.63369555e-06 loss = 1.63369555e-06\n",
            "It 06400: l_u = 1.60487446e-06 loss = 1.60487446e-06\n",
            "It 06450: l_u = 1.57662726e-06 loss = 1.57662726e-06\n",
            "It 06500: l_u = 8.38158012e-05 loss = 8.38158012e-05\n",
            "It 06550: l_u = 2.49228333e-06 loss = 2.49228333e-06\n",
            "It 06600: l_u = 1.51123641e-06 loss = 1.51123641e-06\n",
            "It 06650: l_u = 1.47838978e-06 loss = 1.47838978e-06\n",
            "It 06700: l_u = 1.45234128e-06 loss = 1.45234128e-06\n",
            "It 06750: l_u = 1.42684826e-06 loss = 1.42684826e-06\n",
            "It 06800: l_u = 7.53346249e-05 loss = 7.53346249e-05\n",
            "It 06850: l_u = 2.00100817e-06 loss = 2.00100817e-06\n",
            "It 06900: l_u = 1.36657343e-06 loss = 1.36657343e-06\n",
            "It 06950: l_u = 1.33850460e-06 loss = 1.33850460e-06\n",
            "It 07000: l_u = 1.31482250e-06 loss = 1.31482250e-06\n",
            "It 07050: l_u = 1.30291983e-06 loss = 1.30291983e-06\n",
            "It 07100: l_u = 1.29121429e-06 loss = 1.29121429e-06\n",
            "It 07150: l_u = 1.27947385e-06 loss = 1.27947385e-06\n",
            "It 07200: l_u = 1.26767679e-06 loss = 1.26767679e-06\n",
            "It 07250: l_u = 1.25582380e-06 loss = 1.25582380e-06\n",
            "It 07300: l_u = 1.24391966e-06 loss = 1.24391966e-06\n",
            "It 07350: l_u = 1.23196605e-06 loss = 1.23196605e-06\n",
            "It 07400: l_u = 1.21993764e-06 loss = 1.21993764e-06\n",
            "It 07450: l_u = 1.20786717e-06 loss = 1.20786717e-06\n",
            "It 07500: l_u = 1.19570757e-06 loss = 1.19570757e-06\n",
            "It 07550: l_u = 1.18349499e-06 loss = 1.18349499e-06\n",
            "It 07600: l_u = 1.17123136e-06 loss = 1.17123136e-06\n",
            "It 07650: l_u = 1.15889975e-06 loss = 1.15889975e-06\n",
            "It 07700: l_u = 1.14648628e-06 loss = 1.14648628e-06\n",
            "It 07750: l_u = 1.13400552e-06 loss = 1.13400552e-06\n",
            "It 07800: l_u = 1.12150587e-06 loss = 1.12150587e-06\n",
            "It 07850: l_u = 1.10891926e-06 loss = 1.10891926e-06\n",
            "It 07900: l_u = 1.09625762e-06 loss = 1.09625762e-06\n",
            "It 07950: l_u = 1.08359473e-06 loss = 1.08359473e-06\n",
            "It 08000: l_u = 1.07081235e-06 loss = 1.07081235e-06\n",
            "It 08050: l_u = 1.05804827e-06 loss = 1.05804827e-06\n",
            "It 08100: l_u = 1.04516528e-06 loss = 1.04516528e-06\n",
            "It 08150: l_u = 1.03224147e-06 loss = 1.03224147e-06\n",
            "It 08200: l_u = 1.01931232e-06 loss = 1.01931232e-06\n",
            "It 08250: l_u = 1.00628381e-06 loss = 1.00628381e-06\n",
            "It 08300: l_u = 9.93259846e-07 loss = 9.93259846e-07\n",
            "It 08350: l_u = 9.80198820e-07 loss = 9.80198820e-07\n",
            "It 08400: l_u = 9.67058554e-07 loss = 9.67058554e-07\n",
            "It 08450: l_u = 9.54101210e-07 loss = 9.54101210e-07\n",
            "It 08500: l_u = 3.71919350e-06 loss = 3.71919350e-06\n",
            "It 08550: l_u = 9.48900151e-07 loss = 9.48900151e-07\n",
            "It 08600: l_u = 9.16757699e-07 loss = 9.16757699e-07\n",
            "It 08650: l_u = 9.04211049e-07 loss = 9.04211049e-07\n",
            "It 08700: l_u = 8.91743070e-07 loss = 8.91743070e-07\n",
            "It 08750: l_u = 1.09170824e-05 loss = 1.09170824e-05\n",
            "It 08800: l_u = 1.09600182e-06 loss = 1.09600182e-06\n",
            "It 08850: l_u = 8.56747022e-07 loss = 8.56747022e-07\n",
            "It 08900: l_u = 8.44318549e-07 loss = 8.44318549e-07\n",
            "It 08950: l_u = 8.32504270e-07 loss = 8.32504270e-07\n",
            "It 09000: l_u = 8.20852790e-07 loss = 8.20852790e-07\n",
            "It 09050: l_u = 1.21470168e-06 loss = 1.21470168e-06\n",
            "It 09100: l_u = 8.20296691e-07 loss = 8.20296691e-07\n",
            "It 09150: l_u = 7.87133558e-07 loss = 7.87133558e-07\n",
            "It 09200: l_u = 7.84546216e-07 loss = 7.84546216e-07\n",
            "Timeout is reached. Time elapsed: 20.000226736068726 seconds\n",
            "\n",
            "\n",
            "Finding PDE parameters.\n",
            "It 09250: loss = 5.83444216e-06 lambda = [5.566647  5.5736256]\n",
            "It 09300: loss = 5.83444216e-06 lambda = [2.3166528 2.368149 ]\n",
            "It 09350: loss = 5.83444216e-06 lambda = [0.45812207 0.60717034]\n",
            "It 09400: loss = 5.83444216e-06 lambda = [-0.4527592  -0.15949781]\n",
            "It 09450: loss = 5.83444216e-06 lambda = [-0.87894446 -0.4113027 ]\n",
            "It 09500: loss = 5.83444216e-06 lambda = [-1.1137922  -0.45539904]\n",
            "It 09550: loss = 5.83444216e-06 lambda = [-1.2889599 -0.4314821]\n",
            "It 09600: loss = 5.83444216e-06 lambda = [-1.4494272 -0.3888661]\n",
            "It 09650: loss = 5.83444216e-06 lambda = [-1.6069355  -0.34188882]\n",
            "It 09700: loss = 5.83444216e-06 lambda = [-1.763349   -0.29422653]\n",
            "It 09750: loss = 5.83444216e-06 lambda = [-1.91826    -0.24685487]\n",
            "It 09800: loss = 5.83444216e-06 lambda = [-2.0709429  -0.20014107]\n",
            "It 09850: loss = 5.83444216e-06 lambda = [-2.2207525  -0.15430379]\n",
            "It 09900: loss = 5.83444216e-06 lambda = [-2.3671722  -0.10950373]\n",
            "It 09950: loss = 5.83444216e-06 lambda = [-2.5098033  -0.06586319]\n",
            "It 10000: loss = 5.83444216e-06 lambda = [-2.6483455  -0.02347385]\n",
            "It 10050: loss = 5.83444216e-06 lambda = [-2.782584    0.01759826]\n",
            "It 10100: loss = 5.83444216e-06 lambda = [-2.9123719   0.05730838]\n",
            "It 10150: loss = 5.83444216e-06 lambda = [-3.0376203   0.09562942]\n",
            "It 10200: loss = 5.83444216e-06 lambda = [-3.1582885   0.13254896]\n",
            "It 10250: loss = 5.83444216e-06 lambda = [-3.2743757   0.16806678]\n",
            "It 10300: loss = 5.83444216e-06 lambda = [-3.3859143   0.20219265]\n",
            "It 10350: loss = 5.83444216e-06 lambda = [-3.4929624  0.2349446]\n",
            "It 10400: loss = 5.83444216e-06 lambda = [-3.5956006   0.26634705]\n",
            "It 10450: loss = 5.83444216e-06 lambda = [-3.6939251  0.2964297]\n",
            "It 10500: loss = 5.83444216e-06 lambda = [-3.7880454   0.32522607]\n",
            "It 10550: loss = 5.83444216e-06 lambda = [-3.8780835   0.35277322]\n",
            "It 10600: loss = 5.83444216e-06 lambda = [-3.964166    0.37911007]\n",
            "It 10650: loss = 5.83444216e-06 lambda = [-4.046427   0.4042774]\n",
            "It 10700: loss = 5.83444216e-06 lambda = [-4.125004    0.42831695]\n",
            "It 10750: loss = 5.83444216e-06 lambda = [-4.200029    0.45127136]\n",
            "It 10800: loss = 5.83444216e-06 lambda = [-4.271644   0.4731817]\n",
            "It 10850: loss = 5.83444216e-06 lambda = [-4.3399854   0.49409056]\n",
            "It 10900: loss = 5.83444216e-06 lambda = [-4.4051895   0.51403934]\n",
            "It 10950: loss = 5.83444216e-06 lambda = [-4.4673905  0.5330693]\n",
            "It 11000: loss = 5.83444216e-06 lambda = [-4.5267196  0.5512201]\n",
            "It 11050: loss = 5.83444216e-06 lambda = [-4.5833006  0.568531 ]\n",
            "It 11100: loss = 5.83444216e-06 lambda = [-4.63726    0.5850394]\n",
            "It 11150: loss = 5.83444216e-06 lambda = [-4.6887174  0.6007822]\n",
            "It 11200: loss = 5.83444216e-06 lambda = [-4.737788   0.6157949]\n",
            "It 11250: loss = 5.83444216e-06 lambda = [-4.784584   0.6301116]\n",
            "It 11300: loss = 5.83444216e-06 lambda = [-4.829212    0.64376515]\n",
            "It 11350: loss = 5.83444216e-06 lambda = [-4.871776  0.656787]\n",
            "It 11400: loss = 5.83444216e-06 lambda = [-4.912375   0.6692077]\n",
            "Timeout is reached. Time elapsed: 80.02099323272705 seconds\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration: 5 Initial lambda: [0.0, 0.0]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Adam\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: l_u = 4.42384511e-01 loss = 4.42384511e-01\n",
            "It 00050: l_u = 9.98417139e-02 loss = 9.98417139e-02\n",
            "It 00100: l_u = 9.01343941e-04 loss = 9.01343941e-04\n",
            "It 00150: l_u = 1.54625115e-04 loss = 1.54625115e-04\n",
            "It 00200: l_u = 7.24473139e-05 loss = 7.24473139e-05\n",
            "It 00250: l_u = 4.34321482e-05 loss = 4.34321482e-05\n",
            "It 00300: l_u = 1.65966034e-04 loss = 1.65966034e-04\n",
            "It 00350: l_u = 3.07441260e-05 loss = 3.07441260e-05\n",
            "It 00400: l_u = 2.33369337e-05 loss = 2.33369337e-05\n",
            "It 00450: l_u = 1.97021782e-05 loss = 1.97021782e-05\n",
            "It 00500: l_u = 1.70527128e-05 loss = 1.70527128e-05\n",
            "It 00550: l_u = 1.49567832e-05 loss = 1.49567832e-05\n",
            "It 00600: l_u = 1.32241939e-05 loss = 1.32241939e-05\n",
            "It 00650: l_u = 1.17523959e-05 loss = 1.17523959e-05\n",
            "It 00700: l_u = 1.04802784e-05 loss = 1.04802784e-05\n",
            "It 00750: l_u = 9.36986908e-06 loss = 9.36986908e-06\n",
            "It 00800: l_u = 8.39567201e-06 loss = 8.39567201e-06\n",
            "It 00850: l_u = 7.53972972e-06 loss = 7.53972972e-06\n",
            "It 00900: l_u = 6.78808237e-06 loss = 6.78808237e-06\n",
            "It 00950: l_u = 6.12899839e-06 loss = 6.12899839e-06\n",
            "It 01000: l_u = 5.55203405e-06 loss = 5.55203405e-06\n",
            "It 01050: l_u = 5.04737272e-06 loss = 5.04737272e-06\n",
            "It 01100: l_u = 4.60590581e-06 loss = 4.60590581e-06\n",
            "It 01150: l_u = 4.21936147e-06 loss = 4.21936147e-06\n",
            "It 01200: l_u = 3.88014496e-06 loss = 3.88014496e-06\n",
            "It 01250: l_u = 3.58164993e-06 loss = 3.58164993e-06\n",
            "It 01300: l_u = 3.31794649e-06 loss = 3.31794649e-06\n",
            "It 01350: l_u = 3.08408789e-06 loss = 3.08408789e-06\n",
            "It 01400: l_u = 2.87586727e-06 loss = 2.87586727e-06\n",
            "It 01450: l_u = 2.68973417e-06 loss = 2.68973417e-06\n",
            "It 01500: l_u = 2.52258815e-06 loss = 2.52258815e-06\n",
            "It 01550: l_u = 2.37190852e-06 loss = 2.37190852e-06\n",
            "It 01600: l_u = 2.23557822e-06 loss = 2.23557822e-06\n",
            "It 01650: l_u = 2.11190240e-06 loss = 2.11190240e-06\n",
            "It 01700: l_u = 1.99919441e-06 loss = 1.99919441e-06\n",
            "It 01750: l_u = 1.89632021e-06 loss = 1.89632021e-06\n",
            "It 01800: l_u = 1.80202278e-06 loss = 1.80202278e-06\n",
            "It 01850: l_u = 1.71549186e-06 loss = 1.71549186e-06\n",
            "It 01900: l_u = 1.63575021e-06 loss = 1.63575021e-06\n",
            "It 01950: l_u = 1.56218744e-06 loss = 1.56218744e-06\n",
            "It 02000: l_u = 1.49414575e-06 loss = 1.49414575e-06\n",
            "It 02050: l_u = 1.43104819e-06 loss = 1.43104819e-06\n",
            "It 02100: l_u = 1.37248639e-06 loss = 1.37248639e-06\n",
            "It 02150: l_u = 1.31795809e-06 loss = 1.31795809e-06\n",
            "It 02200: l_u = 1.26714610e-06 loss = 1.26714610e-06\n",
            "It 02250: l_u = 1.21973312e-06 loss = 1.21973312e-06\n",
            "It 02300: l_u = 1.17536013e-06 loss = 1.17536013e-06\n",
            "It 02350: l_u = 1.13376257e-06 loss = 1.13376257e-06\n",
            "It 02400: l_u = 1.09476139e-06 loss = 1.09476139e-06\n",
            "It 02450: l_u = 1.05809966e-06 loss = 1.05809966e-06\n",
            "It 02500: l_u = 1.02361946e-06 loss = 1.02361946e-06\n",
            "It 02550: l_u = 9.91116849e-07 loss = 9.91116849e-07\n",
            "It 02600: l_u = 9.60485181e-07 loss = 9.60485181e-07\n",
            "It 02650: l_u = 9.31546992e-07 loss = 9.31546992e-07\n",
            "It 02700: l_u = 9.04184162e-07 loss = 9.04184162e-07\n",
            "It 02750: l_u = 8.78286073e-07 loss = 8.78286073e-07\n",
            "It 02800: l_u = 8.53755012e-07 loss = 8.53755012e-07\n",
            "It 02850: l_u = 8.30487409e-07 loss = 8.30487409e-07\n",
            "It 02900: l_u = 8.08383106e-07 loss = 8.08383106e-07\n",
            "It 02950: l_u = 7.87410897e-07 loss = 7.87410897e-07\n",
            "It 03000: l_u = 7.67430663e-07 loss = 7.67430663e-07\n",
            "It 03050: l_u = 7.57496537e-07 loss = 7.57496537e-07\n",
            "It 03100: l_u = 7.47707759e-07 loss = 7.47707759e-07\n",
            "It 03150: l_u = 7.37854407e-07 loss = 7.37854407e-07\n",
            "It 03200: l_u = 7.27971383e-07 loss = 7.27971383e-07\n",
            "It 03250: l_u = 7.18022761e-07 loss = 7.18022761e-07\n",
            "It 03300: l_u = 7.08056120e-07 loss = 7.08056120e-07\n",
            "It 03350: l_u = 6.98044687e-07 loss = 6.98044687e-07\n",
            "It 03400: l_u = 6.87994486e-07 loss = 6.87994486e-07\n",
            "It 03450: l_u = 6.77923595e-07 loss = 6.77923595e-07\n",
            "It 03500: l_u = 6.67857194e-07 loss = 6.67857194e-07\n",
            "It 03550: l_u = 6.57756118e-07 loss = 6.57756118e-07\n",
            "It 03600: l_u = 6.47665217e-07 loss = 6.47665217e-07\n",
            "It 03650: l_u = 6.37554251e-07 loss = 6.37554251e-07\n",
            "It 03700: l_u = 6.27450277e-07 loss = 6.27450277e-07\n",
            "It 03750: l_u = 6.17333797e-07 loss = 6.17333797e-07\n",
            "It 03800: l_u = 6.07245227e-07 loss = 6.07245227e-07\n",
            "It 03850: l_u = 5.97160920e-07 loss = 5.97160920e-07\n",
            "It 03900: l_u = 5.87108673e-07 loss = 5.87108673e-07\n",
            "It 03950: l_u = 5.77088372e-07 loss = 5.77088372e-07\n",
            "It 04000: l_u = 5.67077564e-07 loss = 5.67077564e-07\n",
            "It 04050: l_u = 5.57117176e-07 loss = 5.57117176e-07\n",
            "It 04100: l_u = 5.47209993e-07 loss = 5.47209993e-07\n",
            "It 04150: l_u = 5.37323558e-07 loss = 5.37323558e-07\n",
            "It 04200: l_u = 5.27487146e-07 loss = 5.27487146e-07\n",
            "It 04250: l_u = 5.17738670e-07 loss = 5.17738670e-07\n",
            "It 04300: l_u = 5.08019639e-07 loss = 5.08019639e-07\n",
            "It 04350: l_u = 4.98395650e-07 loss = 4.98395650e-07\n",
            "It 04400: l_u = 4.88826629e-07 loss = 4.88826629e-07\n",
            "It 04450: l_u = 4.79317748e-07 loss = 4.79317748e-07\n",
            "It 04500: l_u = 4.69918888e-07 loss = 4.69918888e-07\n",
            "It 04550: l_u = 4.60611687e-07 loss = 4.60611687e-07\n",
            "It 04600: l_u = 4.51361643e-07 loss = 4.51361643e-07\n",
            "It 04650: l_u = 4.42234608e-07 loss = 4.42234608e-07\n",
            "It 04700: l_u = 4.33195993e-07 loss = 4.33195993e-07\n",
            "It 04750: l_u = 4.24259071e-07 loss = 4.24259071e-07\n",
            "It 04800: l_u = 4.15435210e-07 loss = 4.15435210e-07\n",
            "It 04850: l_u = 4.06725206e-07 loss = 4.06725206e-07\n",
            "It 04900: l_u = 4.08491786e-07 loss = 4.08491786e-07\n",
            "It 04950: l_u = 3.87363480e-06 loss = 3.87363480e-06\n",
            "It 05000: l_u = 3.84337170e-07 loss = 3.84337170e-07\n",
            "It 05050: l_u = 3.73686703e-07 loss = 3.73686703e-07\n",
            "It 05100: l_u = 3.65761991e-07 loss = 3.65761991e-07\n",
            "It 05150: l_u = 3.58083355e-07 loss = 3.58083355e-07\n",
            "It 05200: l_u = 3.50582297e-07 loss = 3.50582297e-07\n",
            "It 05250: l_u = 1.08118009e-04 loss = 1.08118009e-04\n",
            "It 05300: l_u = 5.12267945e-07 loss = 5.12267945e-07\n",
            "It 05350: l_u = 3.30361416e-07 loss = 3.30361416e-07\n",
            "It 05400: l_u = 3.22564802e-07 loss = 3.22564802e-07\n",
            "It 05450: l_u = 3.15786309e-07 loss = 3.15786309e-07\n",
            "It 05500: l_u = 3.09273275e-07 loss = 3.09273275e-07\n",
            "It 05550: l_u = 3.06202566e-07 loss = 3.06202566e-07\n",
            "It 05600: l_u = 5.99930388e-07 loss = 5.99930388e-07\n",
            "It 05650: l_u = 2.98094676e-07 loss = 2.98094676e-07\n",
            "It 05700: l_u = 2.85646053e-07 loss = 2.85646053e-07\n",
            "It 05750: l_u = 2.79491019e-07 loss = 2.79491019e-07\n",
            "It 05800: l_u = 2.73879380e-07 loss = 2.73879380e-07\n",
            "It 05850: l_u = 6.42232044e-05 loss = 6.42232044e-05\n",
            "It 05900: l_u = 6.14507144e-07 loss = 6.14507144e-07\n",
            "It 05950: l_u = 2.60938947e-07 loss = 2.60938947e-07\n",
            "It 06000: l_u = 2.53680923e-07 loss = 2.53680923e-07\n",
            "It 06050: l_u = 2.48693624e-07 loss = 2.48693624e-07\n",
            "It 06100: l_u = 1.64000585e-06 loss = 1.64000585e-06\n",
            "It 06150: l_u = 2.96017504e-07 loss = 2.96017504e-07\n",
            "It 06200: l_u = 2.48920287e-07 loss = 2.48920287e-07\n",
            "It 06250: l_u = 2.32073020e-07 loss = 2.32073020e-07\n",
            "It 06300: l_u = 2.27434029e-07 loss = 2.27434029e-07\n",
            "It 06350: l_u = 2.23169195e-07 loss = 2.23169195e-07\n",
            "It 06400: l_u = 2.25025730e-07 loss = 2.25025730e-07\n",
            "It 06450: l_u = 8.47069623e-06 loss = 8.47069623e-06\n",
            "It 06500: l_u = 2.29488734e-07 loss = 2.29488734e-07\n",
            "It 06550: l_u = 2.11307437e-07 loss = 2.11307437e-07\n",
            "It 06600: l_u = 2.06676347e-07 loss = 2.06676347e-07\n",
            "It 06650: l_u = 2.02820914e-07 loss = 2.02820914e-07\n",
            "It 06700: l_u = 1.99208529e-07 loss = 1.99208529e-07\n",
            "It 06750: l_u = 4.03733247e-05 loss = 4.03733247e-05\n",
            "It 06800: l_u = 8.89514183e-07 loss = 8.89514183e-07\n",
            "It 06850: l_u = 1.71114971e-06 loss = 1.71114971e-06\n",
            "It 06900: l_u = 7.87136230e-07 loss = 7.87136230e-07\n",
            "It 06950: l_u = 1.98119920e-07 loss = 1.98119920e-07\n",
            "It 07000: l_u = 2.20047423e-06 loss = 2.20047423e-06\n",
            "It 07050: l_u = 1.97807623e-07 loss = 1.97807623e-07\n",
            "It 07100: l_u = 1.79558214e-07 loss = 1.79558214e-07\n",
            "It 07150: l_u = 1.78032579e-07 loss = 1.78032579e-07\n",
            "It 07200: l_u = 1.76579078e-07 loss = 1.76579078e-07\n",
            "It 07250: l_u = 1.75137160e-07 loss = 1.75137160e-07\n",
            "It 07300: l_u = 1.73712891e-07 loss = 1.73712891e-07\n",
            "It 07350: l_u = 1.72298442e-07 loss = 1.72298442e-07\n",
            "It 07400: l_u = 1.70901885e-07 loss = 1.70901885e-07\n",
            "It 07450: l_u = 1.69516738e-07 loss = 1.69516738e-07\n",
            "It 07500: l_u = 1.68152511e-07 loss = 1.68152511e-07\n",
            "It 07550: l_u = 1.66794720e-07 loss = 1.66794720e-07\n",
            "It 07600: l_u = 1.65451510e-07 loss = 1.65451510e-07\n",
            "It 07650: l_u = 1.64123463e-07 loss = 1.64123463e-07\n",
            "It 07700: l_u = 1.62804781e-07 loss = 1.62804781e-07\n",
            "It 07750: l_u = 1.61500338e-07 loss = 1.61500338e-07\n",
            "It 07800: l_u = 1.60210021e-07 loss = 1.60210021e-07\n",
            "It 07850: l_u = 1.58918169e-07 loss = 1.58918169e-07\n",
            "It 07900: l_u = 1.57652835e-07 loss = 1.57652835e-07\n",
            "It 07950: l_u = 1.56392574e-07 loss = 1.56392574e-07\n",
            "It 08000: l_u = 1.55145329e-07 loss = 1.55145329e-07\n",
            "It 08050: l_u = 1.53903855e-07 loss = 1.53903855e-07\n",
            "It 08100: l_u = 1.52678211e-07 loss = 1.52678211e-07\n",
            "It 08150: l_u = 1.51447153e-07 loss = 1.51447153e-07\n",
            "It 08200: l_u = 1.50242670e-07 loss = 1.50242670e-07\n",
            "It 08250: l_u = 1.49027613e-07 loss = 1.49027613e-07\n",
            "It 08300: l_u = 1.47829894e-07 loss = 1.47829894e-07\n",
            "It 08350: l_u = 1.46652511e-07 loss = 1.46652511e-07\n",
            "It 08400: l_u = 2.01317206e-07 loss = 2.01317206e-07\n",
            "It 08450: l_u = 3.43394305e-07 loss = 3.43394305e-07\n",
            "It 08500: l_u = 1.46210624e-07 loss = 1.46210624e-07\n",
            "It 08550: l_u = 1.42508654e-07 loss = 1.42508654e-07\n",
            "It 08600: l_u = 1.41342980e-07 loss = 1.41342980e-07\n",
            "It 08650: l_u = 2.44219024e-07 loss = 2.44219024e-07\n",
            "It 08700: l_u = 4.81282996e-07 loss = 4.81282996e-07\n",
            "It 08750: l_u = 3.03192934e-07 loss = 3.03192934e-07\n",
            "It 08800: l_u = 1.40838679e-07 loss = 1.40838679e-07\n",
            "It 08850: l_u = 1.06553580e-06 loss = 1.06553580e-06\n",
            "It 08900: l_u = 1.49513852e-07 loss = 1.49513852e-07\n",
            "It 08950: l_u = 1.34505697e-07 loss = 1.34505697e-07\n",
            "It 09000: l_u = 2.71906647e-05 loss = 2.71906647e-05\n",
            "It 09050: l_u = 1.90276864e-07 loss = 1.90276864e-07\n",
            "It 09100: l_u = 7.42136251e-07 loss = 7.42136251e-07\n",
            "It 09150: l_u = 2.46866932e-07 loss = 2.46866932e-07\n",
            "It 09200: l_u = 1.30923155e-07 loss = 1.30923155e-07\n",
            "It 09250: l_u = 4.95019367e-06 loss = 4.95019367e-06\n",
            "It 09300: l_u = 1.29110035e-07 loss = 1.29110035e-07\n",
            "It 09350: l_u = 1.27911548e-07 loss = 1.27911548e-07\n",
            "It 09400: l_u = 2.54817724e-06 loss = 2.54817724e-06\n",
            "It 09450: l_u = 2.78608780e-07 loss = 2.78608780e-07\n",
            "It 09500: l_u = 1.34537077e-05 loss = 1.34537077e-05\n",
            "It 09550: l_u = 1.73635456e-07 loss = 1.73635456e-07\n",
            "It 09600: l_u = 1.23933759e-07 loss = 1.23933759e-07\n",
            "It 09650: l_u = 8.99634870e-06 loss = 8.99634870e-06\n",
            "It 09700: l_u = 1.83601301e-07 loss = 1.83601301e-07\n",
            "It 09750: l_u = 1.22205876e-07 loss = 1.22205876e-07\n",
            "It 09800: l_u = 7.34650939e-06 loss = 7.34650939e-06\n",
            "It 09850: l_u = 7.97794598e-07 loss = 7.97794598e-07\n",
            "Timeout is reached. Time elapsed: 20.00156307220459 seconds\n",
            "\n",
            "\n",
            "Finding PDE parameters.\n",
            "It 09900: loss = 4.83970462e-06 lambda = [-1.8953985  -0.19770171]\n",
            "It 09950: loss = 4.83970462e-06 lambda = [-4.1533504   0.44772944]\n",
            "It 10000: loss = 4.83970462e-06 lambda = [-5.3794866  0.8110523]\n",
            "It 10050: loss = 4.83970462e-06 lambda = [-5.8308463   0.94726735]\n",
            "It 10100: loss = 4.83970462e-06 lambda = [-5.950908    0.98347205]\n",
            "It 10150: loss = 4.83970462e-06 lambda = [-5.974303   0.9905247]\n",
            "It 10200: loss = 4.83970462e-06 lambda = [-5.9775963  0.9915175]\n",
            "It 10250: loss = 4.83970462e-06 lambda = [-5.9779105  0.9916122]\n",
            "It 10300: loss = 4.83970462e-06 lambda = [-5.977924    0.99161625]\n",
            "It 10350: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 10400: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 10450: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 10500: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 10550: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 10600: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 10650: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 10700: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 10750: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 10800: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 10850: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 10900: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 10950: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 11000: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 11050: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 11100: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 11150: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 11200: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 11250: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 11300: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 11350: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 11400: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 11450: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 11500: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 11550: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 11600: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 11650: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 11700: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 11750: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 11800: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 11850: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 11900: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 11950: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "It 12000: loss = 4.83970462e-06 lambda = [-5.977924   0.9916163]\n",
            "Timeout is reached. Time elapsed: 80.00585055351257 seconds\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration: 5 Initial lambda: [1.0, -6.0]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Adam\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: l_u = 4.42384511e-01 loss = 4.42384511e-01\n",
            "It 00050: l_u = 9.98417512e-02 loss = 9.98417512e-02\n",
            "It 00100: l_u = 9.01343185e-04 loss = 9.01343185e-04\n",
            "It 00150: l_u = 1.54624940e-04 loss = 1.54624940e-04\n",
            "It 00200: l_u = 7.24475030e-05 loss = 7.24475030e-05\n",
            "It 00250: l_u = 4.34321737e-05 loss = 4.34321737e-05\n",
            "It 00300: l_u = 1.58230410e-04 loss = 1.58230410e-04\n",
            "It 00350: l_u = 3.05886206e-05 loss = 3.05886206e-05\n",
            "It 00400: l_u = 2.33278824e-05 loss = 2.33278824e-05\n",
            "It 00450: l_u = 1.96968595e-05 loss = 1.96968595e-05\n",
            "It 00500: l_u = 1.70483836e-05 loss = 1.70483836e-05\n",
            "It 00550: l_u = 1.49530424e-05 loss = 1.49530424e-05\n",
            "It 00600: l_u = 1.32206469e-05 loss = 1.32206469e-05\n",
            "It 00650: l_u = 1.17489853e-05 loss = 1.17489853e-05\n",
            "It 00700: l_u = 1.04770288e-05 loss = 1.04770288e-05\n",
            "It 00750: l_u = 9.36667766e-06 loss = 9.36667766e-06\n",
            "It 00800: l_u = 8.39257427e-06 loss = 8.39257427e-06\n",
            "It 00850: l_u = 7.53681843e-06 loss = 7.53681843e-06\n",
            "It 00900: l_u = 6.78542210e-06 loss = 6.78542210e-06\n",
            "It 00950: l_u = 6.12669783e-06 loss = 6.12669783e-06\n",
            "It 01000: l_u = 5.55001589e-06 loss = 5.55001589e-06\n",
            "It 01050: l_u = 5.04562240e-06 loss = 5.04562240e-06\n",
            "It 01100: l_u = 4.60442516e-06 loss = 4.60442516e-06\n",
            "It 01150: l_u = 4.21809227e-06 loss = 4.21809227e-06\n",
            "It 01200: l_u = 3.87903083e-06 loss = 3.87903083e-06\n",
            "It 01250: l_u = 3.58070247e-06 loss = 3.58070247e-06\n",
            "It 01300: l_u = 3.31717865e-06 loss = 3.31717865e-06\n",
            "It 01350: l_u = 3.08347103e-06 loss = 3.08347103e-06\n",
            "It 01400: l_u = 2.87536795e-06 loss = 2.87536795e-06\n",
            "It 01450: l_u = 2.68926192e-06 loss = 2.68926192e-06\n",
            "It 01500: l_u = 2.52217433e-06 loss = 2.52217433e-06\n",
            "It 01550: l_u = 2.37157337e-06 loss = 2.37157337e-06\n",
            "It 01600: l_u = 2.23534857e-06 loss = 2.23534857e-06\n",
            "It 01650: l_u = 2.11166298e-06 loss = 2.11166298e-06\n",
            "It 01700: l_u = 1.99902297e-06 loss = 1.99902297e-06\n",
            "It 01750: l_u = 1.89614491e-06 loss = 1.89614491e-06\n",
            "It 01800: l_u = 1.80194490e-06 loss = 1.80194490e-06\n",
            "It 01850: l_u = 1.71537351e-06 loss = 1.71537351e-06\n",
            "It 01900: l_u = 1.63568552e-06 loss = 1.63568552e-06\n",
            "It 01950: l_u = 1.56214332e-06 loss = 1.56214332e-06\n",
            "It 02000: l_u = 1.49414700e-06 loss = 1.49414700e-06\n",
            "It 02050: l_u = 1.43106308e-06 loss = 1.43106308e-06\n",
            "It 02100: l_u = 1.37249594e-06 loss = 1.37249594e-06\n",
            "It 02150: l_u = 1.31801642e-06 loss = 1.31801642e-06\n",
            "It 02200: l_u = 1.26723182e-06 loss = 1.26723182e-06\n",
            "It 02250: l_u = 1.21981043e-06 loss = 1.21981043e-06\n",
            "It 02300: l_u = 1.17544562e-06 loss = 1.17544562e-06\n",
            "It 02350: l_u = 1.13384795e-06 loss = 1.13384795e-06\n",
            "It 02400: l_u = 1.09487382e-06 loss = 1.09487382e-06\n",
            "It 02450: l_u = 1.05821471e-06 loss = 1.05821471e-06\n",
            "It 02500: l_u = 1.02372553e-06 loss = 1.02372553e-06\n",
            "It 02550: l_u = 9.91257480e-07 loss = 9.91257480e-07\n",
            "It 02600: l_u = 9.60598186e-07 loss = 9.60598186e-07\n",
            "It 02650: l_u = 9.31672275e-07 loss = 9.31672275e-07\n",
            "It 02700: l_u = 9.04319165e-07 loss = 9.04319165e-07\n",
            "It 02750: l_u = 8.78411129e-07 loss = 8.78411129e-07\n",
            "It 02800: l_u = 8.53892175e-07 loss = 8.53892175e-07\n",
            "It 02850: l_u = 8.30607064e-07 loss = 8.30607064e-07\n",
            "It 02900: l_u = 8.08543803e-07 loss = 8.08543803e-07\n",
            "It 02950: l_u = 7.87528847e-07 loss = 7.87528847e-07\n",
            "It 03000: l_u = 7.67582208e-07 loss = 7.67582208e-07\n",
            "It 03050: l_u = 7.57641999e-07 loss = 7.57641999e-07\n",
            "It 03100: l_u = 7.47842535e-07 loss = 7.47842535e-07\n",
            "It 03150: l_u = 7.37990376e-07 loss = 7.37990376e-07\n",
            "It 03200: l_u = 7.28125144e-07 loss = 7.28125144e-07\n",
            "It 03250: l_u = 7.18143497e-07 loss = 7.18143497e-07\n",
            "It 03300: l_u = 7.08171626e-07 loss = 7.08171626e-07\n",
            "It 03350: l_u = 6.98184579e-07 loss = 6.98184579e-07\n",
            "It 03400: l_u = 6.88155467e-07 loss = 6.88155467e-07\n",
            "It 03450: l_u = 6.78074002e-07 loss = 6.78074002e-07\n",
            "It 03500: l_u = 6.67983215e-07 loss = 6.67983215e-07\n",
            "It 03550: l_u = 6.57903570e-07 loss = 6.57903570e-07\n",
            "It 03600: l_u = 6.47804711e-07 loss = 6.47804711e-07\n",
            "It 03650: l_u = 6.37693404e-07 loss = 6.37693404e-07\n",
            "It 03700: l_u = 6.27593295e-07 loss = 6.27593295e-07\n",
            "It 03750: l_u = 6.17467833e-07 loss = 6.17467833e-07\n",
            "It 03800: l_u = 6.07376023e-07 loss = 6.07376023e-07\n",
            "It 03850: l_u = 5.97294559e-07 loss = 5.97294559e-07\n",
            "It 03900: l_u = 5.87244358e-07 loss = 5.87244358e-07\n",
            "It 03950: l_u = 5.77209278e-07 loss = 5.77209278e-07\n",
            "It 04000: l_u = 5.67202164e-07 loss = 5.67202164e-07\n",
            "It 04050: l_u = 5.57259796e-07 loss = 5.57259796e-07\n",
            "It 04100: l_u = 5.47318962e-07 loss = 5.47318962e-07\n",
            "It 04150: l_u = 5.37448500e-07 loss = 5.37448500e-07\n",
            "It 04200: l_u = 5.27624593e-07 loss = 5.27624593e-07\n",
            "It 04250: l_u = 5.17849230e-07 loss = 5.17849230e-07\n",
            "It 04300: l_u = 5.08151231e-07 loss = 5.08151231e-07\n",
            "It 04350: l_u = 4.98508825e-07 loss = 4.98508825e-07\n",
            "It 04400: l_u = 4.88934063e-07 loss = 4.88934063e-07\n",
            "It 04450: l_u = 4.79451330e-07 loss = 4.79451330e-07\n",
            "It 04500: l_u = 4.70050480e-07 loss = 4.70050480e-07\n",
            "It 04550: l_u = 4.60714688e-07 loss = 4.60714688e-07\n",
            "It 04600: l_u = 4.51497385e-07 loss = 4.51497385e-07\n",
            "It 04650: l_u = 4.42346334e-07 loss = 4.42346334e-07\n",
            "It 04700: l_u = 4.33309822e-07 loss = 4.33309822e-07\n",
            "It 04750: l_u = 4.24379380e-07 loss = 4.24379380e-07\n",
            "It 04800: l_u = 4.15542701e-07 loss = 4.15542701e-07\n",
            "It 04850: l_u = 4.06816326e-07 loss = 4.06816326e-07\n",
            "It 04900: l_u = 6.71075122e-06 loss = 6.71075122e-06\n",
            "It 04950: l_u = 6.92513538e-07 loss = 6.92513538e-07\n",
            "It 05000: l_u = 3.85323887e-07 loss = 3.85323887e-07\n",
            "It 05050: l_u = 3.73643473e-07 loss = 3.73643473e-07\n",
            "It 05100: l_u = 3.65755938e-07 loss = 3.65755938e-07\n",
            "It 05150: l_u = 3.58059339e-07 loss = 3.58059339e-07\n",
            "It 05200: l_u = 5.29377176e-05 loss = 5.29377176e-05\n",
            "It 05250: l_u = 3.66708321e-07 loss = 3.66708321e-07\n",
            "It 05300: l_u = 3.36932942e-07 loss = 3.36932942e-07\n",
            "It 05350: l_u = 3.29363587e-07 loss = 3.29363587e-07\n",
            "It 05400: l_u = 3.22445771e-07 loss = 3.22445771e-07\n",
            "It 05450: l_u = 3.15787787e-07 loss = 3.15787787e-07\n",
            "It 05500: l_u = 3.09312298e-07 loss = 3.09312298e-07\n",
            "It 05550: l_u = 2.08405745e-05 loss = 2.08405745e-05\n",
            "It 05600: l_u = 5.06426147e-07 loss = 5.06426147e-07\n",
            "It 05650: l_u = 2.91849631e-07 loss = 2.91849631e-07\n",
            "It 05700: l_u = 2.85294306e-07 loss = 2.85294306e-07\n",
            "It 05750: l_u = 2.79501137e-07 loss = 2.79501137e-07\n",
            "It 05800: l_u = 2.74672573e-07 loss = 2.74672573e-07\n",
            "It 05850: l_u = 3.66555787e-06 loss = 3.66555787e-06\n",
            "It 05900: l_u = 3.49404814e-07 loss = 3.49404814e-07\n",
            "It 05950: l_u = 2.59154348e-07 loss = 2.59154348e-07\n",
            "It 06000: l_u = 2.53638603e-07 loss = 2.53638603e-07\n",
            "It 06050: l_u = 2.48692970e-07 loss = 2.48692970e-07\n",
            "It 06100: l_u = 7.97614557e-05 loss = 7.97614557e-05\n",
            "It 06150: l_u = 5.70178315e-07 loss = 5.70178315e-07\n",
            "It 06200: l_u = 2.37622672e-07 loss = 2.37622672e-07\n",
            "It 06250: l_u = 2.31943943e-07 loss = 2.31943943e-07\n",
            "It 06300: l_u = 2.27433375e-07 loss = 2.27433375e-07\n",
            "It 06350: l_u = 2.23206087e-07 loss = 2.23206087e-07\n",
            "It 06400: l_u = 7.06994761e-05 loss = 7.06994761e-05\n",
            "It 06450: l_u = 7.80664834e-07 loss = 7.80664834e-07\n",
            "It 06500: l_u = 2.16803386e-07 loss = 2.16803386e-07\n",
            "It 06550: l_u = 2.09922206e-07 loss = 2.09922206e-07\n",
            "It 06600: l_u = 2.05900989e-07 loss = 2.05900989e-07\n",
            "It 06650: l_u = 2.02212192e-07 loss = 2.02212192e-07\n",
            "It 06700: l_u = 4.98339868e-05 loss = 4.98339868e-05\n",
            "It 06750: l_u = 5.69110284e-07 loss = 5.69110284e-07\n",
            "It 06800: l_u = 1.95111213e-07 loss = 1.95111213e-07\n",
            "It 06850: l_u = 1.90822362e-07 loss = 1.90822362e-07\n",
            "It 06900: l_u = 1.90059268e-07 loss = 1.90059268e-07\n",
            "It 06950: l_u = 4.95810264e-06 loss = 4.95810264e-06\n",
            "It 07000: l_u = 2.20127177e-07 loss = 2.20127177e-07\n",
            "It 07050: l_u = 1.84426355e-07 loss = 1.84426355e-07\n",
            "It 07100: l_u = 1.82415562e-07 loss = 1.82415562e-07\n",
            "It 07150: l_u = 1.80623587e-07 loss = 1.80623587e-07\n",
            "It 07200: l_u = 1.78931955e-07 loss = 1.78931955e-07\n",
            "It 07250: l_u = 1.77293330e-07 loss = 1.77293330e-07\n",
            "It 07300: l_u = 1.75686040e-07 loss = 1.75686040e-07\n",
            "It 07350: l_u = 1.74131216e-07 loss = 1.74131216e-07\n",
            "It 07400: l_u = 1.72583526e-07 loss = 1.72583526e-07\n",
            "It 07450: l_u = 1.71074134e-07 loss = 1.71074134e-07\n",
            "It 07500: l_u = 1.69584027e-07 loss = 1.69584027e-07\n",
            "It 07550: l_u = 1.68123719e-07 loss = 1.68123719e-07\n",
            "It 07600: l_u = 1.66689091e-07 loss = 1.66689091e-07\n",
            "It 07650: l_u = 1.65268659e-07 loss = 1.65268659e-07\n",
            "It 07700: l_u = 1.63871519e-07 loss = 1.63871519e-07\n",
            "It 07750: l_u = 1.62495041e-07 loss = 1.62495041e-07\n",
            "It 07800: l_u = 1.61132647e-07 loss = 1.61132647e-07\n",
            "It 07850: l_u = 1.59801132e-07 loss = 1.59801132e-07\n",
            "It 07900: l_u = 1.58477249e-07 loss = 1.58477249e-07\n",
            "It 07950: l_u = 1.57180310e-07 loss = 1.57180310e-07\n",
            "It 08000: l_u = 1.55887847e-07 loss = 1.55887847e-07\n",
            "It 08050: l_u = 1.54632374e-07 loss = 1.54632374e-07\n",
            "It 08100: l_u = 1.53373335e-07 loss = 1.53373335e-07\n",
            "It 08150: l_u = 1.52135399e-07 loss = 1.52135399e-07\n",
            "It 08200: l_u = 1.50913266e-07 loss = 1.50913266e-07\n",
            "It 08250: l_u = 1.49700668e-07 loss = 1.49700668e-07\n",
            "It 08300: l_u = 1.48497421e-07 loss = 1.48497421e-07\n",
            "It 08350: l_u = 1.47309464e-07 loss = 1.47309464e-07\n",
            "It 08400: l_u = 1.46134866e-07 loss = 1.46134866e-07\n",
            "It 08450: l_u = 1.44963067e-07 loss = 1.44963067e-07\n",
            "It 08500: l_u = 1.43815001e-07 loss = 1.43815001e-07\n",
            "It 08550: l_u = 9.43430496e-06 loss = 9.43430496e-06\n",
            "It 08600: l_u = 3.72385102e-07 loss = 3.72385102e-07\n",
            "It 08650: l_u = 1.42442445e-07 loss = 1.42442445e-07\n",
            "It 08700: l_u = 1.39810425e-07 loss = 1.39810425e-07\n",
            "It 08750: l_u = 1.38727899e-07 loss = 1.38727899e-07\n",
            "It 08800: l_u = 1.25708384e-05 loss = 1.25708384e-05\n",
            "It 08850: l_u = 2.08399484e-07 loss = 2.08399484e-07\n",
            "It 08900: l_u = 1.36402846e-07 loss = 1.36402846e-07\n",
            "It 08950: l_u = 1.35046591e-07 loss = 1.35046591e-07\n",
            "It 09000: l_u = 1.97560553e-07 loss = 1.97560553e-07\n",
            "It 09050: l_u = 7.25615280e-07 loss = 7.25615280e-07\n",
            "It 09100: l_u = 1.34660780e-07 loss = 1.34660780e-07\n",
            "It 09150: l_u = 1.31494218e-07 loss = 1.31494218e-07\n",
            "It 09200: l_u = 2.50136782e-05 loss = 2.50136782e-05\n",
            "It 09250: l_u = 1.37060127e-07 loss = 1.37060127e-07\n",
            "It 09300: l_u = 1.30116916e-07 loss = 1.30116916e-07\n",
            "It 09350: l_u = 1.28324345e-07 loss = 1.28324345e-07\n",
            "It 09400: l_u = 8.62224624e-07 loss = 8.62224624e-07\n",
            "It 09450: l_u = 3.87564342e-07 loss = 3.87564342e-07\n",
            "It 09500: l_u = 1.26726363e-07 loss = 1.26726363e-07\n",
            "It 09550: l_u = 1.25198085e-07 loss = 1.25198085e-07\n",
            "It 09600: l_u = 8.85035377e-07 loss = 8.85035377e-07\n",
            "It 09650: l_u = 1.41344316e-07 loss = 1.41344316e-07\n",
            "It 09700: l_u = 1.23791807e-07 loss = 1.23791807e-07\n",
            "It 09750: l_u = 1.22522948e-07 loss = 1.22522948e-07\n",
            "Timeout is reached. Time elapsed: 20.001647472381592 seconds\n",
            "\n",
            "\n",
            "Finding PDE parameters.\n",
            "It 09800: loss = 1.22191096e-07 lambda = [ 3.6915596 -3.246966 ]\n",
            "It 09850: loss = 1.22191096e-07 lambda = [ 4.0239224 -1.9677377]\n",
            "It 09900: loss = 1.22191096e-07 lambda = [ 2.8661726 -1.7201704]\n",
            "It 09950: loss = 1.22191096e-07 lambda = [ 1.7604916 -1.3739636]\n",
            "It 10000: loss = 1.22191096e-07 lambda = [ 0.67967457 -1.0432942 ]\n",
            "It 10050: loss = 1.22191096e-07 lambda = [-0.32509425 -0.73591155]\n",
            "It 10100: loss = 1.22191096e-07 lambda = [-1.2310622 -0.4588674]\n",
            "It 10150: loss = 1.22191096e-07 lambda = [-2.0293667  -0.21483436]\n",
            "It 10200: loss = 1.22191096e-07 lambda = [-2.7201414  -0.00372433]\n",
            "It 10250: loss = 1.22191096e-07 lambda = [-3.3090854   0.17623404]\n",
            "It 10300: loss = 1.22191096e-07 lambda = [-3.8050494   0.32776344]\n",
            "It 10350: loss = 1.22191096e-07 lambda = [-4.218371    0.45403334]\n",
            "It 10400: loss = 1.22191096e-07 lambda = [-4.5597587   0.55832136]\n",
            "It 10450: loss = 1.22191096e-07 lambda = [-4.839573    0.64379615]\n",
            "It 10500: loss = 1.22191096e-07 lambda = [-5.067399  0.713389]\n",
            "It 10550: loss = 1.22191096e-07 lambda = [-5.2518344   0.76972634]\n",
            "It 10600: loss = 1.22191096e-07 lambda = [-5.4004073   0.81510854]\n",
            "It 10650: loss = 1.22191096e-07 lambda = [-5.519578    0.85150963]\n",
            "It 10700: loss = 1.22191096e-07 lambda = [-5.6148124  0.8805992]\n",
            "It 10750: loss = 1.22191096e-07 lambda = [-5.6906796   0.90377253]\n",
            "It 10800: loss = 1.22191096e-07 lambda = [-5.7509565   0.92218417]\n",
            "It 10850: loss = 1.22191096e-07 lambda = [-5.79874    0.9367796]\n",
            "It 10900: loss = 1.22191096e-07 lambda = [-5.8365474  0.9483278]\n",
            "It 10950: loss = 1.22191096e-07 lambda = [-5.8664165  0.9574513]\n",
            "It 11000: loss = 1.22191096e-07 lambda = [-5.889984   0.9646501]\n",
            "It 11050: loss = 1.22191096e-07 lambda = [-5.9085617  0.9703244]\n",
            "It 11100: loss = 1.22191096e-07 lambda = [-5.9231973   0.97479486]\n",
            "It 11150: loss = 1.22191096e-07 lambda = [-5.93472    0.9783145]\n",
            "It 11200: loss = 1.22191096e-07 lambda = [-5.9437914  0.9810854]\n",
            "It 11250: loss = 1.22191096e-07 lambda = [-5.950931   0.9832661]\n",
            "It 11300: loss = 1.22191096e-07 lambda = [-5.95655    0.9849828]\n",
            "It 11350: loss = 1.22191096e-07 lambda = [-5.9609756  0.9863341]\n",
            "It 11400: loss = 1.22191096e-07 lambda = [-5.964462   0.9873991]\n",
            "It 11450: loss = 1.22191096e-07 lambda = [-5.967209   0.9882383]\n",
            "It 11500: loss = 1.22191096e-07 lambda = [-5.9693756  0.9889   ]\n",
            "It 11550: loss = 1.22191096e-07 lambda = [-5.971085   0.9894221]\n",
            "It 11600: loss = 1.22191096e-07 lambda = [-5.9724364   0.98983485]\n",
            "It 11650: loss = 1.22191096e-07 lambda = [-5.973505    0.99016124]\n",
            "It 11700: loss = 1.22191096e-07 lambda = [-5.97435     0.99041927]\n",
            "It 11750: loss = 1.22191096e-07 lambda = [-5.975019    0.99062383]\n",
            "It 11800: loss = 1.22191096e-07 lambda = [-5.97555   0.990786]\n",
            "It 11850: loss = 1.22191096e-07 lambda = [-5.975972    0.99091494]\n",
            "It 11900: loss = 1.22191096e-07 lambda = [-5.9763083  0.9910174]\n",
            "It 11950: loss = 1.22191096e-07 lambda = [-5.976575   0.9910992]\n",
            "Timeout is reached. Time elapsed: 80.02051448822021 seconds\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "Iteration: 5 Initial lambda: [10.0, 10.0]\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "Adam\n",
            "\n",
            "Initial Learning Rate = 1.00000e-01\n",
            "It 00000: l_u = 4.42384511e-01 loss = 4.42384511e-01\n",
            "It 00050: l_u = 9.98417288e-02 loss = 9.98417288e-02\n",
            "It 00100: l_u = 9.01345687e-04 loss = 9.01345687e-04\n",
            "It 00150: l_u = 1.54625232e-04 loss = 1.54625232e-04\n",
            "It 00200: l_u = 7.24473284e-05 loss = 7.24473284e-05\n",
            "It 00250: l_u = 4.34283429e-05 loss = 4.34283429e-05\n",
            "It 00300: l_u = 7.77119014e-04 loss = 7.77119014e-04\n",
            "It 00350: l_u = 3.10661562e-05 loss = 3.10661562e-05\n",
            "It 00400: l_u = 2.34526924e-05 loss = 2.34526924e-05\n",
            "It 00450: l_u = 1.97888203e-05 loss = 1.97888203e-05\n",
            "It 00500: l_u = 1.71299162e-05 loss = 1.71299162e-05\n",
            "It 00550: l_u = 1.50292053e-05 loss = 1.50292053e-05\n",
            "It 00600: l_u = 1.32943205e-05 loss = 1.32943205e-05\n",
            "It 00650: l_u = 1.18215521e-05 loss = 1.18215521e-05\n",
            "It 00700: l_u = 1.05485324e-05 loss = 1.05485324e-05\n",
            "It 00750: l_u = 9.43664691e-06 loss = 9.43664691e-06\n",
            "It 00800: l_u = 8.46000421e-06 loss = 8.46000421e-06\n",
            "It 00850: l_u = 7.60062721e-06 loss = 7.60062721e-06\n",
            "It 00900: l_u = 6.84454744e-06 loss = 6.84454744e-06\n",
            "It 00950: l_u = 6.18054946e-06 loss = 6.18054946e-06\n",
            "It 01000: l_u = 5.59841465e-06 loss = 5.59841465e-06\n",
            "It 01050: l_u = 5.08862195e-06 loss = 5.08862195e-06\n",
            "It 01100: l_u = 4.64247478e-06 loss = 4.64247478e-06\n",
            "It 01150: l_u = 4.25178450e-06 loss = 4.25178450e-06\n",
            "It 01200: l_u = 3.90903733e-06 loss = 3.90903733e-06\n",
            "It 01250: l_u = 3.60752324e-06 loss = 3.60752324e-06\n",
            "It 01300: l_u = 3.34135666e-06 loss = 3.34135666e-06\n",
            "It 01350: l_u = 3.10549922e-06 loss = 3.10549922e-06\n",
            "It 01400: l_u = 2.89558852e-06 loss = 2.89558852e-06\n",
            "It 01450: l_u = 2.70793316e-06 loss = 2.70793316e-06\n",
            "It 01500: l_u = 2.53952931e-06 loss = 2.53952931e-06\n",
            "It 01550: l_u = 2.38778648e-06 loss = 2.38778648e-06\n",
            "It 01600: l_u = 2.25049325e-06 loss = 2.25049325e-06\n",
            "It 01650: l_u = 2.12584746e-06 loss = 2.12584746e-06\n",
            "It 01700: l_u = 2.01230205e-06 loss = 2.01230205e-06\n",
            "It 01750: l_u = 1.90858032e-06 loss = 1.90858032e-06\n",
            "It 01800: l_u = 1.81355836e-06 loss = 1.81355836e-06\n",
            "It 01850: l_u = 1.72627006e-06 loss = 1.72627006e-06\n",
            "It 01900: l_u = 1.64584424e-06 loss = 1.64584424e-06\n",
            "It 01950: l_u = 1.57166301e-06 loss = 1.57166301e-06\n",
            "It 02000: l_u = 1.50300400e-06 loss = 1.50300400e-06\n",
            "It 02050: l_u = 1.43935085e-06 loss = 1.43935085e-06\n",
            "It 02100: l_u = 1.38023870e-06 loss = 1.38023870e-06\n",
            "It 02150: l_u = 1.32519517e-06 loss = 1.32519517e-06\n",
            "It 02200: l_u = 1.27393469e-06 loss = 1.27393469e-06\n",
            "It 02250: l_u = 1.22601909e-06 loss = 1.22601909e-06\n",
            "It 02300: l_u = 1.18125024e-06 loss = 1.18125024e-06\n",
            "It 02350: l_u = 1.13929570e-06 loss = 1.13929570e-06\n",
            "It 02400: l_u = 1.09994517e-06 loss = 1.09994517e-06\n",
            "It 02450: l_u = 1.06294635e-06 loss = 1.06294635e-06\n",
            "It 02500: l_u = 1.02818171e-06 loss = 1.02818171e-06\n",
            "It 02550: l_u = 9.95401820e-07 loss = 9.95401820e-07\n",
            "It 02600: l_u = 9.64537662e-07 loss = 9.64537662e-07\n",
            "It 02650: l_u = 9.35348908e-07 loss = 9.35348908e-07\n",
            "It 02700: l_u = 9.07770470e-07 loss = 9.07770470e-07\n",
            "It 02750: l_u = 8.81681615e-07 loss = 8.81681615e-07\n",
            "It 02800: l_u = 8.56982410e-07 loss = 8.56982410e-07\n",
            "It 02850: l_u = 8.33541321e-07 loss = 8.33541321e-07\n",
            "It 02900: l_u = 8.11306052e-07 loss = 8.11306052e-07\n",
            "It 02950: l_u = 7.90167235e-07 loss = 7.90167235e-07\n",
            "It 03000: l_u = 7.70082636e-07 loss = 7.70082636e-07\n",
            "It 03050: l_u = 7.60092348e-07 loss = 7.60092348e-07\n",
            "It 03100: l_u = 7.50236723e-07 loss = 7.50236723e-07\n",
            "It 03150: l_u = 7.40337896e-07 loss = 7.40337896e-07\n",
            "It 03200: l_u = 7.30375007e-07 loss = 7.30375007e-07\n",
            "It 03250: l_u = 7.20386026e-07 loss = 7.20386026e-07\n",
            "It 03300: l_u = 7.10358734e-07 loss = 7.10358734e-07\n",
            "It 03350: l_u = 7.00289149e-07 loss = 7.00289149e-07\n",
            "It 03400: l_u = 6.90195691e-07 loss = 6.90195691e-07\n",
            "It 03450: l_u = 6.80102914e-07 loss = 6.80102914e-07\n",
            "It 03500: l_u = 6.69971200e-07 loss = 6.69971200e-07\n",
            "It 03550: l_u = 6.59804812e-07 loss = 6.59804812e-07\n",
            "It 03600: l_u = 6.49649166e-07 loss = 6.49649166e-07\n",
            "It 03650: l_u = 6.39500342e-07 loss = 6.39500342e-07\n",
            "It 03700: l_u = 6.29345436e-07 loss = 6.29345436e-07\n",
            "It 03750: l_u = 6.19188654e-07 loss = 6.19188654e-07\n",
            "It 03800: l_u = 6.09060010e-07 loss = 6.09060010e-07\n",
            "It 03850: l_u = 5.98928807e-07 loss = 5.98928807e-07\n",
            "It 03900: l_u = 5.88852060e-07 loss = 5.88852060e-07\n",
            "It 03950: l_u = 5.78752747e-07 loss = 5.78752747e-07\n",
            "It 04000: l_u = 5.68716985e-07 loss = 5.68716985e-07\n",
            "It 04050: l_u = 5.58719250e-07 loss = 5.58719250e-07\n",
            "It 04100: l_u = 5.48769606e-07 loss = 5.48769606e-07\n",
            "It 04150: l_u = 5.38837980e-07 loss = 5.38837980e-07\n",
            "It 04200: l_u = 5.28971157e-07 loss = 5.28971157e-07\n",
            "It 04250: l_u = 5.19177547e-07 loss = 5.19177547e-07\n",
            "It 04300: l_u = 5.09448682e-07 loss = 5.09448682e-07\n",
            "It 04350: l_u = 4.99785699e-07 loss = 4.99785699e-07\n",
            "It 04400: l_u = 4.90161995e-07 loss = 4.90161995e-07\n",
            "It 04450: l_u = 4.80637027e-07 loss = 4.80637027e-07\n",
            "It 04500: l_u = 4.71201759e-07 loss = 4.71201759e-07\n",
            "It 04550: l_u = 4.61861248e-07 loss = 4.61861248e-07\n",
            "It 04600: l_u = 4.52580650e-07 loss = 4.52580650e-07\n",
            "It 04650: l_u = 4.43412773e-07 loss = 4.43412773e-07\n",
            "It 04700: l_u = 4.34331071e-07 loss = 4.34331071e-07\n",
            "It 04750: l_u = 4.25367091e-07 loss = 4.25367091e-07\n",
            "It 04800: l_u = 4.16511881e-07 loss = 4.16511881e-07\n",
            "It 04850: l_u = 4.07775985e-07 loss = 4.07775985e-07\n",
            "It 04900: l_u = 3.99531700e-07 loss = 3.99531700e-07\n",
            "It 04950: l_u = 1.08506792e-05 loss = 1.08506792e-05\n",
            "It 05000: l_u = 4.39870234e-07 loss = 4.39870234e-07\n",
            "It 05050: l_u = 3.74938452e-07 loss = 3.74938452e-07\n",
            "It 05100: l_u = 3.66434620e-07 loss = 3.66434620e-07\n",
            "It 05150: l_u = 3.58675948e-07 loss = 3.58675948e-07\n",
            "It 05200: l_u = 6.47994675e-05 loss = 6.47994675e-05\n",
            "It 05250: l_u = 8.55738904e-07 loss = 8.55738904e-07\n",
            "It 05300: l_u = 3.39441840e-07 loss = 3.39441840e-07\n",
            "It 05350: l_u = 3.29818164e-07 loss = 3.29818164e-07\n",
            "It 05400: l_u = 3.22866327e-07 loss = 3.22866327e-07\n",
            "It 05450: l_u = 3.16144707e-07 loss = 3.16144707e-07\n",
            "It 05500: l_u = 3.10176773e-07 loss = 3.10176773e-07\n",
            "It 05550: l_u = 1.84333601e-06 loss = 1.84333601e-06\n",
            "It 05600: l_u = 3.44039989e-07 loss = 3.44039989e-07\n",
            "It 05650: l_u = 2.91469973e-07 loss = 2.91469973e-07\n",
            "It 05700: l_u = 2.85330373e-07 loss = 2.85330373e-07\n",
            "It 05750: l_u = 2.79540046e-07 loss = 2.79540046e-07\n",
            "It 05800: l_u = 2.38367397e-06 loss = 2.38367397e-06\n",
            "It 05850: l_u = 2.80672083e-07 loss = 2.80672083e-07\n",
            "It 05900: l_u = 2.65135071e-07 loss = 2.65135071e-07\n",
            "It 05950: l_u = 2.58540780e-07 loss = 2.58540780e-07\n",
            "It 06000: l_u = 2.53404892e-07 loss = 2.53404892e-07\n",
            "It 06050: l_u = 1.20648430e-04 loss = 1.20648430e-04\n",
            "It 06100: l_u = 2.53022165e-07 loss = 2.53022165e-07\n",
            "It 06150: l_u = 2.40977073e-07 loss = 2.40977073e-07\n",
            "It 06200: l_u = 2.35619041e-07 loss = 2.35619041e-07\n",
            "It 06250: l_u = 2.31004236e-07 loss = 2.31004236e-07\n",
            "It 06300: l_u = 3.03161357e-07 loss = 3.03161357e-07\n",
            "It 06350: l_u = 3.85067733e-06 loss = 3.85067733e-06\n",
            "It 06400: l_u = 2.22286090e-07 loss = 2.22286090e-07\n",
            "It 06450: l_u = 2.16609735e-07 loss = 2.16609735e-07\n",
            "It 06500: l_u = 2.12332111e-07 loss = 2.12332111e-07\n",
            "It 06550: l_u = 2.08430549e-07 loss = 2.08430549e-07\n",
            "It 06600: l_u = 1.11727029e-04 loss = 1.11727029e-04\n",
            "It 06650: l_u = 7.76347747e-07 loss = 7.76347747e-07\n",
            "It 06700: l_u = 2.05464673e-07 loss = 2.05464673e-07\n",
            "It 06750: l_u = 1.96546551e-07 loss = 1.96546551e-07\n",
            "It 06800: l_u = 1.94319625e-07 loss = 1.94319625e-07\n",
            "It 06850: l_u = 3.75781769e-06 loss = 3.75781769e-06\n",
            "It 06900: l_u = 2.18690062e-07 loss = 2.18690062e-07\n",
            "It 06950: l_u = 1.35332232e-06 loss = 1.35332232e-06\n",
            "It 07000: l_u = 2.22700663e-07 loss = 2.22700663e-07\n",
            "It 07050: l_u = 1.82119905e-07 loss = 1.82119905e-07\n",
            "It 07100: l_u = 1.80218450e-07 loss = 1.80218450e-07\n",
            "It 07150: l_u = 1.78570843e-07 loss = 1.78570843e-07\n",
            "It 07200: l_u = 1.77001027e-07 loss = 1.77001027e-07\n",
            "It 07250: l_u = 1.75469609e-07 loss = 1.75469609e-07\n",
            "It 07300: l_u = 1.73959421e-07 loss = 1.73959421e-07\n",
            "It 07350: l_u = 1.72487347e-07 loss = 1.72487347e-07\n",
            "It 07400: l_u = 1.71037769e-07 loss = 1.71037769e-07\n",
            "It 07450: l_u = 1.69597485e-07 loss = 1.69597485e-07\n",
            "It 07500: l_u = 1.68179071e-07 loss = 1.68179071e-07\n",
            "It 07550: l_u = 1.66762689e-07 loss = 1.66762689e-07\n",
            "It 07600: l_u = 1.65386666e-07 loss = 1.65386666e-07\n",
            "It 07650: l_u = 1.64025323e-07 loss = 1.64025323e-07\n",
            "It 07700: l_u = 1.62662502e-07 loss = 1.62662502e-07\n",
            "It 07750: l_u = 1.61331315e-07 loss = 1.61331315e-07\n",
            "It 07800: l_u = 1.59993675e-07 loss = 1.59993675e-07\n",
            "It 07850: l_u = 1.58689019e-07 loss = 1.58689019e-07\n",
            "It 07900: l_u = 1.57404330e-07 loss = 1.57404330e-07\n",
            "It 07950: l_u = 1.56116414e-07 loss = 1.56116414e-07\n",
            "It 08000: l_u = 1.54830232e-07 loss = 1.54830232e-07\n",
            "It 08050: l_u = 1.53577119e-07 loss = 1.53577119e-07\n",
            "It 08100: l_u = 1.52340434e-07 loss = 1.52340434e-07\n",
            "It 08150: l_u = 1.51101844e-07 loss = 1.51101844e-07\n",
            "It 08200: l_u = 1.49882410e-07 loss = 1.49882410e-07\n",
            "It 08250: l_u = 1.48659950e-07 loss = 1.48659950e-07\n",
            "It 08300: l_u = 1.47453207e-07 loss = 1.47453207e-07\n",
            "It 08350: l_u = 1.46263943e-07 loss = 1.46263943e-07\n",
            "It 08400: l_u = 1.45077834e-07 loss = 1.45077834e-07\n",
            "It 08450: l_u = 1.43907556e-07 loss = 1.43907556e-07\n",
            "It 08500: l_u = 8.14914642e-07 loss = 8.14914642e-07\n",
            "It 08550: l_u = 7.80209064e-07 loss = 7.80209064e-07\n",
            "It 08600: l_u = 1.43868775e-07 loss = 1.43868775e-07\n",
            "It 08650: l_u = 1.40035340e-07 loss = 1.40035340e-07\n",
            "It 08700: l_u = 1.39108906e-07 loss = 1.39108906e-07\n",
            "It 08750: l_u = 1.66393534e-07 loss = 1.66393534e-07\n",
            "It 08800: l_u = 1.36982564e-07 loss = 1.36982564e-07\n",
            "It 08850: l_u = 2.79703399e-05 loss = 2.79703399e-05\n",
            "It 08900: l_u = 1.64487147e-07 loss = 1.64487147e-07\n",
            "It 08950: l_u = 1.34871598e-07 loss = 1.34871598e-07\n",
            "It 09000: l_u = 1.33020222e-07 loss = 1.33020222e-07\n",
            "It 09050: l_u = 2.18084915e-06 loss = 2.18084915e-06\n",
            "It 09100: l_u = 1.54605004e-07 loss = 1.54605004e-07\n",
            "Timeout is reached. Time elapsed: 20.00101900100708 seconds\n",
            "\n",
            "\n",
            "Finding PDE parameters.\n",
            "It 09150: loss = 1.69936115e-07 lambda = [7.9424515 7.9430604]\n",
            "It 09200: loss = 1.69936115e-07 lambda = [3.8813589 3.9025748]\n",
            "It 09250: loss = 1.69936115e-07 lambda = [1.313335  1.4027995]\n",
            "It 09300: loss = 1.69936115e-07 lambda = [-0.04441506  0.16549054]\n",
            "It 09350: loss = 1.69936115e-07 lambda = [-0.6821804  -0.31255862]\n",
            "It 09400: loss = 1.69936115e-07 lambda = [-0.9946437 -0.4422327]\n",
            "It 09450: loss = 1.69936115e-07 lambda = [-1.1922792  -0.44497558]\n",
            "It 09500: loss = 1.69936115e-07 lambda = [-1.3578529  -0.40953922]\n",
            "It 09550: loss = 1.69936115e-07 lambda = [-1.5164484  -0.36434284]\n",
            "It 09600: loss = 1.69936115e-07 lambda = [-1.6736063 -0.3170829]\n",
            "It 09650: loss = 1.69936115e-07 lambda = [-1.8296862 -0.2697014]\n",
            "It 09700: loss = 1.69936115e-07 lambda = [-1.9840307 -0.2227784]\n",
            "It 09750: loss = 1.69936115e-07 lambda = [-2.1359322  -0.17658919]\n",
            "It 09800: loss = 1.69936115e-07 lambda = [-2.2848024  -0.13132145]\n",
            "It 09850: loss = 1.69936115e-07 lambda = [-2.4301765  -0.08711703]\n",
            "It 09900: loss = 1.69936115e-07 lambda = [-2.5716968  -0.04408444]\n",
            "It 09950: loss = 1.69936115e-07 lambda = [-2.7090995e+00 -2.3043475e-03]\n",
            "It 10000: loss = 1.69936115e-07 lambda = [-2.842194    0.03816569]\n",
            "It 10050: loss = 1.69936115e-07 lambda = [-2.9708562   0.07728771]\n",
            "It 10100: loss = 1.69936115e-07 lambda = [-3.095014    0.11503993]\n",
            "It 10150: loss = 1.69936115e-07 lambda = [-3.21464     0.15141404]\n",
            "It 10200: loss = 1.69936115e-07 lambda = [-3.3297427  0.1864124]\n",
            "It 10250: loss = 1.69936115e-07 lambda = [-3.4403605   0.22004706]\n",
            "It 10300: loss = 1.69936115e-07 lambda = [-3.546557    0.25233722]\n",
            "It 10350: loss = 1.69936115e-07 lambda = [-3.648415    0.28330806]\n",
            "It 10400: loss = 1.69936115e-07 lambda = [-3.7460327   0.31298935]\n",
            "It 10450: loss = 1.69936115e-07 lambda = [-3.839519   0.3414146]\n",
            "It 10500: loss = 1.69936115e-07 lambda = [-3.9289942   0.36862013]\n",
            "It 10550: loss = 1.69936115e-07 lambda = [-4.0145845  0.3946442]\n",
            "It 10600: loss = 1.69936115e-07 lambda = [-4.0964193   0.41952667]\n",
            "It 10650: loss = 1.69936115e-07 lambda = [-4.174636  0.443308]\n",
            "It 10700: loss = 1.69936115e-07 lambda = [-4.249362    0.46602914]\n",
            "It 10750: loss = 1.69936115e-07 lambda = [-4.3207374  0.4877308]\n",
            "It 10800: loss = 1.69936115e-07 lambda = [-4.3888946  0.5084541]\n",
            "It 10850: loss = 1.69936115e-07 lambda = [-4.4539685   0.52823925]\n",
            "It 10900: loss = 1.69936115e-07 lambda = [-4.5160856  0.5471262]\n",
            "It 10950: loss = 1.69936115e-07 lambda = [-4.5753746   0.56515306]\n",
            "It 11000: loss = 1.69936115e-07 lambda = [-4.6319604   0.58235776]\n",
            "It 11050: loss = 1.69936115e-07 lambda = [-4.6859636  0.5987768]\n",
            "It 11100: loss = 1.69936115e-07 lambda = [-4.7374954   0.61444604]\n",
            "It 11150: loss = 1.69936115e-07 lambda = [-4.786679   0.6293991]\n",
            "It 11200: loss = 1.69936115e-07 lambda = [-4.8336153   0.64366996]\n",
            "It 11250: loss = 1.69936115e-07 lambda = [-4.8784113  0.6572901]\n",
            "Timeout is reached. Time elapsed: 80.004563331604 seconds\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_models = 5\n",
        "timeout = 100\n",
        "initial_lambdas = [[0.0, 0.0], [1.0, -6.0], [10.0, 10.0]]\n",
        "path = dir + \"/model weights/kdv_eqn_inv\"\n",
        "\n",
        "old_timeout = timeout\n",
        "models = [None] * n_models\n",
        "models_Adam = [None] * n_models\n",
        "hists_Adam = [None] * n_models\n",
        "hists_Adam = [None] * n_models\n",
        "lambds_Adam = [None] * n_models\n",
        "losses_Adam = [None] * n_models\n",
        "\n",
        "\n",
        "for i in range(n_models):\n",
        "  tf.random.set_seed(i)\n",
        "  models[i] = pinn.Hybrid_IdentificationNet(initial_lambda=0.0, lb=lb, ub=ub, **arch)\n",
        "  models[i].build((None, 2))\n",
        "\n",
        "  timeout = old_timeout\n",
        "  models_Adam[i] = []\n",
        "  hists_Adam[i] = []\n",
        "  lambds_Adam[i] = []\n",
        "  losses_Adam[i] = []\n",
        "\n",
        "  for j in range(len(initial_lambdas)):\n",
        "    print('{:s}\\nIteration: {:d} Initial lambda: {}\\n{:s}'.format(50*'-',i+1,initial_lambdas[j],50*'-'))\n",
        "    models_Adam[i].append(pinn.Hybrid_IdentificationNet(initial_lambda=initial_lambdas[j], lb=lb, ub=ub, **arch))\n",
        "    models_Adam[i][j].build((None, 2))\n",
        "\n",
        "    # Copy weights from the previous model instance to make every iteration comparable\n",
        "    models_Adam[i][j].set_weights(models[i].get_weights())\n",
        "\n",
        "    # Assigning initial lambda\n",
        "    models_Adam[i][j].initial_lambda = initial_lambdas[j]\n",
        "\n",
        "    # Prepare optimizer for learning given data\n",
        "    optim_Adam = tf.keras.optimizers.Adam(learning_rate=lr_comb)\n",
        "\n",
        "    # Prepare optimizer for minimizing PDE function and finding PDE parameters\n",
        "    optim_inv_Adam = tf.keras.optimizers.Adam(learning_rate=lr_comb)\n",
        "\n",
        "    # Initialize solver\n",
        "    solver_hybrid = pinn.Hybrid_IdentificationSolver(models_Adam[i][j], X_d, fun_r, get_r)\n",
        "\n",
        "    # Train models\n",
        "    print('\\n\\nAdam\\n')\n",
        "    solver_hybrid.solve(optim_Adam, optim_inv_Adam, get_r_param, X_param, u_param,\n",
        "                        timeout_param=timeout*0.8, timeout=timeout*0.2)\n",
        "\n",
        "    # Store evolution of lambdas and hists\n",
        "    hists_Adam[i].append(np.array([models_Adam[i][j].lambd_list, solver_hybrid.hist]))\n",
        "    lambds_Adam[i].append(np.stack(hists_Adam[i][j][0], axis=0))\n",
        "    losses_Adam[i].append(hists_Adam[i][j][1])\n",
        "\n",
        "    print('\\n\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BTSeERjdvec1",
        "outputId": "5c291aa2-f8f9-46a9-be15-9b2961cc40e0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-385cf4e0-9cef-47ac-bc57-705c2803e98f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Adam_0_1</th>\n",
              "      <th>Adam_0_2</th>\n",
              "      <th>Adam_1_1</th>\n",
              "      <th>Adam_1_2</th>\n",
              "      <th>Adam_2_1</th>\n",
              "      <th>Adam_2_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Attempt 1</th>\n",
              "      <td>-5.937997</td>\n",
              "      <td>0.975401</td>\n",
              "      <td>-5.925421</td>\n",
              "      <td>0.970517</td>\n",
              "      <td>-4.647446</td>\n",
              "      <td>0.585942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Attempt 2</th>\n",
              "      <td>-5.987469</td>\n",
              "      <td>0.993371</td>\n",
              "      <td>-6.012897</td>\n",
              "      <td>0.994178</td>\n",
              "      <td>-4.683389</td>\n",
              "      <td>0.598500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Attempt 3</th>\n",
              "      <td>-5.945903</td>\n",
              "      <td>0.983957</td>\n",
              "      <td>-5.942755</td>\n",
              "      <td>0.984458</td>\n",
              "      <td>-4.714555</td>\n",
              "      <td>0.609711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Attempt 4</th>\n",
              "      <td>-5.896593</td>\n",
              "      <td>0.969936</td>\n",
              "      <td>-5.909860</td>\n",
              "      <td>0.974265</td>\n",
              "      <td>-4.686334</td>\n",
              "      <td>0.600053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Attempt 5</th>\n",
              "      <td>-5.977924</td>\n",
              "      <td>0.991616</td>\n",
              "      <td>-5.974034</td>\n",
              "      <td>0.990323</td>\n",
              "      <td>-4.675133</td>\n",
              "      <td>0.595484</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-385cf4e0-9cef-47ac-bc57-705c2803e98f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-385cf4e0-9cef-47ac-bc57-705c2803e98f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-385cf4e0-9cef-47ac-bc57-705c2803e98f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           Adam_0_1  Adam_0_2  Adam_1_1  Adam_1_2  Adam_2_1  Adam_2_2\n",
              "Attempt 1 -5.937997  0.975401 -5.925421  0.970517 -4.647446  0.585942\n",
              "Attempt 2 -5.987469  0.993371 -6.012897  0.994178 -4.683389  0.598500\n",
              "Attempt 3 -5.945903  0.983957 -5.942755  0.984458 -4.714555  0.609711\n",
              "Attempt 4 -5.896593  0.969936 -5.909860  0.974265 -4.686334  0.600053\n",
              "Attempt 5 -5.977924  0.991616 -5.974034  0.990323 -4.675133  0.595484"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def lambdas(hists, iter_model, iter_init, lambd_init, N=500):\n",
        "  return sum(hists[iter_model][iter_init][-N:,lambd_init]) / N\n",
        "\n",
        "df = pd.DataFrame(columns = ['Adam_0_1','Adam_0_2',\n",
        "                             'Adam_1_1','Adam_1_2',\n",
        "                             'Adam_2_1','Adam_2_2'])\n",
        "\n",
        "for i in range(n_models):\n",
        "  x = []\n",
        "  for j in range(len(initial_lambdas)):\n",
        "    x.append(lambdas(lambds_Adam, i, j, 0))\n",
        "    x.append(lambdas(lambds_Adam, i, j, 1))\n",
        "\n",
        "  df.loc['Attempt '+str(i+1)] = x\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAD5XlRazqJm",
        "outputId": "90864415-62e0-413f-99d0-13f37ea51225"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adam_0_1   -5.949177\n",
            "Adam_0_2    0.982856\n",
            "Adam_1_1   -5.952993\n",
            "Adam_1_2    0.982748\n",
            "Adam_2_1   -4.681372\n",
            "Adam_2_2    0.597938\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(df.mean(axis=0))\n",
        "df.loc['Average'] = df.mean(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZFBGKyCzqJs",
        "outputId": "24a80957-287e-4c8a-b1a1-9aeb38ce31b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{lrrrrrr}\n",
            "\\hline\n",
            "           &   Adam\\_0\\_1 &   Adam\\_0\\_2 &   Adam\\_1\\_1 &   Adam\\_1\\_2 &   Adam\\_2\\_1 &   Adam\\_2\\_2 \\\\\n",
            "\\hline\n",
            " Attempt 1 &    -5.9380 &     0.9754 &    -5.9254 &     0.9705 &    -4.6474 &     0.5859 \\\\\n",
            " Attempt 2 &    -5.9875 &     0.9934 &    -6.0129 &     0.9942 &    -4.6834 &     0.5985 \\\\\n",
            " Attempt 3 &    -5.9459 &     0.9840 &    -5.9428 &     0.9845 &    -4.7146 &     0.6097 \\\\\n",
            " Attempt 4 &    -5.8966 &     0.9699 &    -5.9099 &     0.9743 &    -4.6863 &     0.6001 \\\\\n",
            " Attempt 5 &    -5.9779 &     0.9916 &    -5.9740 &     0.9903 &    -4.6751 &     0.5955 \\\\\n",
            " Average   &    -5.9492 &     0.9829 &    -5.9530 &     0.9827 &    -4.6814 &     0.5979 \\\\\n",
            "\\hline\n",
            "\\end{tabular}\n"
          ]
        }
      ],
      "source": [
        "print(tabulate(df.round(4), headers='keys', tablefmt='latex', floatfmt=\"#.4f\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NNBoandHoD2"
      },
      "source": [
        "### Exporting the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0B69WWAxFXhU"
      },
      "outputs": [],
      "source": [
        "path = dir + \"/model weights/kdv_eqn_inv_hybrid\"\n",
        "\n",
        "for i in range(n_models):\n",
        "  for j in range(len(initial_lambdas)):\n",
        "    models_Adam[i][j].save_weights(path+\"/model_Adam_hy_\"+str(i)+\"_\"+str(j)+\".h5\", 'h5')\n",
        "\n",
        "for i in range(n_models):\n",
        "  for j in range(len(initial_lambdas)):\n",
        "    np.savetxt(path+\"/loss and param/lambd_Adam_hy_\"+str(i)+\"_\"+str(j)+\".txt\", lambds_Adam[i][j])\n",
        "    np.savetxt(path+\"/loss and param/loss_Adam_hy_\"+str(i)+\"_\"+str(j)+\".txt\", losses_Adam[i][j])"
      ]
    }
  ]
}